commit 8f1fa541a61a07be3b83476ff1cacdd200753e7f
Author: Code Snapshot <snapshot@code.local>
Date:   Wed Oct 15 15:21:13 2025 +0200

    auto turn change snapshot

diff --git a/.code/agents/1501c673-31f6-4cd1-81cd-d488eaed9489/result.txt b/.code/agents/1501c673-31f6-4cd1-81cd-d488eaed9489/result.txt
new file mode 100644
index 00000000..a3577460
--- /dev/null
+++ b/.code/agents/1501c673-31f6-4cd1-81cd-d488eaed9489/result.txt
@@ -0,0 +1,54 @@
+
+Version:          Code 1.105.0 (03c265b1adee71ac88f833e065f7bb956b60550a, 2025-10-08T14:09:35.891Z)
+OS Version:       Windows_NT x64 10.0.26100
+CPUs:             AMD Ryzen 7 9800X3D 8-Core Processor            (16 x 4700)
+Memory (System):  31.16GB (13.22GB free)
+VM:               33%
+Screen Reader:    no
+Process Argv:     --new-window --crash-reporter-id fcce57d1-422a-4fd6-a752-e27888210d7c
+GPU Status:       2d_canvas:                              enabled
+                  direct_rendering_display_compositor:    disabled_off_ok
+                  gpu_compositing:                        enabled
+                  multiple_raster_threads:                enabled_on
+                  opengl:                                 enabled_on
+                  rasterization:                          enabled
+                  raw_draw:                               disabled_off_ok
+                  skia_graphite:                          disabled_off
+                  trees_in_viz:                           disabled_off
+                  video_decode:                           enabled
+                  video_encode:                           enabled
+                  vulkan:                                 disabled_off
+                  webgl:                                  enabled
+                  webgl2:                                 enabled
+                  webgpu:                                 enabled
+                  webnn:                                  disabled_off
+
+CPU %	Mem MB	   PID	Process
+    0	   149	  4128	code
+    0	    29	   276	   crashpad-handler
+    0	   191	 14164	window [1] (Welcome - CodexAccountant - Visual Studio Code)
+    0	    94	 14512	pty-host
+    0	   136	 15300	shared-process
+    0	    48	 21688	   utility-network-service
+    0	   103	 32400	file-watcher [1]
+    0	    85	 32660	   gpu-process
+    0	   579	 33164	extension-host [1]
+    0	    10	  2856	     c:\Users\sammu\.vscode\extensions\openai.chatgpt-0.5.19-win32-x64\bin\windows-x86_64\codex.exe app-server
+    0	     6	  7652	       C:\windows\system32\conhost.exe 0x4
+    0	    79	  6832	     C:\Users\sammu\AppData\Local\cloud-code\cloudcode_cli\cloudcode_cli\62c1f047\cloudcode_cli.exe duet -trace -logtostderr
+    0	     6	 30472	       C:\windows\system32\conhost.exe 0x4
+    0	    88	 14540	     electron-nodejs (eslintServer.js )
+    0	    27	 19252	     c:\Users\sammu\.vscode\extensions\rust-lang.rust-analyzer-0.3.2593-win32-x64\server\rust-analyzer.exe
+    0	     6	 11676	       C:\windows\system32\conhost.exe 0x4
+    0	    90	 31392	     "C:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\Code.exe" "c:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\json-language-features\server\dist\node\jsonServerMain" --node-ipc --clientProcessId=33164
+    0	    89	 32536	     "C:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\Code.exe" c:\Users\sammu\.vscode\extensions\google.geminicodeassist-2.53.0\agent\agent.mjs
+
+Workspace Stats: 
+|  Window (Welcome - CodexAccountant - Visual Studio Code)
+|    Folder (CodexAccountant): 3544 files
+|      File types: rs(462) txt(431) o(311) json(181) timestamp(163) d(142)
+|                  snap(107) rmeta(106) rlib(104) md(58)
+|      Conf files: github-actions(8) package.json(4) dockerfile(2)
+|                  devcontainer.json(1) launch.json(1) settings.json(1)
+|                  agents.md(1) tsconfig.json(1)
+|      Launch Configs: lldb(2)
diff --git a/.code/agents/18051/exec-call_QtXVWASWiIQkcpIX195bRqC7.txt b/.code/agents/18051/exec-call_QtXVWASWiIQkcpIX195bRqC7.txt
new file mode 100644
index 00000000..d7d20143
--- /dev/null
+++ b/.code/agents/18051/exec-call_QtXVWASWiIQkcpIX195bRqC7.txt
@@ -0,0 +1,17291 @@
+diff --git a/.codespellignore b/.codespellignore
+index 546a1927..2d19437c 100644
+--- a/.codespellignore
++++ b/.codespellignore
+@@ -1 +1 @@
+-iTerm
++iTerm
+diff --git a/.codespellrc b/.codespellrc
+index da831d89..7d57b0e6 100644
+--- a/.codespellrc
++++ b/.codespellrc
+@@ -1,6 +1,6 @@
+-[codespell]
+-# Ref: https://github.com/codespell-project/codespell#using-a-config-file
+-skip = .git*,vendor,*-lock.yaml,*.lock,.codespellrc,*test.ts,*.jsonl,frame*.txt
+-check-hidden = true
+-ignore-regex = ^\s*"image/\S+": ".*|\b(afterAll)\b
+-ignore-words-list = ratatui,ser
++[codespell]
++# Ref: https://github.com/codespell-project/codespell#using-a-config-file
++skip = .git*,vendor,*-lock.yaml,*.lock,.codespellrc,*test.ts,*.jsonl,frame*.txt
++check-hidden = true
++ignore-regex = ^\s*"image/\S+": ".*|\b(afterAll)\b
++ignore-words-list = ratatui,ser
+diff --git a/.devcontainer/Dockerfile b/.devcontainer/Dockerfile
+index d020dfe7..dbd37d12 100644
+--- a/.devcontainer/Dockerfile
++++ b/.devcontainer/Dockerfile
+@@ -1,27 +1,27 @@
+-FROM ubuntu:24.04
+-
+-ARG DEBIAN_FRONTEND=noninteractive
+-# enable 'universe' because musl-tools & clang live there
+-RUN apt-get update && \
+-    apt-get install -y --no-install-recommends \
+-    software-properties-common && \
+-    add-apt-repository --yes universe
+-
+-# now install build deps
+-RUN apt-get update && \
+-    apt-get install -y --no-install-recommends \
+-    build-essential curl git ca-certificates \
+-    pkg-config clang musl-tools libssl-dev just && \
+-    rm -rf /var/lib/apt/lists/*
+-
+-# Ubuntu 24.04 ships with user 'ubuntu' already created with UID 1000.
+-USER ubuntu
+-
+-# install Rust + musl target as dev user
+-RUN curl -sSf https://sh.rustup.rs | sh -s -- -y --profile minimal && \
+-    ~/.cargo/bin/rustup target add aarch64-unknown-linux-musl && \
+-    ~/.cargo/bin/rustup component add clippy rustfmt
+-
+-ENV PATH="/home/ubuntu/.cargo/bin:${PATH}"
+-
+-WORKDIR /workspace
++FROM ubuntu:24.04
++
++ARG DEBIAN_FRONTEND=noninteractive
++# enable 'universe' because musl-tools & clang live there
++RUN apt-get update && \
++    apt-get install -y --no-install-recommends \
++    software-properties-common && \
++    add-apt-repository --yes universe
++
++# now install build deps
++RUN apt-get update && \
++    apt-get install -y --no-install-recommends \
++    build-essential curl git ca-certificates \
++    pkg-config clang musl-tools libssl-dev just && \
++    rm -rf /var/lib/apt/lists/*
++
++# Ubuntu 24.04 ships with user 'ubuntu' already created with UID 1000.
++USER ubuntu
++
++# install Rust + musl target as dev user
++RUN curl -sSf https://sh.rustup.rs | sh -s -- -y --profile minimal && \
++    ~/.cargo/bin/rustup target add aarch64-unknown-linux-musl && \
++    ~/.cargo/bin/rustup component add clippy rustfmt
++
++ENV PATH="/home/ubuntu/.cargo/bin:${PATH}"
++
++WORKDIR /workspace
+diff --git a/.devcontainer/README.md b/.devcontainer/README.md
+index 58e4458a..7a92cac4 100644
+--- a/.devcontainer/README.md
++++ b/.devcontainer/README.md
+@@ -1,30 +1,30 @@
+-# Containerized Development
+-
+-We provide the following options to facilitate Codex development in a container. This is particularly useful for verifying the Linux build when working on a macOS host.
+-
+-## Docker
+-
+-To build the Docker image locally for x64 and then run it with the repo mounted under `/workspace`:
+-
+-```shell
+-CODEX_DOCKER_IMAGE_NAME=codex-linux-dev
+-docker build --platform=linux/amd64 -t "$CODEX_DOCKER_IMAGE_NAME" ./.devcontainer
+-docker run --platform=linux/amd64 --rm -it -e CARGO_TARGET_DIR=/workspace/codex-rs/target-amd64 -v "$PWD":/workspace -w /workspace/codex-rs "$CODEX_DOCKER_IMAGE_NAME"
+-```
+-
+-Note that `/workspace/target` will contain the binaries built for your host platform, so we include `-e CARGO_TARGET_DIR=/workspace/codex-rs/target-amd64` in the `docker run` command so that the binaries built inside your container are written to a separate directory.
+-
+-For arm64, specify `--platform=linux/amd64` instead for both `docker build` and `docker run`.
+-
+-Currently, the `Dockerfile` works for both x64 and arm64 Linux, though you need to run `rustup target add x86_64-unknown-linux-musl` yourself to install the musl toolchain for x64.
+-
+-## VS Code
+-
+-VS Code recognizes the `devcontainer.json` file and gives you the option to develop Codex in a container. Currently, `devcontainer.json` builds and runs the `arm64` flavor of the container.
+-
+-From the integrated terminal in VS Code, you can build either flavor of the `arm64` build (GNU or musl):
+-
+-```shell
+-cargo build --target aarch64-unknown-linux-musl
+-cargo build --target aarch64-unknown-linux-gnu
+-```
++# Containerized Development
++
++We provide the following options to facilitate Codex development in a container. This is particularly useful for verifying the Linux build when working on a macOS host.
++
++## Docker
++
++To build the Docker image locally for x64 and then run it with the repo mounted under `/workspace`:
++
++```shell
++CODEX_DOCKER_IMAGE_NAME=codex-linux-dev
++docker build --platform=linux/amd64 -t "$CODEX_DOCKER_IMAGE_NAME" ./.devcontainer
++docker run --platform=linux/amd64 --rm -it -e CARGO_TARGET_DIR=/workspace/codex-rs/target-amd64 -v "$PWD":/workspace -w /workspace/codex-rs "$CODEX_DOCKER_IMAGE_NAME"
++```
++
++Note that `/workspace/target` will contain the binaries built for your host platform, so we include `-e CARGO_TARGET_DIR=/workspace/codex-rs/target-amd64` in the `docker run` command so that the binaries built inside your container are written to a separate directory.
++
++For arm64, specify `--platform=linux/amd64` instead for both `docker build` and `docker run`.
++
++Currently, the `Dockerfile` works for both x64 and arm64 Linux, though you need to run `rustup target add x86_64-unknown-linux-musl` yourself to install the musl toolchain for x64.
++
++## VS Code
++
++VS Code recognizes the `devcontainer.json` file and gives you the option to develop Codex in a container. Currently, `devcontainer.json` builds and runs the `arm64` flavor of the container.
++
++From the integrated terminal in VS Code, you can build either flavor of the `arm64` build (GNU or musl):
++
++```shell
++cargo build --target aarch64-unknown-linux-musl
++cargo build --target aarch64-unknown-linux-gnu
++```
+diff --git a/.devcontainer/devcontainer.json b/.devcontainer/devcontainer.json
+index 1bed79c3..909a5f0c 100644
+--- a/.devcontainer/devcontainer.json
++++ b/.devcontainer/devcontainer.json
+@@ -1,27 +1,27 @@
+-{
+-  "name": "Codex",
+-  "build": {
+-    "dockerfile": "Dockerfile",
+-    "context": "..",
+-    "platform": "linux/arm64"
+-  },
+-
+-  /* Force VS Code to run the container as arm64 in
+-     case your host is x86 (or vice-versa). */
+-  "runArgs": ["--platform=linux/arm64"],
+-
+-  "containerEnv": {
+-    "RUST_BACKTRACE": "1",
+-    "CARGO_TARGET_DIR": "${containerWorkspaceFolder}/codex-rs/target-arm64"
+-  },
+-
+-  "remoteUser": "ubuntu",
+-  "customizations": {
+-    "vscode": {
+-      "settings": {
+-        "terminal.integrated.defaultProfile.linux": "bash"
+-      },
+-      "extensions": ["rust-lang.rust-analyzer", "tamasfe.even-better-toml"]
+-    }
+-  }
+-}
++{
++  "name": "Codex",
++  "build": {
++    "dockerfile": "Dockerfile",
++    "context": "..",
++    "platform": "linux/arm64"
++  },
++
++  /* Force VS Code to run the container as arm64 in
++     case your host is x86 (or vice-versa). */
++  "runArgs": ["--platform=linux/arm64"],
++
++  "containerEnv": {
++    "RUST_BACKTRACE": "1",
++    "CARGO_TARGET_DIR": "${containerWorkspaceFolder}/codex-rs/target-arm64"
++  },
++
++  "remoteUser": "ubuntu",
++  "customizations": {
++    "vscode": {
++      "settings": {
++        "terminal.integrated.defaultProfile.linux": "bash"
++      },
++      "extensions": ["rust-lang.rust-analyzer", "tamasfe.even-better-toml"]
++    }
++  }
++}
+diff --git a/.github/ISSUE_TEMPLATE/2-bug-report.yml b/.github/ISSUE_TEMPLATE/2-bug-report.yml
+index b2feedc8..d23caf9d 100644
+--- a/.github/ISSUE_TEMPLATE/2-bug-report.yml
++++ b/.github/ISSUE_TEMPLATE/2-bug-report.yml
+@@ -1,56 +1,56 @@
+-name: 🪲 Bug Report
+-description: Report an issue that should be fixed
+-labels:
+-  - bug
+-  - needs triage
+-body:
+-  - type: markdown
+-    attributes:
+-      value: |
+-        Thank you for submitting a bug report! It helps make Codex better for everyone.
+-
+-        If you need help or support using Codex, and are not reporting a bug, please post on [codex/discussions](https://github.com/openai/codex/discussions), where you can ask questions or engage with others on ideas for how to improve codex.
+-
+-        Make sure you are running the [latest](https://npmjs.com/package/@openai/codex) version of Codex CLI. The bug you are experiencing may already have been fixed.
+-
+-        Please try to include as much information as possible.
+-
+-  - type: input
+-    id: version
+-    attributes:
+-      label: What version of Codex is running?
+-      description: Copy the output of `codex --version`
+-  - type: input
+-    id: model
+-    attributes:
+-      label: Which model were you using?
+-      description: Like `gpt-4.1`, `o4-mini`, `o3`, etc.
+-  - type: input
+-    id: platform
+-    attributes:
+-      label: What platform is your computer?
+-      description: |
+-        For MacOS and Linux: copy the output of `uname -mprs`
+-        For Windows: copy the output of `"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { "x64" } else { "x86" })"` in the PowerShell console
+-  - type: textarea
+-    id: steps
+-    attributes:
+-      label: What steps can reproduce the bug?
+-      description: Explain the bug and provide a code snippet that can reproduce it.
+-    validations:
+-      required: true
+-  - type: textarea
+-    id: expected
+-    attributes:
+-      label: What is the expected behavior?
+-      description: If possible, please provide text instead of a screenshot.
+-  - type: textarea
+-    id: actual
+-    attributes:
+-      label: What do you see instead?
+-      description: If possible, please provide text instead of a screenshot.
+-  - type: textarea
+-    id: notes
+-    attributes:
+-      label: Additional information
+-      description: Is there anything else you think we should know?
++name: 🪲 Bug Report
++description: Report an issue that should be fixed
++labels:
++  - bug
++  - needs triage
++body:
++  - type: markdown
++    attributes:
++      value: |
++        Thank you for submitting a bug report! It helps make Codex better for everyone.
++
++        If you need help or support using Codex, and are not reporting a bug, please post on [codex/discussions](https://github.com/openai/codex/discussions), where you can ask questions or engage with others on ideas for how to improve codex.
++
++        Make sure you are running the [latest](https://npmjs.com/package/@openai/codex) version of Codex CLI. The bug you are experiencing may already have been fixed.
++
++        Please try to include as much information as possible.
++
++  - type: input
++    id: version
++    attributes:
++      label: What version of Codex is running?
++      description: Copy the output of `codex --version`
++  - type: input
++    id: model
++    attributes:
++      label: Which model were you using?
++      description: Like `gpt-4.1`, `o4-mini`, `o3`, etc.
++  - type: input
++    id: platform
++    attributes:
++      label: What platform is your computer?
++      description: |
++        For MacOS and Linux: copy the output of `uname -mprs`
++        For Windows: copy the output of `"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { "x64" } else { "x86" })"` in the PowerShell console
++  - type: textarea
++    id: steps
++    attributes:
++      label: What steps can reproduce the bug?
++      description: Explain the bug and provide a code snippet that can reproduce it.
++    validations:
++      required: true
++  - type: textarea
++    id: expected
++    attributes:
++      label: What is the expected behavior?
++      description: If possible, please provide text instead of a screenshot.
++  - type: textarea
++    id: actual
++    attributes:
++      label: What do you see instead?
++      description: If possible, please provide text instead of a screenshot.
++  - type: textarea
++    id: notes
++    attributes:
++      label: Additional information
++      description: Is there anything else you think we should know?
+diff --git a/.github/ISSUE_TEMPLATE/3-docs-issue.yml b/.github/ISSUE_TEMPLATE/3-docs-issue.yml
+index 456602e6..22c4e681 100644
+--- a/.github/ISSUE_TEMPLATE/3-docs-issue.yml
++++ b/.github/ISSUE_TEMPLATE/3-docs-issue.yml
+@@ -1,27 +1,27 @@
+-name: 📗 Documentation Issue
+-description: Tell us if there is missing or incorrect documentation
+-labels: [docs]
+-body:
+-  - type: markdown
+-    attributes:
+-      value: |
+-        Thank you for submitting a documentation request. It helps make Codex better.
+-  - type: dropdown
+-    attributes:
+-      label: What is the type of issue?
+-      multiple: true
+-      options:
+-        - Documentation is missing
+-        - Documentation is incorrect
+-        - Documentation is confusing
+-        - Example code is not working
+-        - Something else
+-  - type: textarea
+-    attributes:
+-      label: What is the issue?
+-    validations:
+-      required: true
+-  - type: textarea
+-    attributes:
+-      label: Where did you find it?
++name: 📗 Documentation Issue
++description: Tell us if there is missing or incorrect documentation
++labels: [docs]
++body:
++  - type: markdown
++    attributes:
++      value: |
++        Thank you for submitting a documentation request. It helps make Codex better.
++  - type: dropdown
++    attributes:
++      label: What is the type of issue?
++      multiple: true
++      options:
++        - Documentation is missing
++        - Documentation is incorrect
++        - Documentation is confusing
++        - Example code is not working
++        - Something else
++  - type: textarea
++    attributes:
++      label: What is the issue?
++    validations:
++      required: true
++  - type: textarea
++    attributes:
++      label: Where did you find it?
+       description: If possible, please provide the URL(s) where you found this issue.
+\ No newline at end of file
+diff --git a/.github/ISSUE_TEMPLATE/4-feature-request.yml b/.github/ISSUE_TEMPLATE/4-feature-request.yml
+index fea86edd..7cf6b1d2 100644
+--- a/.github/ISSUE_TEMPLATE/4-feature-request.yml
++++ b/.github/ISSUE_TEMPLATE/4-feature-request.yml
+@@ -1,25 +1,25 @@
+-name: 🎁 Feature Request
+-description: Propose a new feature for Codex
+-labels:
+-  - enhancement
+-body:
+-  - type: markdown
+-    attributes:
+-      value: |
+-        Is Codex missing a feature that you'd like to see? Feel free to propose it here.
+-
+-        Before you submit a feature:
+-        1. Search existing issues for similar features. If you find one, 👍 it rather than opening a new one.
+-        2. The Codex team will try to balance the varying needs of the community when prioritizing or rejecting new features. Not all features will be accepted. See [Contributing](https://github.com/openai/codex#contributing) for more details.
+-
+-  - type: textarea
+-    id: feature
+-    attributes:
+-      label: What feature would you like to see?
+-    validations:
+-      required: true
+-  - type: textarea
+-    id: notes
+-    attributes:
+-      label: Additional information
+-      description: Is there anything else you think we should know?
++name: 🎁 Feature Request
++description: Propose a new feature for Codex
++labels:
++  - enhancement
++body:
++  - type: markdown
++    attributes:
++      value: |
++        Is Codex missing a feature that you'd like to see? Feel free to propose it here.
++
++        Before you submit a feature:
++        1. Search existing issues for similar features. If you find one, 👍 it rather than opening a new one.
++        2. The Codex team will try to balance the varying needs of the community when prioritizing or rejecting new features. Not all features will be accepted. See [Contributing](https://github.com/openai/codex#contributing) for more details.
++
++  - type: textarea
++    id: feature
++    attributes:
++      label: What feature would you like to see?
++    validations:
++      required: true
++  - type: textarea
++    id: notes
++    attributes:
++      label: Additional information
++      description: Is there anything else you think we should know?
+diff --git a/.github/ISSUE_TEMPLATE/5-vs-code-extension.yml b/.github/ISSUE_TEMPLATE/5-vs-code-extension.yml
+index f2ba251a..0e7d5763 100644
+--- a/.github/ISSUE_TEMPLATE/5-vs-code-extension.yml
++++ b/.github/ISSUE_TEMPLATE/5-vs-code-extension.yml
+@@ -1,50 +1,50 @@
+-name: 🧑‍💻 VS Code Extension
+-description: Report an issue with the VS Code extension
+-labels:
+-  - extension
+-  - needs triage
+-body:
+-  - type: markdown
+-    attributes:
+-      value: |
+-        Before submitting a new issue, please search for existing issues to see if your issue has already been reported.
+-        If it has, please add a 👍 reaction (no need to leave a comment) to the existing issue instead of creating a new one.
+-
+-  - type: input
+-    id: version
+-    attributes:
+-      label: What version of the VS Code extension are you using?
+-  - type: input
+-    id: ide
+-    attributes:
+-      label: Which IDE are you using?
+-      description: Like `VS Code`, `Cursor`, `Windsurf`, etc.
+-  - type: input
+-    id: platform
+-    attributes:
+-      label: What platform is your computer?
+-      description: |
+-        For MacOS and Linux: copy the output of `uname -mprs`
+-        For Windows: copy the output of `"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { "x64" } else { "x86" })"` in the PowerShell console
+-  - type: textarea
+-    id: steps
+-    attributes:
+-      label: What steps can reproduce the bug?
+-      description: Explain the bug and provide a code snippet that can reproduce it.
+-    validations:
+-      required: true
+-  - type: textarea
+-    id: expected
+-    attributes:
+-      label: What is the expected behavior?
+-      description: If possible, please provide text instead of a screenshot.
+-  - type: textarea
+-    id: actual
+-    attributes:
+-      label: What do you see instead?
+-      description: If possible, please provide text instead of a screenshot.
+-  - type: textarea
+-    id: notes
+-    attributes:
+-      label: Additional information
+-      description: Is there anything else you think we should know?
++name: 🧑‍💻 VS Code Extension
++description: Report an issue with the VS Code extension
++labels:
++  - extension
++  - needs triage
++body:
++  - type: markdown
++    attributes:
++      value: |
++        Before submitting a new issue, please search for existing issues to see if your issue has already been reported.
++        If it has, please add a 👍 reaction (no need to leave a comment) to the existing issue instead of creating a new one.
++
++  - type: input
++    id: version
++    attributes:
++      label: What version of the VS Code extension are you using?
++  - type: input
++    id: ide
++    attributes:
++      label: Which IDE are you using?
++      description: Like `VS Code`, `Cursor`, `Windsurf`, etc.
++  - type: input
++    id: platform
++    attributes:
++      label: What platform is your computer?
++      description: |
++        For MacOS and Linux: copy the output of `uname -mprs`
++        For Windows: copy the output of `"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { "x64" } else { "x86" })"` in the PowerShell console
++  - type: textarea
++    id: steps
++    attributes:
++      label: What steps can reproduce the bug?
++      description: Explain the bug and provide a code snippet that can reproduce it.
++    validations:
++      required: true
++  - type: textarea
++    id: expected
++    attributes:
++      label: What is the expected behavior?
++      description: If possible, please provide text instead of a screenshot.
++  - type: textarea
++    id: actual
++    attributes:
++      label: What do you see instead?
++      description: If possible, please provide text instead of a screenshot.
++  - type: textarea
++    id: notes
++    attributes:
++      label: Additional information
++      description: Is there anything else you think we should know?
+diff --git a/.github/codex/home/config.toml b/.github/codex/home/config.toml
+index 8e800ca0..99991ce0 100644
+--- a/.github/codex/home/config.toml
++++ b/.github/codex/home/config.toml
+@@ -1,3 +1,3 @@
+-model = "gpt-5"
+-
+-# Consider setting [mcp_servers] here!
++model = "gpt-5"
++
++# Consider setting [mcp_servers] here!
+diff --git a/.github/codex/labels/codex-attempt.md b/.github/codex/labels/codex-attempt.md
+index b2a3e93a..dcad564c 100644
+--- a/.github/codex/labels/codex-attempt.md
++++ b/.github/codex/labels/codex-attempt.md
+@@ -1,9 +1,9 @@
+-Attempt to solve the reported issue.
+-
+-If a code change is required, create a new branch, commit the fix, and open a pull request that resolves the problem.
+-
+-Here is the original GitHub issue that triggered this run:
+-
+-### {CODEX_ACTION_ISSUE_TITLE}
+-
+-{CODEX_ACTION_ISSUE_BODY}
++Attempt to solve the reported issue.
++
++If a code change is required, create a new branch, commit the fix, and open a pull request that resolves the problem.
++
++Here is the original GitHub issue that triggered this run:
++
++### {CODEX_ACTION_ISSUE_TITLE}
++
++{CODEX_ACTION_ISSUE_BODY}
+diff --git a/.github/codex/labels/codex-review.md b/.github/codex/labels/codex-review.md
+index 7c6c14ad..efce6707 100644
+--- a/.github/codex/labels/codex-review.md
++++ b/.github/codex/labels/codex-review.md
+@@ -1,7 +1,7 @@
+-Review this PR and respond with a very concise final message, formatted in Markdown.
+-
+-There should be a summary of the changes (1-2 sentences) and a few bullet points if necessary.
+-
+-Then provide the **review** (1-2 sentences plus bullet points, friendly tone).
+-
+-{CODEX_ACTION_GITHUB_EVENT_PATH} contains the JSON that triggered this GitHub workflow. It contains the `base` and `head` refs that define this PR. Both refs are available locally.
++Review this PR and respond with a very concise final message, formatted in Markdown.
++
++There should be a summary of the changes (1-2 sentences) and a few bullet points if necessary.
++
++Then provide the **review** (1-2 sentences plus bullet points, friendly tone).
++
++{CODEX_ACTION_GITHUB_EVENT_PATH} contains the JSON that triggered this GitHub workflow. It contains the `base` and `head` refs that define this PR. Both refs are available locally.
+diff --git a/.github/codex/labels/codex-rust-review.md b/.github/codex/labels/codex-rust-review.md
+index ae82d272..0f74e80a 100644
+--- a/.github/codex/labels/codex-rust-review.md
++++ b/.github/codex/labels/codex-rust-review.md
+@@ -1,139 +1,139 @@
+-Review this PR and respond with a very concise final message, formatted in Markdown.
+-
+-There should be a summary of the changes (1-2 sentences) and a few bullet points if necessary.
+-
+-Then provide the **review** (1-2 sentences plus bullet points, friendly tone).
+-
+-Things to look out for when doing the review:
+-
+-## General Principles
+-
+-- **Make sure the pull request body explains the motivation behind the change.** If the author has failed to do this, call it out, and if you think you can deduce the motivation behind the change, propose copy.
+-- Ideally, the PR body also contains a small summary of the change. For small changes, the PR title may be sufficient.
+-- Each PR should ideally do one conceptual thing. For example, if a PR does a refactoring as well as introducing a new feature, push back and suggest the refactoring be done in a separate PR. This makes things easier for the reviewer, as refactoring changes can often be far-reaching, yet quick to review.
+-- When introducing new code, be on the lookout for code that duplicates existing code. When found, propose a way to refactor the existing code such that it should be reused.
+-
+-## Code Organization
+-
+-- Each create in the Cargo workspace in `codex-rs` has a specific purpose: make a note if you believe new code is not introduced in the correct crate.
+-- When possible, try to keep the `core` crate as small as possible. Non-core but shared logic is often a good candidate for `codex-rs/common`.
+-- Be wary of large files and offer suggestions for how to break things into more reasonably-sized files.
+-- Rust files should generally be organized such that the public parts of the API appear near the top of the file and helper functions go below. This is analagous to the "inverted pyramid" structure that is favored in journalism.
+-
+-## Assertions in Tests
+-
+-Assert the equality of the entire objects instead of doing "piecemeal comparisons," performing `assert_eq!()` on individual fields.
+-
+-Note that unit tests also function as "executable documentation." As shown in the following example, "piecemeal comparisons" are often more verbose, provide less coverage, and are not as useful as executable documentation.
+-
+-For example, suppose you have the following enum:
+-
+-```rust
+-#[derive(Debug, PartialEq)]
+-enum Message {
+-    Request {
+-        id: String,
+-        method: String,
+-        params: Option<serde_json::Value>,
+-    },
+-    Notification {
+-        method: String,
+-        params: Option<serde_json::Value>,
+-    },
+-}
+-```
+-
+-This is an example of a _piecemeal_ comparison:
+-
+-```rust
+-// BAD: Piecemeal Comparison
+-
+-#[test]
+-fn test_get_latest_messages() {
+-    let messages = get_latest_messages();
+-    assert_eq!(messages.len(), 2);
+-
+-    let m0 = &messages[0];
+-    match m0 {
+-        Message::Request { id, method, params } => {
+-            assert_eq!(id, "123");
+-            assert_eq!(method, "subscribe");
+-            assert_eq!(
+-                *params,
+-                Some(json!({
+-                    "conversation_id": "x42z86"
+-                }))
+-            )
+-        }
+-        Message::Notification { .. } => {
+-            panic!("expected Request");
+-        }
+-    }
+-
+-    let m1 = &messages[1];
+-    match m1 {
+-        Message::Request { .. } => {
+-            panic!("expected Notification");
+-        }
+-        Message::Notification { method, params } => {
+-            assert_eq!(method, "log");
+-            assert_eq!(
+-                *params,
+-                Some(json!({
+-                    "level": "info",
+-                    "message": "subscribed"
+-                }))
+-            )
+-        }
+-    }
+-}
+-```
+-
+-This is a _deep_ comparison:
+-
+-```rust
+-// GOOD: Verify the entire structure with a single assert_eq!().
+-
+-use pretty_assertions::assert_eq;
+-
+-#[test]
+-fn test_get_latest_messages() {
+-    let messages = get_latest_messages();
+-
+-    assert_eq!(
+-        vec![
+-            Message::Request {
+-                id: "123".to_string(),
+-                method: "subscribe".to_string(),
+-                params: Some(json!({
+-                    "conversation_id": "x42z86"
+-                })),
+-            },
+-            Message::Notification {
+-                method: "log".to_string(),
+-                params: Some(json!({
+-                    "level": "info",
+-                    "message": "subscribed"
+-                })),
+-            },
+-        ],
+-        messages,
+-    );
+-}
+-```
+-
+-## More Tactical Rust Things To Look Out For
+-
+-- Do not use `unsafe` (unless you have a really, really good reason like using an operating system API directly and no safe wrapper exists). For example, there are cases where it is tempting to use `unsafe` in order to use `std::env::set_var()`, but this indeed `unsafe` and has led to race conditions on multiple occasions. (When this happens, find a mechanism other than environment variables to use for configuration.)
+-- Encourage the use of small enums or the newtype pattern in Rust if it helps readability without adding significant cognitive load or lines of code.
+-- If you see opportunities for the changes in a diff to use more idiomatic Rust, please make specific recommendations. For example, favor the use of expressions over `return`.
+-- When modifying a `Cargo.toml` file, make sure that dependency lists stay alphabetically sorted. Also consider whether a new dependency is added to the appropriate place (e.g., `[dependencies]` versus `[dev-dependencies]`)
+-
+-## Pull Request Body
+-
+-- If the nature of the change seems to have a visual component (which is often the case for changes to `codex-rs/tui`), recommend including a screenshot or video to demonstrate the change, if appropriate.
+-- References to existing GitHub issues and PRs are encouraged, where appropriate, though you likely do not have network access, so may not be able to help here.
+-
+-# PR Information
+-
+-{CODEX_ACTION_GITHUB_EVENT_PATH} contains the JSON that triggered this GitHub workflow. It contains the `base` and `head` refs that define this PR. Both refs are available locally.
++Review this PR and respond with a very concise final message, formatted in Markdown.
++
++There should be a summary of the changes (1-2 sentences) and a few bullet points if necessary.
++
++Then provide the **review** (1-2 sentences plus bullet points, friendly tone).
++
++Things to look out for when doing the review:
++
++## General Principles
++
++- **Make sure the pull request body explains the motivation behind the change.** If the author has failed to do this, call it out, and if you think you can deduce the motivation behind the change, propose copy.
++- Ideally, the PR body also contains a small summary of the change. For small changes, the PR title may be sufficient.
++- Each PR should ideally do one conceptual thing. For example, if a PR does a refactoring as well as introducing a new feature, push back and suggest the refactoring be done in a separate PR. This makes things easier for the reviewer, as refactoring changes can often be far-reaching, yet quick to review.
++- When introducing new code, be on the lookout for code that duplicates existing code. When found, propose a way to refactor the existing code such that it should be reused.
++
++## Code Organization
++
++- Each create in the Cargo workspace in `codex-rs` has a specific purpose: make a note if you believe new code is not introduced in the correct crate.
++- When possible, try to keep the `core` crate as small as possible. Non-core but shared logic is often a good candidate for `codex-rs/common`.
++- Be wary of large files and offer suggestions for how to break things into more reasonably-sized files.
++- Rust files should generally be organized such that the public parts of the API appear near the top of the file and helper functions go below. This is analagous to the "inverted pyramid" structure that is favored in journalism.
++
++## Assertions in Tests
++
++Assert the equality of the entire objects instead of doing "piecemeal comparisons," performing `assert_eq!()` on individual fields.
++
++Note that unit tests also function as "executable documentation." As shown in the following example, "piecemeal comparisons" are often more verbose, provide less coverage, and are not as useful as executable documentation.
++
++For example, suppose you have the following enum:
++
++```rust
++#[derive(Debug, PartialEq)]
++enum Message {
++    Request {
++        id: String,
++        method: String,
++        params: Option<serde_json::Value>,
++    },
++    Notification {
++        method: String,
++        params: Option<serde_json::Value>,
++    },
++}
++```
++
++This is an example of a _piecemeal_ comparison:
++
++```rust
++// BAD: Piecemeal Comparison
++
++#[test]
++fn test_get_latest_messages() {
++    let messages = get_latest_messages();
++    assert_eq!(messages.len(), 2);
++
++    let m0 = &messages[0];
++    match m0 {
++        Message::Request { id, method, params } => {
++            assert_eq!(id, "123");
++            assert_eq!(method, "subscribe");
++            assert_eq!(
++                *params,
++                Some(json!({
++                    "conversation_id": "x42z86"
++                }))
++            )
++        }
++        Message::Notification { .. } => {
++            panic!("expected Request");
++        }
++    }
++
++    let m1 = &messages[1];
++    match m1 {
++        Message::Request { .. } => {
++            panic!("expected Notification");
++        }
++        Message::Notification { method, params } => {
++            assert_eq!(method, "log");
++            assert_eq!(
++                *params,
++                Some(json!({
++                    "level": "info",
++                    "message": "subscribed"
++                }))
++            )
++        }
++    }
++}
++```
++
++This is a _deep_ comparison:
++
++```rust
++// GOOD: Verify the entire structure with a single assert_eq!().
++
++use pretty_assertions::assert_eq;
++
++#[test]
++fn test_get_latest_messages() {
++    let messages = get_latest_messages();
++
++    assert_eq!(
++        vec![
++            Message::Request {
++                id: "123".to_string(),
++                method: "subscribe".to_string(),
++                params: Some(json!({
++                    "conversation_id": "x42z86"
++                })),
++            },
++            Message::Notification {
++                method: "log".to_string(),
++                params: Some(json!({
++                    "level": "info",
++                    "message": "subscribed"
++                })),
++            },
++        ],
++        messages,
++    );
++}
++```
++
++## More Tactical Rust Things To Look Out For
++
++- Do not use `unsafe` (unless you have a really, really good reason like using an operating system API directly and no safe wrapper exists). For example, there are cases where it is tempting to use `unsafe` in order to use `std::env::set_var()`, but this indeed `unsafe` and has led to race conditions on multiple occasions. (When this happens, find a mechanism other than environment variables to use for configuration.)
++- Encourage the use of small enums or the newtype pattern in Rust if it helps readability without adding significant cognitive load or lines of code.
++- If you see opportunities for the changes in a diff to use more idiomatic Rust, please make specific recommendations. For example, favor the use of expressions over `return`.
++- When modifying a `Cargo.toml` file, make sure that dependency lists stay alphabetically sorted. Also consider whether a new dependency is added to the appropriate place (e.g., `[dependencies]` versus `[dev-dependencies]`)
++
++## Pull Request Body
++
++- If the nature of the change seems to have a visual component (which is often the case for changes to `codex-rs/tui`), recommend including a screenshot or video to demonstrate the change, if appropriate.
++- References to existing GitHub issues and PRs are encouraged, where appropriate, though you likely do not have network access, so may not be able to help here.
++
++# PR Information
++
++{CODEX_ACTION_GITHUB_EVENT_PATH} contains the JSON that triggered this GitHub workflow. It contains the `base` and `head` refs that define this PR. Both refs are available locally.
+diff --git a/.github/codex/labels/codex-triage.md b/.github/codex/labels/codex-triage.md
+index 46ed3624..a9b31884 100644
+--- a/.github/codex/labels/codex-triage.md
++++ b/.github/codex/labels/codex-triage.md
+@@ -1,7 +1,7 @@
+-Troubleshoot whether the reported issue is valid.
+-
+-Provide a concise and respectful comment summarizing the findings.
+-
+-### {CODEX_ACTION_ISSUE_TITLE}
+-
+-{CODEX_ACTION_ISSUE_BODY}
++Troubleshoot whether the reported issue is valid.
++
++Provide a concise and respectful comment summarizing the findings.
++
++### {CODEX_ACTION_ISSUE_TITLE}
++
++{CODEX_ACTION_ISSUE_BODY}
+diff --git a/.github/dependabot.yaml b/.github/dependabot.yaml
+index bb67fe68..2664f719 100644
+--- a/.github/dependabot.yaml
++++ b/.github/dependabot.yaml
+@@ -1,30 +1,30 @@
+-# https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#package-ecosystem-
+-
+-version: 2
+-updates:
+-  - package-ecosystem: bun
+-    directory: .github/actions/codex
+-    schedule:
+-      interval: weekly
+-  - package-ecosystem: cargo
+-    directories:
+-      - codex-rs
+-      - codex-rs/*
+-    schedule:
+-      interval: weekly
+-  - package-ecosystem: devcontainers
+-    directory: /
+-    schedule:
+-      interval: weekly
+-  - package-ecosystem: docker
+-    directory: codex-cli
+-    schedule:
+-      interval: weekly
+-  - package-ecosystem: github-actions
+-    directory: /
+-    schedule:
+-      interval: weekly
+-  - package-ecosystem: rust-toolchain
+-    directory: codex-rs
+-    schedule:
+-      interval: weekly
++# https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#package-ecosystem-
++
++version: 2
++updates:
++  - package-ecosystem: bun
++    directory: .github/actions/codex
++    schedule:
++      interval: weekly
++  - package-ecosystem: cargo
++    directories:
++      - codex-rs
++      - codex-rs/*
++    schedule:
++      interval: weekly
++  - package-ecosystem: devcontainers
++    directory: /
++    schedule:
++      interval: weekly
++  - package-ecosystem: docker
++    directory: codex-cli
++    schedule:
++      interval: weekly
++  - package-ecosystem: github-actions
++    directory: /
++    schedule:
++      interval: weekly
++  - package-ecosystem: rust-toolchain
++    directory: codex-rs
++    schedule:
++      interval: weekly
+diff --git a/.github/dotslash-config.json b/.github/dotslash-config.json
+index 5e28cdf2..aaba8b70 100644
+--- a/.github/dotslash-config.json
++++ b/.github/dotslash-config.json
+@@ -1,60 +1,60 @@
+-{
+-  "outputs": {
+-    "codex": {
+-      "platforms": {
+-        "macos-aarch64": {
+-          "regex": "^codex-aarch64-apple-darwin\\.zst$",
+-          "path": "codex"
+-        },
+-        "macos-x86_64": {
+-          "regex": "^codex-x86_64-apple-darwin\\.zst$",
+-          "path": "codex"
+-        },
+-        "linux-x86_64": {
+-          "regex": "^codex-x86_64-unknown-linux-musl\\.zst$",
+-          "path": "codex"
+-        },
+-        "linux-aarch64": {
+-          "regex": "^codex-aarch64-unknown-linux-musl\\.zst$",
+-          "path": "codex"
+-        },
+-        "windows-x86_64": {
+-          "regex": "^codex-x86_64-pc-windows-msvc\\.exe\\.zst$",
+-          "path": "codex.exe"
+-        },
+-        "windows-aarch64": {
+-          "regex": "^codex-aarch64-pc-windows-msvc\\.exe\\.zst$",
+-          "path": "codex.exe"
+-        }
+-      }
+-    },
+-    "codex-responses-api-proxy": {
+-      "platforms": {
+-        "macos-aarch64": {
+-          "regex": "^codex-responses-api-proxy-aarch64-apple-darwin\\.zst$",
+-          "path": "codex-responses-api-proxy"
+-        },
+-        "macos-x86_64": {
+-          "regex": "^codex-responses-api-proxy-x86_64-apple-darwin\\.zst$",
+-          "path": "codex-responses-api-proxy"
+-        },
+-        "linux-x86_64": {
+-          "regex": "^codex-responses-api-proxy-x86_64-unknown-linux-musl\\.zst$",
+-          "path": "codex-responses-api-proxy"
+-        },
+-        "linux-aarch64": {
+-          "regex": "^codex-responses-api-proxy-aarch64-unknown-linux-musl\\.zst$",
+-          "path": "codex-responses-api-proxy"
+-        },
+-        "windows-x86_64": {
+-          "regex": "^codex-responses-api-proxy-x86_64-pc-windows-msvc\\.exe\\.zst$",
+-          "path": "codex-responses-api-proxy.exe"
+-        },
+-        "windows-aarch64": {
+-          "regex": "^codex-responses-api-proxy-aarch64-pc-windows-msvc\\.exe\\.zst$",
+-          "path": "codex-responses-api-proxy.exe"
+-        }
+-      }
+-    }
+-  }
+-}
++{
++  "outputs": {
++    "codex": {
++      "platforms": {
++        "macos-aarch64": {
++          "regex": "^codex-aarch64-apple-darwin\\.zst$",
++          "path": "codex"
++        },
++        "macos-x86_64": {
++          "regex": "^codex-x86_64-apple-darwin\\.zst$",
++          "path": "codex"
++        },
++        "linux-x86_64": {
++          "regex": "^codex-x86_64-unknown-linux-musl\\.zst$",
++          "path": "codex"
++        },
++        "linux-aarch64": {
++          "regex": "^codex-aarch64-unknown-linux-musl\\.zst$",
++          "path": "codex"
++        },
++        "windows-x86_64": {
++          "regex": "^codex-x86_64-pc-windows-msvc\\.exe\\.zst$",
++          "path": "codex.exe"
++        },
++        "windows-aarch64": {
++          "regex": "^codex-aarch64-pc-windows-msvc\\.exe\\.zst$",
++          "path": "codex.exe"
++        }
++      }
++    },
++    "codex-responses-api-proxy": {
++      "platforms": {
++        "macos-aarch64": {
++          "regex": "^codex-responses-api-proxy-aarch64-apple-darwin\\.zst$",
++          "path": "codex-responses-api-proxy"
++        },
++        "macos-x86_64": {
++          "regex": "^codex-responses-api-proxy-x86_64-apple-darwin\\.zst$",
++          "path": "codex-responses-api-proxy"
++        },
++        "linux-x86_64": {
++          "regex": "^codex-responses-api-proxy-x86_64-unknown-linux-musl\\.zst$",
++          "path": "codex-responses-api-proxy"
++        },
++        "linux-aarch64": {
++          "regex": "^codex-responses-api-proxy-aarch64-unknown-linux-musl\\.zst$",
++          "path": "codex-responses-api-proxy"
++        },
++        "windows-x86_64": {
++          "regex": "^codex-responses-api-proxy-x86_64-pc-windows-msvc\\.exe\\.zst$",
++          "path": "codex-responses-api-proxy.exe"
++        },
++        "windows-aarch64": {
++          "regex": "^codex-responses-api-proxy-aarch64-pc-windows-msvc\\.exe\\.zst$",
++          "path": "codex-responses-api-proxy.exe"
++        }
++      }
++    }
++  }
++}
+diff --git a/.github/prompts/issue-deduplicator.txt b/.github/prompts/issue-deduplicator.txt
+index 9bdd3af9..4d2c2cf5 100644
+--- a/.github/prompts/issue-deduplicator.txt
++++ b/.github/prompts/issue-deduplicator.txt
+@@ -1,18 +1,18 @@
+-You are an assistant that triages new GitHub issues by identifying potential duplicates.
+-
+-You will receive the following JSON files located in the current working directory:
+-- `codex-current-issue.json`: JSON object describing the newly created issue (fields: number, title, body).
+-- `codex-existing-issues.json`: JSON array of recent issues (each element includes number, title, body, createdAt).
+-
+-Instructions:
+-- Load both files as JSON and review their contents carefully. The codex-existing-issues.json file is large, ensure you explore all of it.
+-- Compare the current issue against the existing issues to find up to five that appear to describe the same underlying problem or request.
+-- Only consider an issue a potential duplicate if there is a clear overlap in symptoms, feature requests, reproduction steps, or error messages.
+-- Prioritize newer issues when similarity is comparable.
+-- Ignore pull requests and issues whose similarity is tenuous.
+-- When unsure, prefer returning fewer matches.
+-
+-Output requirements:
+-- Respond with a JSON array of issue numbers (integers), ordered from most likely duplicate to least.
+-- Include at most five numbers.
+-- If you find no plausible duplicates, respond with `[]`.
++You are an assistant that triages new GitHub issues by identifying potential duplicates.
++
++You will receive the following JSON files located in the current working directory:
++- `codex-current-issue.json`: JSON object describing the newly created issue (fields: number, title, body).
++- `codex-existing-issues.json`: JSON array of recent issues (each element includes number, title, body, createdAt).
++
++Instructions:
++- Load both files as JSON and review their contents carefully. The codex-existing-issues.json file is large, ensure you explore all of it.
++- Compare the current issue against the existing issues to find up to five that appear to describe the same underlying problem or request.
++- Only consider an issue a potential duplicate if there is a clear overlap in symptoms, feature requests, reproduction steps, or error messages.
++- Prioritize newer issues when similarity is comparable.
++- Ignore pull requests and issues whose similarity is tenuous.
++- When unsure, prefer returning fewer matches.
++
++Output requirements:
++- Respond with a JSON array of issue numbers (integers), ordered from most likely duplicate to least.
++- Include at most five numbers.
++- If you find no plausible duplicates, respond with `[]`.
+diff --git a/.github/prompts/issue-labeler.txt b/.github/prompts/issue-labeler.txt
+index 7e880d30..a8c0188d 100644
+--- a/.github/prompts/issue-labeler.txt
++++ b/.github/prompts/issue-labeler.txt
+@@ -1,26 +1,26 @@
+-You are an assistant that reviews GitHub issues for the repository.
+-
+-Your job is to choose the most appropriate existing labels for the issue described later in this prompt.
+-Follow these rules:
+-- Only pick labels out of the list below.
+-- Prefer a small set of precise labels over many broad ones.
+-- If none of the labels fit, respond with an empty JSON array: []
+-- Output must be a JSON array of label names (strings) with no additional commentary.
+-
+-Labels to apply:
+-1. bug — Reproducible defects in Codex products (CLI, VS Code extension, web, auth).
+-2. enhancement — Feature requests or usability improvements that ask for new capabilities, better ergonomics, or quality-of-life tweaks.
+-3. extension — VS Code (or other IDE) extension-specific issues.
+-4. windows-os — Bugs or friction specific to Windows environments (PowerShell behavior, path handling, copy/paste, OS-specific auth or tooling failures).
+-5. mcp — Topics involving Model Context Protocol servers/clients.
+-6. codex-web — Issues targeting the Codex web UI/Cloud experience.
+-8. azure — Problems or requests tied to Azure OpenAI deployments.
+-9. documentation — Updates or corrections needed in docs/README/config references (broken links, missing examples, outdated keys, clarification requests).
+-10. model-behavior — Undesirable LLM behavior: forgetting goals, refusing work, hallucinating environment details, quota misreports, or other reasoning/performance anomalies.
+-
+-Issue information is available in environment variables:
+-
+-ISSUE_NUMBER
+-ISSUE_TITLE
+-ISSUE_BODY
+-REPO_FULL_NAME
++You are an assistant that reviews GitHub issues for the repository.
++
++Your job is to choose the most appropriate existing labels for the issue described later in this prompt.
++Follow these rules:
++- Only pick labels out of the list below.
++- Prefer a small set of precise labels over many broad ones.
++- If none of the labels fit, respond with an empty JSON array: []
++- Output must be a JSON array of label names (strings) with no additional commentary.
++
++Labels to apply:
++1. bug — Reproducible defects in Codex products (CLI, VS Code extension, web, auth).
++2. enhancement — Feature requests or usability improvements that ask for new capabilities, better ergonomics, or quality-of-life tweaks.
++3. extension — VS Code (or other IDE) extension-specific issues.
++4. windows-os — Bugs or friction specific to Windows environments (PowerShell behavior, path handling, copy/paste, OS-specific auth or tooling failures).
++5. mcp — Topics involving Model Context Protocol servers/clients.
++6. codex-web — Issues targeting the Codex web UI/Cloud experience.
++8. azure — Problems or requests tied to Azure OpenAI deployments.
++9. documentation — Updates or corrections needed in docs/README/config references (broken links, missing examples, outdated keys, clarification requests).
++10. model-behavior — Undesirable LLM behavior: forgetting goals, refusing work, hallucinating environment details, quota misreports, or other reasoning/performance anomalies.
++
++Issue information is available in environment variables:
++
++ISSUE_NUMBER
++ISSUE_TITLE
++ISSUE_BODY
++REPO_FULL_NAME
+diff --git a/.github/pull_request_template.md b/.github/pull_request_template.md
+index 0fc0747d..e3b21aef 100644
+--- a/.github/pull_request_template.md
++++ b/.github/pull_request_template.md
+@@ -1,6 +1,6 @@
+-# External (non-OpenAI) Pull Request Requirements
+-
+-Before opening this Pull Request, please read the dedicated "Contributing" markdown file or your PR may be closed:
+-https://github.com/openai/codex/blob/main/docs/contributing.md
+-
+-If your PR conforms to our contribution guidelines, replace this text with a detailed and high quality description of your changes.
++# External (non-OpenAI) Pull Request Requirements
++
++Before opening this Pull Request, please read the dedicated "Contributing" markdown file or your PR may be closed:
++https://github.com/openai/codex/blob/main/docs/contributing.md
++
++If your PR conforms to our contribution guidelines, replace this text with a detailed and high quality description of your changes.
+diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
+index 9fa732a4..4877b61b 100644
+--- a/.github/workflows/ci.yml
++++ b/.github/workflows/ci.yml
+@@ -1,65 +1,65 @@
+-name: ci
+-
+-on:
+-  pull_request: {}
+-  push: { branches: [main] }
+-
+-jobs:
+-  build-test:
+-    runs-on: ubuntu-latest
+-    timeout-minutes: 10
+-    env:
+-      NODE_OPTIONS: --max-old-space-size=4096
+-    steps:
+-      - name: Checkout repository
+-        uses: actions/checkout@v5
+-
+-      - name: Setup pnpm
+-        uses: pnpm/action-setup@v4
+-        with:
+-          run_install: false
+-
+-      - name: Setup Node.js
+-        uses: actions/setup-node@v5
+-        with:
+-          node-version: 22
+-
+-      - name: Install dependencies
+-        run: pnpm install --frozen-lockfile
+-
+-      # stage_npm_packages.py requires DotSlash when staging releases.
+-      - uses: facebook/install-dotslash@v2
+-
+-      - name: Stage npm package
+-        id: stage_npm_package
+-        env:
+-          GH_TOKEN: ${{ github.token }}
+-        run: |
+-          set -euo pipefail
+-          CODEX_VERSION=0.40.0
+-          OUTPUT_DIR="${RUNNER_TEMP}"
+-          python3 ./scripts/stage_npm_packages.py \
+-            --release-version "$CODEX_VERSION" \
+-            --package codex \
+-            --output-dir "$OUTPUT_DIR"
+-          PACK_OUTPUT="${OUTPUT_DIR}/codex-npm-${CODEX_VERSION}.tgz"
+-          echo "pack_output=$PACK_OUTPUT" >> "$GITHUB_OUTPUT"
+-
+-      - name: Upload staged npm package artifact
+-        uses: actions/upload-artifact@v4
+-        with:
+-          name: codex-npm-staging
+-          path: ${{ steps.stage_npm_package.outputs.pack_output }}
+-
+-      - name: Ensure root README.md contains only ASCII and certain Unicode code points
+-        run: ./scripts/asciicheck.py README.md
+-      - name: Check root README ToC
+-        run: python3 scripts/readme_toc.py README.md
+-
+-      - name: Ensure codex-cli/README.md contains only ASCII and certain Unicode code points
+-        run: ./scripts/asciicheck.py codex-cli/README.md
+-      - name: Check codex-cli/README ToC
+-        run: python3 scripts/readme_toc.py codex-cli/README.md
+-
+-      - name: Prettier (run `pnpm run format:fix` to fix)
+-        run: pnpm run format
++name: ci
++
++on:
++  pull_request: {}
++  push: { branches: [main] }
++
++jobs:
++  build-test:
++    runs-on: ubuntu-latest
++    timeout-minutes: 10
++    env:
++      NODE_OPTIONS: --max-old-space-size=4096
++    steps:
++      - name: Checkout repository
++        uses: actions/checkout@v5
++
++      - name: Setup pnpm
++        uses: pnpm/action-setup@v4
++        with:
++          run_install: false
++
++      - name: Setup Node.js
++        uses: actions/setup-node@v5
++        with:
++          node-version: 22
++
++      - name: Install dependencies
++        run: pnpm install --frozen-lockfile
++
++      # stage_npm_packages.py requires DotSlash when staging releases.
++      - uses: facebook/install-dotslash@v2
++
++      - name: Stage npm package
++        id: stage_npm_package
++        env:
++          GH_TOKEN: ${{ github.token }}
++        run: |
++          set -euo pipefail
++          CODEX_VERSION=0.40.0
++          OUTPUT_DIR="${RUNNER_TEMP}"
++          python3 ./scripts/stage_npm_packages.py \
++            --release-version "$CODEX_VERSION" \
++            --package codex \
++            --output-dir "$OUTPUT_DIR"
++          PACK_OUTPUT="${OUTPUT_DIR}/codex-npm-${CODEX_VERSION}.tgz"
++          echo "pack_output=$PACK_OUTPUT" >> "$GITHUB_OUTPUT"
++
++      - name: Upload staged npm package artifact
++        uses: actions/upload-artifact@v4
++        with:
++          name: codex-npm-staging
++          path: ${{ steps.stage_npm_package.outputs.pack_output }}
++
++      - name: Ensure root README.md contains only ASCII and certain Unicode code points
++        run: ./scripts/asciicheck.py README.md
++      - name: Check root README ToC
++        run: python3 scripts/readme_toc.py README.md
++
++      - name: Ensure codex-cli/README.md contains only ASCII and certain Unicode code points
++        run: ./scripts/asciicheck.py codex-cli/README.md
++      - name: Check codex-cli/README ToC
++        run: python3 scripts/readme_toc.py codex-cli/README.md
++
++      - name: Prettier (run `pnpm run format:fix` to fix)
++        run: pnpm run format
+diff --git a/.github/workflows/cla.yml b/.github/workflows/cla.yml
+index 521e917e..ed9c4d40 100644
+--- a/.github/workflows/cla.yml
++++ b/.github/workflows/cla.yml
+@@ -1,29 +1,29 @@
+-name: CLA Assistant
+-on:
+-  issue_comment:
+-    types: [created]
+-  pull_request_target:
+-    types: [opened, closed, synchronize]
+-
+-permissions:
+-  actions: write
+-  contents: write
+-  pull-requests: write
+-  statuses: write
+-
+-jobs:
+-  cla:
+-    runs-on: ubuntu-latest
+-    steps:
+-      - uses: contributor-assistant/github-action@v2.6.1
+-        if: |
+-          github.event_name == 'pull_request_target' ||
+-          github.event.comment.body == 'recheck' ||
+-          github.event.comment.body == 'I have read the CLA Document and I hereby sign the CLA'
+-        env:
+-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+-        with:
+-          path-to-document: https://github.com/openai/codex/blob/main/docs/CLA.md
+-          path-to-signatures: signatures/cla.json
+-          branch: cla-signatures
+-          allowlist: dependabot[bot]
++name: CLA Assistant
++on:
++  issue_comment:
++    types: [created]
++  pull_request_target:
++    types: [opened, closed, synchronize]
++
++permissions:
++  actions: write
++  contents: write
++  pull-requests: write
++  statuses: write
++
++jobs:
++  cla:
++    runs-on: ubuntu-latest
++    steps:
++      - uses: contributor-assistant/github-action@v2.6.1
++        if: |
++          github.event_name == 'pull_request_target' ||
++          github.event.comment.body == 'recheck' ||
++          github.event.comment.body == 'I have read the CLA Document and I hereby sign the CLA'
++        env:
++          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
++        with:
++          path-to-document: https://github.com/openai/codex/blob/main/docs/CLA.md
++          path-to-signatures: signatures/cla.json
++          branch: cla-signatures
++          allowlist: dependabot[bot]
+diff --git a/.github/workflows/codespell.yml b/.github/workflows/codespell.yml
+index ad167694..50d00d84 100644
+--- a/.github/workflows/codespell.yml
++++ b/.github/workflows/codespell.yml
+@@ -1,27 +1,27 @@
+-# Codespell configuration is within .codespellrc
+----
+-name: Codespell
+-
+-on:
+-  push:
+-    branches: [main]
+-  pull_request:
+-    branches: [main]
+-
+-permissions:
+-  contents: read
+-
+-jobs:
+-  codespell:
+-    name: Check for spelling errors
+-    runs-on: ubuntu-latest
+-
+-    steps:
+-      - name: Checkout
+-        uses: actions/checkout@v5
+-      - name: Annotate locations with typos
+-        uses: codespell-project/codespell-problem-matcher@b80729f885d32f78a716c2f107b4db1025001c42 # v1
+-      - name: Codespell
+-        uses: codespell-project/actions-codespell@406322ec52dd7b488e48c1c4b82e2a8b3a1bf630 # v2.1
+-        with:
+-          ignore_words_file: .codespellignore
++# Codespell configuration is within .codespellrc
++---
++name: Codespell
++
++on:
++  push:
++    branches: [main]
++  pull_request:
++    branches: [main]
++
++permissions:
++  contents: read
++
++jobs:
++  codespell:
++    name: Check for spelling errors
++    runs-on: ubuntu-latest
++
++    steps:
++      - name: Checkout
++        uses: actions/checkout@v5
++      - name: Annotate locations with typos
++        uses: codespell-project/codespell-problem-matcher@b80729f885d32f78a716c2f107b4db1025001c42 # v1
++      - name: Codespell
++        uses: codespell-project/actions-codespell@406322ec52dd7b488e48c1c4b82e2a8b3a1bf630 # v2.1
++        with:
++          ignore_words_file: .codespellignore
+diff --git a/.github/workflows/issue-deduplicator.yml b/.github/workflows/issue-deduplicator.yml
+index 2bac731e..e48bbc3d 100644
+--- a/.github/workflows/issue-deduplicator.yml
++++ b/.github/workflows/issue-deduplicator.yml
+@@ -1,140 +1,140 @@
+-name: Issue Deduplicator
+-
+-on:
+-  issues:
+-    types:
+-      - opened
+-      - labeled
+-
+-jobs:
+-  gather-duplicates:
+-    name: Identify potential duplicates
+-    if: ${{ github.event.action == 'opened' || (github.event.action == 'labeled' && github.event.label.name == 'codex-deduplicate') }}
+-    runs-on: ubuntu-latest
+-    permissions:
+-      contents: read
+-    outputs:
+-      codex_output: ${{ steps.codex.outputs.final-message }}
+-    steps:
+-      - uses: actions/checkout@v4
+-
+-      - name: Prepare Codex inputs
+-        env:
+-          GH_TOKEN: ${{ github.token }}
+-        run: |
+-          set -eo pipefail
+-
+-          CURRENT_ISSUE_FILE=codex-current-issue.json
+-          EXISTING_ISSUES_FILE=codex-existing-issues.json
+-
+-          gh issue list --repo "${{ github.repository }}" \
+-            --json number,title,body,createdAt \
+-            --limit 1000 \
+-            --state all \
+-            --search "sort:created-desc" \
+-            | jq '.' \
+-            > "$EXISTING_ISSUES_FILE"
+-
+-          gh issue view "${{ github.event.issue.number }}" \
+-            --repo "${{ github.repository }}" \
+-            --json number,title,body \
+-            | jq '.' \
+-            > "$CURRENT_ISSUE_FILE"
+-
+-      - id: codex
+-        uses: openai/codex-action@main
+-        with:
+-          openai-api-key: ${{ secrets.CODEX_OPENAI_API_KEY }}
+-          allow-users: "*"
+-          model: gpt-5
+-          prompt: |
+-            You are an assistant that triages new GitHub issues by identifying potential duplicates.
+-
+-            You will receive the following JSON files located in the current working directory:
+-            - `codex-current-issue.json`: JSON object describing the newly created issue (fields: number, title, body).
+-            - `codex-existing-issues.json`: JSON array of recent issues (each element includes number, title, body, createdAt).
+-
+-            Instructions:
+-            - Compare the current issue against the existing issues to find up to five that appear to describe the same underlying problem or request.
+-            - Focus on the underlying intent and context of each issue—such as reported symptoms, feature requests, reproduction steps, or error messages—rather than relying solely on string similarity or synthetic metrics.
+-            - After your analysis, validate your results in 1-2 lines explaining your decision to return the selected matches.
+-            - When unsure, prefer returning fewer matches.
+-            - Include at most five numbers.
+-
+-          output-schema: |
+-            {
+-              "type": "object",
+-              "properties": {
+-                "issues": {
+-                  "type": "array",
+-                  "items": {
+-                    "type": "string"
+-                  }
+-                },
+-                "reason": { "type": "string" }
+-              },
+-              "required": ["issues", "reason"],
+-              "additionalProperties": false
+-            }
+-
+-  comment-on-issue:
+-    name: Comment with potential duplicates
+-    needs: gather-duplicates
+-    if: ${{ needs.gather-duplicates.result != 'skipped' }}
+-    runs-on: ubuntu-latest
+-    permissions:
+-      contents: read
+-      issues: write
+-    steps:
+-      - name: Comment on issue
+-        uses: actions/github-script@v7
+-        env:
+-          CODEX_OUTPUT: ${{ needs.gather-duplicates.outputs.codex_output }}
+-        with:
+-          github-token: ${{ github.token }}
+-          script: |
+-            const raw = process.env.CODEX_OUTPUT ?? '';
+-            let parsed;
+-            try {
+-              parsed = JSON.parse(raw);
+-            } catch (error) {
+-              core.info(`Codex output was not valid JSON. Raw output: ${raw}`);
+-              core.info(`Parse error: ${error.message}`);
+-              return;
+-            }
+-
+-            const issues = Array.isArray(parsed?.issues) ? parsed.issues : [];
+-            const currentIssueNumber = String(context.payload.issue.number);
+-
+-            console.log(`Current issue number: ${currentIssueNumber}`);
+-            console.log(issues);
+-
+-            const filteredIssues = issues.filter((value) => String(value) !== currentIssueNumber);
+-
+-            if (filteredIssues.length === 0) {
+-              core.info('Codex reported no potential duplicates.');
+-              return;
+-            }
+-
+-            const lines = [
+-              'Potential duplicates detected. Please review them and close your issue if it is a duplicate.',
+-              '',
+-              ...filteredIssues.map((value) => `- #${String(value)}`),
+-              '',
+-              '*Powered by [Codex Action](https://github.com/openai/codex-action)*'];
+-
+-            await github.rest.issues.createComment({
+-              owner: context.repo.owner,
+-              repo: context.repo.repo,
+-              issue_number: context.payload.issue.number,
+-              body: lines.join("\n"),
+-            });
+-
+-      - name: Remove codex-deduplicate label
+-        if: ${{ always() && github.event.action == 'labeled' && github.event.label.name == 'codex-deduplicate' }}
+-        env:
+-          GH_TOKEN: ${{ github.token }}
+-          GH_REPO: ${{ github.repository }}
+-        run: |
+-          gh issue edit "${{ github.event.issue.number }}" --remove-label codex-deduplicate || true
+-          echo "Attempted to remove label: codex-deduplicate"
++name: Issue Deduplicator
++
++on:
++  issues:
++    types:
++      - opened
++      - labeled
++
++jobs:
++  gather-duplicates:
++    name: Identify potential duplicates
++    if: ${{ github.event.action == 'opened' || (github.event.action == 'labeled' && github.event.label.name == 'codex-deduplicate') }}
++    runs-on: ubuntu-latest
++    permissions:
++      contents: read
++    outputs:
++      codex_output: ${{ steps.codex.outputs.final-message }}
++    steps:
++      - uses: actions/checkout@v4
++
++      - name: Prepare Codex inputs
++        env:
++          GH_TOKEN: ${{ github.token }}
++        run: |
++          set -eo pipefail
++
++          CURRENT_ISSUE_FILE=codex-current-issue.json
++          EXISTING_ISSUES_FILE=codex-existing-issues.json
++
++          gh issue list --repo "${{ github.repository }}" \
++            --json number,title,body,createdAt \
++            --limit 1000 \
++            --state all \
++            --search "sort:created-desc" \
++            | jq '.' \
++            > "$EXISTING_ISSUES_FILE"
++
++          gh issue view "${{ github.event.issue.number }}" \
++            --repo "${{ github.repository }}" \
++            --json number,title,body \
++            | jq '.' \
++            > "$CURRENT_ISSUE_FILE"
++
++      - id: codex
++        uses: openai/codex-action@main
++        with:
++          openai-api-key: ${{ secrets.CODEX_OPENAI_API_KEY }}
++          allow-users: "*"
++          model: gpt-5
++          prompt: |
++            You are an assistant that triages new GitHub issues by identifying potential duplicates.
++
++            You will receive the following JSON files located in the current working directory:
++            - `codex-current-issue.json`: JSON object describing the newly created issue (fields: number, title, body).
++            - `codex-existing-issues.json`: JSON array of recent issues (each element includes number, title, body, createdAt).
++
++            Instructions:
++            - Compare the current issue against the existing issues to find up to five that appear to describe the same underlying problem or request.
++            - Focus on the underlying intent and context of each issue—such as reported symptoms, feature requests, reproduction steps, or error messages—rather than relying solely on string similarity or synthetic metrics.
++            - After your analysis, validate your results in 1-2 lines explaining your decision to return the selected matches.
++            - When unsure, prefer returning fewer matches.
++            - Include at most five numbers.
++
++          output-schema: |
++            {
++              "type": "object",
++              "properties": {
++                "issues": {
++                  "type": "array",
++                  "items": {
++                    "type": "string"
++                  }
++                },
++                "reason": { "type": "string" }
++              },
++              "required": ["issues", "reason"],
++              "additionalProperties": false
++            }
++
++  comment-on-issue:
++    name: Comment with potential duplicates
++    needs: gather-duplicates
++    if: ${{ needs.gather-duplicates.result != 'skipped' }}
++    runs-on: ubuntu-latest
++    permissions:
++      contents: read
++      issues: write
++    steps:
++      - name: Comment on issue
++        uses: actions/github-script@v7
++        env:
++          CODEX_OUTPUT: ${{ needs.gather-duplicates.outputs.codex_output }}
++        with:
++          github-token: ${{ github.token }}
++          script: |
++            const raw = process.env.CODEX_OUTPUT ?? '';
++            let parsed;
++            try {
++              parsed = JSON.parse(raw);
++            } catch (error) {
++              core.info(`Codex output was not valid JSON. Raw output: ${raw}`);
++              core.info(`Parse error: ${error.message}`);
++              return;
++            }
++
++            const issues = Array.isArray(parsed?.issues) ? parsed.issues : [];
++            const currentIssueNumber = String(context.payload.issue.number);
++
++            console.log(`Current issue number: ${currentIssueNumber}`);
++            console.log(issues);
++
++            const filteredIssues = issues.filter((value) => String(value) !== currentIssueNumber);
++
++            if (filteredIssues.length === 0) {
++              core.info('Codex reported no potential duplicates.');
++              return;
++            }
++
++            const lines = [
++              'Potential duplicates detected. Please review them and close your issue if it is a duplicate.',
++              '',
++              ...filteredIssues.map((value) => `- #${String(value)}`),
++              '',
++              '*Powered by [Codex Action](https://github.com/openai/codex-action)*'];
++
++            await github.rest.issues.createComment({
++              owner: context.repo.owner,
++              repo: context.repo.repo,
++              issue_number: context.payload.issue.number,
++              body: lines.join("\n"),
++            });
++
++      - name: Remove codex-deduplicate label
++        if: ${{ always() && github.event.action == 'labeled' && github.event.label.name == 'codex-deduplicate' }}
++        env:
++          GH_TOKEN: ${{ github.token }}
++          GH_REPO: ${{ github.repository }}
++        run: |
++          gh issue edit "${{ github.event.issue.number }}" --remove-label codex-deduplicate || true
++          echo "Attempted to remove label: codex-deduplicate"
+diff --git a/.github/workflows/issue-labeler.yml b/.github/workflows/issue-labeler.yml
+index 7560967e..e883b635 100644
+--- a/.github/workflows/issue-labeler.yml
++++ b/.github/workflows/issue-labeler.yml
+@@ -1,115 +1,115 @@
+-name: Issue Labeler
+-
+-on:
+-  issues:
+-    types:
+-      - opened
+-      - labeled
+-
+-jobs:
+-  gather-labels:
+-    name: Generate label suggestions
+-    if: ${{ github.event.action == 'opened' || (github.event.action == 'labeled' && github.event.label.name == 'codex-label') }}
+-    runs-on: ubuntu-latest
+-    permissions:
+-      contents: read
+-    outputs:
+-      codex_output: ${{ steps.codex.outputs.final-message }}
+-    steps:
+-      - uses: actions/checkout@v4
+-
+-      - id: codex
+-        uses: openai/codex-action@main
+-        with:
+-          openai-api-key: ${{ secrets.CODEX_OPENAI_API_KEY }}
+-          allow-users: "*"
+-          prompt: |
+-            You are an assistant that reviews GitHub issues for the repository.
+-
+-            Your job is to choose the most appropriate existing labels for the issue described later in this prompt.
+-            Follow these rules:
+-            - Only pick labels out of the list below.
+-            - Prefer a small set of precise labels over many broad ones.
+-
+-            Labels to apply:
+-            1. bug — Reproducible defects in Codex products (CLI, VS Code extension, web, auth).
+-            2. enhancement — Feature requests or usability improvements that ask for new capabilities, better ergonomics, or quality-of-life tweaks.
+-            3. extension — VS Code (or other IDE) extension-specific issues.
+-            4. windows-os — Bugs or friction specific to Windows environments (always when PowerShell is mentioned, path handling, copy/paste, OS-specific auth or tooling failures).
+-            5. mcp — Topics involving Model Context Protocol servers/clients.
+-            6. codex-web — Issues targeting the Codex web UI/Cloud experience.
+-            8. azure — Problems or requests tied to Azure OpenAI deployments.
+-            9. documentation — Updates or corrections needed in docs/README/config references (broken links, missing examples, outdated keys, clarification requests).
+-            10. model-behavior — Undesirable LLM behavior: forgetting goals, refusing work, hallucinating environment details, quota misreports, or other reasoning/performance anomalies.
+-
+-            Issue number: ${{ github.event.issue.number }}
+-
+-            Issue title:
+-            ${{ github.event.issue.title }}
+-
+-            Issue body:
+-            ${{ github.event.issue.body }}
+-
+-            Repository full name:
+-            ${{ github.repository }}
+-
+-          output-schema: |
+-            {
+-              "type": "object",
+-              "properties": {
+-                "labels": {
+-                  "type": "array",
+-                  "items": {
+-                    "type": "string"
+-                  }
+-                }
+-              },
+-              "required": ["labels"],
+-              "additionalProperties": false
+-            }
+-
+-  apply-labels:
+-    name: Apply labels from Codex output
+-    needs: gather-labels
+-    if: ${{ needs.gather-labels.result != 'skipped' }}
+-    runs-on: ubuntu-latest
+-    permissions:
+-      contents: read
+-      issues: write
+-    env:
+-      GH_TOKEN: ${{ github.token }}
+-      GH_REPO: ${{ github.repository }}
+-      ISSUE_NUMBER: ${{ github.event.issue.number }}
+-      CODEX_OUTPUT: ${{ needs.gather-labels.outputs.codex_output }}
+-    steps:
+-      - name: Apply labels
+-        run: |
+-          json=${CODEX_OUTPUT//$'\r'/}
+-          if [ -z "$json" ]; then
+-            echo "Codex produced no output. Skipping label application."
+-            exit 0
+-          fi
+-
+-          if ! printf '%s' "$json" | jq -e 'type == "object" and (.labels | type == "array")' >/dev/null 2>&1; then
+-            echo "Codex output did not include a labels array. Raw output: $json"
+-            exit 0
+-          fi
+-
+-          labels=$(printf '%s' "$json" | jq -r '.labels[] | tostring')
+-          if [ -z "$labels" ]; then
+-            echo "Codex returned an empty array. Nothing to do."
+-            exit 0
+-          fi
+-
+-          cmd=(gh issue edit "$ISSUE_NUMBER")
+-          while IFS= read -r label; do
+-            cmd+=(--add-label "$label")
+-          done <<< "$labels"
+-
+-          "${cmd[@]}" || true
+-
+-      - name: Remove codex-label trigger
+-        if: ${{ always() && github.event.action == 'labeled' && github.event.label.name == 'codex-label' }}
+-        run: |
+-          gh issue edit "$ISSUE_NUMBER" --remove-label codex-label || true
+-          echo "Attempted to remove label: codex-label"
++name: Issue Labeler
++
++on:
++  issues:
++    types:
++      - opened
++      - labeled
++
++jobs:
++  gather-labels:
++    name: Generate label suggestions
++    if: ${{ github.event.action == 'opened' || (github.event.action == 'labeled' && github.event.label.name == 'codex-label') }}
++    runs-on: ubuntu-latest
++    permissions:
++      contents: read
++    outputs:
++      codex_output: ${{ steps.codex.outputs.final-message }}
++    steps:
++      - uses: actions/checkout@v4
++
++      - id: codex
++        uses: openai/codex-action@main
++        with:
++          openai-api-key: ${{ secrets.CODEX_OPENAI_API_KEY }}
++          allow-users: "*"
++          prompt: |
++            You are an assistant that reviews GitHub issues for the repository.
++
++            Your job is to choose the most appropriate existing labels for the issue described later in this prompt.
++            Follow these rules:
++            - Only pick labels out of the list below.
++            - Prefer a small set of precise labels over many broad ones.
++
++            Labels to apply:
++            1. bug — Reproducible defects in Codex products (CLI, VS Code extension, web, auth).
++            2. enhancement — Feature requests or usability improvements that ask for new capabilities, better ergonomics, or quality-of-life tweaks.
++            3. extension — VS Code (or other IDE) extension-specific issues.
++            4. windows-os — Bugs or friction specific to Windows environments (always when PowerShell is mentioned, path handling, copy/paste, OS-specific auth or tooling failures).
++            5. mcp — Topics involving Model Context Protocol servers/clients.
++            6. codex-web — Issues targeting the Codex web UI/Cloud experience.
++            8. azure — Problems or requests tied to Azure OpenAI deployments.
++            9. documentation — Updates or corrections needed in docs/README/config references (broken links, missing examples, outdated keys, clarification requests).
++            10. model-behavior — Undesirable LLM behavior: forgetting goals, refusing work, hallucinating environment details, quota misreports, or other reasoning/performance anomalies.
++
++            Issue number: ${{ github.event.issue.number }}
++
++            Issue title:
++            ${{ github.event.issue.title }}
++
++            Issue body:
++            ${{ github.event.issue.body }}
++
++            Repository full name:
++            ${{ github.repository }}
++
++          output-schema: |
++            {
++              "type": "object",
++              "properties": {
++                "labels": {
++                  "type": "array",
++                  "items": {
++                    "type": "string"
++                  }
++                }
++              },
++              "required": ["labels"],
++              "additionalProperties": false
++            }
++
++  apply-labels:
++    name: Apply labels from Codex output
++    needs: gather-labels
++    if: ${{ needs.gather-labels.result != 'skipped' }}
++    runs-on: ubuntu-latest
++    permissions:
++      contents: read
++      issues: write
++    env:
++      GH_TOKEN: ${{ github.token }}
++      GH_REPO: ${{ github.repository }}
++      ISSUE_NUMBER: ${{ github.event.issue.number }}
++      CODEX_OUTPUT: ${{ needs.gather-labels.outputs.codex_output }}
++    steps:
++      - name: Apply labels
++        run: |
++          json=${CODEX_OUTPUT//$'\r'/}
++          if [ -z "$json" ]; then
++            echo "Codex produced no output. Skipping label application."
++            exit 0
++          fi
++
++          if ! printf '%s' "$json" | jq -e 'type == "object" and (.labels | type == "array")' >/dev/null 2>&1; then
++            echo "Codex output did not include a labels array. Raw output: $json"
++            exit 0
++          fi
++
++          labels=$(printf '%s' "$json" | jq -r '.labels[] | tostring')
++          if [ -z "$labels" ]; then
++            echo "Codex returned an empty array. Nothing to do."
++            exit 0
++          fi
++
++          cmd=(gh issue edit "$ISSUE_NUMBER")
++          while IFS= read -r label; do
++            cmd+=(--add-label "$label")
++          done <<< "$labels"
++
++          "${cmd[@]}" || true
++
++      - name: Remove codex-label trigger
++        if: ${{ always() && github.event.action == 'labeled' && github.event.label.name == 'codex-label' }}
++        run: |
++          gh issue edit "$ISSUE_NUMBER" --remove-label codex-label || true
++          echo "Attempted to remove label: codex-label"
+diff --git a/.github/workflows/rust-ci.yml b/.github/workflows/rust-ci.yml
+index cbf62f72..16fc4837 100644
+--- a/.github/workflows/rust-ci.yml
++++ b/.github/workflows/rust-ci.yml
+@@ -1,267 +1,267 @@
+-name: rust-ci
+-on:
+-  pull_request: {}
+-  push:
+-    branches:
+-      - main
+-  workflow_dispatch:
+-
+-# CI builds in debug (dev) for faster signal.
+-
+-jobs:
+-  # --- Detect what changed (always runs) -------------------------------------
+-  changed:
+-    name: Detect changed areas
+-    runs-on: ubuntu-24.04
+-    outputs:
+-      codex: ${{ steps.detect.outputs.codex }}
+-      workflows: ${{ steps.detect.outputs.workflows }}
+-    steps:
+-      - uses: actions/checkout@v5
+-        with:
+-          fetch-depth: 0
+-      - name: Detect changed paths (no external action)
+-        id: detect
+-        shell: bash
+-        run: |
+-          set -euo pipefail
+-
+-          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
+-            BASE_SHA='${{ github.event.pull_request.base.sha }}'
+-            echo "Base SHA: $BASE_SHA"
+-            # List files changed between base and current HEAD (merge-base aware)
+-            mapfile -t files < <(git diff --name-only --no-renames "$BASE_SHA"...HEAD)
+-          else
+-            # On push / manual runs, default to running everything
+-            files=("codex-rs/force" ".github/force")
+-          fi
+-
+-          codex=false
+-          workflows=false
+-          for f in "${files[@]}"; do
+-            [[ $f == codex-rs/* ]] && codex=true
+-            [[ $f == .github/* ]] && workflows=true
+-          done
+-
+-          echo "codex=$codex" >> "$GITHUB_OUTPUT"
+-          echo "workflows=$workflows" >> "$GITHUB_OUTPUT"
+-
+-  # --- CI that doesn't need specific targets ---------------------------------
+-  general:
+-    name: Format / etc
+-    runs-on: ubuntu-24.04
+-    needs: changed
+-    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
+-    defaults:
+-      run:
+-        working-directory: codex-rs
+-    steps:
+-      - uses: actions/checkout@v5
+-      - uses: dtolnay/rust-toolchain@1.90
+-        with:
+-          components: rustfmt
+-      - name: cargo fmt
+-        run: cargo fmt -- --config imports_granularity=Item --check
+-      - name: Verify codegen for mcp-types
+-        run: ./mcp-types/check_lib_rs.py
+-
+-  cargo_shear:
+-    name: cargo shear
+-    runs-on: ubuntu-24.04
+-    needs: changed
+-    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
+-    defaults:
+-      run:
+-        working-directory: codex-rs
+-    steps:
+-      - uses: actions/checkout@v5
+-      - uses: dtolnay/rust-toolchain@1.90
+-      - uses: taiki-e/install-action@0c5db7f7f897c03b771660e91d065338615679f4 # v2
+-        with:
+-          tool: cargo-shear
+-          version: 1.5.1
+-      - name: cargo shear
+-        run: cargo shear
+-
+-  # --- CI to validate on different os/targets --------------------------------
+-  lint_build_test:
+-    name: ${{ matrix.runner }} - ${{ matrix.target }}${{ matrix.profile == 'release' && ' (release)' || '' }}
+-    runs-on: ${{ matrix.runner }}
+-    timeout-minutes: 30
+-    needs: changed
+-    # Keep job-level if to avoid spinning up runners when not needed
+-    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
+-    defaults:
+-      run:
+-        working-directory: codex-rs
+-
+-    strategy:
+-      fail-fast: false
+-      matrix:
+-        include:
+-          - runner: macos-14
+-            target: aarch64-apple-darwin
+-            profile: dev
+-          - runner: macos-14
+-            target: x86_64-apple-darwin
+-            profile: dev
+-          - runner: ubuntu-24.04
+-            target: x86_64-unknown-linux-musl
+-            profile: dev
+-          - runner: ubuntu-24.04
+-            target: x86_64-unknown-linux-gnu
+-            profile: dev
+-          - runner: ubuntu-24.04-arm
+-            target: aarch64-unknown-linux-musl
+-            profile: dev
+-          - runner: ubuntu-24.04-arm
+-            target: aarch64-unknown-linux-gnu
+-            profile: dev
+-          - runner: windows-latest
+-            target: x86_64-pc-windows-msvc
+-            profile: dev
+-          - runner: windows-11-arm
+-            target: aarch64-pc-windows-msvc
+-            profile: dev
+-
+-          # Also run representative release builds on Mac and Linux because
+-          # there could be release-only build errors we want to catch.
+-          # Hopefully this also pre-populates the build cache to speed up
+-          # releases.
+-          - runner: macos-14
+-            target: aarch64-apple-darwin
+-            profile: release
+-          - runner: ubuntu-24.04
+-            target: x86_64-unknown-linux-musl
+-            profile: release
+-          - runner: windows-latest
+-            target: x86_64-pc-windows-msvc
+-            profile: release
+-          - runner: windows-11-arm
+-            target: aarch64-pc-windows-msvc
+-            profile: release
+-
+-    steps:
+-      - uses: actions/checkout@v5
+-      - uses: dtolnay/rust-toolchain@1.90
+-        with:
+-          targets: ${{ matrix.target }}
+-          components: clippy
+-
+-      # Explicit cache restore: split cargo home vs target, so we can
+-      # avoid caching the large target dir on the gnu-dev job.
+-      - name: Restore cargo home cache
+-        id: cache_cargo_home_restore
+-        uses: actions/cache/restore@v4
+-        with:
+-          path: |
+-            ~/.cargo/bin/
+-            ~/.cargo/registry/index/
+-            ~/.cargo/registry/cache/
+-            ~/.cargo/git/db/
+-          key: cargo-home-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
+-
+-      - name: Restore target cache (except gnu-dev)
+-        id: cache_target_restore
+-        if: ${{ !(matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release') }}
+-        uses: actions/cache/restore@v4
+-        with:
+-          path: ${{ github.workspace }}/codex-rs/target/
+-          key: cargo-target-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
+-
+-      - if: ${{ matrix.target == 'x86_64-unknown-linux-musl' || matrix.target == 'aarch64-unknown-linux-musl'}}
+-        name: Install musl build tools
+-        run: |
+-          sudo apt install -y musl-tools pkg-config && sudo rm -rf /var/lib/apt/lists/*
+-
+-      - name: cargo clippy
+-        id: clippy
+-        run: cargo clippy --target ${{ matrix.target }} --all-features --tests --profile ${{ matrix.profile }} -- -D warnings
+-
+-      # Running `cargo build` from the workspace root builds the workspace using
+-      # the union of all features from third-party crates. This can mask errors
+-      # where individual crates have underspecified features. To avoid this, we
+-      # run `cargo check` for each crate individually, though because this is
+-      # slower, we only do this for the x86_64-unknown-linux-gnu target.
+-      - name: cargo check individual crates
+-        id: cargo_check_all_crates
+-        if: ${{ matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release' }}
+-        continue-on-error: true
+-        run: |
+-          find . -name Cargo.toml -mindepth 2 -maxdepth 2 -print0 \
+-            | xargs -0 -n1 -I{} bash -c 'cd "$(dirname "{}")" && cargo check --profile ${{ matrix.profile }}'
+-
+-      - uses: taiki-e/install-action@0c5db7f7f897c03b771660e91d065338615679f4 # v2
+-        with:
+-          tool: nextest
+-          version: 0.9.103
+-
+-      - name: tests
+-        id: test
+-        # Tests take too long for release builds to run them on every PR.
+-        if: ${{ matrix.profile != 'release' }}
+-        continue-on-error: true
+-        run: cargo nextest run --all-features --no-fail-fast --target ${{ matrix.target }}
+-        env:
+-          RUST_BACKTRACE: 1
+-
+-      # Save caches explicitly; make non-fatal so cache packaging
+-      # never fails the overall job. Only save when key wasn't hit.
+-      - name: Save cargo home cache
+-        if: always() && !cancelled() && steps.cache_cargo_home_restore.outputs.cache-hit != 'true'
+-        continue-on-error: true
+-        uses: actions/cache/save@v4
+-        with:
+-          path: |
+-            ~/.cargo/bin/
+-            ~/.cargo/registry/index/
+-            ~/.cargo/registry/cache/
+-            ~/.cargo/git/db/
+-          key: cargo-home-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
+-
+-      - name: Save target cache (except gnu-dev)
+-        if: >-
+-          always() && !cancelled() &&
+-          (steps.cache_target_restore.outputs.cache-hit != 'true') &&
+-          !(matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release')
+-        continue-on-error: true
+-        uses: actions/cache/save@v4
+-        with:
+-          path: ${{ github.workspace }}/codex-rs/target/
+-          key: cargo-target-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
+-
+-      # Fail the job if any of the previous steps failed.
+-      - name: verify all steps passed
+-        if: |
+-          steps.clippy.outcome == 'failure' ||
+-          steps.cargo_check_all_crates.outcome == 'failure' ||
+-          steps.test.outcome == 'failure'
+-        run: |
+-          echo "One or more checks failed (clippy, cargo_check_all_crates, or test). See logs for details."
+-          exit 1
+-
+-  # --- Gatherer job that you mark as the ONLY required status -----------------
+-  results:
+-    name: CI results (required)
+-    needs: [changed, general, cargo_shear, lint_build_test]
+-    if: always()
+-    runs-on: ubuntu-24.04
+-    steps:
+-      - name: Summarize
+-        shell: bash
+-        run: |
+-          echo "general: ${{ needs.general.result }}"
+-          echo "shear  : ${{ needs.cargo_shear.result }}"
+-          echo "matrix : ${{ needs.lint_build_test.result }}"
+-
+-          # If nothing relevant changed (PR touching only root README, etc.),
+-          # declare success regardless of other jobs.
+-          if [[ '${{ needs.changed.outputs.codex }}' != 'true' && '${{ needs.changed.outputs.workflows }}' != 'true' && '${{ github.event_name }}' != 'push' ]]; then
+-            echo 'No relevant changes -> CI not required.'
+-            exit 0
+-          fi
+-
+-          # Otherwise require the jobs to have succeeded
+-          [[ '${{ needs.general.result }}' == 'success' ]] || { echo 'general failed'; exit 1; }
+-          [[ '${{ needs.cargo_shear.result }}' == 'success' ]] || { echo 'cargo_shear failed'; exit 1; }
+-          [[ '${{ needs.lint_build_test.result }}' == 'success' ]] || { echo 'matrix failed'; exit 1; }
++name: rust-ci
++on:
++  pull_request: {}
++  push:
++    branches:
++      - main
++  workflow_dispatch:
++
++# CI builds in debug (dev) for faster signal.
++
++jobs:
++  # --- Detect what changed (always runs) -------------------------------------
++  changed:
++    name: Detect changed areas
++    runs-on: ubuntu-24.04
++    outputs:
++      codex: ${{ steps.detect.outputs.codex }}
++      workflows: ${{ steps.detect.outputs.workflows }}
++    steps:
++      - uses: actions/checkout@v5
++        with:
++          fetch-depth: 0
++      - name: Detect changed paths (no external action)
++        id: detect
++        shell: bash
++        run: |
++          set -euo pipefail
++
++          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
++            BASE_SHA='${{ github.event.pull_request.base.sha }}'
++            echo "Base SHA: $BASE_SHA"
++            # List files changed between base and current HEAD (merge-base aware)
++            mapfile -t files < <(git diff --name-only --no-renames "$BASE_SHA"...HEAD)
++          else
++            # On push / manual runs, default to running everything
++            files=("codex-rs/force" ".github/force")
++          fi
++
++          codex=false
++          workflows=false
++          for f in "${files[@]}"; do
++            [[ $f == codex-rs/* ]] && codex=true
++            [[ $f == .github/* ]] && workflows=true
++          done
++
++          echo "codex=$codex" >> "$GITHUB_OUTPUT"
++          echo "workflows=$workflows" >> "$GITHUB_OUTPUT"
++
++  # --- CI that doesn't need specific targets ---------------------------------
++  general:
++    name: Format / etc
++    runs-on: ubuntu-24.04
++    needs: changed
++    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
++    defaults:
++      run:
++        working-directory: codex-rs
++    steps:
++      - uses: actions/checkout@v5
++      - uses: dtolnay/rust-toolchain@1.90
++        with:
++          components: rustfmt
++      - name: cargo fmt
++        run: cargo fmt -- --config imports_granularity=Item --check
++      - name: Verify codegen for mcp-types
++        run: ./mcp-types/check_lib_rs.py
++
++  cargo_shear:
++    name: cargo shear
++    runs-on: ubuntu-24.04
++    needs: changed
++    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
++    defaults:
++      run:
++        working-directory: codex-rs
++    steps:
++      - uses: actions/checkout@v5
++      - uses: dtolnay/rust-toolchain@1.90
++      - uses: taiki-e/install-action@0c5db7f7f897c03b771660e91d065338615679f4 # v2
++        with:
++          tool: cargo-shear
++          version: 1.5.1
++      - name: cargo shear
++        run: cargo shear
++
++  # --- CI to validate on different os/targets --------------------------------
++  lint_build_test:
++    name: ${{ matrix.runner }} - ${{ matrix.target }}${{ matrix.profile == 'release' && ' (release)' || '' }}
++    runs-on: ${{ matrix.runner }}
++    timeout-minutes: 30
++    needs: changed
++    # Keep job-level if to avoid spinning up runners when not needed
++    if: ${{ needs.changed.outputs.codex == 'true' || needs.changed.outputs.workflows == 'true' || github.event_name == 'push' }}
++    defaults:
++      run:
++        working-directory: codex-rs
++
++    strategy:
++      fail-fast: false
++      matrix:
++        include:
++          - runner: macos-14
++            target: aarch64-apple-darwin
++            profile: dev
++          - runner: macos-14
++            target: x86_64-apple-darwin
++            profile: dev
++          - runner: ubuntu-24.04
++            target: x86_64-unknown-linux-musl
++            profile: dev
++          - runner: ubuntu-24.04
++            target: x86_64-unknown-linux-gnu
++            profile: dev
++          - runner: ubuntu-24.04-arm
++            target: aarch64-unknown-linux-musl
++            profile: dev
++          - runner: ubuntu-24.04-arm
++            target: aarch64-unknown-linux-gnu
++            profile: dev
++          - runner: windows-latest
++            target: x86_64-pc-windows-msvc
++            profile: dev
++          - runner: windows-11-arm
++            target: aarch64-pc-windows-msvc
++            profile: dev
++
++          # Also run representative release builds on Mac and Linux because
++          # there could be release-only build errors we want to catch.
++          # Hopefully this also pre-populates the build cache to speed up
++          # releases.
++          - runner: macos-14
++            target: aarch64-apple-darwin
++            profile: release
++          - runner: ubuntu-24.04
++            target: x86_64-unknown-linux-musl
++            profile: release
++          - runner: windows-latest
++            target: x86_64-pc-windows-msvc
++            profile: release
++          - runner: windows-11-arm
++            target: aarch64-pc-windows-msvc
++            profile: release
++
++    steps:
++      - uses: actions/checkout@v5
++      - uses: dtolnay/rust-toolchain@1.90
++        with:
++          targets: ${{ matrix.target }}
++          components: clippy
++
++      # Explicit cache restore: split cargo home vs target, so we can
++      # avoid caching the large target dir on the gnu-dev job.
++      - name: Restore cargo home cache
++        id: cache_cargo_home_restore
++        uses: actions/cache/restore@v4
++        with:
++          path: |
++            ~/.cargo/bin/
++            ~/.cargo/registry/index/
++            ~/.cargo/registry/cache/
++            ~/.cargo/git/db/
++          key: cargo-home-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
++
++      - name: Restore target cache (except gnu-dev)
++        id: cache_target_restore
++        if: ${{ !(matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release') }}
++        uses: actions/cache/restore@v4
++        with:
++          path: ${{ github.workspace }}/codex-rs/target/
++          key: cargo-target-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
++
++      - if: ${{ matrix.target == 'x86_64-unknown-linux-musl' || matrix.target == 'aarch64-unknown-linux-musl'}}
++        name: Install musl build tools
++        run: |
++          sudo apt install -y musl-tools pkg-config && sudo rm -rf /var/lib/apt/lists/*
++
++      - name: cargo clippy
++        id: clippy
++        run: cargo clippy --target ${{ matrix.target }} --all-features --tests --profile ${{ matrix.profile }} -- -D warnings
++
++      # Running `cargo build` from the workspace root builds the workspace using
++      # the union of all features from third-party crates. This can mask errors
++      # where individual crates have underspecified features. To avoid this, we
++      # run `cargo check` for each crate individually, though because this is
++      # slower, we only do this for the x86_64-unknown-linux-gnu target.
++      - name: cargo check individual crates
++        id: cargo_check_all_crates
++        if: ${{ matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release' }}
++        continue-on-error: true
++        run: |
++          find . -name Cargo.toml -mindepth 2 -maxdepth 2 -print0 \
++            | xargs -0 -n1 -I{} bash -c 'cd "$(dirname "{}")" && cargo check --profile ${{ matrix.profile }}'
++
++      - uses: taiki-e/install-action@0c5db7f7f897c03b771660e91d065338615679f4 # v2
++        with:
++          tool: nextest
++          version: 0.9.103
++
++      - name: tests
++        id: test
++        # Tests take too long for release builds to run them on every PR.
++        if: ${{ matrix.profile != 'release' }}
++        continue-on-error: true
++        run: cargo nextest run --all-features --no-fail-fast --target ${{ matrix.target }}
++        env:
++          RUST_BACKTRACE: 1
++
++      # Save caches explicitly; make non-fatal so cache packaging
++      # never fails the overall job. Only save when key wasn't hit.
++      - name: Save cargo home cache
++        if: always() && !cancelled() && steps.cache_cargo_home_restore.outputs.cache-hit != 'true'
++        continue-on-error: true
++        uses: actions/cache/save@v4
++        with:
++          path: |
++            ~/.cargo/bin/
++            ~/.cargo/registry/index/
++            ~/.cargo/registry/cache/
++            ~/.cargo/git/db/
++          key: cargo-home-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
++
++      - name: Save target cache (except gnu-dev)
++        if: >-
++          always() && !cancelled() &&
++          (steps.cache_target_restore.outputs.cache-hit != 'true') &&
++          !(matrix.target == 'x86_64-unknown-linux-gnu' && matrix.profile != 'release')
++        continue-on-error: true
++        uses: actions/cache/save@v4
++        with:
++          path: ${{ github.workspace }}/codex-rs/target/
++          key: cargo-target-${{ matrix.runner }}-${{ matrix.target }}-${{ matrix.profile }}-${{ hashFiles('**/Cargo.lock') }}
++
++      # Fail the job if any of the previous steps failed.
++      - name: verify all steps passed
++        if: |
++          steps.clippy.outcome == 'failure' ||
++          steps.cargo_check_all_crates.outcome == 'failure' ||
++          steps.test.outcome == 'failure'
++        run: |
++          echo "One or more checks failed (clippy, cargo_check_all_crates, or test). See logs for details."
++          exit 1
++
++  # --- Gatherer job that you mark as the ONLY required status -----------------
++  results:
++    name: CI results (required)
++    needs: [changed, general, cargo_shear, lint_build_test]
++    if: always()
++    runs-on: ubuntu-24.04
++    steps:
++      - name: Summarize
++        shell: bash
++        run: |
++          echo "general: ${{ needs.general.result }}"
++          echo "shear  : ${{ needs.cargo_shear.result }}"
++          echo "matrix : ${{ needs.lint_build_test.result }}"
++
++          # If nothing relevant changed (PR touching only root README, etc.),
++          # declare success regardless of other jobs.
++          if [[ '${{ needs.changed.outputs.codex }}' != 'true' && '${{ needs.changed.outputs.workflows }}' != 'true' && '${{ github.event_name }}' != 'push' ]]; then
++            echo 'No relevant changes -> CI not required.'
++            exit 0
++          fi
++
++          # Otherwise require the jobs to have succeeded
++          [[ '${{ needs.general.result }}' == 'success' ]] || { echo 'general failed'; exit 1; }
++          [[ '${{ needs.cargo_shear.result }}' == 'success' ]] || { echo 'cargo_shear failed'; exit 1; }
++          [[ '${{ needs.lint_build_test.result }}' == 'success' ]] || { echo 'matrix failed'; exit 1; }
+diff --git a/.github/workflows/rust-release.yml b/.github/workflows/rust-release.yml
+index be046156..e5064f93 100644
+--- a/.github/workflows/rust-release.yml
++++ b/.github/workflows/rust-release.yml
+@@ -1,476 +1,476 @@
+-# Release workflow for codex-rs.
+-# To release, follow a workflow like:
+-# ```
+-# git tag -a rust-v0.1.0 -m "Release 0.1.0"
+-# git push origin rust-v0.1.0
+-# ```
+-
+-name: rust-release
+-on:
+-  push:
+-    tags:
+-      - "rust-v*.*.*"
+-
+-concurrency:
+-  group: ${{ github.workflow }}
+-  cancel-in-progress: true
+-
+-jobs:
+-  tag-check:
+-    runs-on: ubuntu-latest
+-    steps:
+-      - uses: actions/checkout@v5
+-
+-      - name: Validate tag matches Cargo.toml version
+-        shell: bash
+-        run: |
+-          set -euo pipefail
+-          echo "::group::Tag validation"
+-
+-          # 1. Must be a tag and match the regex
+-          [[ "${GITHUB_REF_TYPE}" == "tag" ]] \
+-            || { echo "❌  Not a tag push"; exit 1; }
+-          [[ "${GITHUB_REF_NAME}" =~ ^rust-v[0-9]+\.[0-9]+\.[0-9]+(-(alpha|beta)(\.[0-9]+)?)?$ ]] \
+-            || { echo "❌  Tag '${GITHUB_REF_NAME}' doesn't match expected format"; exit 1; }
+-
+-          # 2. Extract versions
+-          tag_ver="${GITHUB_REF_NAME#rust-v}"
+-          cargo_ver="$(grep -m1 '^version' codex-rs/Cargo.toml \
+-                        | sed -E 's/version *= *"([^"]+)".*/\1/')"
+-
+-          # 3. Compare
+-          [[ "${tag_ver}" == "${cargo_ver}" ]] \
+-            || { echo "❌  Tag ${tag_ver} ≠ Cargo.toml ${cargo_ver}"; exit 1; }
+-
+-          echo "✅  Tag and Cargo.toml agree (${tag_ver})"
+-          echo "::endgroup::"
+-
+-  build:
+-    needs: tag-check
+-    name: Build - ${{ matrix.runner }} - ${{ matrix.target }}
+-    runs-on: ${{ matrix.runner }}
+-    timeout-minutes: 30
+-    defaults:
+-      run:
+-        working-directory: codex-rs
+-
+-    strategy:
+-      fail-fast: false
+-      matrix:
+-        include:
+-          - runner: macos-14
+-            target: aarch64-apple-darwin
+-          - runner: macos-14
+-            target: x86_64-apple-darwin
+-          - runner: ubuntu-24.04
+-            target: x86_64-unknown-linux-musl
+-          - runner: ubuntu-24.04
+-            target: x86_64-unknown-linux-gnu
+-          - runner: ubuntu-24.04-arm
+-            target: aarch64-unknown-linux-musl
+-          - runner: ubuntu-24.04-arm
+-            target: aarch64-unknown-linux-gnu
+-          - runner: windows-latest
+-            target: x86_64-pc-windows-msvc
+-          - runner: windows-11-arm
+-            target: aarch64-pc-windows-msvc
+-
+-    steps:
+-      - uses: actions/checkout@v5
+-      - uses: dtolnay/rust-toolchain@1.90
+-        with:
+-          targets: ${{ matrix.target }}
+-
+-      - uses: actions/cache@v4
+-        with:
+-          path: |
+-            ~/.cargo/bin/
+-            ~/.cargo/registry/index/
+-            ~/.cargo/registry/cache/
+-            ~/.cargo/git/db/
+-            ${{ github.workspace }}/codex-rs/target/
+-          key: cargo-${{ matrix.runner }}-${{ matrix.target }}-release-${{ hashFiles('**/Cargo.lock') }}
+-
+-      - if: ${{ matrix.target == 'x86_64-unknown-linux-musl' || matrix.target == 'aarch64-unknown-linux-musl'}}
+-        name: Install musl build tools
+-        run: |
+-          sudo apt-get update
+-          sudo apt-get install -y musl-tools pkg-config
+-
+-      - name: Cargo build
+-        run: cargo build --target ${{ matrix.target }} --release --bin codex --bin codex-responses-api-proxy
+-
+-      - if: ${{ matrix.runner == 'macos-14' }}
+-        name: Configure Apple code signing
+-        shell: bash
+-        env:
+-          KEYCHAIN_PASSWORD: actions
+-          APPLE_CERTIFICATE: ${{ secrets.APPLE_CERTIFICATE_P12 }}
+-          APPLE_CERTIFICATE_PASSWORD: ${{ secrets.APPLE_CERTIFICATE_PASSWORD }}
+-        run: |
+-          set -euo pipefail
+-
+-          if [[ -z "${APPLE_CERTIFICATE:-}" ]]; then
+-            echo "APPLE_CERTIFICATE is required for macOS signing"
+-            exit 1
+-          fi
+-
+-          if [[ -z "${APPLE_CERTIFICATE_PASSWORD:-}" ]]; then
+-            echo "APPLE_CERTIFICATE_PASSWORD is required for macOS signing"
+-            exit 1
+-          fi
+-
+-          cert_path="${RUNNER_TEMP}/apple_signing_certificate.p12"
+-          echo "$APPLE_CERTIFICATE" | base64 -d > "$cert_path"
+-
+-          keychain_path="${RUNNER_TEMP}/codex-signing.keychain-db"
+-          security create-keychain -p "$KEYCHAIN_PASSWORD" "$keychain_path"
+-          security set-keychain-settings -lut 21600 "$keychain_path"
+-          security unlock-keychain -p "$KEYCHAIN_PASSWORD" "$keychain_path"
+-
+-          keychain_args=()
+-          cleanup_keychain() {
+-            if ((${#keychain_args[@]} > 0)); then
+-              security list-keychains -s "${keychain_args[@]}" || true
+-              security default-keychain -s "${keychain_args[0]}" || true
+-            else
+-              security list-keychains -s || true
+-            fi
+-            if [[ -f "$keychain_path" ]]; then
+-              security delete-keychain "$keychain_path" || true
+-            fi
+-          }
+-
+-          while IFS= read -r keychain; do
+-            [[ -n "$keychain" ]] && keychain_args+=("$keychain")
+-          done < <(security list-keychains | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/"//g')
+-
+-          if ((${#keychain_args[@]} > 0)); then
+-            security list-keychains -s "$keychain_path" "${keychain_args[@]}"
+-          else
+-            security list-keychains -s "$keychain_path"
+-          fi
+-
+-          security default-keychain -s "$keychain_path"
+-          security import "$cert_path" -k "$keychain_path" -P "$APPLE_CERTIFICATE_PASSWORD" -T /usr/bin/codesign -T /usr/bin/security
+-          security set-key-partition-list -S apple-tool:,apple: -s -k "$KEYCHAIN_PASSWORD" "$keychain_path" > /dev/null
+-
+-          codesign_hashes=()
+-          while IFS= read -r hash; do
+-            [[ -n "$hash" ]] && codesign_hashes+=("$hash")
+-          done < <(security find-identity -v -p codesigning "$keychain_path" \
+-            | sed -n 's/.*\([0-9A-F]\{40\}\).*/\1/p' \
+-            | sort -u)
+-
+-          if ((${#codesign_hashes[@]} == 0)); then
+-            echo "No signing identities found in $keychain_path"
+-            cleanup_keychain
+-            rm -f "$cert_path"
+-            exit 1
+-          fi
+-
+-          if ((${#codesign_hashes[@]} > 1)); then
+-            echo "Multiple signing identities found in $keychain_path:"
+-            printf '  %s\n' "${codesign_hashes[@]}"
+-            cleanup_keychain
+-            rm -f "$cert_path"
+-            exit 1
+-          fi
+-
+-          APPLE_CODESIGN_IDENTITY="${codesign_hashes[0]}"
+-
+-          rm -f "$cert_path"
+-
+-          echo "APPLE_CODESIGN_IDENTITY=$APPLE_CODESIGN_IDENTITY" >> "$GITHUB_ENV"
+-          echo "APPLE_CODESIGN_KEYCHAIN=$keychain_path" >> "$GITHUB_ENV"
+-          echo "::add-mask::$APPLE_CODESIGN_IDENTITY"
+-
+-      - if: ${{ matrix.runner == 'macos-14' }}
+-        name: Sign macOS binaries
+-        shell: bash
+-        run: |
+-          set -euo pipefail
+-
+-          if [[ -z "${APPLE_CODESIGN_IDENTITY:-}" ]]; then
+-            echo "APPLE_CODESIGN_IDENTITY is required for macOS signing"
+-            exit 1
+-          fi
+-
+-          keychain_args=()
+-          if [[ -n "${APPLE_CODESIGN_KEYCHAIN:-}" && -f "${APPLE_CODESIGN_KEYCHAIN}" ]]; then
+-            keychain_args+=(--keychain "${APPLE_CODESIGN_KEYCHAIN}")
+-          fi
+-
+-          for binary in codex codex-responses-api-proxy; do
+-            path="target/${{ matrix.target }}/release/${binary}"
+-            codesign --force --options runtime --timestamp --sign "$APPLE_CODESIGN_IDENTITY" "${keychain_args[@]}" "$path"
+-          done
+-
+-      - name: Stage artifacts
+-        shell: bash
+-        run: |
+-          dest="dist/${{ matrix.target }}"
+-          mkdir -p "$dest"
+-
+-          if [[ "${{ matrix.runner }}" == windows* ]]; then
+-            cp target/${{ matrix.target }}/release/codex.exe "$dest/codex-${{ matrix.target }}.exe"
+-            cp target/${{ matrix.target }}/release/codex-responses-api-proxy.exe "$dest/codex-responses-api-proxy-${{ matrix.target }}.exe"
+-          else
+-            cp target/${{ matrix.target }}/release/codex "$dest/codex-${{ matrix.target }}"
+-            cp target/${{ matrix.target }}/release/codex-responses-api-proxy "$dest/codex-responses-api-proxy-${{ matrix.target }}"
+-          fi
+-
+-      - if: ${{ matrix.runner == 'windows-11-arm' }}
+-        name: Install zstd
+-        shell: powershell
+-        run: choco install -y zstandard
+-
+-      - name: Compress artifacts
+-        shell: bash
+-        run: |
+-          # Path that contains the uncompressed binaries for the current
+-          # ${{ matrix.target }}
+-          dest="dist/${{ matrix.target }}"
+-
+-          # For compatibility with environments that lack the `zstd` tool we
+-          # additionally create a `.tar.gz` for all platforms and `.zip` for
+-          # Windows alongside every single binary that we publish. The end result is:
+-          #   codex-<target>.zst          (existing)
+-          #   codex-<target>.tar.gz       (new)
+-          #   codex-<target>.zip          (only for Windows)
+-
+-          # 1. Produce a .tar.gz for every file in the directory *before* we
+-          #    run `zstd --rm`, because that flag deletes the original files.
+-          for f in "$dest"/*; do
+-            base="$(basename "$f")"
+-            # Skip files that are already archives (shouldn't happen, but be
+-            # safe).
+-            if [[ "$base" == *.tar.gz || "$base" == *.zip ]]; then
+-              continue
+-            fi
+-
+-            # Create per-binary tar.gz
+-            tar -C "$dest" -czf "$dest/${base}.tar.gz" "$base"
+-
+-            # Create zip archive for Windows binaries
+-            # Must run from inside the dest dir so 7z won't
+-            # embed the directory path inside the zip.
+-            if [[ "${{ matrix.runner }}" == windows* ]]; then
+-              (cd "$dest" && 7z a "${base}.zip" "$base")
+-            fi
+-
+-            # Also create .zst (existing behaviour) *and* remove the original
+-            # uncompressed binary to keep the directory small.
+-            zstd -T0 -19 --rm "$dest/$base"
+-          done
+-
+-      - name: Remove signing keychain
+-        if: ${{ always() && matrix.runner == 'macos-14' }}
+-        shell: bash
+-        env:
+-          APPLE_CODESIGN_KEYCHAIN: ${{ env.APPLE_CODESIGN_KEYCHAIN }}
+-        run: |
+-          set -euo pipefail
+-          if [[ -n "${APPLE_CODESIGN_KEYCHAIN:-}" ]]; then
+-            keychain_args=()
+-            while IFS= read -r keychain; do
+-              [[ "$keychain" == "$APPLE_CODESIGN_KEYCHAIN" ]] && continue
+-              [[ -n "$keychain" ]] && keychain_args+=("$keychain")
+-            done < <(security list-keychains | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/"//g')
+-            if ((${#keychain_args[@]} > 0)); then
+-              security list-keychains -s "${keychain_args[@]}"
+-              security default-keychain -s "${keychain_args[0]}"
+-            fi
+-
+-            if [[ -f "$APPLE_CODESIGN_KEYCHAIN" ]]; then
+-              security delete-keychain "$APPLE_CODESIGN_KEYCHAIN"
+-            fi
+-          fi
+-
+-      - uses: actions/upload-artifact@v4
+-        with:
+-          name: ${{ matrix.target }}
+-          # Upload the per-binary .zst files as well as the new .tar.gz
+-          # equivalents we generated in the previous step.
+-          path: |
+-            codex-rs/dist/${{ matrix.target }}/*
+-
+-  release:
+-    needs: build
+-    name: release
+-    runs-on: ubuntu-latest
+-    permissions:
+-      contents: write
+-      actions: read
+-    outputs:
+-      version: ${{ steps.release_name.outputs.name }}
+-      tag: ${{ github.ref_name }}
+-      should_publish_npm: ${{ steps.npm_publish_settings.outputs.should_publish }}
+-      npm_tag: ${{ steps.npm_publish_settings.outputs.npm_tag }}
+-
+-    steps:
+-      - name: Checkout repository
+-        uses: actions/checkout@v5
+-
+-      - uses: actions/download-artifact@v4
+-        with:
+-          path: dist
+-
+-      - name: List
+-        run: ls -R dist/
+-
+-      - name: Define release name
+-        id: release_name
+-        run: |
+-          # Extract the version from the tag name, which is in the format
+-          # "rust-v0.1.0".
+-          version="${GITHUB_REF_NAME#rust-v}"
+-          echo "name=${version}" >> $GITHUB_OUTPUT
+-
+-      - name: Determine npm publish settings
+-        id: npm_publish_settings
+-        env:
+-          VERSION: ${{ steps.release_name.outputs.name }}
+-        run: |
+-          set -euo pipefail
+-          version="${VERSION}"
+-
+-          if [[ "${version}" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
+-            echo "should_publish=true" >> "$GITHUB_OUTPUT"
+-            echo "npm_tag=" >> "$GITHUB_OUTPUT"
+-          elif [[ "${version}" =~ ^[0-9]+\.[0-9]+\.[0-9]+-alpha\.[0-9]+$ ]]; then
+-            echo "should_publish=true" >> "$GITHUB_OUTPUT"
+-            echo "npm_tag=alpha" >> "$GITHUB_OUTPUT"
+-          else
+-            echo "should_publish=false" >> "$GITHUB_OUTPUT"
+-            echo "npm_tag=" >> "$GITHUB_OUTPUT"
+-          fi
+-
+-      - name: Setup pnpm
+-        uses: pnpm/action-setup@v4
+-        with:
+-          run_install: false
+-
+-      - name: Setup Node.js for npm packaging
+-        uses: actions/setup-node@v5
+-        with:
+-          node-version: 22
+-
+-      - name: Install dependencies
+-        run: pnpm install --frozen-lockfile
+-
+-      # stage_npm_packages.py requires DotSlash when staging releases.
+-      - uses: facebook/install-dotslash@v2
+-      - name: Stage npm packages
+-        env:
+-          GH_TOKEN: ${{ github.token }}
+-        run: |
+-          ./scripts/stage_npm_packages.py \
+-            --release-version "${{ steps.release_name.outputs.name }}" \
+-            --package codex \
+-            --package codex-responses-api-proxy \
+-            --package codex-sdk
+-
+-      - name: Create GitHub Release
+-        uses: softprops/action-gh-release@v2
+-        with:
+-          name: ${{ steps.release_name.outputs.name }}
+-          tag_name: ${{ github.ref_name }}
+-          files: dist/**
+-          # Mark as prerelease only when the version has a suffix after x.y.z
+-          # (e.g. -alpha, -beta). Otherwise publish a normal release.
+-          prerelease: ${{ contains(steps.release_name.outputs.name, '-') }}
+-
+-      - uses: facebook/dotslash-publish-release@v2
+-        env:
+-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+-        with:
+-          tag: ${{ github.ref_name }}
+-          config: .github/dotslash-config.json
+-
+-  # Publish to npm using OIDC authentication.
+-  # July 31, 2025: https://github.blog/changelog/2025-07-31-npm-trusted-publishing-with-oidc-is-generally-available/
+-  # npm docs: https://docs.npmjs.com/trusted-publishers
+-  publish-npm:
+-    # Publish to npm for stable releases and alpha pre-releases with numeric suffixes.
+-    if: ${{ needs.release.outputs.should_publish_npm == 'true' }}
+-    name: publish-npm
+-    needs: release
+-    runs-on: ubuntu-latest
+-    permissions:
+-      id-token: write # Required for OIDC
+-      contents: read
+-
+-    steps:
+-      - name: Setup Node.js
+-        uses: actions/setup-node@v5
+-        with:
+-          node-version: 22
+-          registry-url: "https://registry.npmjs.org"
+-          scope: "@openai"
+-
+-      # Trusted publishing requires npm CLI version 11.5.1 or later.
+-      - name: Update npm
+-        run: npm install -g npm@latest
+-
+-      - name: Download npm tarballs from release
+-        env:
+-          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+-        run: |
+-          set -euo pipefail
+-          version="${{ needs.release.outputs.version }}"
+-          tag="${{ needs.release.outputs.tag }}"
+-          mkdir -p dist/npm
+-          gh release download "$tag" \
+-            --repo "${GITHUB_REPOSITORY}" \
+-            --pattern "codex-npm-${version}.tgz" \
+-            --dir dist/npm
+-          gh release download "$tag" \
+-            --repo "${GITHUB_REPOSITORY}" \
+-            --pattern "codex-responses-api-proxy-npm-${version}.tgz" \
+-            --dir dist/npm
+-          gh release download "$tag" \
+-            --repo "${GITHUB_REPOSITORY}" \
+-            --pattern "codex-sdk-npm-${version}.tgz" \
+-            --dir dist/npm
+-
+-      # No NODE_AUTH_TOKEN needed because we use OIDC.
+-      - name: Publish to npm
+-        env:
+-          VERSION: ${{ needs.release.outputs.version }}
+-          NPM_TAG: ${{ needs.release.outputs.npm_tag }}
+-        run: |
+-          set -euo pipefail
+-          tag_args=()
+-          if [[ -n "${NPM_TAG}" ]]; then
+-            tag_args+=(--tag "${NPM_TAG}")
+-          fi
+-
+-          tarballs=(
+-            "codex-npm-${VERSION}.tgz"
+-            "codex-responses-api-proxy-npm-${VERSION}.tgz"
+-            "codex-sdk-npm-${VERSION}.tgz"
+-          )
+-
+-          for tarball in "${tarballs[@]}"; do
+-            npm publish "${GITHUB_WORKSPACE}/dist/npm/${tarball}" "${tag_args[@]}"
+-          done
+-
+-  update-branch:
+-    name: Update latest-alpha-cli branch
+-    permissions:
+-      contents: write
+-    needs: release
+-    runs-on: ubuntu-latest
+-
+-    steps:
+-      - name: Update latest-alpha-cli branch
+-        env:
+-          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+-        run: |
+-          set -euo pipefail
+-          gh api \
+-            repos/${GITHUB_REPOSITORY}/git/refs/heads/latest-alpha-cli \
+-            -X PATCH \
+-            -f sha="${GITHUB_SHA}" \
+-            -F force=true
++# Release workflow for codex-rs.
++# To release, follow a workflow like:
++# ```
++# git tag -a rust-v0.1.0 -m "Release 0.1.0"
++# git push origin rust-v0.1.0
++# ```
++
++name: rust-release
++on:
++  push:
++    tags:
++      - "rust-v*.*.*"
++
++concurrency:
++  group: ${{ github.workflow }}
++  cancel-in-progress: true
++
++jobs:
++  tag-check:
++    runs-on: ubuntu-latest
++    steps:
++      - uses: actions/checkout@v5
++
++      - name: Validate tag matches Cargo.toml version
++        shell: bash
++        run: |
++          set -euo pipefail
++          echo "::group::Tag validation"
++
++          # 1. Must be a tag and match the regex
++          [[ "${GITHUB_REF_TYPE}" == "tag" ]] \
++            || { echo "❌  Not a tag push"; exit 1; }
++          [[ "${GITHUB_REF_NAME}" =~ ^rust-v[0-9]+\.[0-9]+\.[0-9]+(-(alpha|beta)(\.[0-9]+)?)?$ ]] \
++            || { echo "❌  Tag '${GITHUB_REF_NAME}' doesn't match expected format"; exit 1; }
++
++          # 2. Extract versions
++          tag_ver="${GITHUB_REF_NAME#rust-v}"
++          cargo_ver="$(grep -m1 '^version' codex-rs/Cargo.toml \
++                        | sed -E 's/version *= *"([^"]+)".*/\1/')"
++
++          # 3. Compare
++          [[ "${tag_ver}" == "${cargo_ver}" ]] \
++            || { echo "❌  Tag ${tag_ver} ≠ Cargo.toml ${cargo_ver}"; exit 1; }
++
++          echo "✅  Tag and Cargo.toml agree (${tag_ver})"
++          echo "::endgroup::"
++
++  build:
++    needs: tag-check
++    name: Build - ${{ matrix.runner }} - ${{ matrix.target }}
++    runs-on: ${{ matrix.runner }}
++    timeout-minutes: 30
++    defaults:
++      run:
++        working-directory: codex-rs
++
++    strategy:
++      fail-fast: false
++      matrix:
++        include:
++          - runner: macos-14
++            target: aarch64-apple-darwin
++          - runner: macos-14
++            target: x86_64-apple-darwin
++          - runner: ubuntu-24.04
++            target: x86_64-unknown-linux-musl
++          - runner: ubuntu-24.04
++            target: x86_64-unknown-linux-gnu
++          - runner: ubuntu-24.04-arm
++            target: aarch64-unknown-linux-musl
++          - runner: ubuntu-24.04-arm
++            target: aarch64-unknown-linux-gnu
++          - runner: windows-latest
++            target: x86_64-pc-windows-msvc
++          - runner: windows-11-arm
++            target: aarch64-pc-windows-msvc
++
++    steps:
++      - uses: actions/checkout@v5
++      - uses: dtolnay/rust-toolchain@1.90
++        with:
++          targets: ${{ matrix.target }}
++
++      - uses: actions/cache@v4
++        with:
++          path: |
++            ~/.cargo/bin/
++            ~/.cargo/registry/index/
++            ~/.cargo/registry/cache/
++            ~/.cargo/git/db/
++            ${{ github.workspace }}/codex-rs/target/
++          key: cargo-${{ matrix.runner }}-${{ matrix.target }}-release-${{ hashFiles('**/Cargo.lock') }}
++
++      - if: ${{ matrix.target == 'x86_64-unknown-linux-musl' || matrix.target == 'aarch64-unknown-linux-musl'}}
++        name: Install musl build tools
++        run: |
++          sudo apt-get update
++          sudo apt-get install -y musl-tools pkg-config
++
++      - name: Cargo build
++        run: cargo build --target ${{ matrix.target }} --release --bin codex --bin codex-responses-api-proxy
++
++      - if: ${{ matrix.runner == 'macos-14' }}
++        name: Configure Apple code signing
++        shell: bash
++        env:
++          KEYCHAIN_PASSWORD: actions
++          APPLE_CERTIFICATE: ${{ secrets.APPLE_CERTIFICATE_P12 }}
++          APPLE_CERTIFICATE_PASSWORD: ${{ secrets.APPLE_CERTIFICATE_PASSWORD }}
++        run: |
++          set -euo pipefail
++
++          if [[ -z "${APPLE_CERTIFICATE:-}" ]]; then
++            echo "APPLE_CERTIFICATE is required for macOS signing"
++            exit 1
++          fi
++
++          if [[ -z "${APPLE_CERTIFICATE_PASSWORD:-}" ]]; then
++            echo "APPLE_CERTIFICATE_PASSWORD is required for macOS signing"
++            exit 1
++          fi
++
++          cert_path="${RUNNER_TEMP}/apple_signing_certificate.p12"
++          echo "$APPLE_CERTIFICATE" | base64 -d > "$cert_path"
++
++          keychain_path="${RUNNER_TEMP}/codex-signing.keychain-db"
++          security create-keychain -p "$KEYCHAIN_PASSWORD" "$keychain_path"
++          security set-keychain-settings -lut 21600 "$keychain_path"
++          security unlock-keychain -p "$KEYCHAIN_PASSWORD" "$keychain_path"
++
++          keychain_args=()
++          cleanup_keychain() {
++            if ((${#keychain_args[@]} > 0)); then
++              security list-keychains -s "${keychain_args[@]}" || true
++              security default-keychain -s "${keychain_args[0]}" || true
++            else
++              security list-keychains -s || true
++            fi
++            if [[ -f "$keychain_path" ]]; then
++              security delete-keychain "$keychain_path" || true
++            fi
++          }
++
++          while IFS= read -r keychain; do
++            [[ -n "$keychain" ]] && keychain_args+=("$keychain")
++          done < <(security list-keychains | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/"//g')
++
++          if ((${#keychain_args[@]} > 0)); then
++            security list-keychains -s "$keychain_path" "${keychain_args[@]}"
++          else
++            security list-keychains -s "$keychain_path"
++          fi
++
++          security default-keychain -s "$keychain_path"
++          security import "$cert_path" -k "$keychain_path" -P "$APPLE_CERTIFICATE_PASSWORD" -T /usr/bin/codesign -T /usr/bin/security
++          security set-key-partition-list -S apple-tool:,apple: -s -k "$KEYCHAIN_PASSWORD" "$keychain_path" > /dev/null
++
++          codesign_hashes=()
++          while IFS= read -r hash; do
++            [[ -n "$hash" ]] && codesign_hashes+=("$hash")
++          done < <(security find-identity -v -p codesigning "$keychain_path" \
++            | sed -n 's/.*\([0-9A-F]\{40\}\).*/\1/p' \
++            | sort -u)
++
++          if ((${#codesign_hashes[@]} == 0)); then
++            echo "No signing identities found in $keychain_path"
++            cleanup_keychain
++            rm -f "$cert_path"
++            exit 1
++          fi
++
++          if ((${#codesign_hashes[@]} > 1)); then
++            echo "Multiple signing identities found in $keychain_path:"
++            printf '  %s\n' "${codesign_hashes[@]}"
++            cleanup_keychain
++            rm -f "$cert_path"
++            exit 1
++          fi
++
++          APPLE_CODESIGN_IDENTITY="${codesign_hashes[0]}"
++
++          rm -f "$cert_path"
++
++          echo "APPLE_CODESIGN_IDENTITY=$APPLE_CODESIGN_IDENTITY" >> "$GITHUB_ENV"
++          echo "APPLE_CODESIGN_KEYCHAIN=$keychain_path" >> "$GITHUB_ENV"
++          echo "::add-mask::$APPLE_CODESIGN_IDENTITY"
++
++      - if: ${{ matrix.runner == 'macos-14' }}
++        name: Sign macOS binaries
++        shell: bash
++        run: |
++          set -euo pipefail
++
++          if [[ -z "${APPLE_CODESIGN_IDENTITY:-}" ]]; then
++            echo "APPLE_CODESIGN_IDENTITY is required for macOS signing"
++            exit 1
++          fi
++
++          keychain_args=()
++          if [[ -n "${APPLE_CODESIGN_KEYCHAIN:-}" && -f "${APPLE_CODESIGN_KEYCHAIN}" ]]; then
++            keychain_args+=(--keychain "${APPLE_CODESIGN_KEYCHAIN}")
++          fi
++
++          for binary in codex codex-responses-api-proxy; do
++            path="target/${{ matrix.target }}/release/${binary}"
++            codesign --force --options runtime --timestamp --sign "$APPLE_CODESIGN_IDENTITY" "${keychain_args[@]}" "$path"
++          done
++
++      - name: Stage artifacts
++        shell: bash
++        run: |
++          dest="dist/${{ matrix.target }}"
++          mkdir -p "$dest"
++
++          if [[ "${{ matrix.runner }}" == windows* ]]; then
++            cp target/${{ matrix.target }}/release/codex.exe "$dest/codex-${{ matrix.target }}.exe"
++            cp target/${{ matrix.target }}/release/codex-responses-api-proxy.exe "$dest/codex-responses-api-proxy-${{ matrix.target }}.exe"
++          else
++            cp target/${{ matrix.target }}/release/codex "$dest/codex-${{ matrix.target }}"
++            cp target/${{ matrix.target }}/release/codex-responses-api-proxy "$dest/codex-responses-api-proxy-${{ matrix.target }}"
++          fi
++
++      - if: ${{ matrix.runner == 'windows-11-arm' }}
++        name: Install zstd
++        shell: powershell
++        run: choco install -y zstandard
++
++      - name: Compress artifacts
++        shell: bash
++        run: |
++          # Path that contains the uncompressed binaries for the current
++          # ${{ matrix.target }}
++          dest="dist/${{ matrix.target }}"
++
++          # For compatibility with environments that lack the `zstd` tool we
++          # additionally create a `.tar.gz` for all platforms and `.zip` for
++          # Windows alongside every single binary that we publish. The end result is:
++          #   codex-<target>.zst          (existing)
++          #   codex-<target>.tar.gz       (new)
++          #   codex-<target>.zip          (only for Windows)
++
++          # 1. Produce a .tar.gz for every file in the directory *before* we
++          #    run `zstd --rm`, because that flag deletes the original files.
++          for f in "$dest"/*; do
++            base="$(basename "$f")"
++            # Skip files that are already archives (shouldn't happen, but be
++            # safe).
++            if [[ "$base" == *.tar.gz || "$base" == *.zip ]]; then
++              continue
++            fi
++
++            # Create per-binary tar.gz
++            tar -C "$dest" -czf "$dest/${base}.tar.gz" "$base"
++
++            # Create zip archive for Windows binaries
++            # Must run from inside the dest dir so 7z won't
++            # embed the directory path inside the zip.
++            if [[ "${{ matrix.runner }}" == windows* ]]; then
++              (cd "$dest" && 7z a "${base}.zip" "$base")
++            fi
++
++            # Also create .zst (existing behaviour) *and* remove the original
++            # uncompressed binary to keep the directory small.
++            zstd -T0 -19 --rm "$dest/$base"
++          done
++
++      - name: Remove signing keychain
++        if: ${{ always() && matrix.runner == 'macos-14' }}
++        shell: bash
++        env:
++          APPLE_CODESIGN_KEYCHAIN: ${{ env.APPLE_CODESIGN_KEYCHAIN }}
++        run: |
++          set -euo pipefail
++          if [[ -n "${APPLE_CODESIGN_KEYCHAIN:-}" ]]; then
++            keychain_args=()
++            while IFS= read -r keychain; do
++              [[ "$keychain" == "$APPLE_CODESIGN_KEYCHAIN" ]] && continue
++              [[ -n "$keychain" ]] && keychain_args+=("$keychain")
++            done < <(security list-keychains | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/"//g')
++            if ((${#keychain_args[@]} > 0)); then
++              security list-keychains -s "${keychain_args[@]}"
++              security default-keychain -s "${keychain_args[0]}"
++            fi
++
++            if [[ -f "$APPLE_CODESIGN_KEYCHAIN" ]]; then
++              security delete-keychain "$APPLE_CODESIGN_KEYCHAIN"
++            fi
++          fi
++
++      - uses: actions/upload-artifact@v4
++        with:
++          name: ${{ matrix.target }}
++          # Upload the per-binary .zst files as well as the new .tar.gz
++          # equivalents we generated in the previous step.
++          path: |
++            codex-rs/dist/${{ matrix.target }}/*
++
++  release:
++    needs: build
++    name: release
++    runs-on: ubuntu-latest
++    permissions:
++      contents: write
++      actions: read
++    outputs:
++      version: ${{ steps.release_name.outputs.name }}
++      tag: ${{ github.ref_name }}
++      should_publish_npm: ${{ steps.npm_publish_settings.outputs.should_publish }}
++      npm_tag: ${{ steps.npm_publish_settings.outputs.npm_tag }}
++
++    steps:
++      - name: Checkout repository
++        uses: actions/checkout@v5
++
++      - uses: actions/download-artifact@v4
++        with:
++          path: dist
++
++      - name: List
++        run: ls -R dist/
++
++      - name: Define release name
++        id: release_name
++        run: |
++          # Extract the version from the tag name, which is in the format
++          # "rust-v0.1.0".
++          version="${GITHUB_REF_NAME#rust-v}"
++          echo "name=${version}" >> $GITHUB_OUTPUT
++
++      - name: Determine npm publish settings
++        id: npm_publish_settings
++        env:
++          VERSION: ${{ steps.release_name.outputs.name }}
++        run: |
++          set -euo pipefail
++          version="${VERSION}"
++
++          if [[ "${version}" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
++            echo "should_publish=true" >> "$GITHUB_OUTPUT"
++            echo "npm_tag=" >> "$GITHUB_OUTPUT"
++          elif [[ "${version}" =~ ^[0-9]+\.[0-9]+\.[0-9]+-alpha\.[0-9]+$ ]]; then
++            echo "should_publish=true" >> "$GITHUB_OUTPUT"
++            echo "npm_tag=alpha" >> "$GITHUB_OUTPUT"
++          else
++            echo "should_publish=false" >> "$GITHUB_OUTPUT"
++            echo "npm_tag=" >> "$GITHUB_OUTPUT"
++          fi
++
++      - name: Setup pnpm
++        uses: pnpm/action-setup@v4
++        with:
++          run_install: false
++
++      - name: Setup Node.js for npm packaging
++        uses: actions/setup-node@v5
++        with:
++          node-version: 22
++
++      - name: Install dependencies
++        run: pnpm install --frozen-lockfile
++
++      # stage_npm_packages.py requires DotSlash when staging releases.
++      - uses: facebook/install-dotslash@v2
++      - name: Stage npm packages
++        env:
++          GH_TOKEN: ${{ github.token }}
++        run: |
++          ./scripts/stage_npm_packages.py \
++            --release-version "${{ steps.release_name.outputs.name }}" \
++            --package codex \
++            --package codex-responses-api-proxy \
++            --package codex-sdk
++
++      - name: Create GitHub Release
++        uses: softprops/action-gh-release@v2
++        with:
++          name: ${{ steps.release_name.outputs.name }}
++          tag_name: ${{ github.ref_name }}
++          files: dist/**
++          # Mark as prerelease only when the version has a suffix after x.y.z
++          # (e.g. -alpha, -beta). Otherwise publish a normal release.
++          prerelease: ${{ contains(steps.release_name.outputs.name, '-') }}
++
++      - uses: facebook/dotslash-publish-release@v2
++        env:
++          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
++        with:
++          tag: ${{ github.ref_name }}
++          config: .github/dotslash-config.json
++
++  # Publish to npm using OIDC authentication.
++  # July 31, 2025: https://github.blog/changelog/2025-07-31-npm-trusted-publishing-with-oidc-is-generally-available/
++  # npm docs: https://docs.npmjs.com/trusted-publishers
++  publish-npm:
++    # Publish to npm for stable releases and alpha pre-releases with numeric suffixes.
++    if: ${{ needs.release.outputs.should_publish_npm == 'true' }}
++    name: publish-npm
++    needs: release
++    runs-on: ubuntu-latest
++    permissions:
++      id-token: write # Required for OIDC
++      contents: read
++
++    steps:
++      - name: Setup Node.js
++        uses: actions/setup-node@v5
++        with:
++          node-version: 22
++          registry-url: "https://registry.npmjs.org"
++          scope: "@openai"
++
++      # Trusted publishing requires npm CLI version 11.5.1 or later.
++      - name: Update npm
++        run: npm install -g npm@latest
++
++      - name: Download npm tarballs from release
++        env:
++          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
++        run: |
++          set -euo pipefail
++          version="${{ needs.release.outputs.version }}"
++          tag="${{ needs.release.outputs.tag }}"
++          mkdir -p dist/npm
++          gh release download "$tag" \
++            --repo "${GITHUB_REPOSITORY}" \
++            --pattern "codex-npm-${version}.tgz" \
++            --dir dist/npm
++          gh release download "$tag" \
++            --repo "${GITHUB_REPOSITORY}" \
++            --pattern "codex-responses-api-proxy-npm-${version}.tgz" \
++            --dir dist/npm
++          gh release download "$tag" \
++            --repo "${GITHUB_REPOSITORY}" \
++            --pattern "codex-sdk-npm-${version}.tgz" \
++            --dir dist/npm
++
++      # No NODE_AUTH_TOKEN needed because we use OIDC.
++      - name: Publish to npm
++        env:
++          VERSION: ${{ needs.release.outputs.version }}
++          NPM_TAG: ${{ needs.release.outputs.npm_tag }}
++        run: |
++          set -euo pipefail
++          tag_args=()
++          if [[ -n "${NPM_TAG}" ]]; then
++            tag_args+=(--tag "${NPM_TAG}")
++          fi
++
++          tarballs=(
++            "codex-npm-${VERSION}.tgz"
++            "codex-responses-api-proxy-npm-${VERSION}.tgz"
++            "codex-sdk-npm-${VERSION}.tgz"
++          )
++
++          for tarball in "${tarballs[@]}"; do
++            npm publish "${GITHUB_WORKSPACE}/dist/npm/${tarball}" "${tag_args[@]}"
++          done
++
++  update-branch:
++    name: Update latest-alpha-cli branch
++    permissions:
++      contents: write
++    needs: release
++    runs-on: ubuntu-latest
++
++    steps:
++      - name: Update latest-alpha-cli branch
++        env:
++          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
++        run: |
++          set -euo pipefail
++          gh api \
++            repos/${GITHUB_REPOSITORY}/git/refs/heads/latest-alpha-cli \
++            -X PATCH \
++            -f sha="${GITHUB_SHA}" \
++            -F force=true
+diff --git a/.github/workflows/sdk.yml b/.github/workflows/sdk.yml
+index 0f3a7a19..46b39408 100644
+--- a/.github/workflows/sdk.yml
++++ b/.github/workflows/sdk.yml
+@@ -1,43 +1,43 @@
+-name: sdk
+-
+-on:
+-  push:
+-    branches: [main]
+-  pull_request: {}
+-
+-jobs:
+-  sdks:
+-    runs-on: ubuntu-latest
+-    timeout-minutes: 10
+-    steps:
+-      - name: Checkout repository
+-        uses: actions/checkout@v5
+-
+-      - name: Setup pnpm
+-        uses: pnpm/action-setup@v4
+-        with:
+-          run_install: false
+-
+-      - name: Setup Node.js
+-        uses: actions/setup-node@v5
+-        with:
+-          node-version: 22
+-          cache: pnpm
+-
+-      - uses: dtolnay/rust-toolchain@1.90
+-
+-      - name: build codex
+-        run: cargo build --bin codex
+-        working-directory: codex-rs
+-
+-      - name: Install dependencies
+-        run: pnpm install --frozen-lockfile
+-
+-      - name: Build SDK packages
+-        run: pnpm -r --filter ./sdk/typescript run build
+-
+-      - name: Lint SDK packages
+-        run: pnpm -r --filter ./sdk/typescript run lint
+-
+-      - name: Test SDK packages
+-        run: pnpm -r --filter ./sdk/typescript run test
++name: sdk
++
++on:
++  push:
++    branches: [main]
++  pull_request: {}
++
++jobs:
++  sdks:
++    runs-on: ubuntu-latest
++    timeout-minutes: 10
++    steps:
++      - name: Checkout repository
++        uses: actions/checkout@v5
++
++      - name: Setup pnpm
++        uses: pnpm/action-setup@v4
++        with:
++          run_install: false
++
++      - name: Setup Node.js
++        uses: actions/setup-node@v5
++        with:
++          node-version: 22
++          cache: pnpm
++
++      - uses: dtolnay/rust-toolchain@1.90
++
++      - name: build codex
++        run: cargo build --bin codex
++        working-directory: codex-rs
++
++      - name: Install dependencies
++        run: pnpm install --frozen-lockfile
++
++      - name: Build SDK packages
++        run: pnpm -r --filter ./sdk/typescript run build
++
++      - name: Lint SDK packages
++        run: pnpm -r --filter ./sdk/typescript run lint
++
++      - name: Test SDK packages
++        run: pnpm -r --filter ./sdk/typescript run test
+diff --git a/.gitignore b/.gitignore
+index a264d918..b3615eb1 100644
+--- a/.gitignore
++++ b/.gitignore
+@@ -1,83 +1,83 @@
+-# deps
+-# Node.js dependencies
+-node_modules
+-.pnpm-store
+-.pnpm-debug.log
+-
+-# Keep pnpm-lock.yaml
+-!pnpm-lock.yaml
+-
+-# build
+-dist/
+-build/
+-out/
+-storybook-static/
+-
+-# ignore README for publishing
+-codex-cli/README.md
+-
+-# ignore Nix derivation results
+-result
+-
+-# editor
+-.vscode/
+-.idea/
+-.history/
+-.zed/
+-*.swp
+-*~
+-
+-# cli tools
+-CLAUDE.md
+-.claude/
+-
+-# caches
+-.cache/
+-.turbo/
+-.parcel-cache/
+-.eslintcache
+-.nyc_output/
+-.jest/
+-*.tsbuildinfo
+-
+-# logs
+-*.log
+-npm-debug.log*
+-yarn-debug.log*
+-yarn-error.log*
+-
+-# env
+-.env*
+-!.env.example
+-
+-# package
+-*.tgz
+-
+-# ci
+-.vercel/
+-.netlify/
+-
+-# patches
+-apply_patch/
+-
+-# coverage
+-coverage/
+-
+-# os
+-.DS_Store
+-Thumbs.db
+-Icon?
+-.Spotlight-V100/
+-
+-# Unwanted package managers
+-.yarn/
+-yarn.lock
+-
+-# release
+-package.json-e
+-session.ts-e
+-CHANGELOG.ignore.md
+-
+-# nix related
+-.direnv
+-.envrc
++# deps
++# Node.js dependencies
++node_modules
++.pnpm-store
++.pnpm-debug.log
++
++# Keep pnpm-lock.yaml
++!pnpm-lock.yaml
++
++# build
++dist/
++build/
++out/
++storybook-static/
++
++# ignore README for publishing
++codex-cli/README.md
++
++# ignore Nix derivation results
++result
++
++# editor
++.vscode/
++.idea/
++.history/
++.zed/
++*.swp
++*~
++
++# cli tools
++CLAUDE.md
++.claude/
++
++# caches
++.cache/
++.turbo/
++.parcel-cache/
++.eslintcache
++.nyc_output/
++.jest/
++*.tsbuildinfo
++
++# logs
++*.log
++npm-debug.log*
++yarn-debug.log*
++yarn-error.log*
++
++# env
++.env*
++!.env.example
++
++# package
++*.tgz
++
++# ci
++.vercel/
++.netlify/
++
++# patches
++apply_patch/
++
++# coverage
++coverage/
++
++# os
++.DS_Store
++Thumbs.db
++Icon?
++.Spotlight-V100/
++
++# Unwanted package managers
++.yarn/
++yarn.lock
++
++# release
++package.json-e
++session.ts-e
++CHANGELOG.ignore.md
++
++# nix related
++.direnv
++.envrc
+diff --git a/.npmrc b/.npmrc
+index 4153fe87..70bd5064 100644
+--- a/.npmrc
++++ b/.npmrc
+@@ -1,4 +1,4 @@
+-shamefully-hoist=true
+-strict-peer-dependencies=false
+-node-linker=hoisted
+-prefer-workspace-packages=true
++shamefully-hoist=true
++strict-peer-dependencies=false
++node-linker=hoisted
++prefer-workspace-packages=true
+diff --git a/.prettierignore b/.prettierignore
+index f5b50f6b..9673a1b3 100644
+--- a/.prettierignore
++++ b/.prettierignore
+@@ -1,7 +1,7 @@
+-/codex-cli/dist
+-/codex-cli/node_modules
+-pnpm-lock.yaml
+-
+-prompt.md
+-*_prompt.md
+-*_instructions.md
++/codex-cli/dist
++/codex-cli/node_modules
++pnpm-lock.yaml
++
++prompt.md
++*_prompt.md
++*_instructions.md
+diff --git a/.prettierrc.toml b/.prettierrc.toml
+index 4c58c583..23c455b6 100644
+--- a/.prettierrc.toml
++++ b/.prettierrc.toml
+@@ -1,8 +1,8 @@
+-printWidth = 80
+-quoteProps = "consistent"
+-semi = true
+-tabWidth = 2
+-trailingComma = "all"
+-
+-# Preserve existing behavior for markdown/text wrapping.
+-proseWrap = "preserve"
++printWidth = 80
++quoteProps = "consistent"
++semi = true
++tabWidth = 2
++trailingComma = "all"
++
++# Preserve existing behavior for markdown/text wrapping.
++proseWrap = "preserve"
+diff --git a/.vscode/extensions.json b/.vscode/extensions.json
+index 8d6532aa..03dbb371 100644
+--- a/.vscode/extensions.json
++++ b/.vscode/extensions.json
+@@ -1,11 +1,11 @@
+-{
+-    "recommendations": [
+-        "rust-lang.rust-analyzer",
+-        "tamasfe.even-better-toml",
+-        "vadimcn.vscode-lldb",
+-
+-        // Useful if touching files in .github/workflows, though most
+-        // contributors will not be doing that?
+-        // "github.vscode-github-actions",
+-    ]
+-}
++{
++    "recommendations": [
++        "rust-lang.rust-analyzer",
++        "tamasfe.even-better-toml",
++        "vadimcn.vscode-lldb",
++
++        // Useful if touching files in .github/workflows, though most
++        // contributors will not be doing that?
++        // "github.vscode-github-actions",
++    ]
++}
+diff --git a/.vscode/launch.json b/.vscode/launch.json
+index d87ce482..e55bf60b 100644
+--- a/.vscode/launch.json
++++ b/.vscode/launch.json
+@@ -1,22 +1,22 @@
+-{
+-  "version": "0.2.0",
+-  "configurations": [
+-    {
+-      "type": "lldb",
+-      "request": "launch",
+-      "name": "Cargo launch",
+-      "cargo": {
+-        "cwd": "${workspaceFolder}/codex-rs",
+-        "args": ["build", "--bin=codex-tui"]
+-      },
+-      "args": []
+-    },
+-    {
+-      "type": "lldb",
+-      "request": "attach",
+-      "name": "Attach to running codex CLI",
+-      "pid": "${command:pickProcess}",
+-      "sourceLanguages": ["rust"]
+-    }
+-  ]
+-}
++{
++  "version": "0.2.0",
++  "configurations": [
++    {
++      "type": "lldb",
++      "request": "launch",
++      "name": "Cargo launch",
++      "cargo": {
++        "cwd": "${workspaceFolder}/codex-rs",
++        "args": ["build", "--bin=codex-tui"]
++      },
++      "args": []
++    },
++    {
++      "type": "lldb",
++      "request": "attach",
++      "name": "Attach to running codex CLI",
++      "pid": "${command:pickProcess}",
++      "sourceLanguages": ["rust"]
++    }
++  ]
++}
+diff --git a/.vscode/settings.json b/.vscode/settings.json
+index aadeca08..b4f32b3b 100644
+--- a/.vscode/settings.json
++++ b/.vscode/settings.json
+@@ -1,18 +1,18 @@
+-{
+-    "rust-analyzer.checkOnSave": true,
+-    "rust-analyzer.check.command": "clippy",
+-    "rust-analyzer.check.extraArgs": ["--all-features", "--tests"],
+-    "rust-analyzer.rustfmt.extraArgs": ["--config", "imports_granularity=Item"],
+-    "[rust]": {
+-        "editor.defaultFormatter": "rust-lang.rust-analyzer",
+-        "editor.formatOnSave": true,
+-    },
+-    "[toml]": {
+-        "editor.defaultFormatter": "tamasfe.even-better-toml",
+-        "editor.formatOnSave": true,
+-    },
+-    // Array order for options in ~/.codex/config.toml such as `notify` and the
+-    // `args` for an MCP server is significant, so we disable reordering.
+-    "evenBetterToml.formatter.reorderArrays": false,
+-    "evenBetterToml.formatter.reorderKeys": true,
+-}
++{
++    "rust-analyzer.checkOnSave": true,
++    "rust-analyzer.check.command": "clippy",
++    "rust-analyzer.check.extraArgs": ["--all-features", "--tests"],
++    "rust-analyzer.rustfmt.extraArgs": ["--config", "imports_granularity=Item"],
++    "[rust]": {
++        "editor.defaultFormatter": "rust-lang.rust-analyzer",
++        "editor.formatOnSave": true,
++    },
++    "[toml]": {
++        "editor.defaultFormatter": "tamasfe.even-better-toml",
++        "editor.formatOnSave": true,
++    },
++    // Array order for options in ~/.codex/config.toml such as `notify` and the
++    // `args` for an MCP server is significant, so we disable reordering.
++    "evenBetterToml.formatter.reorderArrays": false,
++    "evenBetterToml.formatter.reorderKeys": true,
++}
+diff --git a/AGENTS.md b/AGENTS.md
+index 832f1d65..3d1caf22 100644
+--- a/AGENTS.md
++++ b/AGENTS.md
+@@ -1,100 +1,100 @@
+-# Rust/codex-rs
+-
+-In the codex-rs folder where the rust code lives:
+-
+-- Crate names are prefixed with `codex-`. For example, the `core` folder's crate is named `codex-core`
+-- When using format! and you can inline variables into {}, always do that.
+-- Install any commands the repo relies on (for example `just`, `rg`, or `cargo-insta`) if they aren't already available before running instructions here.
+-- Never add or modify any code related to `CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR` or `CODEX_SANDBOX_ENV_VAR`.
+-  - You operate in a sandbox where `CODEX_SANDBOX_NETWORK_DISABLED=1` will be set whenever you use the `shell` tool. Any existing code that uses `CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR` was authored with this fact in mind. It is often used to early exit out of tests that the author knew you would not be able to run given your sandbox limitations.
+-  - Similarly, when you spawn a process using Seatbelt (`/usr/bin/sandbox-exec`), `CODEX_SANDBOX=seatbelt` will be set on the child process. Integration tests that want to run Seatbelt themselves cannot be run under Seatbelt, so checks for `CODEX_SANDBOX=seatbelt` are also often used to early exit out of tests, as appropriate.
+-- Always collapse if statements per https://rust-lang.github.io/rust-clippy/master/index.html#collapsible_if
+-- Always inline format! args when possible per https://rust-lang.github.io/rust-clippy/master/index.html#uninlined_format_args
+-- Use method references over closures when possible per https://rust-lang.github.io/rust-clippy/master/index.html#redundant_closure_for_method_calls
+-- When writing tests, prefer comparing the equality of entire objects over fields one by one.
+-
+-Run `just fmt` (in `codex-rs` directory) automatically after making Rust code changes; do not ask for approval to run it. Before finalizing a change to `codex-rs`, run `just fix -p <project>` (in `codex-rs` directory) to fix any linter issues in the code. Prefer scoping with `-p` to avoid slow workspace‑wide Clippy builds; only run `just fix` without `-p` if you changed shared crates. Additionally, run the tests:
+-
+-1. Run the test for the specific project that was changed. For example, if changes were made in `codex-rs/tui`, run `cargo test -p codex-tui`.
+-2. Once those pass, if any changes were made in common, core, or protocol, run the complete test suite with `cargo test --all-features`.
+-   When running interactively, ask the user before running `just fix` to finalize. `just fmt` does not require approval. project-specific or individual tests can be run without asking the user, but do ask the user before running the complete test suite.
+-
+-## TUI style conventions
+-
+-See `codex-rs/tui/styles.md`.
+-
+-## TUI code conventions
+-
+-- Use concise styling helpers from ratatui’s Stylize trait.
+-  - Basic spans: use "text".into()
+-  - Styled spans: use "text".red(), "text".green(), "text".magenta(), "text".dim(), etc.
+-  - Prefer these over constructing styles with `Span::styled` and `Style` directly.
+-  - Example: patch summary file lines
+-    - Desired: vec!["  └ ".into(), "M".red(), " ".dim(), "tui/src/app.rs".dim()]
+-
+-### TUI Styling (ratatui)
+-
+-- Prefer Stylize helpers: use "text".dim(), .bold(), .cyan(), .italic(), .underlined() instead of manual Style where possible.
+-- Prefer simple conversions: use "text".into() for spans and vec![…].into() for lines; when inference is ambiguous (e.g., Paragraph::new/Cell::from), use Line::from(spans) or Span::from(text).
+-- Computed styles: if the Style is computed at runtime, using `Span::styled` is OK (`Span::from(text).set_style(style)` is also acceptable).
+-- Avoid hardcoded white: do not use `.white()`; prefer the default foreground (no color).
+-- Chaining: combine helpers by chaining for readability (e.g., url.cyan().underlined()).
+-- Single items: prefer "text".into(); use Line::from(text) or Span::from(text) only when the target type isn’t obvious from context, or when using .into() would require extra type annotations.
+-- Building lines: use vec![…].into() to construct a Line when the target type is obvious and no extra type annotations are needed; otherwise use Line::from(vec![…]).
+-- Avoid churn: don’t refactor between equivalent forms (Span::styled ↔ set_style, Line::from ↔ .into()) without a clear readability or functional gain; follow file‑local conventions and do not introduce type annotations solely to satisfy .into().
+-- Compactness: prefer the form that stays on one line after rustfmt; if only one of Line::from(vec![…]) or vec![…].into() avoids wrapping, choose that. If both wrap, pick the one with fewer wrapped lines.
+-
+-### Text wrapping
+-
+-- Always use textwrap::wrap to wrap plain strings.
+-- If you have a ratatui Line and you want to wrap it, use the helpers in tui/src/wrapping.rs, e.g. word_wrap_lines / word_wrap_line.
+-- If you need to indent wrapped lines, use the initial_indent / subsequent_indent options from RtOptions if you can, rather than writing custom logic.
+-- If you have a list of lines and you need to prefix them all with some prefix (optionally different on the first vs subsequent lines), use the `prefix_lines` helper from line_utils.
+-
+-## Tests
+-
+-### Snapshot tests
+-
+-This repo uses snapshot tests (via `insta`), especially in `codex-rs/tui`, to validate rendered output. When UI or text output changes intentionally, update the snapshots as follows:
+-
+-- Run tests to generate any updated snapshots:
+-  - `cargo test -p codex-tui`
+-- Check what’s pending:
+-  - `cargo insta pending-snapshots -p codex-tui`
+-- Review changes by reading the generated `*.snap.new` files directly in the repo, or preview a specific file:
+-  - `cargo insta show -p codex-tui path/to/file.snap.new`
+-- Only if you intend to accept all new snapshots in this crate, run:
+-  - `cargo insta accept -p codex-tui`
+-
+-If you don’t have the tool:
+-
+-- `cargo install cargo-insta`
+-
+-### Test assertions
+-
+-- Tests should use pretty_assertions::assert_eq for clearer diffs. Import this at the top of the test module if it isn't already.
+-
+-### Integration tests (core)
+-
+-- Prefer the utilities in `core_test_support::responses` when writing end-to-end Codex tests.
+-
+-- All `mount_sse*` helpers return a `ResponseMock`; hold onto it so you can assert against outbound `/responses` POST bodies.
+-- Use `ResponseMock::single_request()` when a test should only issue one POST, or `ResponseMock::requests()` to inspect every captured `ResponsesRequest`.
+-- `ResponsesRequest` exposes helpers (`body_json`, `input`, `function_call_output`, `custom_tool_call_output`, `call_output`, `header`, `path`, `query_param`) so assertions can target structured payloads instead of manual JSON digging.
+-- Build SSE payloads with the provided `ev_*` constructors and the `sse(...)`.
+-
+-- Typical pattern:
+-
+-  ```rust
+-  let mock = responses::mount_sse_once(&server, responses::sse(vec![
+-      responses::ev_response_created("resp-1"),
+-      responses::ev_function_call(call_id, "shell", &serde_json::to_string(&args)?),
+-      responses::ev_completed("resp-1"),
+-  ])).await;
+-
+-  codex.submit(Op::UserTurn { ... }).await?;
+-
+-  // Assert request body if needed.
+-  let request = mock.single_request();
+-  // assert using request.function_call_output(call_id) or request.json_body() or other helpers.
+-  ```
++# Rust/codex-rs
++
++In the codex-rs folder where the rust code lives:
++
++- Crate names are prefixed with `codex-`. For example, the `core` folder's crate is named `codex-core`
++- When using format! and you can inline variables into {}, always do that.
++- Install any commands the repo relies on (for example `just`, `rg`, or `cargo-insta`) if they aren't already available before running instructions here.
++- Never add or modify any code related to `CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR` or `CODEX_SANDBOX_ENV_VAR`.
++  - You operate in a sandbox where `CODEX_SANDBOX_NETWORK_DISABLED=1` will be set whenever you use the `shell` tool. Any existing code that uses `CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR` was authored with this fact in mind. It is often used to early exit out of tests that the author knew you would not be able to run given your sandbox limitations.
++  - Similarly, when you spawn a process using Seatbelt (`/usr/bin/sandbox-exec`), `CODEX_SANDBOX=seatbelt` will be set on the child process. Integration tests that want to run Seatbelt themselves cannot be run under Seatbelt, so checks for `CODEX_SANDBOX=seatbelt` are also often used to early exit out of tests, as appropriate.
++- Always collapse if statements per https://rust-lang.github.io/rust-clippy/master/index.html#collapsible_if
++- Always inline format! args when possible per https://rust-lang.github.io/rust-clippy/master/index.html#uninlined_format_args
++- Use method references over closures when possible per https://rust-lang.github.io/rust-clippy/master/index.html#redundant_closure_for_method_calls
++- When writing tests, prefer comparing the equality of entire objects over fields one by one.
++
++Run `just fmt` (in `codex-rs` directory) automatically after making Rust code changes; do not ask for approval to run it. Before finalizing a change to `codex-rs`, run `just fix -p <project>` (in `codex-rs` directory) to fix any linter issues in the code. Prefer scoping with `-p` to avoid slow workspace‑wide Clippy builds; only run `just fix` without `-p` if you changed shared crates. Additionally, run the tests:
++
++1. Run the test for the specific project that was changed. For example, if changes were made in `codex-rs/tui`, run `cargo test -p codex-tui`.
++2. Once those pass, if any changes were made in common, core, or protocol, run the complete test suite with `cargo test --all-features`.
++   When running interactively, ask the user before running `just fix` to finalize. `just fmt` does not require approval. project-specific or individual tests can be run without asking the user, but do ask the user before running the complete test suite.
++
++## TUI style conventions
++
++See `codex-rs/tui/styles.md`.
++
++## TUI code conventions
++
++- Use concise styling helpers from ratatui’s Stylize trait.
++  - Basic spans: use "text".into()
++  - Styled spans: use "text".red(), "text".green(), "text".magenta(), "text".dim(), etc.
++  - Prefer these over constructing styles with `Span::styled` and `Style` directly.
++  - Example: patch summary file lines
++    - Desired: vec!["  └ ".into(), "M".red(), " ".dim(), "tui/src/app.rs".dim()]
++
++### TUI Styling (ratatui)
++
++- Prefer Stylize helpers: use "text".dim(), .bold(), .cyan(), .italic(), .underlined() instead of manual Style where possible.
++- Prefer simple conversions: use "text".into() for spans and vec![…].into() for lines; when inference is ambiguous (e.g., Paragraph::new/Cell::from), use Line::from(spans) or Span::from(text).
++- Computed styles: if the Style is computed at runtime, using `Span::styled` is OK (`Span::from(text).set_style(style)` is also acceptable).
++- Avoid hardcoded white: do not use `.white()`; prefer the default foreground (no color).
++- Chaining: combine helpers by chaining for readability (e.g., url.cyan().underlined()).
++- Single items: prefer "text".into(); use Line::from(text) or Span::from(text) only when the target type isn’t obvious from context, or when using .into() would require extra type annotations.
++- Building lines: use vec![…].into() to construct a Line when the target type is obvious and no extra type annotations are needed; otherwise use Line::from(vec![…]).
++- Avoid churn: don’t refactor between equivalent forms (Span::styled ↔ set_style, Line::from ↔ .into()) without a clear readability or functional gain; follow file‑local conventions and do not introduce type annotations solely to satisfy .into().
++- Compactness: prefer the form that stays on one line after rustfmt; if only one of Line::from(vec![…]) or vec![…].into() avoids wrapping, choose that. If both wrap, pick the one with fewer wrapped lines.
++
++### Text wrapping
++
++- Always use textwrap::wrap to wrap plain strings.
++- If you have a ratatui Line and you want to wrap it, use the helpers in tui/src/wrapping.rs, e.g. word_wrap_lines / word_wrap_line.
++- If you need to indent wrapped lines, use the initial_indent / subsequent_indent options from RtOptions if you can, rather than writing custom logic.
++- If you have a list of lines and you need to prefix them all with some prefix (optionally different on the first vs subsequent lines), use the `prefix_lines` helper from line_utils.
++
++## Tests
++
++### Snapshot tests
++
++This repo uses snapshot tests (via `insta`), especially in `codex-rs/tui`, to validate rendered output. When UI or text output changes intentionally, update the snapshots as follows:
++
++- Run tests to generate any updated snapshots:
++  - `cargo test -p codex-tui`
++- Check what’s pending:
++  - `cargo insta pending-snapshots -p codex-tui`
++- Review changes by reading the generated `*.snap.new` files directly in the repo, or preview a specific file:
++  - `cargo insta show -p codex-tui path/to/file.snap.new`
++- Only if you intend to accept all new snapshots in this crate, run:
++  - `cargo insta accept -p codex-tui`
++
++If you don’t have the tool:
++
++- `cargo install cargo-insta`
++
++### Test assertions
++
++- Tests should use pretty_assertions::assert_eq for clearer diffs. Import this at the top of the test module if it isn't already.
++
++### Integration tests (core)
++
++- Prefer the utilities in `core_test_support::responses` when writing end-to-end Codex tests.
++
++- All `mount_sse*` helpers return a `ResponseMock`; hold onto it so you can assert against outbound `/responses` POST bodies.
++- Use `ResponseMock::single_request()` when a test should only issue one POST, or `ResponseMock::requests()` to inspect every captured `ResponsesRequest`.
++- `ResponsesRequest` exposes helpers (`body_json`, `input`, `function_call_output`, `custom_tool_call_output`, `call_output`, `header`, `path`, `query_param`) so assertions can target structured payloads instead of manual JSON digging.
++- Build SSE payloads with the provided `ev_*` constructors and the `sse(...)`.
++
++- Typical pattern:
++
++  ```rust
++  let mock = responses::mount_sse_once(&server, responses::sse(vec![
++      responses::ev_response_created("resp-1"),
++      responses::ev_function_call(call_id, "shell", &serde_json::to_string(&args)?),
++      responses::ev_completed("resp-1"),
++  ])).await;
++
++  codex.submit(Op::UserTurn { ... }).await?;
++
++  // Assert request body if needed.
++  let request = mock.single_request();
++  // assert using request.function_call_output(call_id) or request.json_body() or other helpers.
++  ```
+diff --git a/CHANGELOG.md b/CHANGELOG.md
+index ed8bb455..136be7e3 100644
+--- a/CHANGELOG.md
++++ b/CHANGELOG.md
+@@ -1 +1 @@
+-The changelog can be found on the [releases page](https://github.com/openai/codex/releases)
++The changelog can be found on the [releases page](https://github.com/openai/codex/releases)
+diff --git a/LICENSE b/LICENSE
+index 4606e72e..42d4a999 100644
+--- a/LICENSE
++++ b/LICENSE
+@@ -1,201 +1,201 @@
+-                                 Apache License
+-                           Version 2.0, January 2004
+-                        http://www.apache.org/licenses/
+-
+-TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+-
+-1.  Definitions.
+-
+-    "License" shall mean the terms and conditions for use, reproduction,
+-    and distribution as defined by Sections 1 through 9 of this document.
+-
+-    "Licensor" shall mean the copyright owner or entity authorized by
+-    the copyright owner that is granting the License.
+-
+-    "Legal Entity" shall mean the union of the acting entity and all
+-    other entities that control, are controlled by, or are under common
+-    control with that entity. For the purposes of this definition,
+-    "control" means (i) the power, direct or indirect, to cause the
+-    direction or management of such entity, whether by contract or
+-    otherwise, or (ii) ownership of fifty percent (50%) or more of the
+-    outstanding shares, or (iii) beneficial ownership of such entity.
+-
+-    "You" (or "Your") shall mean an individual or Legal Entity
+-    exercising permissions granted by this License.
+-
+-    "Source" form shall mean the preferred form for making modifications,
+-    including but not limited to software source code, documentation
+-    source, and configuration files.
+-
+-    "Object" form shall mean any form resulting from mechanical
+-    transformation or translation of a Source form, including but
+-    not limited to compiled object code, generated documentation,
+-    and conversions to other media types.
+-
+-    "Work" shall mean the work of authorship, whether in Source or
+-    Object form, made available under the License, as indicated by a
+-    copyright notice that is included in or attached to the work
+-    (an example is provided in the Appendix below).
+-
+-    "Derivative Works" shall mean any work, whether in Source or Object
+-    form, that is based on (or derived from) the Work and for which the
+-    editorial revisions, annotations, elaborations, or other modifications
+-    represent, as a whole, an original work of authorship. For the purposes
+-    of this License, Derivative Works shall not include works that remain
+-    separable from, or merely link (or bind by name) to the interfaces of,
+-    the Work and Derivative Works thereof.
+-
+-    "Contribution" shall mean any work of authorship, including
+-    the original version of the Work and any modifications or additions
+-    to that Work or Derivative Works thereof, that is intentionally
+-    submitted to Licensor for inclusion in the Work by the copyright owner
+-    or by an individual or Legal Entity authorized to submit on behalf of
+-    the copyright owner. For the purposes of this definition, "submitted"
+-    means any form of electronic, verbal, or written communication sent
+-    to the Licensor or its representatives, including but not limited to
+-    communication on electronic mailing lists, source code control systems,
+-    and issue tracking systems that are managed by, or on behalf of, the
+-    Licensor for the purpose of discussing and improving the Work, but
+-    excluding communication that is conspicuously marked or otherwise
+-    designated in writing by the copyright owner as "Not a Contribution."
+-
+-    "Contributor" shall mean Licensor and any individual or Legal Entity
+-    on behalf of whom a Contribution has been received by Licensor and
+-    subsequently incorporated within the Work.
+-
+-2.  Grant of Copyright License. Subject to the terms and conditions of
+-    this License, each Contributor hereby grants to You a perpetual,
+-    worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+-    copyright license to reproduce, prepare Derivative Works of,
+-    publicly display, publicly perform, sublicense, and distribute the
+-    Work and such Derivative Works in Source or Object form.
+-
+-3.  Grant of Patent License. Subject to the terms and conditions of
+-    this License, each Contributor hereby grants to You a perpetual,
+-    worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+-    (except as stated in this section) patent license to make, have made,
+-    use, offer to sell, sell, import, and otherwise transfer the Work,
+-    where such license applies only to those patent claims licensable
+-    by such Contributor that are necessarily infringed by their
+-    Contribution(s) alone or by combination of their Contribution(s)
+-    with the Work to which such Contribution(s) was submitted. If You
+-    institute patent litigation against any entity (including a
+-    cross-claim or counterclaim in a lawsuit) alleging that the Work
+-    or a Contribution incorporated within the Work constitutes direct
+-    or contributory patent infringement, then any patent licenses
+-    granted to You under this License for that Work shall terminate
+-    as of the date such litigation is filed.
+-
+-4.  Redistribution. You may reproduce and distribute copies of the
+-    Work or Derivative Works thereof in any medium, with or without
+-    modifications, and in Source or Object form, provided that You
+-    meet the following conditions:
+-
+-    (a) You must give any other recipients of the Work or
+-    Derivative Works a copy of this License; and
+-
+-    (b) You must cause any modified files to carry prominent notices
+-    stating that You changed the files; and
+-
+-    (c) You must retain, in the Source form of any Derivative Works
+-    that You distribute, all copyright, patent, trademark, and
+-    attribution notices from the Source form of the Work,
+-    excluding those notices that do not pertain to any part of
+-    the Derivative Works; and
+-
+-    (d) If the Work includes a "NOTICE" text file as part of its
+-    distribution, then any Derivative Works that You distribute must
+-    include a readable copy of the attribution notices contained
+-    within such NOTICE file, excluding those notices that do not
+-    pertain to any part of the Derivative Works, in at least one
+-    of the following places: within a NOTICE text file distributed
+-    as part of the Derivative Works; within the Source form or
+-    documentation, if provided along with the Derivative Works; or,
+-    within a display generated by the Derivative Works, if and
+-    wherever such third-party notices normally appear. The contents
+-    of the NOTICE file are for informational purposes only and
+-    do not modify the License. You may add Your own attribution
+-    notices within Derivative Works that You distribute, alongside
+-    or as an addendum to the NOTICE text from the Work, provided
+-    that such additional attribution notices cannot be construed
+-    as modifying the License.
+-
+-    You may add Your own copyright statement to Your modifications and
+-    may provide additional or different license terms and conditions
+-    for use, reproduction, or distribution of Your modifications, or
+-    for any such Derivative Works as a whole, provided Your use,
+-    reproduction, and distribution of the Work otherwise complies with
+-    the conditions stated in this License.
+-
+-5.  Submission of Contributions. Unless You explicitly state otherwise,
+-    any Contribution intentionally submitted for inclusion in the Work
+-    by You to the Licensor shall be under the terms and conditions of
+-    this License, without any additional terms or conditions.
+-    Notwithstanding the above, nothing herein shall supersede or modify
+-    the terms of any separate license agreement you may have executed
+-    with Licensor regarding such Contributions.
+-
+-6.  Trademarks. This License does not grant permission to use the trade
+-    names, trademarks, service marks, or product names of the Licensor,
+-    except as required for reasonable and customary use in describing the
+-    origin of the Work and reproducing the content of the NOTICE file.
+-
+-7.  Disclaimer of Warranty. Unless required by applicable law or
+-    agreed to in writing, Licensor provides the Work (and each
+-    Contributor provides its Contributions) on an "AS IS" BASIS,
+-    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+-    implied, including, without limitation, any warranties or conditions
+-    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+-    PARTICULAR PURPOSE. You are solely responsible for determining the
+-    appropriateness of using or redistributing the Work and assume any
+-    risks associated with Your exercise of permissions under this License.
+-
+-8.  Limitation of Liability. In no event and under no legal theory,
+-    whether in tort (including negligence), contract, or otherwise,
+-    unless required by applicable law (such as deliberate and grossly
+-    negligent acts) or agreed to in writing, shall any Contributor be
+-    liable to You for damages, including any direct, indirect, special,
+-    incidental, or consequential damages of any character arising as a
+-    result of this License or out of the use or inability to use the
+-    Work (including but not limited to damages for loss of goodwill,
+-    work stoppage, computer failure or malfunction, or any and all
+-    other commercial damages or losses), even if such Contributor
+-    has been advised of the possibility of such damages.
+-
+-9.  Accepting Warranty or Additional Liability. While redistributing
+-    the Work or Derivative Works thereof, You may choose to offer,
+-    and charge a fee for, acceptance of support, warranty, indemnity,
+-    or other liability obligations and/or rights consistent with this
+-    License. However, in accepting such obligations, You may act only
+-    on Your own behalf and on Your sole responsibility, not on behalf
+-    of any other Contributor, and only if You agree to indemnify,
+-    defend, and hold each Contributor harmless for any liability
+-    incurred by, or claims asserted against, such Contributor by reason
+-    of your accepting any such warranty or additional liability.
+-
+-END OF TERMS AND CONDITIONS
+-
+-APPENDIX: How to apply the Apache License to your work.
+-
+-      To apply the Apache License to your work, attach the following
+-      boilerplate notice, with the fields enclosed by brackets "[]"
+-      replaced with your own identifying information. (Don't include
+-      the brackets!)  The text should be enclosed in the appropriate
+-      comment syntax for the file format. We also recommend that a
+-      file or class name and description of purpose be included on the
+-      same "printed page" as the copyright notice for easier
+-      identification within third-party archives.
+-
+-Copyright 2025 OpenAI
+-
+-Licensed under the Apache License, Version 2.0 (the "License");
+-you may not use this file except in compliance with the License.
+-You may obtain a copy of the License at
+-
+-       http://www.apache.org/licenses/LICENSE-2.0
+-
+-Unless required by applicable law or agreed to in writing, software
+-distributed under the License is distributed on an "AS IS" BASIS,
+-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+-See the License for the specific language governing permissions and
+-limitations under the License.
++                                 Apache License
++                           Version 2.0, January 2004
++                        http://www.apache.org/licenses/
++
++TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
++
++1.  Definitions.
++
++    "License" shall mean the terms and conditions for use, reproduction,
++    and distribution as defined by Sections 1 through 9 of this document.
++
++    "Licensor" shall mean the copyright owner or entity authorized by
++    the copyright owner that is granting the License.
++
++    "Legal Entity" shall mean the union of the acting entity and all
++    other entities that control, are controlled by, or are under common
++    control with that entity. For the purposes of this definition,
++    "control" means (i) the power, direct or indirect, to cause the
++    direction or management of such entity, whether by contract or
++    otherwise, or (ii) ownership of fifty percent (50%) or more of the
++    outstanding shares, or (iii) beneficial ownership of such entity.
++
++    "You" (or "Your") shall mean an individual or Legal Entity
++    exercising permissions granted by this License.
++
++    "Source" form shall mean the preferred form for making modifications,
++    including but not limited to software source code, documentation
++    source, and configuration files.
++
++    "Object" form shall mean any form resulting from mechanical
++    transformation or translation of a Source form, including but
++    not limited to compiled object code, generated documentation,
++    and conversions to other media types.
++
++    "Work" shall mean the work of authorship, whether in Source or
++    Object form, made available under the License, as indicated by a
++    copyright notice that is included in or attached to the work
++    (an example is provided in the Appendix below).
++
++    "Derivative Works" shall mean any work, whether in Source or Object
++    form, that is based on (or derived from) the Work and for which the
++    editorial revisions, annotations, elaborations, or other modifications
++    represent, as a whole, an original work of authorship. For the purposes
++    of this License, Derivative Works shall not include works that remain
++    separable from, or merely link (or bind by name) to the interfaces of,
++    the Work and Derivative Works thereof.
++
++    "Contribution" shall mean any work of authorship, including
++    the original version of the Work and any modifications or additions
++    to that Work or Derivative Works thereof, that is intentionally
++    submitted to Licensor for inclusion in the Work by the copyright owner
++    or by an individual or Legal Entity authorized to submit on behalf of
++    the copyright owner. For the purposes of this definition, "submitted"
++    means any form of electronic, verbal, or written communication sent
++    to the Licensor or its representatives, including but not limited to
++    communication on electronic mailing lists, source code control systems,
++    and issue tracking systems that are managed by, or on behalf of, the
++    Licensor for the purpose of discussing and improving the Work, but
++    excluding communication that is conspicuously marked or otherwise
++    designated in writing by the copyright owner as "Not a Contribution."
++
++    "Contributor" shall mean Licensor and any individual or Legal Entity
++    on behalf of whom a Contribution has been received by Licensor and
++    subsequently incorporated within the Work.
++
++2.  Grant of Copyright License. Subject to the terms and conditions of
++    this License, each Contributor hereby grants to You a perpetual,
++    worldwide, non-exclusive, no-charge, royalty-free, irrevocable
++    copyright license to reproduce, prepare Derivative Works of,
++    publicly display, publicly perform, sublicense, and distribute the
++    Work and such Derivative Works in Source or Object form.
++
++3.  Grant of Patent License. Subject to the terms and conditions of
++    this License, each Contributor hereby grants to You a perpetual,
++    worldwide, non-exclusive, no-charge, royalty-free, irrevocable
++    (except as stated in this section) patent license to make, have made,
++    use, offer to sell, sell, import, and otherwise transfer the Work,
++    where such license applies only to those patent claims licensable
++    by such Contributor that are necessarily infringed by their
++    Contribution(s) alone or by combination of their Contribution(s)
++    with the Work to which such Contribution(s) was submitted. If You
++    institute patent litigation against any entity (including a
++    cross-claim or counterclaim in a lawsuit) alleging that the Work
++    or a Contribution incorporated within the Work constitutes direct
++    or contributory patent infringement, then any patent licenses
++    granted to You under this License for that Work shall terminate
++    as of the date such litigation is filed.
++
++4.  Redistribution. You may reproduce and distribute copies of the
++    Work or Derivative Works thereof in any medium, with or without
++    modifications, and in Source or Object form, provided that You
++    meet the following conditions:
++
++    (a) You must give any other recipients of the Work or
++    Derivative Works a copy of this License; and
++
++    (b) You must cause any modified files to carry prominent notices
++    stating that You changed the files; and
++
++    (c) You must retain, in the Source form of any Derivative Works
++    that You distribute, all copyright, patent, trademark, and
++    attribution notices from the Source form of the Work,
++    excluding those notices that do not pertain to any part of
++    the Derivative Works; and
++
++    (d) If the Work includes a "NOTICE" text file as part of its
++    distribution, then any Derivative Works that You distribute must
++    include a readable copy of the attribution notices contained
++    within such NOTICE file, excluding those notices that do not
++    pertain to any part of the Derivative Works, in at least one
++    of the following places: within a NOTICE text file distributed
++    as part of the Derivative Works; within the Source form or
++    documentation, if provided along with the Derivative Works; or,
++    within a display generated by the Derivative Works, if and
++    wherever such third-party notices normally appear. The contents
++    of the NOTICE file are for informational purposes only and
++    do not modify the License. You may add Your own attribution
++    notices within Derivative Works that You distribute, alongside
++    or as an addendum to the NOTICE text from the Work, provided
++    that such additional attribution notices cannot be construed
++    as modifying the License.
++
++    You may add Your own copyright statement to Your modifications and
++    may provide additional or different license terms and conditions
++    for use, reproduction, or distribution of Your modifications, or
++    for any such Derivative Works as a whole, provided Your use,
++    reproduction, and distribution of the Work otherwise complies with
++    the conditions stated in this License.
++
++5.  Submission of Contributions. Unless You explicitly state otherwise,
++    any Contribution intentionally submitted for inclusion in the Work
++    by You to the Licensor shall be under the terms and conditions of
++    this License, without any additional terms or conditions.
++    Notwithstanding the above, nothing herein shall supersede or modify
++    the terms of any separate license agreement you may have executed
++    with Licensor regarding such Contributions.
++
++6.  Trademarks. This License does not grant permission to use the trade
++    names, trademarks, service marks, or product names of the Licensor,
++    except as required for reasonable and customary use in describing the
++    origin of the Work and reproducing the content of the NOTICE file.
++
++7.  Disclaimer of Warranty. Unless required by applicable law or
++    agreed to in writing, Licensor provides the Work (and each
++    Contributor provides its Contributions) on an "AS IS" BASIS,
++    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
++    implied, including, without limitation, any warranties or conditions
++    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
++    PARTICULAR PURPOSE. You are solely responsible for determining the
++    appropriateness of using or redistributing the Work and assume any
++    risks associated with Your exercise of permissions under this License.
++
++8.  Limitation of Liability. In no event and under no legal theory,
++    whether in tort (including negligence), contract, or otherwise,
++    unless required by applicable law (such as deliberate and grossly
++    negligent acts) or agreed to in writing, shall any Contributor be
++    liable to You for damages, including any direct, indirect, special,
++    incidental, or consequential damages of any character arising as a
++    result of this License or out of the use or inability to use the
++    Work (including but not limited to damages for loss of goodwill,
++    work stoppage, computer failure or malfunction, or any and all
++    other commercial damages or losses), even if such Contributor
++    has been advised of the possibility of such damages.
++
++9.  Accepting Warranty or Additional Liability. While redistributing
++    the Work or Derivative Works thereof, You may choose to offer,
++    and charge a fee for, acceptance of support, warranty, indemnity,
++    or other liability obligations and/or rights consistent with this
++    License. However, in accepting such obligations, You may act only
++    on Your own behalf and on Your sole responsibility, not on behalf
++    of any other Contributor, and only if You agree to indemnify,
++    defend, and hold each Contributor harmless for any liability
++    incurred by, or claims asserted against, such Contributor by reason
++    of your accepting any such warranty or additional liability.
++
++END OF TERMS AND CONDITIONS
++
++APPENDIX: How to apply the Apache License to your work.
++
++      To apply the Apache License to your work, attach the following
++      boilerplate notice, with the fields enclosed by brackets "[]"
++      replaced with your own identifying information. (Don't include
++      the brackets!)  The text should be enclosed in the appropriate
++      comment syntax for the file format. We also recommend that a
++      file or class name and description of purpose be included on the
++      same "printed page" as the copyright notice for easier
++      identification within third-party archives.
++
++Copyright 2025 OpenAI
++
++Licensed under the Apache License, Version 2.0 (the "License");
++you may not use this file except in compliance with the License.
++You may obtain a copy of the License at
++
++       http://www.apache.org/licenses/LICENSE-2.0
++
++Unless required by applicable law or agreed to in writing, software
++distributed under the License is distributed on an "AS IS" BASIS,
++WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
++See the License for the specific language governing permissions and
++limitations under the License.
+diff --git a/NOTICE b/NOTICE
+index 2805899d..04137cca 100644
+--- a/NOTICE
++++ b/NOTICE
+@@ -1,6 +1,6 @@
+-OpenAI Codex
+-Copyright 2025 OpenAI
+-
+-This project includes code derived from [Ratatui](https://github.com/ratatui/ratatui), licensed under the MIT license.
+-Copyright (c) 2016-2022 Florian Dehau
+-Copyright (c) 2023-2025 The Ratatui Developers
++OpenAI Codex
++Copyright 2025 OpenAI
++
++This project includes code derived from [Ratatui](https://github.com/ratatui/ratatui), licensed under the MIT license.
++Copyright (c) 2016-2022 Florian Dehau
++Copyright (c) 2023-2025 The Ratatui Developers
+diff --git a/PNPM.md b/PNPM.md
+index 860633c8..daa4b729 100644
+--- a/PNPM.md
++++ b/PNPM.md
+@@ -1,70 +1,70 @@
+-# Migration to pnpm
+-
+-This project has been migrated from npm to pnpm to improve dependency management and developer experience.
+-
+-## Why pnpm?
+-
+-- **Faster installation**: pnpm is significantly faster than npm and yarn
+-- **Disk space savings**: pnpm uses a content-addressable store to avoid duplication
+-- **Phantom dependency prevention**: pnpm creates a strict node_modules structure
+-- **Native workspaces support**: simplified monorepo management
+-
+-## How to use pnpm
+-
+-### Installation
+-
+-```bash
+-# Global installation of pnpm
+-npm install -g pnpm@10.8.1
+-
+-# Or with corepack (available with Node.js 22+)
+-corepack enable
+-corepack prepare pnpm@10.8.1 --activate
+-```
+-
+-### Common commands
+-
+-| npm command     | pnpm equivalent  |
+-| --------------- | ---------------- |
+-| `npm install`   | `pnpm install`   |
+-| `npm run build` | `pnpm run build` |
+-| `npm test`      | `pnpm test`      |
+-| `npm run lint`  | `pnpm run lint`  |
+-
+-### Workspace-specific commands
+-
+-| Action                                     | Command                                  |
+-| ------------------------------------------ | ---------------------------------------- |
+-| Run a command in a specific package        | `pnpm --filter @openai/codex run build`  |
+-| Install a dependency in a specific package | `pnpm --filter @openai/codex add lodash` |
+-| Run a command in all packages              | `pnpm -r run test`                       |
+-
+-## Monorepo structure
+-
+-```
+-codex/
+-├── pnpm-workspace.yaml    # Workspace configuration
+-├── .npmrc                 # pnpm configuration
+-├── package.json           # Root dependencies and scripts
+-├── codex-cli/             # Main package
+-│   └── package.json       # codex-cli specific dependencies
+-└── docs/                  # Documentation (future package)
+-```
+-
+-## Configuration files
+-
+-- **pnpm-workspace.yaml**: Defines the packages included in the monorepo
+-- **.npmrc**: Configures pnpm behavior
+-- **Root package.json**: Contains shared scripts and dependencies
+-
+-## CI/CD
+-
+-CI/CD workflows have been updated to use pnpm instead of npm. Make sure your CI environments use pnpm 10.8.1 or higher.
+-
+-## Known issues
+-
+-If you encounter issues with pnpm, try the following solutions:
+-
+-1. Remove the `node_modules` folder and `pnpm-lock.yaml` file, then run `pnpm install`
+-2. Make sure you're using pnpm 10.8.1 or higher
+-3. Verify that Node.js 22 or higher is installed
++# Migration to pnpm
++
++This project has been migrated from npm to pnpm to improve dependency management and developer experience.
++
++## Why pnpm?
++
++- **Faster installation**: pnpm is significantly faster than npm and yarn
++- **Disk space savings**: pnpm uses a content-addressable store to avoid duplication
++- **Phantom dependency prevention**: pnpm creates a strict node_modules structure
++- **Native workspaces support**: simplified monorepo management
++
++## How to use pnpm
++
++### Installation
++
++```bash
++# Global installation of pnpm
++npm install -g pnpm@10.8.1
++
++# Or with corepack (available with Node.js 22+)
++corepack enable
++corepack prepare pnpm@10.8.1 --activate
++```
++
++### Common commands
++
++| npm command     | pnpm equivalent  |
++| --------------- | ---------------- |
++| `npm install`   | `pnpm install`   |
++| `npm run build` | `pnpm run build` |
++| `npm test`      | `pnpm test`      |
++| `npm run lint`  | `pnpm run lint`  |
++
++### Workspace-specific commands
++
++| Action                                     | Command                                  |
++| ------------------------------------------ | ---------------------------------------- |
++| Run a command in a specific package        | `pnpm --filter @openai/codex run build`  |
++| Install a dependency in a specific package | `pnpm --filter @openai/codex add lodash` |
++| Run a command in all packages              | `pnpm -r run test`                       |
++
++## Monorepo structure
++
++```
++codex/
++├── pnpm-workspace.yaml    # Workspace configuration
++├── .npmrc                 # pnpm configuration
++├── package.json           # Root dependencies and scripts
++├── codex-cli/             # Main package
++│   └── package.json       # codex-cli specific dependencies
++└── docs/                  # Documentation (future package)
++```
++
++## Configuration files
++
++- **pnpm-workspace.yaml**: Defines the packages included in the monorepo
++- **.npmrc**: Configures pnpm behavior
++- **Root package.json**: Contains shared scripts and dependencies
++
++## CI/CD
++
++CI/CD workflows have been updated to use pnpm instead of npm. Make sure your CI environments use pnpm 10.8.1 or higher.
++
++## Known issues
++
++If you encounter issues with pnpm, try the following solutions:
++
++1. Remove the `node_modules` folder and `pnpm-lock.yaml` file, then run `pnpm install`
++2. Make sure you're using pnpm 10.8.1 or higher
++3. Verify that Node.js 22 or higher is installed
+diff --git a/README.md b/README.md
+index c9cc4e1f..aa625f8c 100644
+--- a/README.md
++++ b/README.md
+@@ -1,104 +1,104 @@
+-<p align="center"><code>npm i -g @openai/codex</code><br />or <code>brew install codex</code></p>
+-
+-<p align="center"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.
+-</br>
+-</br>If you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href="https://developers.openai.com/codex/ide">install in your IDE</a>
+-</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href="https://chatgpt.com/codex">chatgpt.com/codex</a></p>
+-
+-<p align="center">
+-  <img src="./.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" />
+-  </p>
+-
+----
+-
+-## Quickstart
+-
+-### Installing and running Codex CLI
+-
+-Install globally with your preferred package manager. If you use npm:
+-
+-```shell
+-npm install -g @openai/codex
+-```
+-
+-Alternatively, if you use Homebrew:
+-
+-```shell
+-brew install codex
+-```
+-
+-Then simply run `codex` to get started:
+-
+-```shell
+-codex
+-```
+-
+-<details>
+-<summary>You can also go to the <a href="https://github.com/openai/codex/releases/latest">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>
+-
+-Each GitHub Release contains many executables, but in practice, you likely want one of these:
+-
+-- macOS
+-  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
+-  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
+-- Linux
+-  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
+-  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`
+-
+-Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.
+-
+-</details>
+-
+-### Using Codex with your ChatGPT plan
+-
+-<p align="center">
+-  <img src="./.github/codex-cli-login.png" alt="Codex CLI login" width="80%" />
+-  </p>
+-
+-Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).
+-
+-You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you're having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).
+-
+-### Model Context Protocol (MCP)
+-
+-Codex can access MCP servers. To configure them, refer to the [config docs](./docs/config.md#mcp_servers).
+-
+-### Configuration
+-
+-Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).
+-
+----
+-
+-### Docs & FAQ
+-
+-- [**Getting started**](./docs/getting-started.md)
+-  - [CLI usage](./docs/getting-started.md#cli-usage)
+-  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
+-  - [Example prompts](./docs/getting-started.md#example-prompts)
+-  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
+-  - [Configuration](./docs/config.md)
+-- [**Sandbox & approvals**](./docs/sandbox.md)
+-- [**Authentication**](./docs/authentication.md)
+-  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
+-  - [Login on a "Headless" machine](./docs/authentication.md#connecting-on-a-headless-machine)
+-- **Automating Codex**
+-  - [GitHub Action](https://github.com/openai/codex-action)
+-  - [TypeScript SDK](./sdk/typescript/README.md)
+-  - [Non-interactive mode (`codex exec`)](./docs/exec.md)
+-- [**Advanced**](./docs/advanced.md)
+-  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
+-  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
+-- [**Zero data retention (ZDR)**](./docs/zdr.md)
+-- [**Contributing**](./docs/contributing.md)
+-- [**Install & build**](./docs/install.md)
+-  - [System Requirements](./docs/install.md#system-requirements)
+-  - [DotSlash](./docs/install.md#dotslash)
+-  - [Build from source](./docs/install.md#build-from-source)
+-- [**FAQ**](./docs/faq.md)
+-- [**Open source fund**](./docs/open-source-fund.md)
+-
+----
+-
+-## License
+-
+-This repository is licensed under the [Apache-2.0 License](LICENSE).
++<p align="center"><code>npm i -g @openai/codex</code><br />or <code>brew install codex</code></p>
++
++<p align="center"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.
++</br>
++</br>If you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href="https://developers.openai.com/codex/ide">install in your IDE</a>
++</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href="https://chatgpt.com/codex">chatgpt.com/codex</a></p>
++
++<p align="center">
++  <img src="./.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" />
++  </p>
++
++---
++
++## Quickstart
++
++### Installing and running Codex CLI
++
++Install globally with your preferred package manager. If you use npm:
++
++```shell
++npm install -g @openai/codex
++```
++
++Alternatively, if you use Homebrew:
++
++```shell
++brew install codex
++```
++
++Then simply run `codex` to get started:
++
++```shell
++codex
++```
++
++<details>
++<summary>You can also go to the <a href="https://github.com/openai/codex/releases/latest">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>
++
++Each GitHub Release contains many executables, but in practice, you likely want one of these:
++
++- macOS
++  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
++  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
++- Linux
++  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
++  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`
++
++Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.
++
++</details>
++
++### Using Codex with your ChatGPT plan
++
++<p align="center">
++  <img src="./.github/codex-cli-login.png" alt="Codex CLI login" width="80%" />
++  </p>
++
++Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).
++
++You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you're having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).
++
++### Model Context Protocol (MCP)
++
++Codex can access MCP servers. To configure them, refer to the [config docs](./docs/config.md#mcp_servers).
++
++### Configuration
++
++Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).
++
++---
++
++### Docs & FAQ
++
++- [**Getting started**](./docs/getting-started.md)
++  - [CLI usage](./docs/getting-started.md#cli-usage)
++  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
++  - [Example prompts](./docs/getting-started.md#example-prompts)
++  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
++  - [Configuration](./docs/config.md)
++- [**Sandbox & approvals**](./docs/sandbox.md)
++- [**Authentication**](./docs/authentication.md)
++  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
++  - [Login on a "Headless" machine](./docs/authentication.md#connecting-on-a-headless-machine)
++- **Automating Codex**
++  - [GitHub Action](https://github.com/openai/codex-action)
++  - [TypeScript SDK](./sdk/typescript/README.md)
++  - [Non-interactive mode (`codex exec`)](./docs/exec.md)
++- [**Advanced**](./docs/advanced.md)
++  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
++  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
++- [**Zero data retention (ZDR)**](./docs/zdr.md)
++- [**Contributing**](./docs/contributing.md)
++- [**Install & build**](./docs/install.md)
++  - [System Requirements](./docs/install.md#system-requirements)
++  - [DotSlash](./docs/install.md#dotslash)
++  - [Build from source](./docs/install.md#build-from-source)
++- [**FAQ**](./docs/faq.md)
++- [**Open source fund**](./docs/open-source-fund.md)
++
++---
++
++## License
++
++This repository is licensed under the [Apache-2.0 License](LICENSE).
+diff --git a/cliff.toml b/cliff.toml
+index 30aa1f1a..f0417f57 100644
+--- a/cliff.toml
++++ b/cliff.toml
+@@ -1,46 +1,46 @@
+-# https://git-cliff.org/docs/configuration
+-
+-[changelog]
+-header = """
+-# Changelog
+-
+-You can install any of these versions: `npm install -g codex@version`
+-"""
+-
+-body = """
+-{% if version -%}
+-## [{{ version | trim_start_matches(pat="v") }}] - {{ timestamp | date(format="%Y-%m-%d") }}
+-{%- else %}
+-## [unreleased]
+-{% endif %}
+-
+-{%- for group, commits in commits | group_by(attribute="group") %}
+-### {{ group | striptags | trim }}
+-
+-{% for commit in commits %}- {% if commit.scope %}*({{ commit.scope }})* {% endif %}{% if commit.breaking %}[**breaking**] {% endif %}{{ commit.message | upper_first }}
+-{% endfor %}
+-
+-{%- endfor -%}
+-"""
+-
+-footer = """
+-<!-- generated - do not edit -->
+-"""
+-
+-trim = true
+-postprocessors = []
+-
+-[git]
+-conventional_commits = true
+-
+-commit_parsers = [
+-  { message = "^feat", group = "<!-- 0 -->🚀 Features" },
+-  { message = "^fix",  group = "<!-- 1 -->🪲 Bug Fixes" },
+-  { message = "^bump", group = "<!-- 6 -->🛳️ Release" },
+-  # Fallback – skip anything that didn't match the above rules.
+-  { message = ".*",  group = "<!-- 10 -->💼 Other" },
+-]
+-
+-filter_unconventional = false
+-sort_commits = "oldest"
++# https://git-cliff.org/docs/configuration
++
++[changelog]
++header = """
++# Changelog
++
++You can install any of these versions: `npm install -g codex@version`
++"""
++
++body = """
++{% if version -%}
++## [{{ version | trim_start_matches(pat="v") }}] - {{ timestamp | date(format="%Y-%m-%d") }}
++{%- else %}
++## [unreleased]
++{% endif %}
++
++{%- for group, commits in commits | group_by(attribute="group") %}
++### {{ group | striptags | trim }}
++
++{% for commit in commits %}- {% if commit.scope %}*({{ commit.scope }})* {% endif %}{% if commit.breaking %}[**breaking**] {% endif %}{{ commit.message | upper_first }}
++{% endfor %}
++
++{%- endfor -%}
++"""
++
++footer = """
++<!-- generated - do not edit -->
++"""
++
++trim = true
++postprocessors = []
++
++[git]
++conventional_commits = true
++
++commit_parsers = [
++  { message = "^feat", group = "<!-- 0 -->🚀 Features" },
++  { message = "^fix",  group = "<!-- 1 -->🪲 Bug Fixes" },
++  { message = "^bump", group = "<!-- 6 -->🛳️ Release" },
++  # Fallback – skip anything that didn't match the above rules.
++  { message = ".*",  group = "<!-- 10 -->💼 Other" },
++]
++
++filter_unconventional = false
++sort_commits = "oldest"
+ topo_order = false
+\ No newline at end of file
+diff --git a/codex-cli/.dockerignore b/codex-cli/.dockerignore
+index c2658d7d..bca51b35 100644
+--- a/codex-cli/.dockerignore
++++ b/codex-cli/.dockerignore
+@@ -1 +1 @@
+-node_modules/
++node_modules/
+diff --git a/codex-cli/.gitignore b/codex-cli/.gitignore
+index 57872d0f..a4655bff 100644
+--- a/codex-cli/.gitignore
++++ b/codex-cli/.gitignore
+@@ -1 +1 @@
+-/vendor/
++/vendor/
+diff --git a/codex-cli/Dockerfile b/codex-cli/Dockerfile
+index 21a90a48..a6a9c138 100644
+--- a/codex-cli/Dockerfile
++++ b/codex-cli/Dockerfile
+@@ -1,59 +1,59 @@
+-FROM node:24-slim
+-
+-ARG TZ
+-ENV TZ="$TZ"
+-
+-# Install basic development tools, ca-certificates, and iptables/ipset, then clean up apt cache to reduce image size
+-RUN apt-get update && apt-get install -y --no-install-recommends \
+-  aggregate \
+-  ca-certificates \
+-  curl \
+-  dnsutils \
+-  fzf \
+-  gh \
+-  git \
+-  gnupg2 \
+-  iproute2 \
+-  ipset \
+-  iptables \
+-  jq \
+-  less \
+-  man-db \
+-  procps \
+-  unzip \
+-  ripgrep \
+-  zsh \
+-  && rm -rf /var/lib/apt/lists/*
+-
+-# Ensure default node user has access to /usr/local/share
+-RUN mkdir -p /usr/local/share/npm-global && \
+-  chown -R node:node /usr/local/share
+-
+-ARG USERNAME=node
+-
+-# Set up non-root user
+-USER node
+-
+-# Install global packages
+-ENV NPM_CONFIG_PREFIX=/usr/local/share/npm-global
+-ENV PATH=$PATH:/usr/local/share/npm-global/bin
+-
+-# Install codex
+-COPY dist/codex.tgz codex.tgz
+-RUN npm install -g codex.tgz \
+-  && npm cache clean --force \
+-  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/node_modules/.cache \
+-  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/tests \
+-  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/docs
+-
+-# Inside the container we consider the environment already sufficiently locked
+-# down, therefore instruct Codex CLI to allow running without sandboxing.
+-ENV CODEX_UNSAFE_ALLOW_NO_SANDBOX=1
+-
+-# Copy and set up firewall script as root.
+-USER root
+-COPY scripts/init_firewall.sh /usr/local/bin/
+-RUN chmod 500 /usr/local/bin/init_firewall.sh
+-
+-# Drop back to non-root.
+-USER node
++FROM node:24-slim
++
++ARG TZ
++ENV TZ="$TZ"
++
++# Install basic development tools, ca-certificates, and iptables/ipset, then clean up apt cache to reduce image size
++RUN apt-get update && apt-get install -y --no-install-recommends \
++  aggregate \
++  ca-certificates \
++  curl \
++  dnsutils \
++  fzf \
++  gh \
++  git \
++  gnupg2 \
++  iproute2 \
++  ipset \
++  iptables \
++  jq \
++  less \
++  man-db \
++  procps \
++  unzip \
++  ripgrep \
++  zsh \
++  && rm -rf /var/lib/apt/lists/*
++
++# Ensure default node user has access to /usr/local/share
++RUN mkdir -p /usr/local/share/npm-global && \
++  chown -R node:node /usr/local/share
++
++ARG USERNAME=node
++
++# Set up non-root user
++USER node
++
++# Install global packages
++ENV NPM_CONFIG_PREFIX=/usr/local/share/npm-global
++ENV PATH=$PATH:/usr/local/share/npm-global/bin
++
++# Install codex
++COPY dist/codex.tgz codex.tgz
++RUN npm install -g codex.tgz \
++  && npm cache clean --force \
++  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/node_modules/.cache \
++  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/tests \
++  && rm -rf /usr/local/share/npm-global/lib/node_modules/codex-cli/docs
++
++# Inside the container we consider the environment already sufficiently locked
++# down, therefore instruct Codex CLI to allow running without sandboxing.
++ENV CODEX_UNSAFE_ALLOW_NO_SANDBOX=1
++
++# Copy and set up firewall script as root.
++USER root
++COPY scripts/init_firewall.sh /usr/local/bin/
++RUN chmod 500 /usr/local/bin/init_firewall.sh
++
++# Drop back to non-root.
++USER node
+diff --git a/codex-cli/README.md b/codex-cli/README.md
+index f3414f1c..48339974 100644
+--- a/codex-cli/README.md
++++ b/codex-cli/README.md
+@@ -1,736 +1,736 @@
+-<h1 align="center">OpenAI Codex CLI</h1>
+-<p align="center">Lightweight coding agent that runs in your terminal</p>
+-
+-<p align="center"><code>npm i -g @openai/codex</code></p>
+-
+-> [!IMPORTANT]
+-> This is the documentation for the _legacy_ TypeScript implementation of the Codex CLI. It has been superseded by the _Rust_ implementation. See the [README in the root of the Codex repository](https://github.com/openai/codex/blob/main/README.md) for details.
+-
+-![Codex demo GIF using: codex "explain this codebase to me"](../.github/demo.gif)
+-
+----
+-
+-<details>
+-<summary><strong>Table of contents</strong></summary>
+-
+-<!-- Begin ToC -->
+-
+-- [Experimental technology disclaimer](#experimental-technology-disclaimer)
+-- [Quickstart](#quickstart)
+-- [Why Codex?](#why-codex)
+-- [Security model & permissions](#security-model--permissions)
+-  - [Platform sandboxing details](#platform-sandboxing-details)
+-- [System requirements](#system-requirements)
+-- [CLI reference](#cli-reference)
+-- [Memory & project docs](#memory--project-docs)
+-- [Non-interactive / CI mode](#non-interactive--ci-mode)
+-- [Tracing / verbose logging](#tracing--verbose-logging)
+-- [Recipes](#recipes)
+-- [Installation](#installation)
+-- [Configuration guide](#configuration-guide)
+-  - [Basic configuration parameters](#basic-configuration-parameters)
+-  - [Custom AI provider configuration](#custom-ai-provider-configuration)
+-  - [History configuration](#history-configuration)
+-  - [Configuration examples](#configuration-examples)
+-  - [Full configuration example](#full-configuration-example)
+-  - [Custom instructions](#custom-instructions)
+-  - [Environment variables setup](#environment-variables-setup)
+-- [FAQ](#faq)
+-- [Zero data retention (ZDR) usage](#zero-data-retention-zdr-usage)
+-- [Codex open source fund](#codex-open-source-fund)
+-- [Contributing](#contributing)
+-  - [Development workflow](#development-workflow)
+-  - [Git hooks with Husky](#git-hooks-with-husky)
+-  - [Debugging](#debugging)
+-  - [Writing high-impact code changes](#writing-high-impact-code-changes)
+-  - [Opening a pull request](#opening-a-pull-request)
+-  - [Review process](#review-process)
+-  - [Community values](#community-values)
+-  - [Getting help](#getting-help)
+-  - [Contributor license agreement (CLA)](#contributor-license-agreement-cla)
+-    - [Quick fixes](#quick-fixes)
+-  - [Releasing `codex`](#releasing-codex)
+-  - [Alternative build options](#alternative-build-options)
+-    - [Nix flake development](#nix-flake-development)
+-- [Security & responsible AI](#security--responsible-ai)
+-- [License](#license)
+-
+-<!-- End ToC -->
+-
+-</details>
+-
+----
+-
+-## Experimental technology disclaimer
+-
+-Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:
+-
+-- Bug reports
+-- Feature requests
+-- Pull requests
+-- Good vibes
+-
+-Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!
+-
+-## Quickstart
+-
+-Install globally:
+-
+-```shell
+-npm install -g @openai/codex
+-```
+-
+-Next, set your OpenAI API key as an environment variable:
+-
+-```shell
+-export OPENAI_API_KEY="your-api-key-here"
+-```
+-
+-> **Note:** This command sets the key only for your current terminal session. You can add the `export` line to your shell's configuration file (e.g., `~/.zshrc`) but we recommend setting for the session. **Tip:** You can also place your API key into a `.env` file at the root of your project:
+->
+-> ```env
+-> OPENAI_API_KEY=your-api-key-here
+-> ```
+->
+-> The CLI will automatically load variables from `.env` (via `dotenv/config`).
+-
+-<details>
+-<summary><strong>Use <code>--provider</code> to use other models</strong></summary>
+-
+-> Codex also allows you to use other providers that support the OpenAI Chat Completions API. You can set the provider in the config file or use the `--provider` flag. The possible options for `--provider` are:
+->
+-> - openai (default)
+-> - openrouter
+-> - azure
+-> - gemini
+-> - ollama
+-> - mistral
+-> - deepseek
+-> - xai
+-> - groq
+-> - arceeai
+-> - any other provider that is compatible with the OpenAI API
+->
+-> If you use a provider other than OpenAI, you will need to set the API key for the provider in the config file or in the environment variable as:
+->
+-> ```shell
+-> export <provider>_API_KEY="your-api-key-here"
+-> ```
+->
+-> If you use a provider not listed above, you must also set the base URL for the provider:
+->
+-> ```shell
+-> export <provider>_BASE_URL="https://your-provider-api-base-url"
+-> ```
+-
+-</details>
+-<br />
+-
+-Run interactively:
+-
+-```shell
+-codex
+-```
+-
+-Or, run with a prompt as input (and optionally in `Full Auto` mode):
+-
+-```shell
+-codex "explain this codebase to me"
+-```
+-
+-```shell
+-codex --approval-mode full-auto "create the fanciest todo-list app"
+-```
+-
+-That's it - Codex will scaffold a file, run it inside a sandbox, install any
+-missing dependencies, and show you the live result. Approve the changes and
+-they'll be committed to your working directory.
+-
+----
+-
+-## Why Codex?
+-
+-Codex CLI is built for developers who already **live in the terminal** and want
+-ChatGPT-level reasoning **plus** the power to actually run code, manipulate
+-files, and iterate - all under version control. In short, it's _chat-driven
+-development_ that understands and executes your repo.
+-
+-- **Zero setup** - bring your OpenAI API key and it just works!
+-- **Full auto-approval, while safe + secure** by running network-disabled and directory-sandboxed
+-- **Multimodal** - pass in screenshots or diagrams to implement features ✨
+-
+-And it's **fully open-source** so you can see and contribute to how it develops!
+-
+----
+-
+-## Security model & permissions
+-
+-Codex lets you decide _how much autonomy_ the agent receives and auto-approval policy via the
+-`--approval-mode` flag (or the interactive onboarding prompt):
+-
+-| Mode                      | What the agent may do without asking                                                                | Still requires approval                                                                         |
+-| ------------------------- | --------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
+-| **Suggest** <br>(default) | <li>Read any file in the repo                                                                       | <li>**All** file writes/patches<li> **Any** arbitrary shell commands (aside from reading files) |
+-| **Auto Edit**             | <li>Read **and** apply-patch writes to files                                                        | <li>**All** shell commands                                                                      |
+-| **Full Auto**             | <li>Read/write files <li> Execute shell commands (network disabled, writes limited to your workdir) | -                                                                                               |
+-
+-In **Full Auto** every command is run **network-disabled** and confined to the
+-current working directory (plus temporary files) for defense-in-depth. Codex
+-will also show a warning/confirmation if you start in **auto-edit** or
+-**full-auto** while the directory is _not_ tracked by Git, so you always have a
+-safety net.
+-
+-Coming soon: you'll be able to whitelist specific commands to auto-execute with
+-the network enabled, once we're confident in additional safeguards.
+-
+-### Platform sandboxing details
+-
+-The hardening mechanism Codex uses depends on your OS:
+-
+-- **macOS 12+** - commands are wrapped with **Apple Seatbelt** (`sandbox-exec`).
+-
+-  - Everything is placed in a read-only jail except for a small set of
+-    writable roots (`$PWD`, `$TMPDIR`, `~/.codex`, etc.).
+-  - Outbound network is _fully blocked_ by default - even if a child process
+-    tries to `curl` somewhere it will fail.
+-
+-- **Linux** - there is no sandboxing by default.
+-  We recommend using Docker for sandboxing, where Codex launches itself inside a **minimal
+-  container image** and mounts your repo _read/write_ at the same path. A
+-  custom `iptables`/`ipset` firewall script denies all egress except the
+-  OpenAI API. This gives you deterministic, reproducible runs without needing
+-  root on the host. You can use the [`run_in_container.sh`](../codex-cli/scripts/run_in_container.sh) script to set up the sandbox.
+-
+----
+-
+-## System requirements
+-
+-| Requirement                 | Details                                                         |
+-| --------------------------- | --------------------------------------------------------------- |
+-| Operating systems           | macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 **via WSL2** |
+-| Node.js                     | **16 or newer** (Node 20 LTS recommended)                       |
+-| Git (optional, recommended) | 2.23+ for built-in PR helpers                                   |
+-| RAM                         | 4-GB minimum (8-GB recommended)                                 |
+-
+-> Never run `sudo npm install -g`; fix npm permissions instead.
+-
+----
+-
+-## CLI reference
+-
+-| Command                              | Purpose                             | Example                              |
+-| ------------------------------------ | ----------------------------------- | ------------------------------------ |
+-| `codex`                              | Interactive REPL                    | `codex`                              |
+-| `codex "..."`                        | Initial prompt for interactive REPL | `codex "fix lint errors"`            |
+-| `codex -q "..."`                     | Non-interactive "quiet mode"        | `codex -q --json "explain utils.ts"` |
+-| `codex completion <bash\|zsh\|fish>` | Print shell completion script       | `codex completion bash`              |
+-
+-Key flags: `--model/-m`, `--approval-mode/-a`, `--quiet/-q`, and `--notify`.
+-
+----
+-
+-## Memory & project docs
+-
+-You can give Codex extra instructions and guidance using `AGENTS.md` files. Codex looks for `AGENTS.md` files in the following places, and merges them top-down:
+-
+-1. `~/.codex/AGENTS.md` - personal global guidance
+-2. `AGENTS.md` at repo root - shared project notes
+-3. `AGENTS.md` in the current working directory - sub-folder/feature specifics
+-
+-Disable loading of these files with `--no-project-doc` or the environment variable `CODEX_DISABLE_PROJECT_DOC=1`.
+-
+----
+-
+-## Non-interactive / CI mode
+-
+-Run Codex head-less in pipelines. Example GitHub Action step:
+-
+-```yaml
+-- name: Update changelog via Codex
+-  run: |
+-    npm install -g @openai/codex
+-    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
+-    codex -a auto-edit --quiet "update CHANGELOG for next release"
+-```
+-
+-Set `CODEX_QUIET_MODE=1` to silence interactive UI noise.
+-
+-## Tracing / verbose logging
+-
+-Setting the environment variable `DEBUG=true` prints full API request and response details:
+-
+-```shell
+-DEBUG=true codex
+-```
+-
+----
+-
+-## Recipes
+-
+-Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the [prompting guide](https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md) for more tips and usage patterns.
+-
+-| ✨  | What you type                                                                   | What happens                                                               |
+-| --- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
+-| 1   | `codex "Refactor the Dashboard component to React Hooks"`                       | Codex rewrites the class component, runs `npm test`, and shows the diff.   |
+-| 2   | `codex "Generate SQL migrations for adding a users table"`                      | Infers your ORM, creates migration files, and runs them in a sandboxed DB. |
+-| 3   | `codex "Write unit tests for utils/date.ts"`                                    | Generates tests, executes them, and iterates until they pass.              |
+-| 4   | `codex "Bulk-rename *.jpeg -> *.jpg with git mv"`                               | Safely renames files and updates imports/usages.                           |
+-| 5   | `codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"`                      | Outputs a step-by-step human explanation.                                  |
+-| 6   | `codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"` | Suggests impactful PRs in the current codebase.                            |
+-| 7   | `codex "Look for vulnerabilities and create a security review report"`          | Finds and explains security bugs.                                          |
+-
+----
+-
+-## Installation
+-
+-<details open>
+-<summary><strong>From npm (Recommended)</strong></summary>
+-
+-```bash
+-npm install -g @openai/codex
+-# or
+-yarn global add @openai/codex
+-# or
+-bun install -g @openai/codex
+-# or
+-pnpm add -g @openai/codex
+-```
+-
+-</details>
+-
+-<details>
+-<summary><strong>Build from source</strong></summary>
+-
+-```bash
+-# Clone the repository and navigate to the CLI package
+-git clone https://github.com/openai/codex.git
+-cd codex/codex-cli
+-
+-# Enable corepack
+-corepack enable
+-
+-# Install dependencies and build
+-pnpm install
+-pnpm build
+-
+-# Linux-only: download prebuilt sandboxing binaries (requires gh and zstd).
+-./scripts/install_native_deps.sh
+-
+-# Get the usage and the options
+-node ./dist/cli.js --help
+-
+-# Run the locally-built CLI directly
+-node ./dist/cli.js
+-
+-# Or link the command globally for convenience
+-pnpm link
+-```
+-
+-</details>
+-
+----
+-
+-## Configuration guide
+-
+-Codex configuration files can be placed in the `~/.codex/` directory, supporting both YAML and JSON formats.
+-
+-### Basic configuration parameters
+-
+-| Parameter           | Type    | Default    | Description                      | Available Options                                                                              |
+-| ------------------- | ------- | ---------- | -------------------------------- | ---------------------------------------------------------------------------------------------- |
+-| `model`             | string  | `o4-mini`  | AI model to use                  | Any model name supporting OpenAI API                                                           |
+-| `approvalMode`      | string  | `suggest`  | AI assistant's permission mode   | `suggest` (suggestions only)<br>`auto-edit` (automatic edits)<br>`full-auto` (fully automatic) |
+-| `fullAutoErrorMode` | string  | `ask-user` | Error handling in full-auto mode | `ask-user` (prompt for user input)<br>`ignore-and-continue` (ignore and proceed)               |
+-| `notify`            | boolean | `true`     | Enable desktop notifications     | `true`/`false`                                                                                 |
+-
+-### Custom AI provider configuration
+-
+-In the `providers` object, you can configure multiple AI service providers. Each provider requires the following parameters:
+-
+-| Parameter | Type   | Description                             | Example                       |
+-| --------- | ------ | --------------------------------------- | ----------------------------- |
+-| `name`    | string | Display name of the provider            | `"OpenAI"`                    |
+-| `baseURL` | string | API service URL                         | `"https://api.openai.com/v1"` |
+-| `envKey`  | string | Environment variable name (for API key) | `"OPENAI_API_KEY"`            |
+-
+-### History configuration
+-
+-In the `history` object, you can configure conversation history settings:
+-
+-| Parameter           | Type    | Description                                            | Example Value |
+-| ------------------- | ------- | ------------------------------------------------------ | ------------- |
+-| `maxSize`           | number  | Maximum number of history entries to save              | `1000`        |
+-| `saveHistory`       | boolean | Whether to save history                                | `true`        |
+-| `sensitivePatterns` | array   | Patterns of sensitive information to filter in history | `[]`          |
+-
+-### Configuration examples
+-
+-1. YAML format (save as `~/.codex/config.yaml`):
+-
+-```yaml
+-model: o4-mini
+-approvalMode: suggest
+-fullAutoErrorMode: ask-user
+-notify: true
+-```
+-
+-2. JSON format (save as `~/.codex/config.json`):
+-
+-```json
+-{
+-  "model": "o4-mini",
+-  "approvalMode": "suggest",
+-  "fullAutoErrorMode": "ask-user",
+-  "notify": true
+-}
+-```
+-
+-### Full configuration example
+-
+-Below is a comprehensive example of `config.json` with multiple custom providers:
+-
+-```json
+-{
+-  "model": "o4-mini",
+-  "provider": "openai",
+-  "providers": {
+-    "openai": {
+-      "name": "OpenAI",
+-      "baseURL": "https://api.openai.com/v1",
+-      "envKey": "OPENAI_API_KEY"
+-    },
+-    "azure": {
+-      "name": "AzureOpenAI",
+-      "baseURL": "https://YOUR_PROJECT_NAME.openai.azure.com/openai",
+-      "envKey": "AZURE_OPENAI_API_KEY"
+-    },
+-    "openrouter": {
+-      "name": "OpenRouter",
+-      "baseURL": "https://openrouter.ai/api/v1",
+-      "envKey": "OPENROUTER_API_KEY"
+-    },
+-    "gemini": {
+-      "name": "Gemini",
+-      "baseURL": "https://generativelanguage.googleapis.com/v1beta/openai",
+-      "envKey": "GEMINI_API_KEY"
+-    },
+-    "ollama": {
+-      "name": "Ollama",
+-      "baseURL": "http://localhost:11434/v1",
+-      "envKey": "OLLAMA_API_KEY"
+-    },
+-    "mistral": {
+-      "name": "Mistral",
+-      "baseURL": "https://api.mistral.ai/v1",
+-      "envKey": "MISTRAL_API_KEY"
+-    },
+-    "deepseek": {
+-      "name": "DeepSeek",
+-      "baseURL": "https://api.deepseek.com",
+-      "envKey": "DEEPSEEK_API_KEY"
+-    },
+-    "xai": {
+-      "name": "xAI",
+-      "baseURL": "https://api.x.ai/v1",
+-      "envKey": "XAI_API_KEY"
+-    },
+-    "groq": {
+-      "name": "Groq",
+-      "baseURL": "https://api.groq.com/openai/v1",
+-      "envKey": "GROQ_API_KEY"
+-    },
+-    "arceeai": {
+-      "name": "ArceeAI",
+-      "baseURL": "https://conductor.arcee.ai/v1",
+-      "envKey": "ARCEEAI_API_KEY"
+-    }
+-  },
+-  "history": {
+-    "maxSize": 1000,
+-    "saveHistory": true,
+-    "sensitivePatterns": []
+-  }
+-}
+-```
+-
+-### Custom instructions
+-
+-You can create a `~/.codex/AGENTS.md` file to define custom guidance for the agent:
+-
+-```markdown
+-- Always respond with emojis
+-- Only use git commands when explicitly requested
+-```
+-
+-### Environment variables setup
+-
+-For each AI provider, you need to set the corresponding API key in your environment variables. For example:
+-
+-```bash
+-# OpenAI
+-export OPENAI_API_KEY="your-api-key-here"
+-
+-# Azure OpenAI
+-export AZURE_OPENAI_API_KEY="your-azure-api-key-here"
+-export AZURE_OPENAI_API_VERSION="2025-04-01-preview" (Optional)
+-
+-# OpenRouter
+-export OPENROUTER_API_KEY="your-openrouter-key-here"
+-
+-# Similarly for other providers
+-```
+-
+----
+-
+-## FAQ
+-
+-<details>
+-<summary>OpenAI released a model called Codex in 2021 - is this related?</summary>
+-
+-In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.
+-
+-</details>
+-
+-<details>
+-<summary>Which models are supported?</summary>
+-
+-Any model available with [Responses API](https://platform.openai.com/docs/api-reference/responses). The default is `o4-mini`, but pass `--model gpt-4.1` or set `model: gpt-4.1` in your config file to override.
+-
+-</details>
+-<details>
+-<summary>Why does <code>o3</code> or <code>o4-mini</code> not work for me?</summary>
+-
+-It's possible that your [API account needs to be verified](https://help.openai.com/en/articles/10910291-api-organization-verification) in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!
+-
+-</details>
+-
+-<details>
+-<summary>How do I stop Codex from editing my files?</summary>
+-
+-Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type **n** to deny the command or give the model feedback.
+-
+-</details>
+-<details>
+-<summary>Does it work on Windows?</summary>
+-
+-Not directly. It requires [Windows Subsystem for Linux (WSL2)](https://learn.microsoft.com/en-us/windows/wsl/install) - Codex is regularly tested on macOS and Linux with Node 20+, and also supports Node 16.
+-
+-</details>
+-
+----
+-
+-## Zero data retention (ZDR) usage
+-
+-Codex CLI **does** support OpenAI organizations with [Zero Data Retention (ZDR)](https://platform.openai.com/docs/guides/your-data#zero-data-retention) enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:
+-
+-```
+-OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
+-```
+-
+-You may need to upgrade to a more recent version with: `npm i -g @openai/codex@latest`
+-
+----
+-
+-## Codex open source fund
+-
+-We're excited to launch a **$1 million initiative** supporting open source projects that use Codex CLI and other OpenAI models.
+-
+-- Grants are awarded up to **$25,000** API credits.
+-- Applications are reviewed **on a rolling basis**.
+-
+-**Interested? [Apply here](https://openai.com/form/codex-open-source-fund/).**
+-
+----
+-
+-## Contributing
+-
+-This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!
+-
+-More broadly we welcome contributions - whether you are opening your very first pull request or you're a seasoned maintainer. At the same time we care about reliability and long-term maintainability, so the bar for merging code is intentionally **high**. The guidelines below spell out what "high-quality" means in practice and should make the whole process transparent and friendly.
+-
+-### Development workflow
+-
+-- Create a _topic branch_ from `main` - e.g. `feat/interactive-prompt`.
+-- Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.
+-- Use `pnpm test:watch` during development for super-fast feedback.
+-- We use **Vitest** for unit tests, **ESLint** + **Prettier** for style, and **TypeScript** for type-checking.
+-- Before pushing, run the full test/type/lint suite:
+-
+-### Git hooks with Husky
+-
+-This project uses [Husky](https://typicode.github.io/husky/) to enforce code quality checks:
+-
+-- **Pre-commit hook**: Automatically runs lint-staged to format and lint files before committing
+-- **Pre-push hook**: Runs tests and type checking before pushing to the remote
+-
+-These hooks help maintain code quality and prevent pushing code with failing tests. For more details, see [HUSKY.md](./HUSKY.md).
+-
+-```bash
+-pnpm test && pnpm run lint && pnpm run typecheck
+-```
+-
+-- If you have **not** yet signed the Contributor License Agreement (CLA), add a PR comment containing the exact text
+-
+-  ```text
+-  I have read the CLA Document and I hereby sign the CLA
+-  ```
+-
+-  The CLA-Assistant bot will turn the PR status green once all authors have signed.
+-
+-```bash
+-# Watch mode (tests rerun on change)
+-pnpm test:watch
+-
+-# Type-check without emitting files
+-pnpm typecheck
+-
+-# Automatically fix lint + prettier issues
+-pnpm lint:fix
+-pnpm format:fix
+-```
+-
+-### Debugging
+-
+-To debug the CLI with a visual debugger, do the following in the `codex-cli` folder:
+-
+-- Run `pnpm run build` to build the CLI, which will generate `cli.js.map` alongside `cli.js` in the `dist` folder.
+-- Run the CLI with `node --inspect-brk ./dist/cli.js` The program then waits until a debugger is attached before proceeding. Options:
+-  - In VS Code, choose **Debug: Attach to Node Process** from the command palette and choose the option in the dropdown with debug port `9229` (likely the first option)
+-  - Go to <chrome://inspect> in Chrome and find **localhost:9229** and click **trace**
+-
+-### Writing high-impact code changes
+-
+-1. **Start with an issue.** Open a new one or comment on an existing discussion so we can agree on the solution before code is written.
+-2. **Add or update tests.** Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.
+-3. **Document behaviour.** If your change affects user-facing behaviour, update the README, inline help (`codex --help`), or relevant example projects.
+-4. **Keep commits atomic.** Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.
+-
+-### Opening a pull request
+-
+-- Fill in the PR template (or include similar information) - **What? Why? How?**
+-- Run **all** checks locally (`npm test && npm run lint && npm run typecheck`). CI failures that could have been caught locally slow down the process.
+-- Make sure your branch is up-to-date with `main` and that you have resolved merge conflicts.
+-- Mark the PR as **Ready for review** only when you believe it is in a merge-able state.
+-
+-### Review process
+-
+-1. One maintainer will be assigned as a primary reviewer.
+-2. We may ask for changes - please do not take this personally. We value the work, we just also value consistency and long-term maintainability.
+-3. When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.
+-
+-### Community values
+-
+-- **Be kind and inclusive.** Treat others with respect; we follow the [Contributor Covenant](https://www.contributor-covenant.org/).
+-- **Assume good intent.** Written communication is hard - err on the side of generosity.
+-- **Teach & learn.** If you spot something confusing, open an issue or PR with improvements.
+-
+-### Getting help
+-
+-If you run into problems setting up the project, would like feedback on an idea, or just want to say _hi_ - please open a Discussion or jump into the relevant issue. We are happy to help.
+-
+-Together we can make Codex CLI an incredible tool. **Happy hacking!** :rocket:
+-
+-### Contributor license agreement (CLA)
+-
+-All contributors **must** accept the CLA. The process is lightweight:
+-
+-1. Open your pull request.
+-2. Paste the following comment (or reply `recheck` if you've signed before):
+-
+-   ```text
+-   I have read the CLA Document and I hereby sign the CLA
+-   ```
+-
+-3. The CLA-Assistant bot records your signature in the repo and marks the status check as passed.
+-
+-No special Git commands, email attachments, or commit footers required.
+-
+-#### Quick fixes
+-
+-| Scenario          | Command                                          |
+-| ----------------- | ------------------------------------------------ |
+-| Amend last commit | `git commit --amend -s --no-edit && git push -f` |
+-
+-The **DCO check** blocks merges until every commit in the PR carries the footer (with squash this is just the one).
+-
+-### Releasing `codex`
+-
+-To publish a new version of the CLI you first need to stage the npm package. A
+-helper script in `codex-cli/scripts/` does all the heavy lifting. Inside the
+-`codex-cli` folder run:
+-
+-```bash
+-# Classic, JS implementation that includes small, native binaries for Linux sandboxing.
+-pnpm stage-release
+-
+-# Optionally specify the temp directory to reuse between runs.
+-RELEASE_DIR=$(mktemp -d)
+-pnpm stage-release --tmp "$RELEASE_DIR"
+-
+-# "Fat" package that additionally bundles the native Rust CLI binaries for
+-# Linux. End-users can then opt-in at runtime by setting CODEX_RUST=1.
+-pnpm stage-release --native
+-```
+-
+-Go to the folder where the release is staged and verify that it works as intended. If so, run the following from the temp folder:
+-
+-```
+-cd "$RELEASE_DIR"
+-npm publish
+-```
+-
+-### Alternative build options
+-
+-#### Nix flake development
+-
+-Prerequisite: Nix >= 2.4 with flakes enabled (`experimental-features = nix-command flakes` in `~/.config/nix/nix.conf`).
+-
+-Enter a Nix development shell:
+-
+-```bash
+-# Use either one of the commands according to which implementation you want to work with
+-nix develop .#codex-cli # For entering codex-cli specific shell
+-nix develop .#codex-rs # For entering codex-rs specific shell
+-```
+-
+-This shell includes Node.js, installs dependencies, builds the CLI, and provides a `codex` command alias.
+-
+-Build and run the CLI directly:
+-
+-```bash
+-# Use either one of the commands according to which implementation you want to work with
+-nix build .#codex-cli # For building codex-cli
+-nix build .#codex-rs # For building codex-rs
+-./result/bin/codex --help
+-```
+-
+-Run the CLI via the flake app:
+-
+-```bash
+-# Use either one of the commands according to which implementation you want to work with
+-nix run .#codex-cli # For running codex-cli
+-nix run .#codex-rs # For running codex-rs
+-```
+-
+-Use direnv with flakes
+-
+-If you have direnv installed, you can use the following `.envrc` to automatically enter the Nix shell when you `cd` into the project directory:
+-
+-```bash
+-cd codex-rs
+-echo "use flake ../flake.nix#codex-cli" >> .envrc && direnv allow
+-cd codex-cli
+-echo "use flake ../flake.nix#codex-rs" >> .envrc && direnv allow
+-```
+-
+----
+-
+-## Security & responsible AI
+-
+-Have you discovered a vulnerability or have concerns about model output? Please e-mail **security@openai.com** and we will respond promptly.
+-
+----
+-
+-## License
+-
+-This repository is licensed under the [Apache-2.0 License](LICENSE).
++<h1 align="center">OpenAI Codex CLI</h1>
++<p align="center">Lightweight coding agent that runs in your terminal</p>
++
++<p align="center"><code>npm i -g @openai/codex</code></p>
++
++> [!IMPORTANT]
++> This is the documentation for the _legacy_ TypeScript implementation of the Codex CLI. It has been superseded by the _Rust_ implementation. See the [README in the root of the Codex repository](https://github.com/openai/codex/blob/main/README.md) for details.
++
++![Codex demo GIF using: codex "explain this codebase to me"](../.github/demo.gif)
++
++---
++
++<details>
++<summary><strong>Table of contents</strong></summary>
++
++<!-- Begin ToC -->
++
++- [Experimental technology disclaimer](#experimental-technology-disclaimer)
++- [Quickstart](#quickstart)
++- [Why Codex?](#why-codex)
++- [Security model & permissions](#security-model--permissions)
++  - [Platform sandboxing details](#platform-sandboxing-details)
++- [System requirements](#system-requirements)
++- [CLI reference](#cli-reference)
++- [Memory & project docs](#memory--project-docs)
++- [Non-interactive / CI mode](#non-interactive--ci-mode)
++- [Tracing / verbose logging](#tracing--verbose-logging)
++- [Recipes](#recipes)
++- [Installation](#installation)
++- [Configuration guide](#configuration-guide)
++  - [Basic configuration parameters](#basic-configuration-parameters)
++  - [Custom AI provider configuration](#custom-ai-provider-configuration)
++  - [History configuration](#history-configuration)
++  - [Configuration examples](#configuration-examples)
++  - [Full configuration example](#full-configuration-example)
++  - [Custom instructions](#custom-instructions)
++  - [Environment variables setup](#environment-variables-setup)
++- [FAQ](#faq)
++- [Zero data retention (ZDR) usage](#zero-data-retention-zdr-usage)
++- [Codex open source fund](#codex-open-source-fund)
++- [Contributing](#contributing)
++  - [Development workflow](#development-workflow)
++  - [Git hooks with Husky](#git-hooks-with-husky)
++  - [Debugging](#debugging)
++  - [Writing high-impact code changes](#writing-high-impact-code-changes)
++  - [Opening a pull request](#opening-a-pull-request)
++  - [Review process](#review-process)
++  - [Community values](#community-values)
++  - [Getting help](#getting-help)
++  - [Contributor license agreement (CLA)](#contributor-license-agreement-cla)
++    - [Quick fixes](#quick-fixes)
++  - [Releasing `codex`](#releasing-codex)
++  - [Alternative build options](#alternative-build-options)
++    - [Nix flake development](#nix-flake-development)
++- [Security & responsible AI](#security--responsible-ai)
++- [License](#license)
++
++<!-- End ToC -->
++
++</details>
++
++---
++
++## Experimental technology disclaimer
++
++Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:
++
++- Bug reports
++- Feature requests
++- Pull requests
++- Good vibes
++
++Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!
++
++## Quickstart
++
++Install globally:
++
++```shell
++npm install -g @openai/codex
++```
++
++Next, set your OpenAI API key as an environment variable:
++
++```shell
++export OPENAI_API_KEY="your-api-key-here"
++```
++
++> **Note:** This command sets the key only for your current terminal session. You can add the `export` line to your shell's configuration file (e.g., `~/.zshrc`) but we recommend setting for the session. **Tip:** You can also place your API key into a `.env` file at the root of your project:
++>
++> ```env
++> OPENAI_API_KEY=your-api-key-here
++> ```
++>
++> The CLI will automatically load variables from `.env` (via `dotenv/config`).
++
++<details>
++<summary><strong>Use <code>--provider</code> to use other models</strong></summary>
++
++> Codex also allows you to use other providers that support the OpenAI Chat Completions API. You can set the provider in the config file or use the `--provider` flag. The possible options for `--provider` are:
++>
++> - openai (default)
++> - openrouter
++> - azure
++> - gemini
++> - ollama
++> - mistral
++> - deepseek
++> - xai
++> - groq
++> - arceeai
++> - any other provider that is compatible with the OpenAI API
++>
++> If you use a provider other than OpenAI, you will need to set the API key for the provider in the config file or in the environment variable as:
++>
++> ```shell
++> export <provider>_API_KEY="your-api-key-here"
++> ```
++>
++> If you use a provider not listed above, you must also set the base URL for the provider:
++>
++> ```shell
++> export <provider>_BASE_URL="https://your-provider-api-base-url"
++> ```
++
++</details>
++<br />
++
++Run interactively:
++
++```shell
++codex
++```
++
++Or, run with a prompt as input (and optionally in `Full Auto` mode):
++
++```shell
++codex "explain this codebase to me"
++```
++
++```shell
++codex --approval-mode full-auto "create the fanciest todo-list app"
++```
++
++That's it - Codex will scaffold a file, run it inside a sandbox, install any
++missing dependencies, and show you the live result. Approve the changes and
++they'll be committed to your working directory.
++
++---
++
++## Why Codex?
++
++Codex CLI is built for developers who already **live in the terminal** and want
++ChatGPT-level reasoning **plus** the power to actually run code, manipulate
++files, and iterate - all under version control. In short, it's _chat-driven
++development_ that understands and executes your repo.
++
++- **Zero setup** - bring your OpenAI API key and it just works!
++- **Full auto-approval, while safe + secure** by running network-disabled and directory-sandboxed
++- **Multimodal** - pass in screenshots or diagrams to implement features ✨
++
++And it's **fully open-source** so you can see and contribute to how it develops!
++
++---
++
++## Security model & permissions
++
++Codex lets you decide _how much autonomy_ the agent receives and auto-approval policy via the
++`--approval-mode` flag (or the interactive onboarding prompt):
++
++| Mode                      | What the agent may do without asking                                                                | Still requires approval                                                                         |
++| ------------------------- | --------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
++| **Suggest** <br>(default) | <li>Read any file in the repo                                                                       | <li>**All** file writes/patches<li> **Any** arbitrary shell commands (aside from reading files) |
++| **Auto Edit**             | <li>Read **and** apply-patch writes to files                                                        | <li>**All** shell commands                                                                      |
++| **Full Auto**             | <li>Read/write files <li> Execute shell commands (network disabled, writes limited to your workdir) | -                                                                                               |
++
++In **Full Auto** every command is run **network-disabled** and confined to the
++current working directory (plus temporary files) for defense-in-depth. Codex
++will also show a warning/confirmation if you start in **auto-edit** or
++**full-auto** while the directory is _not_ tracked by Git, so you always have a
++safety net.
++
++Coming soon: you'll be able to whitelist specific commands to auto-execute with
++the network enabled, once we're confident in additional safeguards.
++
++### Platform sandboxing details
++
++The hardening mechanism Codex uses depends on your OS:
++
++- **macOS 12+** - commands are wrapped with **Apple Seatbelt** (`sandbox-exec`).
++
++  - Everything is placed in a read-only jail except for a small set of
++    writable roots (`$PWD`, `$TMPDIR`, `~/.codex`, etc.).
++  - Outbound network is _fully blocked_ by default - even if a child process
++    tries to `curl` somewhere it will fail.
++
++- **Linux** - there is no sandboxing by default.
++  We recommend using Docker for sandboxing, where Codex launches itself inside a **minimal
++  container image** and mounts your repo _read/write_ at the same path. A
++  custom `iptables`/`ipset` firewall script denies all egress except the
++  OpenAI API. This gives you deterministic, reproducible runs without needing
++  root on the host. You can use the [`run_in_container.sh`](../codex-cli/scripts/run_in_container.sh) script to set up the sandbox.
++
++---
++
++## System requirements
++
++| Requirement                 | Details                                                         |
++| --------------------------- | --------------------------------------------------------------- |
++| Operating systems           | macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 **via WSL2** |
++| Node.js                     | **16 or newer** (Node 20 LTS recommended)                       |
++| Git (optional, recommended) | 2.23+ for built-in PR helpers                                   |
++| RAM                         | 4-GB minimum (8-GB recommended)                                 |
++
++> Never run `sudo npm install -g`; fix npm permissions instead.
++
++---
++
++## CLI reference
++
++| Command                              | Purpose                             | Example                              |
++| ------------------------------------ | ----------------------------------- | ------------------------------------ |
++| `codex`                              | Interactive REPL                    | `codex`                              |
++| `codex "..."`                        | Initial prompt for interactive REPL | `codex "fix lint errors"`            |
++| `codex -q "..."`                     | Non-interactive "quiet mode"        | `codex -q --json "explain utils.ts"` |
++| `codex completion <bash\|zsh\|fish>` | Print shell completion script       | `codex completion bash`              |
++
++Key flags: `--model/-m`, `--approval-mode/-a`, `--quiet/-q`, and `--notify`.
++
++---
++
++## Memory & project docs
++
++You can give Codex extra instructions and guidance using `AGENTS.md` files. Codex looks for `AGENTS.md` files in the following places, and merges them top-down:
++
++1. `~/.codex/AGENTS.md` - personal global guidance
++2. `AGENTS.md` at repo root - shared project notes
++3. `AGENTS.md` in the current working directory - sub-folder/feature specifics
++
++Disable loading of these files with `--no-project-doc` or the environment variable `CODEX_DISABLE_PROJECT_DOC=1`.
++
++---
++
++## Non-interactive / CI mode
++
++Run Codex head-less in pipelines. Example GitHub Action step:
++
++```yaml
++- name: Update changelog via Codex
++  run: |
++    npm install -g @openai/codex
++    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
++    codex -a auto-edit --quiet "update CHANGELOG for next release"
++```
++
++Set `CODEX_QUIET_MODE=1` to silence interactive UI noise.
++
++## Tracing / verbose logging
++
++Setting the environment variable `DEBUG=true` prints full API request and response details:
++
++```shell
++DEBUG=true codex
++```
++
++---
++
++## Recipes
++
++Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the [prompting guide](https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md) for more tips and usage patterns.
++
++| ✨  | What you type                                                                   | What happens                                                               |
++| --- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
++| 1   | `codex "Refactor the Dashboard component to React Hooks"`                       | Codex rewrites the class component, runs `npm test`, and shows the diff.   |
++| 2   | `codex "Generate SQL migrations for adding a users table"`                      | Infers your ORM, creates migration files, and runs them in a sandboxed DB. |
++| 3   | `codex "Write unit tests for utils/date.ts"`                                    | Generates tests, executes them, and iterates until they pass.              |
++| 4   | `codex "Bulk-rename *.jpeg -> *.jpg with git mv"`                               | Safely renames files and updates imports/usages.                           |
++| 5   | `codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"`                      | Outputs a step-by-step human explanation.                                  |
++| 6   | `codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"` | Suggests impactful PRs in the current codebase.                            |
++| 7   | `codex "Look for vulnerabilities and create a security review report"`          | Finds and explains security bugs.                                          |
++
++---
++
++## Installation
++
++<details open>
++<summary><strong>From npm (Recommended)</strong></summary>
++
++```bash
++npm install -g @openai/codex
++# or
++yarn global add @openai/codex
++# or
++bun install -g @openai/codex
++# or
++pnpm add -g @openai/codex
++```
++
++</details>
++
++<details>
++<summary><strong>Build from source</strong></summary>
++
++```bash
++# Clone the repository and navigate to the CLI package
++git clone https://github.com/openai/codex.git
++cd codex/codex-cli
++
++# Enable corepack
++corepack enable
++
++# Install dependencies and build
++pnpm install
++pnpm build
++
++# Linux-only: download prebuilt sandboxing binaries (requires gh and zstd).
++./scripts/install_native_deps.sh
++
++# Get the usage and the options
++node ./dist/cli.js --help
++
++# Run the locally-built CLI directly
++node ./dist/cli.js
++
++# Or link the command globally for convenience
++pnpm link
++```
++
++</details>
++
++---
++
++## Configuration guide
++
++Codex configuration files can be placed in the `~/.codex/` directory, supporting both YAML and JSON formats.
++
++### Basic configuration parameters
++
++| Parameter           | Type    | Default    | Description                      | Available Options                                                                              |
++| ------------------- | ------- | ---------- | -------------------------------- | ---------------------------------------------------------------------------------------------- |
++| `model`             | string  | `o4-mini`  | AI model to use                  | Any model name supporting OpenAI API                                                           |
++| `approvalMode`      | string  | `suggest`  | AI assistant's permission mode   | `suggest` (suggestions only)<br>`auto-edit` (automatic edits)<br>`full-auto` (fully automatic) |
++| `fullAutoErrorMode` | string  | `ask-user` | Error handling in full-auto mode | `ask-user` (prompt for user input)<br>`ignore-and-continue` (ignore and proceed)               |
++| `notify`            | boolean | `true`     | Enable desktop notifications     | `true`/`false`                                                                                 |
++
++### Custom AI provider configuration
++
++In the `providers` object, you can configure multiple AI service providers. Each provider requires the following parameters:
++
++| Parameter | Type   | Description                             | Example                       |
++| --------- | ------ | --------------------------------------- | ----------------------------- |
++| `name`    | string | Display name of the provider            | `"OpenAI"`                    |
++| `baseURL` | string | API service URL                         | `"https://api.openai.com/v1"` |
++| `envKey`  | string | Environment variable name (for API key) | `"OPENAI_API_KEY"`            |
++
++### History configuration
++
++In the `history` object, you can configure conversation history settings:
++
++| Parameter           | Type    | Description                                            | Example Value |
++| ------------------- | ------- | ------------------------------------------------------ | ------------- |
++| `maxSize`           | number  | Maximum number of history entries to save              | `1000`        |
++| `saveHistory`       | boolean | Whether to save history                                | `true`        |
++| `sensitivePatterns` | array   | Patterns of sensitive information to filter in history | `[]`          |
++
++### Configuration examples
++
++1. YAML format (save as `~/.codex/config.yaml`):
++
++```yaml
++model: o4-mini
++approvalMode: suggest
++fullAutoErrorMode: ask-user
++notify: true
++```
++
++2. JSON format (save as `~/.codex/config.json`):
++
++```json
++{
++  "model": "o4-mini",
++  "approvalMode": "suggest",
++  "fullAutoErrorMode": "ask-user",
++  "notify": true
++}
++```
++
++### Full configuration example
++
++Below is a comprehensive example of `config.json` with multiple custom providers:
++
++```json
++{
++  "model": "o4-mini",
++  "provider": "openai",
++  "providers": {
++    "openai": {
++      "name": "OpenAI",
++      "baseURL": "https://api.openai.com/v1",
++      "envKey": "OPENAI_API_KEY"
++    },
++    "azure": {
++      "name": "AzureOpenAI",
++      "baseURL": "https://YOUR_PROJECT_NAME.openai.azure.com/openai",
++      "envKey": "AZURE_OPENAI_API_KEY"
++    },
++    "openrouter": {
++      "name": "OpenRouter",
++      "baseURL": "https://openrouter.ai/api/v1",
++      "envKey": "OPENROUTER_API_KEY"
++    },
++    "gemini": {
++      "name": "Gemini",
++      "baseURL": "https://generativelanguage.googleapis.com/v1beta/openai",
++      "envKey": "GEMINI_API_KEY"
++    },
++    "ollama": {
++      "name": "Ollama",
++      "baseURL": "http://localhost:11434/v1",
++      "envKey": "OLLAMA_API_KEY"
++    },
++    "mistral": {
++      "name": "Mistral",
++      "baseURL": "https://api.mistral.ai/v1",
++      "envKey": "MISTRAL_API_KEY"
++    },
++    "deepseek": {
++      "name": "DeepSeek",
++      "baseURL": "https://api.deepseek.com",
++      "envKey": "DEEPSEEK_API_KEY"
++    },
++    "xai": {
++      "name": "xAI",
++      "baseURL": "https://api.x.ai/v1",
++      "envKey": "XAI_API_KEY"
++    },
++    "groq": {
++      "name": "Groq",
++      "baseURL": "https://api.groq.com/openai/v1",
++      "envKey": "GROQ_API_KEY"
++    },
++    "arceeai": {
++      "name": "ArceeAI",
++      "baseURL": "https://conductor.arcee.ai/v1",
++      "envKey": "ARCEEAI_API_KEY"
++    }
++  },
++  "history": {
++    "maxSize": 1000,
++    "saveHistory": true,
++    "sensitivePatterns": []
++  }
++}
++```
++
++### Custom instructions
++
++You can create a `~/.codex/AGENTS.md` file to define custom guidance for the agent:
++
++```markdown
++- Always respond with emojis
++- Only use git commands when explicitly requested
++```
++
++### Environment variables setup
++
++For each AI provider, you need to set the corresponding API key in your environment variables. For example:
++
++```bash
++# OpenAI
++export OPENAI_API_KEY="your-api-key-here"
++
++# Azure OpenAI
++export AZURE_OPENAI_API_KEY="your-azure-api-key-here"
++export AZURE_OPENAI_API_VERSION="2025-04-01-preview" (Optional)
++
++# OpenRouter
++export OPENROUTER_API_KEY="your-openrouter-key-here"
++
++# Similarly for other providers
++```
++
++---
++
++## FAQ
++
++<details>
++<summary>OpenAI released a model called Codex in 2021 - is this related?</summary>
++
++In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.
++
++</details>
++
++<details>
++<summary>Which models are supported?</summary>
++
++Any model available with [Responses API](https://platform.openai.com/docs/api-reference/responses). The default is `o4-mini`, but pass `--model gpt-4.1` or set `model: gpt-4.1` in your config file to override.
++
++</details>
++<details>
++<summary>Why does <code>o3</code> or <code>o4-mini</code> not work for me?</summary>
++
++It's possible that your [API account needs to be verified](https://help.openai.com/en/articles/10910291-api-organization-verification) in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!
++
++</details>
++
++<details>
++<summary>How do I stop Codex from editing my files?</summary>
++
++Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type **n** to deny the command or give the model feedback.
++
++</details>
++<details>
++<summary>Does it work on Windows?</summary>
++
++Not directly. It requires [Windows Subsystem for Linux (WSL2)](https://learn.microsoft.com/en-us/windows/wsl/install) - Codex is regularly tested on macOS and Linux with Node 20+, and also supports Node 16.
++
++</details>
++
++---
++
++## Zero data retention (ZDR) usage
++
++Codex CLI **does** support OpenAI organizations with [Zero Data Retention (ZDR)](https://platform.openai.com/docs/guides/your-data#zero-data-retention) enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:
++
++```
++OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
++```
++
++You may need to upgrade to a more recent version with: `npm i -g @openai/codex@latest`
++
++---
++
++## Codex open source fund
++
++We're excited to launch a **$1 million initiative** supporting open source projects that use Codex CLI and other OpenAI models.
++
++- Grants are awarded up to **$25,000** API credits.
++- Applications are reviewed **on a rolling basis**.
++
++**Interested? [Apply here](https://openai.com/form/codex-open-source-fund/).**
++
++---
++
++## Contributing
++
++This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!
++
++More broadly we welcome contributions - whether you are opening your very first pull request or you're a seasoned maintainer. At the same time we care about reliability and long-term maintainability, so the bar for merging code is intentionally **high**. The guidelines below spell out what "high-quality" means in practice and should make the whole process transparent and friendly.
++
++### Development workflow
++
++- Create a _topic branch_ from `main` - e.g. `feat/interactive-prompt`.
++- Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.
++- Use `pnpm test:watch` during development for super-fast feedback.
++- We use **Vitest** for unit tests, **ESLint** + **Prettier** for style, and **TypeScript** for type-checking.
++- Before pushing, run the full test/type/lint suite:
++
++### Git hooks with Husky
++
++This project uses [Husky](https://typicode.github.io/husky/) to enforce code quality checks:
++
++- **Pre-commit hook**: Automatically runs lint-staged to format and lint files before committing
++- **Pre-push hook**: Runs tests and type checking before pushing to the remote
++
++These hooks help maintain code quality and prevent pushing code with failing tests. For more details, see [HUSKY.md](./HUSKY.md).
++
++```bash
++pnpm test && pnpm run lint && pnpm run typecheck
++```
++
++- If you have **not** yet signed the Contributor License Agreement (CLA), add a PR comment containing the exact text
++
++  ```text
++  I have read the CLA Document and I hereby sign the CLA
++  ```
++
++  The CLA-Assistant bot will turn the PR status green once all authors have signed.
++
++```bash
++# Watch mode (tests rerun on change)
++pnpm test:watch
++
++# Type-check without emitting files
++pnpm typecheck
++
++# Automatically fix lint + prettier issues
++pnpm lint:fix
++pnpm format:fix
++```
++
++### Debugging
++
++To debug the CLI with a visual debugger, do the following in the `codex-cli` folder:
++
++- Run `pnpm run build` to build the CLI, which will generate `cli.js.map` alongside `cli.js` in the `dist` folder.
++- Run the CLI with `node --inspect-brk ./dist/cli.js` The program then waits until a debugger is attached before proceeding. Options:
++  - In VS Code, choose **Debug: Attach to Node Process** from the command palette and choose the option in the dropdown with debug port `9229` (likely the first option)
++  - Go to <chrome://inspect> in Chrome and find **localhost:9229** and click **trace**
++
++### Writing high-impact code changes
++
++1. **Start with an issue.** Open a new one or comment on an existing discussion so we can agree on the solution before code is written.
++2. **Add or update tests.** Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.
++3. **Document behaviour.** If your change affects user-facing behaviour, update the README, inline help (`codex --help`), or relevant example projects.
++4. **Keep commits atomic.** Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.
++
++### Opening a pull request
++
++- Fill in the PR template (or include similar information) - **What? Why? How?**
++- Run **all** checks locally (`npm test && npm run lint && npm run typecheck`). CI failures that could have been caught locally slow down the process.
++- Make sure your branch is up-to-date with `main` and that you have resolved merge conflicts.
++- Mark the PR as **Ready for review** only when you believe it is in a merge-able state.
++
++### Review process
++
++1. One maintainer will be assigned as a primary reviewer.
++2. We may ask for changes - please do not take this personally. We value the work, we just also value consistency and long-term maintainability.
++3. When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.
++
++### Community values
++
++- **Be kind and inclusive.** Treat others with respect; we follow the [Contributor Covenant](https://www.contributor-covenant.org/).
++- **Assume good intent.** Written communication is hard - err on the side of generosity.
++- **Teach & learn.** If you spot something confusing, open an issue or PR with improvements.
++
++### Getting help
++
++If you run into problems setting up the project, would like feedback on an idea, or just want to say _hi_ - please open a Discussion or jump into the relevant issue. We are happy to help.
++
++Together we can make Codex CLI an incredible tool. **Happy hacking!** :rocket:
++
++### Contributor license agreement (CLA)
++
++All contributors **must** accept the CLA. The process is lightweight:
++
++1. Open your pull request.
++2. Paste the following comment (or reply `recheck` if you've signed before):
++
++   ```text
++   I have read the CLA Document and I hereby sign the CLA
++   ```
++
++3. The CLA-Assistant bot records your signature in the repo and marks the status check as passed.
++
++No special Git commands, email attachments, or commit footers required.
++
++#### Quick fixes
++
++| Scenario          | Command                                          |
++| ----------------- | ------------------------------------------------ |
++| Amend last commit | `git commit --amend -s --no-edit && git push -f` |
++
++The **DCO check** blocks merges until every commit in the PR carries the footer (with squash this is just the one).
++
++### Releasing `codex`
++
++To publish a new version of the CLI you first need to stage the npm package. A
++helper script in `codex-cli/scripts/` does all the heavy lifting. Inside the
++`codex-cli` folder run:
++
++```bash
++# Classic, JS implementation that includes small, native binaries for Linux sandboxing.
++pnpm stage-release
++
++# Optionally specify the temp directory to reuse between runs.
++RELEASE_DIR=$(mktemp -d)
++pnpm stage-release --tmp "$RELEASE_DIR"
++
++# "Fat" package that additionally bundles the native Rust CLI binaries for
++# Linux. End-users can then opt-in at runtime by setting CODEX_RUST=1.
++pnpm stage-release --native
++```
++
++Go to the folder where the release is staged and verify that it works as intended. If so, run the following from the temp folder:
++
++```
++cd "$RELEASE_DIR"
++npm publish
++```
++
++### Alternative build options
++
++#### Nix flake development
++
++Prerequisite: Nix >= 2.4 with flakes enabled (`experimental-features = nix-command flakes` in `~/.config/nix/nix.conf`).
++
++Enter a Nix development shell:
++
++```bash
++# Use either one of the commands according to which implementation you want to work with
++nix develop .#codex-cli # For entering codex-cli specific shell
++nix develop .#codex-rs # For entering codex-rs specific shell
++```
++
++This shell includes Node.js, installs dependencies, builds the CLI, and provides a `codex` command alias.
++
++Build and run the CLI directly:
++
++```bash
++# Use either one of the commands according to which implementation you want to work with
++nix build .#codex-cli # For building codex-cli
++nix build .#codex-rs # For building codex-rs
++./result/bin/codex --help
++```
++
++Run the CLI via the flake app:
++
++```bash
++# Use either one of the commands according to which implementation you want to work with
++nix run .#codex-cli # For running codex-cli
++nix run .#codex-rs # For running codex-rs
++```
++
++Use direnv with flakes
++
++If you have direnv installed, you can use the following `.envrc` to automatically enter the Nix shell when you `cd` into the project directory:
++
++```bash
++cd codex-rs
++echo "use flake ../flake.nix#codex-cli" >> .envrc && direnv allow
++cd codex-cli
++echo "use flake ../flake.nix#codex-rs" >> .envrc && direnv allow
++```
++
++---
++
++## Security & responsible AI
++
++Have you discovered a vulnerability or have concerns about model output? Please e-mail **security@openai.com** and we will respond promptly.
++
++---
++
++## License
++
++This repository is licensed under the [Apache-2.0 License](LICENSE).
+diff --git a/codex-cli/bin/codex.js b/codex-cli/bin/codex.js
+index 805be85a..6061cb70 100644
+--- a/codex-cli/bin/codex.js
++++ b/codex-cli/bin/codex.js
+@@ -1,177 +1,177 @@
+-#!/usr/bin/env node
+-// Unified entry point for the Codex CLI.
+-
+-import { spawn } from "node:child_process";
+-import { existsSync } from "fs";
+-import path from "path";
+-import { fileURLToPath } from "url";
+-
+-// __dirname equivalent in ESM
+-const __filename = fileURLToPath(import.meta.url);
+-const __dirname = path.dirname(__filename);
+-
+-const { platform, arch } = process;
+-
+-let targetTriple = null;
+-switch (platform) {
+-  case "linux":
+-  case "android":
+-    switch (arch) {
+-      case "x64":
+-        targetTriple = "x86_64-unknown-linux-musl";
+-        break;
+-      case "arm64":
+-        targetTriple = "aarch64-unknown-linux-musl";
+-        break;
+-      default:
+-        break;
+-    }
+-    break;
+-  case "darwin":
+-    switch (arch) {
+-      case "x64":
+-        targetTriple = "x86_64-apple-darwin";
+-        break;
+-      case "arm64":
+-        targetTriple = "aarch64-apple-darwin";
+-        break;
+-      default:
+-        break;
+-    }
+-    break;
+-  case "win32":
+-    switch (arch) {
+-      case "x64":
+-        targetTriple = "x86_64-pc-windows-msvc";
+-        break;
+-      case "arm64":
+-        targetTriple = "aarch64-pc-windows-msvc";
+-        break;
+-      default:
+-        break;
+-    }
+-    break;
+-  default:
+-    break;
+-}
+-
+-if (!targetTriple) {
+-  throw new Error(`Unsupported platform: ${platform} (${arch})`);
+-}
+-
+-const vendorRoot = path.join(__dirname, "..", "vendor");
+-const archRoot = path.join(vendorRoot, targetTriple);
+-const codexBinaryName = process.platform === "win32" ? "codex.exe" : "codex";
+-const binaryPath = path.join(archRoot, "codex", codexBinaryName);
+-
+-// Use an asynchronous spawn instead of spawnSync so that Node is able to
+-// respond to signals (e.g. Ctrl-C / SIGINT) while the native binary is
+-// executing. This allows us to forward those signals to the child process
+-// and guarantees that when either the child terminates or the parent
+-// receives a fatal signal, both processes exit in a predictable manner.
+-
+-function getUpdatedPath(newDirs) {
+-  const pathSep = process.platform === "win32" ? ";" : ":";
+-  const existingPath = process.env.PATH || "";
+-  const updatedPath = [
+-    ...newDirs,
+-    ...existingPath.split(pathSep).filter(Boolean),
+-  ].join(pathSep);
+-  return updatedPath;
+-}
+-
+-/**
+- * Use heuristics to detect the package manager that was used to install Codex
+- * in order to give the user a hint about how to update it.
+- */
+-function detectPackageManager() {
+-  const userAgent = process.env.npm_config_user_agent || "";
+-  if (/\bbun\//.test(userAgent)) {
+-    return "bun";
+-  }
+-
+-  const execPath = process.env.npm_execpath || "";
+-  if (execPath.includes("bun")) {
+-    return "bun";
+-  }
+-
+-  if (
+-    process.env.BUN_INSTALL ||
+-    process.env.BUN_INSTALL_GLOBAL_DIR ||
+-    process.env.BUN_INSTALL_BIN_DIR
+-  ) {
+-    return "bun";
+-  }
+-
+-  return userAgent ? "npm" : null;
+-}
+-
+-const additionalDirs = [];
+-const pathDir = path.join(archRoot, "path");
+-if (existsSync(pathDir)) {
+-  additionalDirs.push(pathDir);
+-}
+-const updatedPath = getUpdatedPath(additionalDirs);
+-
+-const env = { ...process.env, PATH: updatedPath };
+-const packageManagerEnvVar =
+-  detectPackageManager() === "bun"
+-    ? "CODEX_MANAGED_BY_BUN"
+-    : "CODEX_MANAGED_BY_NPM";
+-env[packageManagerEnvVar] = "1";
+-
+-const child = spawn(binaryPath, process.argv.slice(2), {
+-  stdio: "inherit",
+-  env,
+-});
+-
+-child.on("error", (err) => {
+-  // Typically triggered when the binary is missing or not executable.
+-  // Re-throwing here will terminate the parent with a non-zero exit code
+-  // while still printing a helpful stack trace.
+-  // eslint-disable-next-line no-console
+-  console.error(err);
+-  process.exit(1);
+-});
+-
+-// Forward common termination signals to the child so that it shuts down
+-// gracefully. In the handler we temporarily disable the default behavior of
+-// exiting immediately; once the child has been signaled we simply wait for
+-// its exit event which will in turn terminate the parent (see below).
+-const forwardSignal = (signal) => {
+-  if (child.killed) {
+-    return;
+-  }
+-  try {
+-    child.kill(signal);
+-  } catch {
+-    /* ignore */
+-  }
+-};
+-
+-["SIGINT", "SIGTERM", "SIGHUP"].forEach((sig) => {
+-  process.on(sig, () => forwardSignal(sig));
+-});
+-
+-// When the child exits, mirror its termination reason in the parent so that
+-// shell scripts and other tooling observe the correct exit status.
+-// Wrap the lifetime of the child process in a Promise so that we can await
+-// its termination in a structured way. The Promise resolves with an object
+-// describing how the child exited: either via exit code or due to a signal.
+-const childResult = await new Promise((resolve) => {
+-  child.on("exit", (code, signal) => {
+-    if (signal) {
+-      resolve({ type: "signal", signal });
+-    } else {
+-      resolve({ type: "code", exitCode: code ?? 1 });
+-    }
+-  });
+-});
+-
+-if (childResult.type === "signal") {
+-  // Re-emit the same signal so that the parent terminates with the expected
+-  // semantics (this also sets the correct exit code of 128 + n).
+-  process.kill(process.pid, childResult.signal);
+-} else {
+-  process.exit(childResult.exitCode);
+-}
++#!/usr/bin/env node
++// Unified entry point for the Codex CLI.
++
++import { spawn } from "node:child_process";
++import { existsSync } from "fs";
++import path from "path";
++import { fileURLToPath } from "url";
++
++// __dirname equivalent in ESM
++const __filename = fileURLToPath(import.meta.url);
++const __dirname = path.dirname(__filename);
++
++const { platform, arch } = process;
++
++let targetTriple = null;
++switch (platform) {
++  case "linux":
++  case "android":
++    switch (arch) {
++      case "x64":
++        targetTriple = "x86_64-unknown-linux-musl";
++        break;
++      case "arm64":
++        targetTriple = "aarch64-unknown-linux-musl";
++        break;
++      default:
++        break;
++    }
++    break;
++  case "darwin":
++    switch (arch) {
++      case "x64":
++        targetTriple = "x86_64-apple-darwin";
++        break;
++      case "arm64":
++        targetTriple = "aarch64-apple-darwin";
++        break;
++      default:
++        break;
++    }
++    break;
++  case "win32":
++    switch (arch) {
++      case "x64":
++        targetTriple = "x86_64-pc-windows-msvc";
++        break;
++      case "arm64":
++        targetTriple = "aarch64-pc-windows-msvc";
++        break;
++      default:
++        break;
++    }
++    break;
++  default:
++    break;
++}
++
++if (!targetTriple) {
++  throw new Error(`Unsupported platform: ${platform} (${arch})`);
++}
++
++const vendorRoot = path.join(__dirname, "..", "vendor");
++const archRoot = path.join(vendorRoot, targetTriple);
++const codexBinaryName = process.platform === "win32" ? "codex.exe" : "codex";
++const binaryPath = path.join(archRoot, "codex", codexBinaryName);
++
++// Use an asynchronous spawn instead of spawnSync so that Node is able to
++// respond to signals (e.g. Ctrl-C / SIGINT) while the native binary is
++// executing. This allows us to forward those signals to the child process
++// and guarantees that when either the child terminates or the parent
++// receives a fatal signal, both processes exit in a predictable manner.
++
++function getUpdatedPath(newDirs) {
++  const pathSep = process.platform === "win32" ? ";" : ":";
++  const existingPath = process.env.PATH || "";
++  const updatedPath = [
++    ...newDirs,
++    ...existingPath.split(pathSep).filter(Boolean),
++  ].join(pathSep);
++  return updatedPath;
++}
++
++/**
++ * Use heuristics to detect the package manager that was used to install Codex
++ * in order to give the user a hint about how to update it.
++ */
++function detectPackageManager() {
++  const userAgent = process.env.npm_config_user_agent || "";
++  if (/\bbun\//.test(userAgent)) {
++    return "bun";
++  }
++
++  const execPath = process.env.npm_execpath || "";
++  if (execPath.includes("bun")) {
++    return "bun";
++  }
++
++  if (
++    process.env.BUN_INSTALL ||
++    process.env.BUN_INSTALL_GLOBAL_DIR ||
++    process.env.BUN_INSTALL_BIN_DIR
++  ) {
++    return "bun";
++  }
++
++  return userAgent ? "npm" : null;
++}
++
++const additionalDirs = [];
++const pathDir = path.join(archRoot, "path");
++if (existsSync(pathDir)) {
++  additionalDirs.push(pathDir);
++}
++const updatedPath = getUpdatedPath(additionalDirs);
++
++const env = { ...process.env, PATH: updatedPath };
++const packageManagerEnvVar =
++  detectPackageManager() === "bun"
++    ? "CODEX_MANAGED_BY_BUN"
++    : "CODEX_MANAGED_BY_NPM";
++env[packageManagerEnvVar] = "1";
++
++const child = spawn(binaryPath, process.argv.slice(2), {
++  stdio: "inherit",
++  env,
++});
++
++child.on("error", (err) => {
++  // Typically triggered when the binary is missing or not executable.
++  // Re-throwing here will terminate the parent with a non-zero exit code
++  // while still printing a helpful stack trace.
++  // eslint-disable-next-line no-console
++  console.error(err);
++  process.exit(1);
++});
++
++// Forward common termination signals to the child so that it shuts down
++// gracefully. In the handler we temporarily disable the default behavior of
++// exiting immediately; once the child has been signaled we simply wait for
++// its exit event which will in turn terminate the parent (see below).
++const forwardSignal = (signal) => {
++  if (child.killed) {
++    return;
++  }
++  try {
++    child.kill(signal);
++  } catch {
++    /* ignore */
++  }
++};
++
++["SIGINT", "SIGTERM", "SIGHUP"].forEach((sig) => {
++  process.on(sig, () => forwardSignal(sig));
++});
++
++// When the child exits, mirror its termination reason in the parent so that
++// shell scripts and other tooling observe the correct exit status.
++// Wrap the lifetime of the child process in a Promise so that we can await
++// its termination in a structured way. The Promise resolves with an object
++// describing how the child exited: either via exit code or due to a signal.
++const childResult = await new Promise((resolve) => {
++  child.on("exit", (code, signal) => {
++    if (signal) {
++      resolve({ type: "signal", signal });
++    } else {
++      resolve({ type: "code", exitCode: code ?? 1 });
++    }
++  });
++});
++
++if (childResult.type === "signal") {
++  // Re-emit the same signal so that the parent terminates with the expected
++  // semantics (this also sets the correct exit code of 128 + n).
++  process.kill(process.pid, childResult.signal);
++} else {
++  process.exit(childResult.exitCode);
++}
+diff --git a/codex-cli/bin/rg b/codex-cli/bin/rg
+index 5a992570..d388d972 100755
+--- a/codex-cli/bin/rg
++++ b/codex-cli/bin/rg
+@@ -1,79 +1,79 @@
+-#!/usr/bin/env dotslash
+-
+-{
+-  "name": "rg",
+-  "platforms": {
+-    "macos-aarch64": {
+-      "size": 1787248,
+-      "hash": "blake3",
+-      "digest": "8d9942032585ea8ee805937634238d9aee7b210069f4703c88fbe568e26fb78a",
+-      "format": "tar.gz",
+-      "path": "ripgrep-14.1.1-aarch64-apple-darwin/rg",
+-      "providers": [
+-        {
+-          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-aarch64-apple-darwin.tar.gz"
+-        }
+-      ]
+-    },
+-    "linux-aarch64": {
+-      "size": 2047405,
+-      "hash": "blake3",
+-      "digest": "0b670b8fa0a3df2762af2fc82cc4932f684ca4c02dbd1260d4f3133fd4b2a515",
+-      "format": "tar.gz",
+-      "path": "ripgrep-14.1.1-aarch64-unknown-linux-gnu/rg",
+-      "providers": [
+-        {
+-          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-aarch64-unknown-linux-gnu.tar.gz"
+-        }
+-      ]
+-    },
+-    "macos-x86_64": {
+-      "size": 2082672,
+-      "hash": "blake3",
+-      "digest": "e9b862fc8da3127f92791f0ff6a799504154ca9d36c98bf3e60a81c6b1f7289e",
+-      "format": "tar.gz",
+-      "path": "ripgrep-14.1.1-x86_64-apple-darwin/rg",
+-      "providers": [
+-        {
+-          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-apple-darwin.tar.gz"
+-        }
+-      ]
+-    },
+-    "linux-x86_64": {
+-      "size": 2566310,
+-      "hash": "blake3",
+-      "digest": "f73cca4e54d78c31f832c7f6e2c0b4db8b04fa3eaa747915727d570893dbee76",
+-      "format": "tar.gz",
+-      "path": "ripgrep-14.1.1-x86_64-unknown-linux-musl/rg",
+-      "providers": [
+-        {
+-          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-unknown-linux-musl.tar.gz"
+-        }
+-      ]
+-    },
+-    "windows-x86_64": {
+-      "size": 2058893,
+-      "hash": "blake3",
+-      "digest": "a8ce1a6fed4f8093ee997e57f33254e94b2cd18e26358b09db599c89882eadbd",
+-      "format": "zip",
+-      "path": "ripgrep-14.1.1-x86_64-pc-windows-msvc/rg.exe",
+-      "providers": [
+-        {
+-          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-pc-windows-msvc.zip"
+-        }
+-      ]
+-    },
+-    "windows-aarch64": {
+-      "size": 1667740,
+-      "hash": "blake3",
+-      "digest": "47b971a8c4fca1d23a4e7c19bd4d88465ebc395598458133139406d3bf85f3fa",
+-      "format": "zip",
+-      "path": "rg.exe",
+-      "providers": [
+-        {
+-          "url": "https://github.com/microsoft/ripgrep-prebuilt/releases/download/v13.0.0-13/ripgrep-v13.0.0-13-aarch64-pc-windows-msvc.zip"
+-        }
+-      ]
+-    }
+-  }
+-}
++#!/usr/bin/env dotslash
++
++{
++  "name": "rg",
++  "platforms": {
++    "macos-aarch64": {
++      "size": 1787248,
++      "hash": "blake3",
++      "digest": "8d9942032585ea8ee805937634238d9aee7b210069f4703c88fbe568e26fb78a",
++      "format": "tar.gz",
++      "path": "ripgrep-14.1.1-aarch64-apple-darwin/rg",
++      "providers": [
++        {
++          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-aarch64-apple-darwin.tar.gz"
++        }
++      ]
++    },
++    "linux-aarch64": {
++      "size": 2047405,
++      "hash": "blake3",
++      "digest": "0b670b8fa0a3df2762af2fc82cc4932f684ca4c02dbd1260d4f3133fd4b2a515",
++      "format": "tar.gz",
++      "path": "ripgrep-14.1.1-aarch64-unknown-linux-gnu/rg",
++      "providers": [
++        {
++          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-aarch64-unknown-linux-gnu.tar.gz"
++        }
++      ]
++    },
++    "macos-x86_64": {
++      "size": 2082672,
++      "hash": "blake3",
++      "digest": "e9b862fc8da3127f92791f0ff6a799504154ca9d36c98bf3e60a81c6b1f7289e",
++      "format": "tar.gz",
++      "path": "ripgrep-14.1.1-x86_64-apple-darwin/rg",
++      "providers": [
++        {
++          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-apple-darwin.tar.gz"
++        }
++      ]
++    },
++    "linux-x86_64": {
++      "size": 2566310,
++      "hash": "blake3",
++      "digest": "f73cca4e54d78c31f832c7f6e2c0b4db8b04fa3eaa747915727d570893dbee76",
++      "format": "tar.gz",
++      "path": "ripgrep-14.1.1-x86_64-unknown-linux-musl/rg",
++      "providers": [
++        {
++          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-unknown-linux-musl.tar.gz"
++        }
++      ]
++    },
++    "windows-x86_64": {
++      "size": 2058893,
++      "hash": "blake3",
++      "digest": "a8ce1a6fed4f8093ee997e57f33254e94b2cd18e26358b09db599c89882eadbd",
++      "format": "zip",
++      "path": "ripgrep-14.1.1-x86_64-pc-windows-msvc/rg.exe",
++      "providers": [
++        {
++          "url": "https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep-14.1.1-x86_64-pc-windows-msvc.zip"
++        }
++      ]
++    },
++    "windows-aarch64": {
++      "size": 1667740,
++      "hash": "blake3",
++      "digest": "47b971a8c4fca1d23a4e7c19bd4d88465ebc395598458133139406d3bf85f3fa",
++      "format": "zip",
++      "path": "rg.exe",
++      "providers": [
++        {
++          "url": "https://github.com/microsoft/ripgrep-prebuilt/releases/download/v13.0.0-13/ripgrep-v13.0.0-13-aarch64-pc-windows-msvc.zip"
++        }
++      ]
++    }
++  }
++}
+diff --git a/codex-cli/package-lock.json b/codex-cli/package-lock.json
+index 58ee8463..ddf0f069 100644
+--- a/codex-cli/package-lock.json
++++ b/codex-cli/package-lock.json
+@@ -1,18 +1,18 @@
+-{
+-  "name": "@openai/codex",
+-  "version": "0.0.0-dev",
+-  "lockfileVersion": 3,
+-  "packages": {
+-    "": {
+-      "name": "@openai/codex",
+-      "version": "0.0.0-dev",
+-      "license": "Apache-2.0",
+-      "bin": {
+-        "codex": "bin/codex.js"
+-      },
+-      "engines": {
+-        "node": ">=16"
+-      }
+-    }
+-  }
+-}
++{
++  "name": "@openai/codex",
++  "version": "0.0.0-dev",
++  "lockfileVersion": 3,
++  "packages": {
++    "": {
++      "name": "@openai/codex",
++      "version": "0.0.0-dev",
++      "license": "Apache-2.0",
++      "bin": {
++        "codex": "bin/codex.js"
++      },
++      "engines": {
++        "node": ">=16"
++      }
++    }
++  }
++}
+diff --git a/codex-cli/package.json b/codex-cli/package.json
+index b83309e4..e127a2ec 100644
+--- a/codex-cli/package.json
++++ b/codex-cli/package.json
+@@ -1,21 +1,21 @@
+-{
+-  "name": "@openai/codex",
+-  "version": "0.0.0-dev",
+-  "license": "Apache-2.0",
+-  "bin": {
+-    "codex": "bin/codex.js"
+-  },
+-  "type": "module",
+-  "engines": {
+-    "node": ">=16"
+-  },
+-  "files": [
+-    "bin",
+-    "vendor"
+-  ],
+-  "repository": {
+-    "type": "git",
+-    "url": "git+https://github.com/openai/codex.git",
+-    "directory": "codex-cli"
+-  }
+-}
++{
++  "name": "@openai/codex",
++  "version": "0.0.0-dev",
++  "license": "Apache-2.0",
++  "bin": {
++    "codex": "bin/codex.js"
++  },
++  "type": "module",
++  "engines": {
++    "node": ">=16"
++  },
++  "files": [
++    "bin",
++    "vendor"
++  ],
++  "repository": {
++    "type": "git",
++    "url": "git+https://github.com/openai/codex.git",
++    "directory": "codex-cli"
++  }
++}
+diff --git a/codex-cli/scripts/README.md b/codex-cli/scripts/README.md
+index 052cf81a..26e61fe7 100644
+--- a/codex-cli/scripts/README.md
++++ b/codex-cli/scripts/README.md
+@@ -1,19 +1,19 @@
+-# npm releases
+-
+-Use the staging helper in the repo root to generate npm tarballs for a release. For
+-example, to stage the CLI, responses proxy, and SDK packages for version `0.6.0`:
+-
+-```bash
+-./scripts/stage_npm_packages.py \
+-  --release-version 0.6.0 \
+-  --package codex \
+-  --package codex-responses-api-proxy \
+-  --package codex-sdk
+-```
+-
+-This downloads the native artifacts once, hydrates `vendor/` for each package, and writes
+-tarballs to `dist/npm/`.
+-
+-If you need to invoke `build_npm_package.py` directly, run
+-`codex-cli/scripts/install_native_deps.py` first and pass `--vendor-src` pointing to the
+-directory that contains the populated `vendor/` tree.
++# npm releases
++
++Use the staging helper in the repo root to generate npm tarballs for a release. For
++example, to stage the CLI, responses proxy, and SDK packages for version `0.6.0`:
++
++```bash
++./scripts/stage_npm_packages.py \
++  --release-version 0.6.0 \
++  --package codex \
++  --package codex-responses-api-proxy \
++  --package codex-sdk
++```
++
++This downloads the native artifacts once, hydrates `vendor/` for each package, and writes
++tarballs to `dist/npm/`.
++
++If you need to invoke `build_npm_package.py` directly, run
++`codex-cli/scripts/install_native_deps.py` first and pass `--vendor-src` pointing to the
++directory that contains the populated `vendor/` tree.
+diff --git a/codex-cli/scripts/build_container.sh b/codex-cli/scripts/build_container.sh
+index d4d29f6b..9c5bd156 100755
+--- a/codex-cli/scripts/build_container.sh
++++ b/codex-cli/scripts/build_container.sh
+@@ -1,16 +1,16 @@
+-#!/bin/bash
+-
+-set -euo pipefail
+-
+-SCRIPT_DIR=$(realpath "$(dirname "$0")")
+-trap "popd >> /dev/null" EXIT
+-pushd "$SCRIPT_DIR/.." >> /dev/null || {
+-  echo "Error: Failed to change directory to $SCRIPT_DIR/.."
+-  exit 1
+-}
+-pnpm install
+-pnpm run build
+-rm -rf ./dist/openai-codex-*.tgz
+-pnpm pack --pack-destination ./dist
+-mv ./dist/openai-codex-*.tgz ./dist/codex.tgz
+-docker build -t codex -f "./Dockerfile" .
++#!/bin/bash
++
++set -euo pipefail
++
++SCRIPT_DIR=$(realpath "$(dirname "$0")")
++trap "popd >> /dev/null" EXIT
++pushd "$SCRIPT_DIR/.." >> /dev/null || {
++  echo "Error: Failed to change directory to $SCRIPT_DIR/.."
++  exit 1
++}
++pnpm install
++pnpm run build
++rm -rf ./dist/openai-codex-*.tgz
++pnpm pack --pack-destination ./dist
++mv ./dist/openai-codex-*.tgz ./dist/codex.tgz
++docker build -t codex -f "./Dockerfile" .
+diff --git a/codex-cli/scripts/build_npm_package.py b/codex-cli/scripts/build_npm_package.py
+index ef96bef2..25fb5db4 100755
+--- a/codex-cli/scripts/build_npm_package.py
++++ b/codex-cli/scripts/build_npm_package.py
+@@ -1,308 +1,308 @@
+-#!/usr/bin/env python3
+-"""Stage and optionally package the @openai/codex npm module."""
+-
+-import argparse
+-import json
+-import shutil
+-import subprocess
+-import sys
+-import tempfile
+-from pathlib import Path
+-
+-SCRIPT_DIR = Path(__file__).resolve().parent
+-CODEX_CLI_ROOT = SCRIPT_DIR.parent
+-REPO_ROOT = CODEX_CLI_ROOT.parent
+-RESPONSES_API_PROXY_NPM_ROOT = REPO_ROOT / "codex-rs" / "responses-api-proxy" / "npm"
+-CODEX_SDK_ROOT = REPO_ROOT / "sdk" / "typescript"
+-
+-PACKAGE_NATIVE_COMPONENTS: dict[str, list[str]] = {
+-    "codex": ["codex", "rg"],
+-    "codex-responses-api-proxy": ["codex-responses-api-proxy"],
+-    "codex-sdk": ["codex"],
+-}
+-COMPONENT_DEST_DIR: dict[str, str] = {
+-    "codex": "codex",
+-    "codex-responses-api-proxy": "codex-responses-api-proxy",
+-    "rg": "path",
+-}
+-
+-
+-def parse_args() -> argparse.Namespace:
+-    parser = argparse.ArgumentParser(description="Build or stage the Codex CLI npm package.")
+-    parser.add_argument(
+-        "--package",
+-        choices=("codex", "codex-responses-api-proxy", "codex-sdk"),
+-        default="codex",
+-        help="Which npm package to stage (default: codex).",
+-    )
+-    parser.add_argument(
+-        "--version",
+-        help="Version number to write to package.json inside the staged package.",
+-    )
+-    parser.add_argument(
+-        "--release-version",
+-        help=(
+-            "Version to stage for npm release."
+-        ),
+-    )
+-    parser.add_argument(
+-        "--staging-dir",
+-        type=Path,
+-        help=(
+-            "Directory to stage the package contents. Defaults to a new temporary directory "
+-            "if omitted. The directory must be empty when provided."
+-        ),
+-    )
+-    parser.add_argument(
+-        "--tmp",
+-        dest="staging_dir",
+-        type=Path,
+-        help=argparse.SUPPRESS,
+-    )
+-    parser.add_argument(
+-        "--pack-output",
+-        type=Path,
+-        help="Path where the generated npm tarball should be written.",
+-    )
+-    parser.add_argument(
+-        "--vendor-src",
+-        type=Path,
+-        help="Directory containing pre-installed native binaries to bundle (vendor root).",
+-    )
+-    return parser.parse_args()
+-
+-
+-def main() -> int:
+-    args = parse_args()
+-
+-    package = args.package
+-    version = args.version
+-    release_version = args.release_version
+-    if release_version:
+-        if version and version != release_version:
+-            raise RuntimeError("--version and --release-version must match when both are provided.")
+-        version = release_version
+-
+-    if not version:
+-        raise RuntimeError("Must specify --version or --release-version.")
+-
+-    staging_dir, created_temp = prepare_staging_dir(args.staging_dir)
+-
+-    try:
+-        stage_sources(staging_dir, version, package)
+-
+-        vendor_src = args.vendor_src.resolve() if args.vendor_src else None
+-        native_components = PACKAGE_NATIVE_COMPONENTS.get(package, [])
+-
+-        if native_components:
+-            if vendor_src is None:
+-                components_str = ", ".join(native_components)
+-                raise RuntimeError(
+-                    "Native components "
+-                    f"({components_str}) required for package '{package}'. Provide --vendor-src "
+-                    "pointing to a directory containing pre-installed binaries."
+-                )
+-
+-            copy_native_binaries(vendor_src, staging_dir, native_components)
+-
+-        if release_version:
+-            staging_dir_str = str(staging_dir)
+-            if package == "codex":
+-                print(
+-                    f"Staged version {version} for release in {staging_dir_str}\n\n"
+-                    "Verify the CLI:\n"
+-                    f"    node {staging_dir_str}/bin/codex.js --version\n"
+-                    f"    node {staging_dir_str}/bin/codex.js --help\n\n"
+-                )
+-            elif package == "codex-responses-api-proxy":
+-                print(
+-                    f"Staged version {version} for release in {staging_dir_str}\n\n"
+-                    "Verify the responses API proxy:\n"
+-                    f"    node {staging_dir_str}/bin/codex-responses-api-proxy.js --help\n\n"
+-                )
+-            else:
+-                print(
+-                    f"Staged version {version} for release in {staging_dir_str}\n\n"
+-                    "Verify the SDK contents:\n"
+-                    f"    ls {staging_dir_str}/dist\n"
+-                    f"    ls {staging_dir_str}/vendor\n"
+-                    "    node -e \"import('./dist/index.js').then(() => console.log('ok'))\"\n\n"
+-                )
+-        else:
+-            print(f"Staged package in {staging_dir}")
+-
+-        if args.pack_output is not None:
+-            output_path = run_npm_pack(staging_dir, args.pack_output)
+-            print(f"npm pack output written to {output_path}")
+-    finally:
+-        if created_temp:
+-            # Preserve the staging directory for further inspection.
+-            pass
+-
+-    return 0
+-
+-
+-def prepare_staging_dir(staging_dir: Path | None) -> tuple[Path, bool]:
+-    if staging_dir is not None:
+-        staging_dir = staging_dir.resolve()
+-        staging_dir.mkdir(parents=True, exist_ok=True)
+-        if any(staging_dir.iterdir()):
+-            raise RuntimeError(f"Staging directory {staging_dir} is not empty.")
+-        return staging_dir, False
+-
+-    temp_dir = Path(tempfile.mkdtemp(prefix="codex-npm-stage-"))
+-    return temp_dir, True
+-
+-
+-def stage_sources(staging_dir: Path, version: str, package: str) -> None:
+-    if package == "codex":
+-        bin_dir = staging_dir / "bin"
+-        bin_dir.mkdir(parents=True, exist_ok=True)
+-        shutil.copy2(CODEX_CLI_ROOT / "bin" / "codex.js", bin_dir / "codex.js")
+-        rg_manifest = CODEX_CLI_ROOT / "bin" / "rg"
+-        if rg_manifest.exists():
+-            shutil.copy2(rg_manifest, bin_dir / "rg")
+-
+-        readme_src = REPO_ROOT / "README.md"
+-        if readme_src.exists():
+-            shutil.copy2(readme_src, staging_dir / "README.md")
+-
+-        package_json_path = CODEX_CLI_ROOT / "package.json"
+-    elif package == "codex-responses-api-proxy":
+-        bin_dir = staging_dir / "bin"
+-        bin_dir.mkdir(parents=True, exist_ok=True)
+-        launcher_src = RESPONSES_API_PROXY_NPM_ROOT / "bin" / "codex-responses-api-proxy.js"
+-        shutil.copy2(launcher_src, bin_dir / "codex-responses-api-proxy.js")
+-
+-        readme_src = RESPONSES_API_PROXY_NPM_ROOT / "README.md"
+-        if readme_src.exists():
+-            shutil.copy2(readme_src, staging_dir / "README.md")
+-
+-        package_json_path = RESPONSES_API_PROXY_NPM_ROOT / "package.json"
+-    elif package == "codex-sdk":
+-        package_json_path = CODEX_SDK_ROOT / "package.json"
+-        stage_codex_sdk_sources(staging_dir)
+-    else:
+-        raise RuntimeError(f"Unknown package '{package}'.")
+-
+-    with open(package_json_path, "r", encoding="utf-8") as fh:
+-        package_json = json.load(fh)
+-    package_json["version"] = version
+-
+-    if package == "codex-sdk":
+-        scripts = package_json.get("scripts")
+-        if isinstance(scripts, dict):
+-            scripts.pop("prepare", None)
+-
+-        files = package_json.get("files")
+-        if isinstance(files, list):
+-            if "vendor" not in files:
+-                files.append("vendor")
+-        else:
+-            package_json["files"] = ["dist", "vendor"]
+-
+-    with open(staging_dir / "package.json", "w", encoding="utf-8") as out:
+-        json.dump(package_json, out, indent=2)
+-        out.write("\n")
+-
+-
+-def run_command(cmd: list[str], cwd: Path | None = None) -> None:
+-    print("+", " ".join(cmd))
+-    subprocess.run(cmd, cwd=cwd, check=True)
+-
+-
+-def stage_codex_sdk_sources(staging_dir: Path) -> None:
+-    package_root = CODEX_SDK_ROOT
+-
+-    run_command(["pnpm", "install", "--frozen-lockfile"], cwd=package_root)
+-    run_command(["pnpm", "run", "build"], cwd=package_root)
+-
+-    dist_src = package_root / "dist"
+-    if not dist_src.exists():
+-        raise RuntimeError("codex-sdk build did not produce a dist directory.")
+-
+-    shutil.copytree(dist_src, staging_dir / "dist")
+-
+-    readme_src = package_root / "README.md"
+-    if readme_src.exists():
+-        shutil.copy2(readme_src, staging_dir / "README.md")
+-
+-    license_src = REPO_ROOT / "LICENSE"
+-    if license_src.exists():
+-        shutil.copy2(license_src, staging_dir / "LICENSE")
+-
+-
+-def copy_native_binaries(vendor_src: Path, staging_dir: Path, components: list[str]) -> None:
+-    vendor_src = vendor_src.resolve()
+-    if not vendor_src.exists():
+-        raise RuntimeError(f"Vendor source directory not found: {vendor_src}")
+-
+-    components_set = {component for component in components if component in COMPONENT_DEST_DIR}
+-    if not components_set:
+-        return
+-
+-    vendor_dest = staging_dir / "vendor"
+-    if vendor_dest.exists():
+-        shutil.rmtree(vendor_dest)
+-    vendor_dest.mkdir(parents=True, exist_ok=True)
+-
+-    for target_dir in vendor_src.iterdir():
+-        if not target_dir.is_dir():
+-            continue
+-
+-        dest_target_dir = vendor_dest / target_dir.name
+-        dest_target_dir.mkdir(parents=True, exist_ok=True)
+-
+-        for component in components_set:
+-            dest_dir_name = COMPONENT_DEST_DIR.get(component)
+-            if dest_dir_name is None:
+-                continue
+-
+-            src_component_dir = target_dir / dest_dir_name
+-            if not src_component_dir.exists():
+-                raise RuntimeError(
+-                    f"Missing native component '{component}' in vendor source: {src_component_dir}"
+-                )
+-
+-            dest_component_dir = dest_target_dir / dest_dir_name
+-            if dest_component_dir.exists():
+-                shutil.rmtree(dest_component_dir)
+-            shutil.copytree(src_component_dir, dest_component_dir)
+-
+-
+-def run_npm_pack(staging_dir: Path, output_path: Path) -> Path:
+-    output_path = output_path.resolve()
+-    output_path.parent.mkdir(parents=True, exist_ok=True)
+-
+-    with tempfile.TemporaryDirectory(prefix="codex-npm-pack-") as pack_dir_str:
+-        pack_dir = Path(pack_dir_str)
+-        stdout = subprocess.check_output(
+-            ["npm", "pack", "--json", "--pack-destination", str(pack_dir)],
+-            cwd=staging_dir,
+-            text=True,
+-        )
+-        try:
+-            pack_output = json.loads(stdout)
+-        except json.JSONDecodeError as exc:
+-            raise RuntimeError("Failed to parse npm pack output.") from exc
+-
+-        if not pack_output:
+-            raise RuntimeError("npm pack did not produce an output tarball.")
+-
+-        tarball_name = pack_output[0].get("filename") or pack_output[0].get("name")
+-        if not tarball_name:
+-            raise RuntimeError("Unable to determine npm pack output filename.")
+-
+-        tarball_path = pack_dir / tarball_name
+-        if not tarball_path.exists():
+-            raise RuntimeError(f"Expected npm pack output not found: {tarball_path}")
+-
+-        shutil.move(str(tarball_path), output_path)
+-
+-    return output_path
+-
+-
+-if __name__ == "__main__":
+-    import sys
+-
+-    sys.exit(main())
++#!/usr/bin/env python3
++"""Stage and optionally package the @openai/codex npm module."""
++
++import argparse
++import json
++import shutil
++import subprocess
++import sys
++import tempfile
++from pathlib import Path
++
++SCRIPT_DIR = Path(__file__).resolve().parent
++CODEX_CLI_ROOT = SCRIPT_DIR.parent
++REPO_ROOT = CODEX_CLI_ROOT.parent
++RESPONSES_API_PROXY_NPM_ROOT = REPO_ROOT / "codex-rs" / "responses-api-proxy" / "npm"
++CODEX_SDK_ROOT = REPO_ROOT / "sdk" / "typescript"
++
++PACKAGE_NATIVE_COMPONENTS: dict[str, list[str]] = {
++    "codex": ["codex", "rg"],
++    "codex-responses-api-proxy": ["codex-responses-api-proxy"],
++    "codex-sdk": ["codex"],
++}
++COMPONENT_DEST_DIR: dict[str, str] = {
++    "codex": "codex",
++    "codex-responses-api-proxy": "codex-responses-api-proxy",
++    "rg": "path",
++}
++
++
++def parse_args() -> argparse.Namespace:
++    parser = argparse.ArgumentParser(description="Build or stage the Codex CLI npm package.")
++    parser.add_argument(
++        "--package",
++        choices=("codex", "codex-responses-api-proxy", "codex-sdk"),
++        default="codex",
++        help="Which npm package to stage (default: codex).",
++    )
++    parser.add_argument(
++        "--version",
++        help="Version number to write to package.json inside the staged package.",
++    )
++    parser.add_argument(
++        "--release-version",
++        help=(
++            "Version to stage for npm release."
++        ),
++    )
++    parser.add_argument(
++        "--staging-dir",
++        type=Path,
++        help=(
++            "Directory to stage the package contents. Defaults to a new temporary directory "
++            "if omitted. The directory must be empty when provided."
++        ),
++    )
++    parser.add_argument(
++        "--tmp",
++        dest="staging_dir",
++        type=Path,
++        help=argparse.SUPPRESS,
++    )
++    parser.add_argument(
++        "--pack-output",
++        type=Path,
++        help="Path where the generated npm tarball should be written.",
++    )
++    parser.add_argument(
++        "--vendor-src",
++        type=Path,
++        help="Directory containing pre-installed native binaries to bundle (vendor root).",
++    )
++    return parser.parse_args()
++
++
++def main() -> int:
++    args = parse_args()
++
++    package = args.package
++    version = args.version
++    release_version = args.release_version
++    if release_version:
++        if version and version != release_version:
++            raise RuntimeError("--version and --release-version must match when both are provided.")
++        version = release_version
++
++    if not version:
++        raise RuntimeError("Must specify --version or --release-version.")
++
++    staging_dir, created_temp = prepare_staging_dir(args.staging_dir)
++
++    try:
++        stage_sources(staging_dir, version, package)
++
++        vendor_src = args.vendor_src.resolve() if args.vendor_src else None
++        native_components = PACKAGE_NATIVE_COMPONENTS.get(package, [])
++
++        if native_components:
++            if vendor_src is None:
++                components_str = ", ".join(native_components)
++                raise RuntimeError(
++                    "Native components "
++                    f"({components_str}) required for package '{package}'. Provide --vendor-src "
++                    "pointing to a directory containing pre-installed binaries."
++                )
++
++            copy_native_binaries(vendor_src, staging_dir, native_components)
++
++        if release_version:
++            staging_dir_str = str(staging_dir)
++            if package == "codex":
++                print(
++                    f"Staged version {version} for release in {staging_dir_str}\n\n"
++                    "Verify the CLI:\n"
++                    f"    node {staging_dir_str}/bin/codex.js --version\n"
++                    f"    node {staging_dir_str}/bin/codex.js --help\n\n"
++                )
++            elif package == "codex-responses-api-proxy":
++                print(
++                    f"Staged version {version} for release in {staging_dir_str}\n\n"
++                    "Verify the responses API proxy:\n"
++                    f"    node {staging_dir_str}/bin/codex-responses-api-proxy.js --help\n\n"
++                )
++            else:
++                print(
++                    f"Staged version {version} for release in {staging_dir_str}\n\n"
++                    "Verify the SDK contents:\n"
++                    f"    ls {staging_dir_str}/dist\n"
++                    f"    ls {staging_dir_str}/vendor\n"
++                    "    node -e \"import('./dist/index.js').then(() => console.log('ok'))\"\n\n"
++                )
++        else:
++            print(f"Staged package in {staging_dir}")
++
++        if args.pack_output is not None:
++            output_path = run_npm_pack(staging_dir, args.pack_output)
++            print(f"npm pack output written to {output_path}")
++    finally:
++        if created_temp:
++            # Preserve the staging directory for further inspection.
++            pass
++
++    return 0
++
++
++def prepare_staging_dir(staging_dir: Path | None) -> tuple[Path, bool]:
++    if staging_dir is not None:
++        staging_dir = staging_dir.resolve()
++        staging_dir.mkdir(parents=True, exist_ok=True)
++        if any(staging_dir.iterdir()):
++            raise RuntimeError(f"Staging directory {staging_dir} is not empty.")
++        return staging_dir, False
++
++    temp_dir = Path(tempfile.mkdtemp(prefix="codex-npm-stage-"))
++    return temp_dir, True
++
++
++def stage_sources(staging_dir: Path, version: str, package: str) -> None:
++    if package == "codex":
++        bin_dir = staging_dir / "bin"
++        bin_dir.mkdir(parents=True, exist_ok=True)
++        shutil.copy2(CODEX_CLI_ROOT / "bin" / "codex.js", bin_dir / "codex.js")
++        rg_manifest = CODEX_CLI_ROOT / "bin" / "rg"
++        if rg_manifest.exists():
++            shutil.copy2(rg_manifest, bin_dir / "rg")
++
++        readme_src = REPO_ROOT / "README.md"
++        if readme_src.exists():
++            shutil.copy2(readme_src, staging_dir / "README.md")
++
++        package_json_path = CODEX_CLI_ROOT / "package.json"
++    elif package == "codex-responses-api-proxy":
++        bin_dir = staging_dir / "bin"
++        bin_dir.mkdir(parents=True, exist_ok=True)
++        launcher_src = RESPONSES_API_PROXY_NPM_ROOT / "bin" / "codex-responses-api-proxy.js"
++        shutil.copy2(launcher_src, bin_dir / "codex-responses-api-proxy.js")
++
++        readme_src = RESPONSES_API_PROXY_NPM_ROOT / "README.md"
++        if readme_src.exists():
++            shutil.copy2(readme_src, staging_dir / "README.md")
++
++        package_json_path = RESPONSES_API_PROXY_NPM_ROOT / "package.json"
++    elif package == "codex-sdk":
++        package_json_path = CODEX_SDK_ROOT / "package.json"
++        stage_codex_sdk_sources(staging_dir)
++    else:
++        raise RuntimeError(f"Unknown package '{package}'.")
++
++    with open(package_json_path, "r", encoding="utf-8") as fh:
++        package_json = json.load(fh)
++    package_json["version"] = version
++
++    if package == "codex-sdk":
++        scripts = package_json.get("scripts")
++        if isinstance(scripts, dict):
++            scripts.pop("prepare", None)
++
++        files = package_json.get("files")
++        if isinstance(files, list):
++            if "vendor" not in files:
++                files.append("vendor")
++        else:
++            package_json["files"] = ["dist", "vendor"]
++
++    with open(staging_dir / "package.json", "w", encoding="utf-8") as out:
++        json.dump(package_json, out, indent=2)
++        out.write("\n")
++
++
++def run_command(cmd: list[str], cwd: Path | None = None) -> None:
++    print("+", " ".join(cmd))
++    subprocess.run(cmd, cwd=cwd, check=True)
++
++
++def stage_codex_sdk_sources(staging_dir: Path) -> None:
++    package_root = CODEX_SDK_ROOT
++
++    run_command(["pnpm", "install", "--frozen-lockfile"], cwd=package_root)
++    run_command(["pnpm", "run", "build"], cwd=package_root)
++
++    dist_src = package_root / "dist"
++    if not dist_src.exists():
++        raise RuntimeError("codex-sdk build did not produce a dist directory.")
++
++    shutil.copytree(dist_src, staging_dir / "dist")
++
++    readme_src = package_root / "README.md"
++    if readme_src.exists():
++        shutil.copy2(readme_src, staging_dir / "README.md")
++
++    license_src = REPO_ROOT / "LICENSE"
++    if license_src.exists():
++        shutil.copy2(license_src, staging_dir / "LICENSE")
++
++
++def copy_native_binaries(vendor_src: Path, staging_dir: Path, components: list[str]) -> None:
++    vendor_src = vendor_src.resolve()
++    if not vendor_src.exists():
++        raise RuntimeError(f"Vendor source directory not found: {vendor_src}")
++
++    components_set = {component for component in components if component in COMPONENT_DEST_DIR}
++    if not components_set:
++        return
++
++    vendor_dest = staging_dir / "vendor"
++    if vendor_dest.exists():
++        shutil.rmtree(vendor_dest)
++    vendor_dest.mkdir(parents=True, exist_ok=True)
++
++    for target_dir in vendor_src.iterdir():
++        if not target_dir.is_dir():
++            continue
++
++        dest_target_dir = vendor_dest / target_dir.name
++        dest_target_dir.mkdir(parents=True, exist_ok=True)
++
++        for component in components_set:
++            dest_dir_name = COMPONENT_DEST_DIR.get(component)
++            if dest_dir_name is None:
++                continue
++
++            src_component_dir = target_dir / dest_dir_name
++            if not src_component_dir.exists():
++                raise RuntimeError(
++                    f"Missing native component '{component}' in vendor source: {src_component_dir}"
++                )
++
++            dest_component_dir = dest_target_dir / dest_dir_name
++            if dest_component_dir.exists():
++                shutil.rmtree(dest_component_dir)
++            shutil.copytree(src_component_dir, dest_component_dir)
++
++
++def run_npm_pack(staging_dir: Path, output_path: Path) -> Path:
++    output_path = output_path.resolve()
++    output_path.parent.mkdir(parents=True, exist_ok=True)
++
++    with tempfile.TemporaryDirectory(prefix="codex-npm-pack-") as pack_dir_str:
++        pack_dir = Path(pack_dir_str)
++        stdout = subprocess.check_output(
++            ["npm", "pack", "--json", "--pack-destination", str(pack_dir)],
++            cwd=staging_dir,
++            text=True,
++        )
++        try:
++            pack_output = json.loads(stdout)
++        except json.JSONDecodeError as exc:
++            raise RuntimeError("Failed to parse npm pack output.") from exc
++
++        if not pack_output:
++            raise RuntimeError("npm pack did not produce an output tarball.")
++
++        tarball_name = pack_output[0].get("filename") or pack_output[0].get("name")
++        if not tarball_name:
++            raise RuntimeError("Unable to determine npm pack output filename.")
++
++        tarball_path = pack_dir / tarball_name
++        if not tarball_path.exists():
++            raise RuntimeError(f"Expected npm pack output not found: {tarball_path}")
++
++        shutil.move(str(tarball_path), output_path)
++
++    return output_path
++
++
++if __name__ == "__main__":
++    import sys
++
++    sys.exit(main())
+diff --git a/codex-cli/scripts/init_firewall.sh b/codex-cli/scripts/init_firewall.sh
+index 1251325f..7751a4e4 100644
+--- a/codex-cli/scripts/init_firewall.sh
++++ b/codex-cli/scripts/init_firewall.sh
+@@ -1,115 +1,115 @@
+-#!/bin/bash
+-set -euo pipefail  # Exit on error, undefined vars, and pipeline failures
+-IFS=$'\n\t'       # Stricter word splitting
+-
+-# Read allowed domains from file
+-ALLOWED_DOMAINS_FILE="/etc/codex/allowed_domains.txt"
+-if [ -f "$ALLOWED_DOMAINS_FILE" ]; then
+-    ALLOWED_DOMAINS=()
+-    while IFS= read -r domain; do
+-        ALLOWED_DOMAINS+=("$domain")
+-    done < "$ALLOWED_DOMAINS_FILE"
+-    echo "Using domains from file: ${ALLOWED_DOMAINS[*]}"
+-else
+-    # Fallback to default domains
+-    ALLOWED_DOMAINS=("api.openai.com")
+-    echo "Domains file not found, using default: ${ALLOWED_DOMAINS[*]}"
+-fi
+-
+-# Ensure we have at least one domain
+-if [ ${#ALLOWED_DOMAINS[@]} -eq 0 ]; then
+-    echo "ERROR: No allowed domains specified"
+-    exit 1
+-fi
+-
+-# Flush existing rules and delete existing ipsets
+-iptables -F
+-iptables -X
+-iptables -t nat -F
+-iptables -t nat -X
+-iptables -t mangle -F
+-iptables -t mangle -X
+-ipset destroy allowed-domains 2>/dev/null || true
+-
+-# First allow DNS and localhost before any restrictions
+-# Allow outbound DNS
+-iptables -A OUTPUT -p udp --dport 53 -j ACCEPT
+-# Allow inbound DNS responses
+-iptables -A INPUT -p udp --sport 53 -j ACCEPT
+-# Allow localhost
+-iptables -A INPUT -i lo -j ACCEPT
+-iptables -A OUTPUT -o lo -j ACCEPT
+-
+-# Create ipset with CIDR support
+-ipset create allowed-domains hash:net
+-
+-# Resolve and add other allowed domains
+-for domain in "${ALLOWED_DOMAINS[@]}"; do
+-    echo "Resolving $domain..."
+-    ips=$(dig +short A "$domain")
+-    if [ -z "$ips" ]; then
+-        echo "ERROR: Failed to resolve $domain"
+-        exit 1
+-    fi
+-
+-    while read -r ip; do
+-        if [[ ! "$ip" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
+-            echo "ERROR: Invalid IP from DNS for $domain: $ip"
+-            exit 1
+-        fi
+-        echo "Adding $ip for $domain"
+-        ipset add allowed-domains "$ip"
+-    done < <(echo "$ips")
+-done
+-
+-# Get host IP from default route
+-HOST_IP=$(ip route | grep default | cut -d" " -f3)
+-if [ -z "$HOST_IP" ]; then
+-    echo "ERROR: Failed to detect host IP"
+-    exit 1
+-fi
+-
+-HOST_NETWORK=$(echo "$HOST_IP" | sed "s/\.[0-9]*$/.0\/24/")
+-echo "Host network detected as: $HOST_NETWORK"
+-
+-# Set up remaining iptables rules
+-iptables -A INPUT -s "$HOST_NETWORK" -j ACCEPT
+-iptables -A OUTPUT -d "$HOST_NETWORK" -j ACCEPT
+-
+-# Set default policies to DROP first
+-iptables -P INPUT DROP
+-iptables -P FORWARD DROP
+-iptables -P OUTPUT DROP
+-
+-# First allow established connections for already approved traffic
+-iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
+-iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
+-
+-# Then allow only specific outbound traffic to allowed domains
+-iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
+-
+-# Append final REJECT rules for immediate error responses
+-# For TCP traffic, send a TCP reset; for UDP, send ICMP port unreachable.
+-iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset
+-iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable
+-iptables -A OUTPUT -p tcp -j REJECT --reject-with tcp-reset
+-iptables -A OUTPUT -p udp -j REJECT --reject-with icmp-port-unreachable
+-iptables -A FORWARD -p tcp -j REJECT --reject-with tcp-reset
+-iptables -A FORWARD -p udp -j REJECT --reject-with icmp-port-unreachable
+-
+-echo "Firewall configuration complete"
+-echo "Verifying firewall rules..."
+-if curl --connect-timeout 5 https://example.com >/dev/null 2>&1; then
+-    echo "ERROR: Firewall verification failed - was able to reach https://example.com"
+-    exit 1
+-else
+-    echo "Firewall verification passed - unable to reach https://example.com as expected"
+-fi
+-
+-# Always verify OpenAI API access is working
+-if ! curl --connect-timeout 5 https://api.openai.com >/dev/null 2>&1; then
+-    echo "ERROR: Firewall verification failed - unable to reach https://api.openai.com"
+-    exit 1
+-else
+-    echo "Firewall verification passed - able to reach https://api.openai.com as expected"
+-fi
++#!/bin/bash
++set -euo pipefail  # Exit on error, undefined vars, and pipeline failures
++IFS=$'\n\t'       # Stricter word splitting
++
++# Read allowed domains from file
++ALLOWED_DOMAINS_FILE="/etc/codex/allowed_domains.txt"
++if [ -f "$ALLOWED_DOMAINS_FILE" ]; then
++    ALLOWED_DOMAINS=()
++    while IFS= read -r domain; do
++        ALLOWED_DOMAINS+=("$domain")
++    done < "$ALLOWED_DOMAINS_FILE"
++    echo "Using domains from file: ${ALLOWED_DOMAINS[*]}"
++else
++    # Fallback to default domains
++    ALLOWED_DOMAINS=("api.openai.com")
++    echo "Domains file not found, using default: ${ALLOWED_DOMAINS[*]}"
++fi
++
++# Ensure we have at least one domain
++if [ ${#ALLOWED_DOMAINS[@]} -eq 0 ]; then
++    echo "ERROR: No allowed domains specified"
++    exit 1
++fi
++
++# Flush existing rules and delete existing ipsets
++iptables -F
++iptables -X
++iptables -t nat -F
++iptables -t nat -X
++iptables -t mangle -F
++iptables -t mangle -X
++ipset destroy allowed-domains 2>/dev/null || true
++
++# First allow DNS and localhost before any restrictions
++# Allow outbound DNS
++iptables -A OUTPUT -p udp --dport 53 -j ACCEPT
++# Allow inbound DNS responses
++iptables -A INPUT -p udp --sport 53 -j ACCEPT
++# Allow localhost
++iptables -A INPUT -i lo -j ACCEPT
++iptables -A OUTPUT -o lo -j ACCEPT
++
++# Create ipset with CIDR support
++ipset create allowed-domains hash:net
++
++# Resolve and add other allowed domains
++for domain in "${ALLOWED_DOMAINS[@]}"; do
++    echo "Resolving $domain..."
++    ips=$(dig +short A "$domain")
++    if [ -z "$ips" ]; then
++        echo "ERROR: Failed to resolve $domain"
++        exit 1
++    fi
++
++    while read -r ip; do
++        if [[ ! "$ip" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
++            echo "ERROR: Invalid IP from DNS for $domain: $ip"
++            exit 1
++        fi
++        echo "Adding $ip for $domain"
++        ipset add allowed-domains "$ip"
++    done < <(echo "$ips")
++done
++
++# Get host IP from default route
++HOST_IP=$(ip route | grep default | cut -d" " -f3)
++if [ -z "$HOST_IP" ]; then
++    echo "ERROR: Failed to detect host IP"
++    exit 1
++fi
++
++HOST_NETWORK=$(echo "$HOST_IP" | sed "s/\.[0-9]*$/.0\/24/")
++echo "Host network detected as: $HOST_NETWORK"
++
++# Set up remaining iptables rules
++iptables -A INPUT -s "$HOST_NETWORK" -j ACCEPT
++iptables -A OUTPUT -d "$HOST_NETWORK" -j ACCEPT
++
++# Set default policies to DROP first
++iptables -P INPUT DROP
++iptables -P FORWARD DROP
++iptables -P OUTPUT DROP
++
++# First allow established connections for already approved traffic
++iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
++iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
++
++# Then allow only specific outbound traffic to allowed domains
++iptables -A OUTPUT -m set --match-set allowed-domains dst -j ACCEPT
++
++# Append final REJECT rules for immediate error responses
++# For TCP traffic, send a TCP reset; for UDP, send ICMP port unreachable.
++iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset
++iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable
++iptables -A OUTPUT -p tcp -j REJECT --reject-with tcp-reset
++iptables -A OUTPUT -p udp -j REJECT --reject-with icmp-port-unreachable
++iptables -A FORWARD -p tcp -j REJECT --reject-with tcp-reset
++iptables -A FORWARD -p udp -j REJECT --reject-with icmp-port-unreachable
++
++echo "Firewall configuration complete"
++echo "Verifying firewall rules..."
++if curl --connect-timeout 5 https://example.com >/dev/null 2>&1; then
++    echo "ERROR: Firewall verification failed - was able to reach https://example.com"
++    exit 1
++else
++    echo "Firewall verification passed - unable to reach https://example.com as expected"
++fi
++
++# Always verify OpenAI API access is working
++if ! curl --connect-timeout 5 https://api.openai.com >/dev/null 2>&1; then
++    echo "ERROR: Firewall verification failed - unable to reach https://api.openai.com"
++    exit 1
++else
++    echo "Firewall verification passed - able to reach https://api.openai.com as expected"
++fi
+diff --git a/codex-cli/scripts/install_native_deps.py b/codex-cli/scripts/install_native_deps.py
+index 8d3909c9..99ca53e2 100755
+--- a/codex-cli/scripts/install_native_deps.py
++++ b/codex-cli/scripts/install_native_deps.py
+@@ -1,383 +1,383 @@
+-#!/usr/bin/env python3
+-"""Install Codex native binaries (Rust CLI plus ripgrep helpers)."""
+-
+-import argparse
+-import json
+-import os
+-import shutil
+-import subprocess
+-import tarfile
+-import tempfile
+-import zipfile
+-from dataclasses import dataclass
+-from concurrent.futures import ThreadPoolExecutor, as_completed
+-from pathlib import Path
+-from typing import Iterable, Sequence
+-from urllib.parse import urlparse
+-from urllib.request import urlopen
+-
+-SCRIPT_DIR = Path(__file__).resolve().parent
+-CODEX_CLI_ROOT = SCRIPT_DIR.parent
+-DEFAULT_WORKFLOW_URL = "https://github.com/openai/codex/actions/runs/17952349351"  # rust-v0.40.0
+-VENDOR_DIR_NAME = "vendor"
+-RG_MANIFEST = CODEX_CLI_ROOT / "bin" / "rg"
+-BINARY_TARGETS = (
+-    "x86_64-unknown-linux-musl",
+-    "aarch64-unknown-linux-musl",
+-    "x86_64-apple-darwin",
+-    "aarch64-apple-darwin",
+-    "x86_64-pc-windows-msvc",
+-    "aarch64-pc-windows-msvc",
+-)
+-
+-
+-@dataclass(frozen=True)
+-class BinaryComponent:
+-    artifact_prefix: str  # matches the artifact filename prefix (e.g. codex-<target>.zst)
+-    dest_dir: str  # directory under vendor/<target>/ where the binary is installed
+-    binary_basename: str  # executable name inside dest_dir (before optional .exe)
+-
+-
+-BINARY_COMPONENTS = {
+-    "codex": BinaryComponent(
+-        artifact_prefix="codex",
+-        dest_dir="codex",
+-        binary_basename="codex",
+-    ),
+-    "codex-responses-api-proxy": BinaryComponent(
+-        artifact_prefix="codex-responses-api-proxy",
+-        dest_dir="codex-responses-api-proxy",
+-        binary_basename="codex-responses-api-proxy",
+-    ),
+-}
+-
+-RG_TARGET_PLATFORM_PAIRS: list[tuple[str, str]] = [
+-    ("x86_64-unknown-linux-musl", "linux-x86_64"),
+-    ("aarch64-unknown-linux-musl", "linux-aarch64"),
+-    ("x86_64-apple-darwin", "macos-x86_64"),
+-    ("aarch64-apple-darwin", "macos-aarch64"),
+-    ("x86_64-pc-windows-msvc", "windows-x86_64"),
+-    ("aarch64-pc-windows-msvc", "windows-aarch64"),
+-]
+-RG_TARGET_TO_PLATFORM = {target: platform for target, platform in RG_TARGET_PLATFORM_PAIRS}
+-DEFAULT_RG_TARGETS = [target for target, _ in RG_TARGET_PLATFORM_PAIRS]
+-
+-
+-def parse_args() -> argparse.Namespace:
+-    parser = argparse.ArgumentParser(description="Install native Codex binaries.")
+-    parser.add_argument(
+-        "--workflow-url",
+-        help=(
+-            "GitHub Actions workflow URL that produced the artifacts. Defaults to a "
+-            "known good run when omitted."
+-        ),
+-    )
+-    parser.add_argument(
+-        "--component",
+-        dest="components",
+-        action="append",
+-        choices=tuple(list(BINARY_COMPONENTS) + ["rg"]),
+-        help=(
+-            "Limit installation to the specified components."
+-            " May be repeated. Defaults to 'codex' and 'rg'."
+-        ),
+-    )
+-    parser.add_argument(
+-        "root",
+-        nargs="?",
+-        type=Path,
+-        help=(
+-            "Directory containing package.json for the staged package. If omitted, the "
+-            "repository checkout is used."
+-        ),
+-    )
+-    return parser.parse_args()
+-
+-
+-def main() -> int:
+-    args = parse_args()
+-
+-    codex_cli_root = (args.root or CODEX_CLI_ROOT).resolve()
+-    vendor_dir = codex_cli_root / VENDOR_DIR_NAME
+-    vendor_dir.mkdir(parents=True, exist_ok=True)
+-
+-    components = args.components or ["codex", "rg"]
+-
+-    workflow_url = (args.workflow_url or DEFAULT_WORKFLOW_URL).strip()
+-    if not workflow_url:
+-        workflow_url = DEFAULT_WORKFLOW_URL
+-
+-    workflow_id = workflow_url.rstrip("/").split("/")[-1]
+-    print(f"Downloading native artifacts from workflow {workflow_id}...")
+-
+-    with tempfile.TemporaryDirectory(prefix="codex-native-artifacts-") as artifacts_dir_str:
+-        artifacts_dir = Path(artifacts_dir_str)
+-        _download_artifacts(workflow_id, artifacts_dir)
+-        install_binary_components(
+-            artifacts_dir,
+-            vendor_dir,
+-            BINARY_TARGETS,
+-            [name for name in components if name in BINARY_COMPONENTS],
+-        )
+-
+-    if "rg" in components:
+-        print("Fetching ripgrep binaries...")
+-        fetch_rg(vendor_dir, DEFAULT_RG_TARGETS, manifest_path=RG_MANIFEST)
+-
+-    print(f"Installed native dependencies into {vendor_dir}")
+-    return 0
+-
+-
+-def fetch_rg(
+-    vendor_dir: Path,
+-    targets: Sequence[str] | None = None,
+-    *,
+-    manifest_path: Path,
+-) -> list[Path]:
+-    """Download ripgrep binaries described by the DotSlash manifest."""
+-
+-    if targets is None:
+-        targets = DEFAULT_RG_TARGETS
+-
+-    if not manifest_path.exists():
+-        raise FileNotFoundError(f"DotSlash manifest not found: {manifest_path}")
+-
+-    manifest = _load_manifest(manifest_path)
+-    platforms = manifest.get("platforms", {})
+-
+-    vendor_dir.mkdir(parents=True, exist_ok=True)
+-
+-    targets = list(targets)
+-    if not targets:
+-        return []
+-
+-    task_configs: list[tuple[str, str, dict]] = []
+-    for target in targets:
+-        platform_key = RG_TARGET_TO_PLATFORM.get(target)
+-        if platform_key is None:
+-            raise ValueError(f"Unsupported ripgrep target '{target}'.")
+-
+-        platform_info = platforms.get(platform_key)
+-        if platform_info is None:
+-            raise RuntimeError(f"Platform '{platform_key}' not found in manifest {manifest_path}.")
+-
+-        task_configs.append((target, platform_key, platform_info))
+-
+-    results: dict[str, Path] = {}
+-    max_workers = min(len(task_configs), max(1, (os.cpu_count() or 1)))
+-
+-    print("Installing ripgrep binaries for targets: " + ", ".join(targets))
+-
+-    with ThreadPoolExecutor(max_workers=max_workers) as executor:
+-        future_map = {
+-            executor.submit(
+-                _fetch_single_rg,
+-                vendor_dir,
+-                target,
+-                platform_key,
+-                platform_info,
+-                manifest_path,
+-            ): target
+-            for target, platform_key, platform_info in task_configs
+-        }
+-
+-        for future in as_completed(future_map):
+-            target = future_map[future]
+-            results[target] = future.result()
+-            print(f"  installed ripgrep for {target}")
+-
+-    return [results[target] for target in targets]
+-
+-
+-def _download_artifacts(workflow_id: str, dest_dir: Path) -> None:
+-    cmd = [
+-        "gh",
+-        "run",
+-        "download",
+-        "--dir",
+-        str(dest_dir),
+-        "--repo",
+-        "openai/codex",
+-        workflow_id,
+-    ]
+-    subprocess.check_call(cmd)
+-
+-
+-def install_binary_components(
+-    artifacts_dir: Path,
+-    vendor_dir: Path,
+-    targets: Iterable[str],
+-    component_names: Sequence[str],
+-) -> None:
+-    selected_components = [BINARY_COMPONENTS[name] for name in component_names if name in BINARY_COMPONENTS]
+-    if not selected_components:
+-        return
+-
+-    targets = list(targets)
+-    if not targets:
+-        return
+-
+-    for component in selected_components:
+-        print(
+-            f"Installing {component.binary_basename} binaries for targets: "
+-            + ", ".join(targets)
+-        )
+-        max_workers = min(len(targets), max(1, (os.cpu_count() or 1)))
+-        with ThreadPoolExecutor(max_workers=max_workers) as executor:
+-            futures = {
+-                executor.submit(
+-                    _install_single_binary,
+-                    artifacts_dir,
+-                    vendor_dir,
+-                    target,
+-                    component,
+-                ): target
+-                for target in targets
+-            }
+-            for future in as_completed(futures):
+-                installed_path = future.result()
+-                print(f"  installed {installed_path}")
+-
+-
+-def _install_single_binary(
+-    artifacts_dir: Path,
+-    vendor_dir: Path,
+-    target: str,
+-    component: BinaryComponent,
+-) -> Path:
+-    artifact_subdir = artifacts_dir / target
+-    archive_name = _archive_name_for_target(component.artifact_prefix, target)
+-    archive_path = artifact_subdir / archive_name
+-    if not archive_path.exists():
+-        raise FileNotFoundError(f"Expected artifact not found: {archive_path}")
+-
+-    dest_dir = vendor_dir / target / component.dest_dir
+-    dest_dir.mkdir(parents=True, exist_ok=True)
+-
+-    binary_name = (
+-        f"{component.binary_basename}.exe" if "windows" in target else component.binary_basename
+-    )
+-    dest = dest_dir / binary_name
+-    dest.unlink(missing_ok=True)
+-    extract_archive(archive_path, "zst", None, dest)
+-    if "windows" not in target:
+-        dest.chmod(0o755)
+-    return dest
+-
+-
+-def _archive_name_for_target(artifact_prefix: str, target: str) -> str:
+-    if "windows" in target:
+-        return f"{artifact_prefix}-{target}.exe.zst"
+-    return f"{artifact_prefix}-{target}.zst"
+-
+-
+-def _fetch_single_rg(
+-    vendor_dir: Path,
+-    target: str,
+-    platform_key: str,
+-    platform_info: dict,
+-    manifest_path: Path,
+-) -> Path:
+-    providers = platform_info.get("providers", [])
+-    if not providers:
+-        raise RuntimeError(f"No providers listed for platform '{platform_key}' in {manifest_path}.")
+-
+-    url = providers[0]["url"]
+-    archive_format = platform_info.get("format", "zst")
+-    archive_member = platform_info.get("path")
+-
+-    dest_dir = vendor_dir / target / "path"
+-    dest_dir.mkdir(parents=True, exist_ok=True)
+-
+-    is_windows = platform_key.startswith("win")
+-    binary_name = "rg.exe" if is_windows else "rg"
+-    dest = dest_dir / binary_name
+-
+-    with tempfile.TemporaryDirectory() as tmp_dir_str:
+-        tmp_dir = Path(tmp_dir_str)
+-        archive_filename = os.path.basename(urlparse(url).path)
+-        download_path = tmp_dir / archive_filename
+-        _download_file(url, download_path)
+-
+-        dest.unlink(missing_ok=True)
+-        extract_archive(download_path, archive_format, archive_member, dest)
+-
+-    if not is_windows:
+-        dest.chmod(0o755)
+-
+-    return dest
+-
+-
+-def _download_file(url: str, dest: Path) -> None:
+-    dest.parent.mkdir(parents=True, exist_ok=True)
+-    with urlopen(url) as response, open(dest, "wb") as out:
+-        shutil.copyfileobj(response, out)
+-
+-
+-def extract_archive(
+-    archive_path: Path,
+-    archive_format: str,
+-    archive_member: str | None,
+-    dest: Path,
+-) -> None:
+-    dest.parent.mkdir(parents=True, exist_ok=True)
+-
+-    if archive_format == "zst":
+-        output_path = archive_path.parent / dest.name
+-        subprocess.check_call(
+-            ["zstd", "-f", "-d", str(archive_path), "-o", str(output_path)]
+-        )
+-        shutil.move(str(output_path), dest)
+-        return
+-
+-    if archive_format == "tar.gz":
+-        if not archive_member:
+-            raise RuntimeError("Missing 'path' for tar.gz archive in DotSlash manifest.")
+-        with tarfile.open(archive_path, "r:gz") as tar:
+-            try:
+-                member = tar.getmember(archive_member)
+-            except KeyError as exc:
+-                raise RuntimeError(
+-                    f"Entry '{archive_member}' not found in archive {archive_path}."
+-                ) from exc
+-            tar.extract(member, path=archive_path.parent, filter="data")
+-        extracted = archive_path.parent / archive_member
+-        shutil.move(str(extracted), dest)
+-        return
+-
+-    if archive_format == "zip":
+-        if not archive_member:
+-            raise RuntimeError("Missing 'path' for zip archive in DotSlash manifest.")
+-        with zipfile.ZipFile(archive_path) as archive:
+-            try:
+-                with archive.open(archive_member) as src, open(dest, "wb") as out:
+-                    shutil.copyfileobj(src, out)
+-            except KeyError as exc:
+-                raise RuntimeError(
+-                    f"Entry '{archive_member}' not found in archive {archive_path}."
+-                ) from exc
+-        return
+-
+-    raise RuntimeError(f"Unsupported archive format '{archive_format}'.")
+-
+-
+-def _load_manifest(manifest_path: Path) -> dict:
+-    cmd = ["dotslash", "--", "parse", str(manifest_path)]
+-    stdout = subprocess.check_output(cmd, text=True)
+-    try:
+-        manifest = json.loads(stdout)
+-    except json.JSONDecodeError as exc:
+-        raise RuntimeError(f"Invalid DotSlash manifest output from {manifest_path}.") from exc
+-
+-    if not isinstance(manifest, dict):
+-        raise RuntimeError(
+-            f"Unexpected DotSlash manifest structure for {manifest_path}: {type(manifest)!r}"
+-        )
+-
+-    return manifest
+-
+-
+-if __name__ == "__main__":
+-    import sys
+-
+-    sys.exit(main())
++#!/usr/bin/env python3
++"""Install Codex native binaries (Rust CLI plus ripgrep helpers)."""
++
++import argparse
++import json
++import os
++import shutil
++import subprocess
++import tarfile
++import tempfile
++import zipfile
++from dataclasses import dataclass
++from concurrent.futures import ThreadPoolExecutor, as_completed
++from pathlib import Path
++from typing import Iterable, Sequence
++from urllib.parse import urlparse
++from urllib.request import urlopen
++
++SCRIPT_DIR = Path(__file__).resolve().parent
++CODEX_CLI_ROOT = SCRIPT_DIR.parent
++DEFAULT_WORKFLOW_URL = "https://github.com/openai/codex/actions/runs/17952349351"  # rust-v0.40.0
++VENDOR_DIR_NAME = "vendor"
++RG_MANIFEST = CODEX_CLI_ROOT / "bin" / "rg"
++BINARY_TARGETS = (
++    "x86_64-unknown-linux-musl",
++    "aarch64-unknown-linux-musl",
++    "x86_64-apple-darwin",
++    "aarch64-apple-darwin",
++    "x86_64-pc-windows-msvc",
++    "aarch64-pc-windows-msvc",
++)
++
++
++@dataclass(frozen=True)
++class BinaryComponent:
++    artifact_prefix: str  # matches the artifact filename prefix (e.g. codex-<target>.zst)
++    dest_dir: str  # directory under vendor/<target>/ where the binary is installed
++    binary_basename: str  # executable name inside dest_dir (before optional .exe)
++
++
++BINARY_COMPONENTS = {
++    "codex": BinaryComponent(
++        artifact_prefix="codex",
++        dest_dir="codex",
++        binary_basename="codex",
++    ),
++    "codex-responses-api-proxy": BinaryComponent(
++        artifact_prefix="codex-responses-api-proxy",
++        dest_dir="codex-responses-api-proxy",
++        binary_basename="codex-responses-api-proxy",
++    ),
++}
++
++RG_TARGET_PLATFORM_PAIRS: list[tuple[str, str]] = [
++    ("x86_64-unknown-linux-musl", "linux-x86_64"),
++    ("aarch64-unknown-linux-musl", "linux-aarch64"),
++    ("x86_64-apple-darwin", "macos-x86_64"),
++    ("aarch64-apple-darwin", "macos-aarch64"),
++    ("x86_64-pc-windows-msvc", "windows-x86_64"),
++    ("aarch64-pc-windows-msvc", "windows-aarch64"),
++]
++RG_TARGET_TO_PLATFORM = {target: platform for target, platform in RG_TARGET_PLATFORM_PAIRS}
++DEFAULT_RG_TARGETS = [target for target, _ in RG_TARGET_PLATFORM_PAIRS]
++
++
++def parse_args() -> argparse.Namespace:
++    parser = argparse.ArgumentParser(description="Install native Codex binaries.")
++    parser.add_argument(
++        "--workflow-url",
++        help=(
++            "GitHub Actions workflow URL that produced the artifacts. Defaults to a "
++            "known good run when omitted."
++        ),
++    )
++    parser.add_argument(
++        "--component",
++        dest="components",
++        action="append",
++        choices=tuple(list(BINARY_COMPONENTS) + ["rg"]),
++        help=(
++            "Limit installation to the specified components."
++            " May be repeated. Defaults to 'codex' and 'rg'."
++        ),
++    )
++    parser.add_argument(
++        "root",
++        nargs="?",
++        type=Path,
++        help=(
++            "Directory containing package.json for the staged package. If omitted, the "
++            "repository checkout is used."
++        ),
++    )
++    return parser.parse_args()
++
++
++def main() -> int:
++    args = parse_args()
++
++    codex_cli_root = (args.root or CODEX_CLI_ROOT).resolve()
++    vendor_dir = codex_cli_root / VENDOR_DIR_NAME
++    vendor_dir.mkdir(parents=True, exist_ok=True)
++
++    components = args.components or ["codex", "rg"]
++
++    workflow_url = (args.workflow_url or DEFAULT_WORKFLOW_URL).strip()
++    if not workflow_url:
++        workflow_url = DEFAULT_WORKFLOW_URL
++
++    workflow_id = workflow_url.rstrip("/").split("/")[-1]
++    print(f"Downloading native artifacts from workflow {workflow_id}...")
++
++    with tempfile.TemporaryDirectory(prefix="codex-native-artifacts-") as artifacts_dir_str:
++        artifacts_dir = Path(artifacts_dir_str)
++        _download_artifacts(workflow_id, artifacts_dir)
++        install_binary_components(
++            artifacts_dir,
++            vendor_dir,
++            BINARY_TARGETS,
++            [name for name in components if name in BINARY_COMPONENTS],
++        )
++
++    if "rg" in components:
++        print("Fetching ripgrep binaries...")
++        fetch_rg(vendor_dir, DEFAULT_RG_TARGETS, manifest_path=RG_MANIFEST)
++
++    print(f"Installed native dependencies into {vendor_dir}")
++    return 0
++
++
++def fetch_rg(
++    vendor_dir: Path,
++    targets: Sequence[str] | None = None,
++    *,
++    manifest_path: Path,
++) -> list[Path]:
++    """Download ripgrep binaries described by the DotSlash manifest."""
++
++    if targets is None:
++        targets = DEFAULT_RG_TARGETS
++
++    if not manifest_path.exists():
++        raise FileNotFoundError(f"DotSlash manifest not found: {manifest_path}")
++
++    manifest = _load_manifest(manifest_path)
++    platforms = manifest.get("platforms", {})
++
++    vendor_dir.mkdir(parents=True, exist_ok=True)
++
++    targets = list(targets)
++    if not targets:
++        return []
++
++    task_configs: list[tuple[str, str, dict]] = []
++    for target in targets:
++        platform_key = RG_TARGET_TO_PLATFORM.get(target)
++        if platform_key is None:
++            raise ValueError(f"Unsupported ripgrep target '{target}'.")
++
++        platform_info = platforms.get(platform_key)
++        if platform_info is None:
++            raise RuntimeError(f"Platform '{platform_key}' not found in manifest {manifest_path}.")
++
++        task_configs.append((target, platform_key, platform_info))
++
++    results: dict[str, Path] = {}
++    max_workers = min(len(task_configs), max(1, (os.cpu_count() or 1)))
++
++    print("Installing ripgrep binaries for targets: " + ", ".join(targets))
++
++    with ThreadPoolExecutor(max_workers=max_workers) as executor:
++        future_map = {
++            executor.submit(
++                _fetch_single_rg,
++                vendor_dir,
++                target,
++                platform_key,
++                platform_info,
++                manifest_path,
++            ): target
++            for target, platform_key, platform_info in task_configs
++        }
++
++        for future in as_completed(future_map):
++            target = future_map[future]
++            results[target] = future.result()
++            print(f"  installed ripgrep for {target}")
++
++    return [results[target] for target in targets]
++
++
++def _download_artifacts(workflow_id: str, dest_dir: Path) -> None:
++    cmd = [
++        "gh",
++        "run",
++        "download",
++        "--dir",
++        str(dest_dir),
++        "--repo",
++        "openai/codex",
++        workflow_id,
++    ]
++    subprocess.check_call(cmd)
++
++
++def install_binary_components(
++    artifacts_dir: Path,
++    vendor_dir: Path,
++    targets: Iterable[str],
++    component_names: Sequence[str],
++) -> None:
++    selected_components = [BINARY_COMPONENTS[name] for name in component_names if name in BINARY_COMPONENTS]
++    if not selected_components:
++        return
++
++    targets = list(targets)
++    if not targets:
++        return
++
++    for component in selected_components:
++        print(
++            f"Installing {component.binary_basename} binaries for targets: "
++            + ", ".join(targets)
++        )
++        max_workers = min(len(targets), max(1, (os.cpu_count() or 1)))
++        with ThreadPoolExecutor(max_workers=max_workers) as executor:
++            futures = {
++                executor.submit(
++                    _install_single_binary,
++                    artifacts_dir,
++                    vendor_dir,
++                    target,
++                    component,
++                ): target
++                for target in targets
++            }
++            for future in as_completed(futures):
++                installed_path = future.result()
++                print(f"  installed {installed_path}")
++
++
++def _install_single_binary(
++    artifacts_dir: Path,
++    vendor_dir: Path,
++    target: str,
++    component: BinaryComponent,
++) -> Path:
++    artifact_subdir = artifacts_dir / target
++    archive_name = _archive_name_for_target(component.artifact_prefix, target)
++    archive_path = artifact_subdir / archive_name
++    if not archive_path.exists():
++        raise FileNotFoundError(f"Expected artifact not found: {archive_path}")
++
++    dest_dir = vendor_dir / target / component.dest_dir
++    dest_dir.mkdir(parents=True, exist_ok=True)
++
++    binary_name = (
++        f"{component.binary_basename}.exe" if "windows" in target else component.binary_basename
++    )
++    dest = dest_dir / binary_name
++    dest.unlink(missing_ok=True)
++    extract_archive(archive_path, "zst", None, dest)
++    if "windows" not in target:
++        dest.chmod(0o755)
++    return dest
++
++
++def _archive_name_for_target(artifact_prefix: str, target: str) -> str:
++    if "windows" in target:
++        return f"{artifact_prefix}-{target}.exe.zst"
++    return f"{artifact_prefix}-{target}.zst"
++
++
++def _fetch_single_rg(
++    vendor_dir: Path,
++    target: str,
++    platform_key: str,
++    platform_info: dict,
++    manifest_path: Path,
++) -> Path:
++    providers = platform_info.get("providers", [])
++    if not providers:
++        raise RuntimeError(f"No providers listed for platform '{platform_key}' in {manifest_path}.")
++
++    url = providers[0]["url"]
++    archive_format = platform_info.get("format", "zst")
++    archive_member = platform_info.get("path")
++
++    dest_dir = vendor_dir / target / "path"
++    dest_dir.mkdir(parents=True, exist_ok=True)
++
++    is_windows = platform_key.startswith("win")
++    binary_name = "rg.exe" if is_windows else "rg"
++    dest = dest_dir / binary_name
++
++    with tempfile.TemporaryDirectory() as tmp_dir_str:
++        tmp_dir = Path(tmp_dir_str)
++        archive_filename = os.path.basename(urlparse(url).path)
++        download_path = tmp_dir / archive_filename
++        _download_file(url, download_path)
++
++        dest.unlink(missing_ok=True)
++        extract_archive(download_path, archive_format, archive_member, dest)
++
++    if not is_windows:
++        dest.chmod(0o755)
++
++    return dest
++
++
++def _download_file(url: str, dest: Path) -> None:
++    dest.parent.mkdir(parents=True, exist_ok=True)
++    with urlopen(url) as response, open(dest, "wb") as out:
++        shutil.copyfileobj(response, out)
++
++
++def extract_archive(
++    archive_path: Path,
++    archive_format: str,
++    archive_member: str | None,
++    dest: Path,
++) -> None:
++    dest.parent.mkdir(parents=True, exist_ok=True)
++
++    if archive_format == "zst":
++        output_path = archive_path.parent / dest.name
++        subprocess.check_call(
++            ["zstd", "-f", "-d", str(archive_path), "-o", str(output_path)]
++        )
++        shutil.move(str(output_path), dest)
++        return
++
++    if archive_format == "tar.gz":
++        if not archive_member:
++            raise RuntimeError("Missing 'path' for tar.gz archive in DotSlash manifest.")
++        with tarfile.open(archive_path, "r:gz") as tar:
++            try:
++                member = tar.getmember(archive_member)
++            except KeyError as exc:
++                raise RuntimeError(
++                    f"Entry '{archive_member}' not found in archive {archive_path}."
++                ) from exc
++            tar.extract(member, path=archive_path.parent, filter="data")
++        extracted = archive_path.parent / archive_member
++        shutil.move(str(extracted), dest)
++        return
++
++    if archive_format == "zip":
++        if not archive_member:
++            raise RuntimeError("Missing 'path' for zip archive in DotSlash manifest.")
++        with zipfile.ZipFile(archive_path) as archive:
++            try:
++                with archive.open(archive_member) as src, open(dest, "wb") as out:
++                    shutil.copyfileobj(src, out)
++            except KeyError as exc:
++                raise RuntimeError(
++                    f"Entry '{archive_member}' not found in archive {archive_path}."
++                ) from exc
++        return
++
++    raise RuntimeError(f"Unsupported archive format '{archive_format}'.")
++
++
++def _load_manifest(manifest_path: Path) -> dict:
++    cmd = ["dotslash", "--", "parse", str(manifest_path)]
++    stdout = subprocess.check_output(cmd, text=True)
++    try:
++        manifest = json.loads(stdout)
++    except json.JSONDecodeError as exc:
++        raise RuntimeError(f"Invalid DotSlash manifest output from {manifest_path}.") from exc
++
++    if not isinstance(manifest, dict):
++        raise RuntimeError(
++            f"Unexpected DotSlash manifest structure for {manifest_path}: {type(manifest)!r}"
++        )
++
++    return manifest
++
++
++if __name__ == "__main__":
++    import sys
++
++    sys.exit(main())
+diff --git a/codex-cli/scripts/run_in_container.sh b/codex-cli/scripts/run_in_container.sh
+index 01070cf0..1d5e3f51 100755
+--- a/codex-cli/scripts/run_in_container.sh
++++ b/codex-cli/scripts/run_in_container.sh
+@@ -1,95 +1,95 @@
+-#!/bin/bash
+-set -e
+-
+-# Usage:
+-#   ./run_in_container.sh [--work_dir directory] "COMMAND"
+-#
+-#   Examples:
+-#     ./run_in_container.sh --work_dir project/code "ls -la"
+-#     ./run_in_container.sh "echo Hello, world!"
+-
+-# Default the work directory to WORKSPACE_ROOT_DIR if not provided.
+-WORK_DIR="${WORKSPACE_ROOT_DIR:-$(pwd)}"
+-# Default allowed domains - can be overridden with OPENAI_ALLOWED_DOMAINS env var
+-OPENAI_ALLOWED_DOMAINS="${OPENAI_ALLOWED_DOMAINS:-api.openai.com}"
+-
+-# Parse optional flag.
+-if [ "$1" = "--work_dir" ]; then
+-  if [ -z "$2" ]; then
+-    echo "Error: --work_dir flag provided but no directory specified."
+-    exit 1
+-  fi
+-  WORK_DIR="$2"
+-  shift 2
+-fi
+-
+-WORK_DIR=$(realpath "$WORK_DIR")
+-
+-# Generate a unique container name based on the normalized work directory
+-CONTAINER_NAME="codex_$(echo "$WORK_DIR" | sed 's/\//_/g' | sed 's/[^a-zA-Z0-9_-]//g')"
+-
+-# Define cleanup to remove the container on script exit, ensuring no leftover containers
+-cleanup() {
+-  docker rm -f "$CONTAINER_NAME" >/dev/null 2>&1 || true
+-}
+-# Trap EXIT to invoke cleanup regardless of how the script terminates
+-trap cleanup EXIT
+-
+-# Ensure a command is provided.
+-if [ "$#" -eq 0 ]; then
+-  echo "Usage: $0 [--work_dir directory] \"COMMAND\""
+-  exit 1
+-fi
+-
+-# Check if WORK_DIR is set.
+-if [ -z "$WORK_DIR" ]; then
+-  echo "Error: No work directory provided and WORKSPACE_ROOT_DIR is not set."
+-  exit 1
+-fi
+-
+-# Verify that OPENAI_ALLOWED_DOMAINS is not empty
+-if [ -z "$OPENAI_ALLOWED_DOMAINS" ]; then
+-  echo "Error: OPENAI_ALLOWED_DOMAINS is empty."
+-  exit 1
+-fi
+-
+-# Kill any existing container for the working directory using cleanup(), centralizing removal logic.
+-cleanup
+-
+-# Run the container with the specified directory mounted at the same path inside the container.
+-docker run --name "$CONTAINER_NAME" -d \
+-  -e OPENAI_API_KEY \
+-  --cap-add=NET_ADMIN \
+-  --cap-add=NET_RAW \
+-  -v "$WORK_DIR:/app$WORK_DIR" \
+-  codex \
+-  sleep infinity
+-
+-# Write the allowed domains to a file in the container
+-docker exec --user root "$CONTAINER_NAME" bash -c "mkdir -p /etc/codex"
+-for domain in $OPENAI_ALLOWED_DOMAINS; do
+-  # Validate domain format to prevent injection
+-  if [[ ! "$domain" =~ ^[a-zA-Z0-9][a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
+-    echo "Error: Invalid domain format: $domain"
+-    exit 1
+-  fi
+-  echo "$domain" | docker exec --user root -i "$CONTAINER_NAME" bash -c "cat >> /etc/codex/allowed_domains.txt"
+-done
+-
+-# Set proper permissions on the domains file
+-docker exec --user root "$CONTAINER_NAME" bash -c "chmod 444 /etc/codex/allowed_domains.txt && chown root:root /etc/codex/allowed_domains.txt"
+-
+-# Initialize the firewall inside the container as root user
+-docker exec --user root "$CONTAINER_NAME" bash -c "/usr/local/bin/init_firewall.sh"
+-
+-# Remove the firewall script after running it
+-docker exec --user root "$CONTAINER_NAME" bash -c "rm -f /usr/local/bin/init_firewall.sh"
+-
+-# Execute the provided command in the container, ensuring it runs in the work directory.
+-# We use a parameterized bash command to safely handle the command and directory.
+-
+-quoted_args=""
+-for arg in "$@"; do
+-  quoted_args+=" $(printf '%q' "$arg")"
+-done
+-docker exec -it "$CONTAINER_NAME" bash -c "cd \"/app$WORK_DIR\" && codex --full-auto ${quoted_args}"
++#!/bin/bash
++set -e
++
++# Usage:
++#   ./run_in_container.sh [--work_dir directory] "COMMAND"
++#
++#   Examples:
++#     ./run_in_container.sh --work_dir project/code "ls -la"
++#     ./run_in_container.sh "echo Hello, world!"
++
++# Default the work directory to WORKSPACE_ROOT_DIR if not provided.
++WORK_DIR="${WORKSPACE_ROOT_DIR:-$(pwd)}"
++# Default allowed domains - can be overridden with OPENAI_ALLOWED_DOMAINS env var
++OPENAI_ALLOWED_DOMAINS="${OPENAI_ALLOWED_DOMAINS:-api.openai.com}"
++
++# Parse optional flag.
++if [ "$1" = "--work_dir" ]; then
++  if [ -z "$2" ]; then
++    echo "Error: --work_dir flag provided but no directory specified."
++    exit 1
++  fi
++  WORK_DIR="$2"
++  shift 2
++fi
++
++WORK_DIR=$(realpath "$WORK_DIR")
++
++# Generate a unique container name based on the normalized work directory
++CONTAINER_NAME="codex_$(echo "$WORK_DIR" | sed 's/\//_/g' | sed 's/[^a-zA-Z0-9_-]//g')"
++
++# Define cleanup to remove the container on script exit, ensuring no leftover containers
++cleanup() {
++  docker rm -f "$CONTAINER_NAME" >/dev/null 2>&1 || true
++}
++# Trap EXIT to invoke cleanup regardless of how the script terminates
++trap cleanup EXIT
++
++# Ensure a command is provided.
++if [ "$#" -eq 0 ]; then
++  echo "Usage: $0 [--work_dir directory] \"COMMAND\""
++  exit 1
++fi
++
++# Check if WORK_DIR is set.
++if [ -z "$WORK_DIR" ]; then
++  echo "Error: No work directory provided and WORKSPACE_ROOT_DIR is not set."
++  exit 1
++fi
++
++# Verify that OPENAI_ALLOWED_DOMAINS is not empty
++if [ -z "$OPENAI_ALLOWED_DOMAINS" ]; then
++  echo "Error: OPENAI_ALLOWED_DOMAINS is empty."
++  exit 1
++fi
++
++# Kill any existing container for the working directory using cleanup(), centralizing removal logic.
++cleanup
++
++# Run the container with the specified directory mounted at the same path inside the container.
++docker run --name "$CONTAINER_NAME" -d \
++  -e OPENAI_API_KEY \
++  --cap-add=NET_ADMIN \
++  --cap-add=NET_RAW \
++  -v "$WORK_DIR:/app$WORK_DIR" \
++  codex \
++  sleep infinity
++
++# Write the allowed domains to a file in the container
++docker exec --user root "$CONTAINER_NAME" bash -c "mkdir -p /etc/codex"
++for domain in $OPENAI_ALLOWED_DOMAINS; do
++  # Validate domain format to prevent injection
++  if [[ ! "$domain" =~ ^[a-zA-Z0-9][a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
++    echo "Error: Invalid domain format: $domain"
++    exit 1
++  fi
++  echo "$domain" | docker exec --user root -i "$CONTAINER_NAME" bash -c "cat >> /etc/codex/allowed_domains.txt"
++done
++
++# Set proper permissions on the domains file
++docker exec --user root "$CONTAINER_NAME" bash -c "chmod 444 /etc/codex/allowed_domains.txt && chown root:root /etc/codex/allowed_domains.txt"
++
++# Initialize the firewall inside the container as root user
++docker exec --user root "$CONTAINER_NAME" bash -c "/usr/local/bin/init_firewall.sh"
++
++# Remove the firewall script after running it
++docker exec --user root "$CONTAINER_NAME" bash -c "rm -f /usr/local/bin/init_firewall.sh"
++
++# Execute the provided command in the container, ensuring it runs in the work directory.
++# We use a parameterized bash command to safely handle the command and directory.
++
++quoted_args=""
++for arg in "$@"; do
++  quoted_args+=" $(printf '%q' "$arg")"
++done
++docker exec -it "$CONTAINER_NAME" bash -c "cd \"/app$WORK_DIR\" && codex --full-auto ${quoted_args}"
+diff --git a/codex-rs/.gitignore b/codex-rs/.gitignore
+index e9962537..464f8225 100644
+--- a/codex-rs/.gitignore
++++ b/codex-rs/.gitignore
+@@ -1,7 +1,7 @@
+-/target/
+-
+-# Recommended value of CARGO_TARGET_DIR when using Docker as explained in .devcontainer/README.md.
+-/target-amd64/
+-
+-# Value of CARGO_TARGET_DIR when using .devcontainer/devcontainer.json.
+-/target-arm64/
++/target/
++
++# Recommended value of CARGO_TARGET_DIR when using Docker as explained in .devcontainer/README.md.
++/target-amd64/
++
++# Value of CARGO_TARGET_DIR when using .devcontainer/devcontainer.json.
++/target-arm64/
+diff --git a/codex-rs/Cargo.lock b/codex-rs/Cargo.lock
+index 0c12880c..26e2052d 100644
+--- a/codex-rs/Cargo.lock
++++ b/codex-rs/Cargo.lock
+@@ -839,6 +839,7 @@ dependencies = [
+  "codex-common",
+  "codex-core",
+  "codex-file-search",
++ "codex-ledger",
+  "codex-login",
+  "codex-protocol",
+  "codex-utils-json-to-toml",
+@@ -1177,6 +1178,15 @@ dependencies = [
+  "walkdir",
+ ]
+ 
++[[package]]
++name = "codex-ledger"
++version = "0.0.0"
++dependencies = [
++ "async-trait",
++ "thiserror 2.0.16",
++ "tokio",
++]
++
+ [[package]]
+ name = "codex-linux-sandbox"
+ version = "0.0.0"
+diff --git a/codex-rs/Cargo.toml b/codex-rs/Cargo.toml
+index ca40b1a5..2a9b3284 100644
+--- a/codex-rs/Cargo.toml
++++ b/codex-rs/Cargo.toml
+@@ -7,6 +7,7 @@ members = [
+     "apply-patch",
+     "arg0",
+     "codex-backend-openapi-models",
++    "codex-ledger",
+     "cloud-tasks",
+     "cloud-tasks-client",
+     "cli",
+diff --git a/codex-rs/README.md b/codex-rs/README.md
+index a05a8d48..3a720d47 100644
+--- a/codex-rs/README.md
++++ b/codex-rs/README.md
+@@ -1,114 +1,114 @@
+-# Codex CLI (Rust Implementation)
+-
+-We provide Codex CLI as a standalone, native executable to ensure a zero-dependency install.
+-
+-## Installing Codex
+-
+-Today, the easiest way to install Codex is via `npm`:
+-
+-```shell
+-npm i -g @openai/codex
+-codex
+-```
+-
+-You can also install via Homebrew (`brew install codex`) or download a platform-specific release directly from our [GitHub Releases](https://github.com/openai/codex/releases).
+-
+-## What's new in the Rust CLI
+-
+-The Rust implementation is now the maintained Codex CLI and serves as the default experience. It includes a number of features that the legacy TypeScript CLI never supported.
+-
+-### Config
+-
+-Codex supports a rich set of configuration options. Note that the Rust CLI uses `config.toml` instead of `config.json`. See [`docs/config.md`](../docs/config.md) for details.
+-
+-### Model Context Protocol Support
+-
+-#### MCP client
+-
+-Codex CLI functions as an MCP client that allows the Codex CLI and IDE extension to connect to MCP servers on startup. See the [`configuration documentation`](../docs/config.md#mcp_servers) for details.
+-
+-#### MCP server (experimental)
+-
+-Codex can be launched as an MCP _server_ by running `codex mcp-server`. This allows _other_ MCP clients to use Codex as a tool for another agent.
+-
+-Use the [`@modelcontextprotocol/inspector`](https://github.com/modelcontextprotocol/inspector) to try it out:
+-
+-```shell
+-npx @modelcontextprotocol/inspector codex mcp-server
+-```
+-
+-Use `codex mcp` to add/list/get/remove MCP server launchers defined in `config.toml`, and `codex mcp-server` to run the MCP server directly.
+-
+-### Notifications
+-
+-You can enable notifications by configuring a script that is run whenever the agent finishes a turn. The [notify documentation](../docs/config.md#notify) includes a detailed example that explains how to get desktop notifications via [terminal-notifier](https://github.com/julienXX/terminal-notifier) on macOS.
+-
+-### `codex exec` to run Codex programmatically/non-interactively
+-
+-To run Codex non-interactively, run `codex exec PROMPT` (you can also pass the prompt via `stdin`) and Codex will work on your task until it decides that it is done and exits. Output is printed to the terminal directly. You can set the `RUST_LOG` environment variable to see more about what's going on.
+-
+-### Use `@` for file search
+-
+-Typing `@` triggers a fuzzy-filename search over the workspace root. Use up/down to select among the results and Tab or Enter to replace the `@` with the selected path. You can use Esc to cancel the search.
+-
+-### Esc–Esc to edit a previous message
+-
+-When the chat composer is empty, press Esc to prime “backtrack” mode. Press Esc again to open a transcript preview highlighting the last user message; press Esc repeatedly to step to older user messages. Press Enter to confirm and Codex will fork the conversation from that point, trim the visible transcript accordingly, and pre‑fill the composer with the selected user message so you can edit and resubmit it.
+-
+-In the transcript preview, the footer shows an `Esc edit prev` hint while editing is active.
+-
+-### `--cd`/`-C` flag
+-
+-Sometimes it is not convenient to `cd` to the directory you want Codex to use as the "working root" before running Codex. Fortunately, `codex` supports a `--cd` option so you can specify whatever folder you want. You can confirm that Codex is honoring `--cd` by double-checking the **workdir** it reports in the TUI at the start of a new session.
+-
+-### Shell completions
+-
+-Generate shell completion scripts via:
+-
+-```shell
+-codex completion bash
+-codex completion zsh
+-codex completion fish
+-```
+-
+-### Experimenting with the Codex Sandbox
+-
+-To test to see what happens when a command is run under the sandbox provided by Codex, we provide the following subcommands in Codex CLI:
+-
+-```
+-# macOS
+-codex sandbox macos [--full-auto] [COMMAND]...
+-
+-# Linux
+-codex sandbox linux [--full-auto] [COMMAND]...
+-
+-# Legacy aliases
+-codex debug seatbelt [--full-auto] [COMMAND]...
+-codex debug landlock [--full-auto] [COMMAND]...
+-```
+-
+-### Selecting a sandbox policy via `--sandbox`
+-
+-The Rust CLI exposes a dedicated `--sandbox` (`-s`) flag that lets you pick the sandbox policy **without** having to reach for the generic `-c/--config` option:
+-
+-```shell
+-# Run Codex with the default, read-only sandbox
+-codex --sandbox read-only
+-
+-# Allow the agent to write within the current workspace while still blocking network access
+-codex --sandbox workspace-write
+-
+-# Danger! Disable sandboxing entirely (only do this if you are already running in a container or other isolated env)
+-codex --sandbox danger-full-access
+-```
+-
+-The same setting can be persisted in `~/.codex/config.toml` via the top-level `sandbox_mode = "MODE"` key, e.g. `sandbox_mode = "workspace-write"`.
+-
+-## Code Organization
+-
+-This folder is the root of a Cargo workspace. It contains quite a bit of experimental code, but here are the key crates:
+-
+-- [`core/`](./core) contains the business logic for Codex. Ultimately, we hope this to be a library crate that is generally useful for building other Rust/native applications that use Codex.
+-- [`exec/`](./exec) "headless" CLI for use in automation.
+-- [`tui/`](./tui) CLI that launches a fullscreen TUI built with [Ratatui](https://ratatui.rs/).
+-- [`cli/`](./cli) CLI multitool that provides the aforementioned CLIs via subcommands.
++# Codex CLI (Rust Implementation)
++
++We provide Codex CLI as a standalone, native executable to ensure a zero-dependency install.
++
++## Installing Codex
++
++Today, the easiest way to install Codex is via `npm`:
++
++```shell
++npm i -g @openai/codex
++codex
++```
++
++You can also install via Homebrew (`brew install codex`) or download a platform-specific release directly from our [GitHub Releases](https://github.com/openai/codex/releases).
++
++## What's new in the Rust CLI
++
++The Rust implementation is now the maintained Codex CLI and serves as the default experience. It includes a number of features that the legacy TypeScript CLI never supported.
++
++### Config
++
++Codex supports a rich set of configuration options. Note that the Rust CLI uses `config.toml` instead of `config.json`. See [`docs/config.md`](../docs/config.md) for details.
++
++### Model Context Protocol Support
++
++#### MCP client
++
++Codex CLI functions as an MCP client that allows the Codex CLI and IDE extension to connect to MCP servers on startup. See the [`configuration documentation`](../docs/config.md#mcp_servers) for details.
++
++#### MCP server (experimental)
++
++Codex can be launched as an MCP _server_ by running `codex mcp-server`. This allows _other_ MCP clients to use Codex as a tool for another agent.
++
++Use the [`@modelcontextprotocol/inspector`](https://github.com/modelcontextprotocol/inspector) to try it out:
++
++```shell
++npx @modelcontextprotocol/inspector codex mcp-server
++```
++
++Use `codex mcp` to add/list/get/remove MCP server launchers defined in `config.toml`, and `codex mcp-server` to run the MCP server directly.
++
++### Notifications
++
++You can enable notifications by configuring a script that is run whenever the agent finishes a turn. The [notify documentation](../docs/config.md#notify) includes a detailed example that explains how to get desktop notifications via [terminal-notifier](https://github.com/julienXX/terminal-notifier) on macOS.
++
++### `codex exec` to run Codex programmatically/non-interactively
++
++To run Codex non-interactively, run `codex exec PROMPT` (you can also pass the prompt via `stdin`) and Codex will work on your task until it decides that it is done and exits. Output is printed to the terminal directly. You can set the `RUST_LOG` environment variable to see more about what's going on.
++
++### Use `@` for file search
++
++Typing `@` triggers a fuzzy-filename search over the workspace root. Use up/down to select among the results and Tab or Enter to replace the `@` with the selected path. You can use Esc to cancel the search.
++
++### Esc–Esc to edit a previous message
++
++When the chat composer is empty, press Esc to prime “backtrack” mode. Press Esc again to open a transcript preview highlighting the last user message; press Esc repeatedly to step to older user messages. Press Enter to confirm and Codex will fork the conversation from that point, trim the visible transcript accordingly, and pre‑fill the composer with the selected user message so you can edit and resubmit it.
++
++In the transcript preview, the footer shows an `Esc edit prev` hint while editing is active.
++
++### `--cd`/`-C` flag
++
++Sometimes it is not convenient to `cd` to the directory you want Codex to use as the "working root" before running Codex. Fortunately, `codex` supports a `--cd` option so you can specify whatever folder you want. You can confirm that Codex is honoring `--cd` by double-checking the **workdir** it reports in the TUI at the start of a new session.
++
++### Shell completions
++
++Generate shell completion scripts via:
++
++```shell
++codex completion bash
++codex completion zsh
++codex completion fish
++```
++
++### Experimenting with the Codex Sandbox
++
++To test to see what happens when a command is run under the sandbox provided by Codex, we provide the following subcommands in Codex CLI:
++
++```
++# macOS
++codex sandbox macos [--full-auto] [COMMAND]...
++
++# Linux
++codex sandbox linux [--full-auto] [COMMAND]...
++
++# Legacy aliases
++codex debug seatbelt [--full-auto] [COMMAND]...
++codex debug landlock [--full-auto] [COMMAND]...
++```
++
++### Selecting a sandbox policy via `--sandbox`
++
++The Rust CLI exposes a dedicated `--sandbox` (`-s`) flag that lets you pick the sandbox policy **without** having to reach for the generic `-c/--config` option:
++
++```shell
++# Run Codex with the default, read-only sandbox
++codex --sandbox read-only
++
++# Allow the agent to write within the current workspace while still blocking network access
++codex --sandbox workspace-write
++
++# Danger! Disable sandboxing entirely (only do this if you are already running in a container or other isolated env)
++codex --sandbox danger-full-access
++```
++
++The same setting can be persisted in `~/.codex/config.toml` via the top-level `sandbox_mode = "MODE"` key, e.g. `sandbox_mode = "workspace-write"`.
++
++## Code Organization
++
++This folder is the root of a Cargo workspace. It contains quite a bit of experimental code, but here are the key crates:
++
++- [`core/`](./core) contains the business logic for Codex. Ultimately, we hope this to be a library crate that is generally useful for building other Rust/native applications that use Codex.
++- [`exec/`](./exec) "headless" CLI for use in automation.
++- [`tui/`](./tui) CLI that launches a fullscreen TUI built with [Ratatui](https://ratatui.rs/).
++- [`cli/`](./cli) CLI multitool that provides the aforementioned CLIs via subcommands.
+diff --git a/codex-rs/ansi-escape/Cargo.toml b/codex-rs/ansi-escape/Cargo.toml
+index 4107a727..f659ed7c 100644
+--- a/codex-rs/ansi-escape/Cargo.toml
++++ b/codex-rs/ansi-escape/Cargo.toml
+@@ -1,16 +1,16 @@
+-[package]
+-edition = "2024"
+-name = "codex-ansi-escape"
+-version = { workspace = true }
+-
+-[lib]
+-name = "codex_ansi_escape"
+-path = "src/lib.rs"
+-
+-[dependencies]
+-ansi-to-tui = { workspace = true }
+-ratatui = { workspace = true, features = [
+-    "unstable-rendered-line-info",
+-    "unstable-widget-ref",
+-] }
+-tracing = { workspace = true, features = ["log"] }
++[package]
++edition = "2024"
++name = "codex-ansi-escape"
++version = { workspace = true }
++
++[lib]
++name = "codex_ansi_escape"
++path = "src/lib.rs"
++
++[dependencies]
++ansi-to-tui = { workspace = true }
++ratatui = { workspace = true, features = [
++    "unstable-rendered-line-info",
++    "unstable-widget-ref",
++] }
++tracing = { workspace = true, features = ["log"] }
+diff --git a/codex-rs/ansi-escape/README.md b/codex-rs/ansi-escape/README.md
+index 19f239cb..924ee833 100644
+--- a/codex-rs/ansi-escape/README.md
++++ b/codex-rs/ansi-escape/README.md
+@@ -1,15 +1,15 @@
+-# oai-codex-ansi-escape
+-
+-Small helper functions that wrap functionality from
+-<https://crates.io/crates/ansi-to-tui>:
+-
+-```rust
+-pub fn ansi_escape_line(s: &str) -> Line<'static>
+-pub fn ansi_escape<'a>(s: &'a str) -> Text<'a>
+-```
+-
+-Advantages:
+-
+-- `ansi_to_tui::IntoText` is not in scope for the entire TUI crate
+-- we `panic!()` and log if `IntoText` returns an `Err` and log it so that
+-  the caller does not have to deal with it
++# oai-codex-ansi-escape
++
++Small helper functions that wrap functionality from
++<https://crates.io/crates/ansi-to-tui>:
++
++```rust
++pub fn ansi_escape_line(s: &str) -> Line<'static>
++pub fn ansi_escape<'a>(s: &'a str) -> Text<'a>
++```
++
++Advantages:
++
++- `ansi_to_tui::IntoText` is not in scope for the entire TUI crate
++- we `panic!()` and log if `IntoText` returns an `Err` and log it so that
++  the caller does not have to deal with it
+diff --git a/codex-rs/ansi-escape/src/lib.rs b/codex-rs/ansi-escape/src/lib.rs
+index b47cf14f..f43ff86a 100644
+--- a/codex-rs/ansi-escape/src/lib.rs
++++ b/codex-rs/ansi-escape/src/lib.rs
+@@ -1,58 +1,58 @@
+-use ansi_to_tui::Error;
+-use ansi_to_tui::IntoText;
+-use ratatui::text::Line;
+-use ratatui::text::Text;
+-
+-// Expand tabs in a best-effort way for transcript rendering.
+-// Tabs can interact poorly with left-gutter prefixes in our TUI and CLI
+-// transcript views (e.g., `nl` separates line numbers from content with a tab).
+-// Replacing tabs with spaces avoids odd visual artifacts without changing
+-// semantics for our use cases.
+-fn expand_tabs(s: &str) -> std::borrow::Cow<'_, str> {
+-    if s.contains('\t') {
+-        // Keep it simple: replace each tab with 4 spaces.
+-        // We do not try to align to tab stops since most usages (like `nl`)
+-        // look acceptable with a fixed substitution and this avoids stateful math
+-        // across spans.
+-        std::borrow::Cow::Owned(s.replace('\t', "    "))
+-    } else {
+-        std::borrow::Cow::Borrowed(s)
+-    }
+-}
+-
+-/// This function should be used when the contents of `s` are expected to match
+-/// a single line. If multiple lines are found, a warning is logged and only the
+-/// first line is returned.
+-pub fn ansi_escape_line(s: &str) -> Line<'static> {
+-    // Normalize tabs to spaces to avoid odd gutter collisions in transcript mode.
+-    let s = expand_tabs(s);
+-    let text = ansi_escape(&s);
+-    match text.lines.as_slice() {
+-        [] => "".into(),
+-        [only] => only.clone(),
+-        [first, rest @ ..] => {
+-            tracing::warn!("ansi_escape_line: expected a single line, got {first:?} and {rest:?}");
+-            first.clone()
+-        }
+-    }
+-}
+-
+-pub fn ansi_escape(s: &str) -> Text<'static> {
+-    // to_text() claims to be faster, but introduces complex lifetime issues
+-    // such that it's not worth it.
+-    match s.into_text() {
+-        Ok(text) => text,
+-        Err(err) => match err {
+-            Error::NomError(message) => {
+-                tracing::error!(
+-                    "ansi_to_tui NomError docs claim should never happen when parsing `{s}`: {message}"
+-                );
+-                panic!();
+-            }
+-            Error::Utf8Error(utf8error) => {
+-                tracing::error!("Utf8Error: {utf8error}");
+-                panic!();
+-            }
+-        },
+-    }
+-}
++use ansi_to_tui::Error;
++use ansi_to_tui::IntoText;
++use ratatui::text::Line;
++use ratatui::text::Text;
++
++// Expand tabs in a best-effort way for transcript rendering.
++// Tabs can interact poorly with left-gutter prefixes in our TUI and CLI
++// transcript views (e.g., `nl` separates line numbers from content with a tab).
++// Replacing tabs with spaces avoids odd visual artifacts without changing
++// semantics for our use cases.
++fn expand_tabs(s: &str) -> std::borrow::Cow<'_, str> {
++    if s.contains('\t') {
++        // Keep it simple: replace each tab with 4 spaces.
++        // We do not try to align to tab stops since most usages (like `nl`)
++        // look acceptable with a fixed substitution and this avoids stateful math
++        // across spans.
++        std::borrow::Cow::Owned(s.replace('\t', "    "))
++    } else {
++        std::borrow::Cow::Borrowed(s)
++    }
++}
++
++/// This function should be used when the contents of `s` are expected to match
++/// a single line. If multiple lines are found, a warning is logged and only the
++/// first line is returned.
++pub fn ansi_escape_line(s: &str) -> Line<'static> {
++    // Normalize tabs to spaces to avoid odd gutter collisions in transcript mode.
++    let s = expand_tabs(s);
++    let text = ansi_escape(&s);
++    match text.lines.as_slice() {
++        [] => "".into(),
++        [only] => only.clone(),
++        [first, rest @ ..] => {
++            tracing::warn!("ansi_escape_line: expected a single line, got {first:?} and {rest:?}");
++            first.clone()
++        }
++    }
++}
++
++pub fn ansi_escape(s: &str) -> Text<'static> {
++    // to_text() claims to be faster, but introduces complex lifetime issues
++    // such that it's not worth it.
++    match s.into_text() {
++        Ok(text) => text,
++        Err(err) => match err {
++            Error::NomError(message) => {
++                tracing::error!(
++                    "ansi_to_tui NomError docs claim should never happen when parsing `{s}`: {message}"
++                );
++                panic!();
++            }
++            Error::Utf8Error(utf8error) => {
++                tracing::error!("Utf8Error: {utf8error}");
++                panic!();
++            }
++        },
++    }
++}
+diff --git a/codex-rs/app-server-protocol/Cargo.toml b/codex-rs/app-server-protocol/Cargo.toml
+index b18028fb..832ae2e6 100644
+--- a/codex-rs/app-server-protocol/Cargo.toml
++++ b/codex-rs/app-server-protocol/Cargo.toml
+@@ -1,24 +1,24 @@
+-[package]
+-edition = "2024"
+-name = "codex-app-server-protocol"
+-version = { workspace = true }
+-
+-[lib]
+-name = "codex_app_server_protocol"
+-path = "src/lib.rs"
+-
+-[lints]
+-workspace = true
+-
+-[dependencies]
+-codex-protocol = { workspace = true }
+-paste = { workspace = true }
+-serde = { workspace = true, features = ["derive"] }
+-serde_json = { workspace = true }
+-strum_macros = { workspace = true }
+-ts-rs = { workspace = true }
+-uuid = { workspace = true, features = ["serde", "v7"] }
+-
+-[dev-dependencies]
+-anyhow = { workspace = true }
+-pretty_assertions = { workspace = true }
++[package]
++edition = "2024"
++name = "codex-app-server-protocol"
++version = { workspace = true }
++
++[lib]
++name = "codex_app_server_protocol"
++path = "src/lib.rs"
++
++[lints]
++workspace = true
++
++[dependencies]
++codex-protocol = { workspace = true }
++paste = { workspace = true }
++serde = { workspace = true, features = ["derive"] }
++serde_json = { workspace = true }
++strum_macros = { workspace = true }
++ts-rs = { workspace = true }
++uuid = { workspace = true, features = ["serde", "v7"] }
++
++[dev-dependencies]
++anyhow = { workspace = true }
++pretty_assertions = { workspace = true }
+diff --git a/codex-rs/app-server-protocol/src/jsonrpc_lite.rs b/codex-rs/app-server-protocol/src/jsonrpc_lite.rs
+index 9d6d6da0..981b9970 100644
+--- a/codex-rs/app-server-protocol/src/jsonrpc_lite.rs
++++ b/codex-rs/app-server-protocol/src/jsonrpc_lite.rs
+@@ -1,67 +1,67 @@
+-//! We do not do true JSON-RPC 2.0, as we neither send nor expect the
+-//! "jsonrpc": "2.0" field.
+-
+-use serde::Deserialize;
+-use serde::Serialize;
+-use ts_rs::TS;
+-
+-pub const JSONRPC_VERSION: &str = "2.0";
+-
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, Hash, Eq, TS)]
+-#[serde(untagged)]
+-pub enum RequestId {
+-    String(String),
+-    #[ts(type = "number")]
+-    Integer(i64),
+-}
+-
+-pub type Result = serde_json::Value;
+-
+-/// Refers to any valid JSON-RPC object that can be decoded off the wire, or encoded to be sent.
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-#[serde(untagged)]
+-pub enum JSONRPCMessage {
+-    Request(JSONRPCRequest),
+-    Notification(JSONRPCNotification),
+-    Response(JSONRPCResponse),
+-    Error(JSONRPCError),
+-}
+-
+-/// A request that expects a response.
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-pub struct JSONRPCRequest {
+-    pub id: RequestId,
+-    pub method: String,
+-    #[serde(default, skip_serializing_if = "Option::is_none")]
+-    pub params: Option<serde_json::Value>,
+-}
+-
+-/// A notification which does not expect a response.
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-pub struct JSONRPCNotification {
+-    pub method: String,
+-    #[serde(default, skip_serializing_if = "Option::is_none")]
+-    pub params: Option<serde_json::Value>,
+-}
+-
+-/// A successful (non-error) response to a request.
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-pub struct JSONRPCResponse {
+-    pub id: RequestId,
+-    pub result: Result,
+-}
+-
+-/// A response to a request that indicates an error occurred.
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-pub struct JSONRPCError {
+-    pub error: JSONRPCErrorError,
+-    pub id: RequestId,
+-}
+-
+-#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
+-pub struct JSONRPCErrorError {
+-    pub code: i64,
+-    #[serde(default, skip_serializing_if = "Option::is_none")]
+-    pub data: Option<serde_json::Value>,
+-    pub message: String,
+-}
++//! We do not do true JSON-RPC 2.0, as we neither send nor expect the
++//! "jsonrpc": "2.0" field.
++
++use serde::Deserialize;
++use serde::Serialize;
++use ts_rs::TS;
++
++pub const JSONRPC_VERSION: &str = "2.0";
++
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, Hash, Eq, TS)]
++#[serde(untagged)]
++pub enum RequestId {
++    String(String),
++    #[ts(type = "number")]
++    Integer(i64),
++}
++
++pub type Result = serde_json::Value;
++
++/// Refers to any valid JSON-RPC object that can be decoded off the wire, or encoded to be sent.
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++#[serde(untagged)]
++pub enum JSONRPCMessage {
++    Request(JSONRPCRequest),
++    Notification(JSONRPCNotification),
++    Response(JSONRPCResponse),
++    Error(JSONRPCError),
++}
++
++/// A request that expects a response.
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++pub struct JSONRPCRequest {
++    pub id: RequestId,
++    pub method: String,
++    #[serde(default, skip_serializing_if = "Option::is_none")]
++    pub params: Option<serde_json::Value>,
++}
++
++/// A notification which does not expect a response.
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++pub struct JSONRPCNotification {
++    pub method: String,
++    #[serde(default, skip_serializing_if = "Option::is_none")]
++    pub params: Option<serde_json::Value>,
++}
++
++/// A successful (non-error) response to a request.
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++pub struct JSONRPCResponse {
++    pub id: RequestId,
++    pub result: Result,
++}
++
++/// A response to a request that indicates an error occurred.
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++pub struct JSONRPCError {
++    pub error: JSONRPCErrorError,
++    pub id: RequestId,
++}
++
++#[derive(Debug, Clone, PartialEq, Deserialize, Serialize, TS)]
++pub struct JSONRPCErrorError {
++    pub code: i64,
++    #[serde(default, skip_serializing_if = "Option::is_none")]
++    pub data: Option<serde_json::Value>,
++    pub message: String,
++}
+diff --git a/codex-rs/app-server-protocol/src/lib.rs b/codex-rs/app-server-protocol/src/lib.rs
+index 517702bb..c4a629d7 100644
+--- a/codex-rs/app-server-protocol/src/lib.rs
++++ b/codex-rs/app-server-protocol/src/lib.rs
+@@ -1,5 +1,5 @@
+-mod jsonrpc_lite;
+-mod protocol;
+-
+-pub use jsonrpc_lite::*;
+-pub use protocol::*;
++mod jsonrpc_lite;
++mod protocol;
++
++pub use jsonrpc_lite::*;
++pub use protocol::*;
+diff --git a/codex-rs/app-server-protocol/src/protocol.rs b/codex-rs/app-server-protocol/src/protocol.rs
+index 845a2431..9befe971 100644
+--- a/codex-rs/app-server-protocol/src/protocol.rs
++++ b/codex-rs/app-server-protocol/src/protocol.rs
+@@ -171,6 +171,26 @@ client_request_definitions! {
+         params: ExecOneOffCommandParams,
+         response: ExecOneOffCommandResponse,
+     },
++    LedgerCreateCompany {
++        params: LedgerCreateCompanyParams,
++        response: LedgerCreateCompanyResponse,
++    },
++    LedgerUpsertAccount {
++        params: LedgerUpsertAccountParams,
++        response: LedgerUpsertAccountResponse,
++    },
++    LedgerPostEntry {
++        params: LedgerPostEntryParams,
++        response: LedgerPostEntryResponse,
++    },
++    LedgerReverseEntry {
++        params: LedgerReverseEntryParams,
++        response: LedgerReverseEntryResponse,
++    },
++    LedgerLockPeriod {
++        params: LedgerLockPeriodParams,
++        response: LedgerLockPeriodResponse,
++    },
+ }
+ 
+ #[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Default, TS)]
+@@ -194,6 +214,260 @@ pub struct InitializeResponse {
+     pub user_agent: String,
+ }
+ 
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerCurrency {
++    pub code: String,
++    pub precision: u8,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerFiscalCalendar {
++    pub periods_per_year: u8,
++    pub opening_month: u8,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerCompany {
++    pub id: String,
++    pub name: String,
++    pub base_currency: LedgerCurrency,
++    pub fiscal_calendar: LedgerFiscalCalendar,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub metadata: Option<String>,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerCreateCompanyParams {
++    pub name: String,
++    pub base_currency: LedgerCurrency,
++    pub fiscal_calendar: LedgerFiscalCalendar,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerCreateCompanyResponse {
++    pub company: LedgerCompany,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerAccountType {
++    Asset,
++    Liability,
++    Equity,
++    Revenue,
++    Expense,
++    OffBalance,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerCurrencyMode {
++    FunctionalOnly,
++    Transactional,
++    MultiCurrency,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerTaxCode {
++    pub code: String,
++    pub description: String,
++    pub rate_percent: f32,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerAccount {
++    pub id: String,
++    pub company_id: String,
++    pub code: String,
++    pub name: String,
++    pub account_type: LedgerAccountType,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub parent_account_id: Option<String>,
++    pub currency_mode: LedgerCurrencyMode,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub tax_code: Option<LedgerTaxCode>,
++    pub is_summary: bool,
++    pub is_active: bool,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerUpsertAccountParams {
++    pub account: LedgerAccount,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerUpsertAccountResponse {
++    pub account: LedgerAccount,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerCurrencyRate {
++    pub base: LedgerCurrency,
++    pub quote: LedgerCurrency,
++    pub rate: f64,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub source: Option<String>,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerPostingSide {
++    Debit,
++    Credit,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerJournalLine {
++    pub id: String,
++    pub account_id: String,
++    pub side: LedgerPostingSide,
++    pub amount_minor: i64,
++    pub currency: LedgerCurrency,
++    pub functional_amount_minor: i64,
++    pub functional_currency: LedgerCurrency,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub exchange_rate: Option<LedgerCurrencyRate>,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub tax_code: Option<LedgerTaxCode>,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub memo: Option<String>,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerEntryStatus {
++    Draft,
++    Proposed,
++    Posted,
++    Reversed,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerEntryOrigin {
++    Manual,
++    Ingestion,
++    AiSuggested,
++    Adjustment,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerJournalEntry {
++    pub id: String,
++    pub journal_id: String,
++    pub status: LedgerEntryStatus,
++    pub lines: Vec<LedgerJournalLine>,
++    pub origin: LedgerEntryOrigin,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub memo: Option<String>,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub reverses_entry_id: Option<String>,
++    #[serde(skip_serializing_if = "Option::is_none")]
++    pub reversed_by_entry_id: Option<String>,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerPostingMode {
++    DryRun,
++    Commit,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerPostEntryParams {
++    pub entry: LedgerJournalEntry,
++    pub mode: LedgerPostingMode,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerPostEntryResponse {
++    pub entry: LedgerJournalEntry,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerReverseEntryParams {
++    pub entry_id: String,
++    pub reason: String,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerReverseEntryResponse {
++    pub entry: LedgerJournalEntry,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerPeriodRef {
++    pub fiscal_year: i32,
++    pub period: u8,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerPeriodAction {
++    SoftClose,
++    Close,
++    ReopenSoft,
++    ReopenFull,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerJournalType {
++    General,
++    AccountsPayable,
++    AccountsReceivable,
++    Cash,
++    SubLedger,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
++#[serde(rename_all = "camelCase")]
++pub enum LedgerPeriodState {
++    Open,
++    SoftClosed,
++    Closed,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerJournal {
++    pub id: String,
++    pub company_id: String,
++    pub ledger_type: LedgerJournalType,
++    pub period_state: LedgerPeriodState,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerLockPeriodParams {
++    pub journal_id: String,
++    pub period: LedgerPeriodRef,
++    pub action: LedgerPeriodAction,
++}
++
++#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
++#[serde(rename_all = "camelCase")]
++pub struct LedgerLockPeriodResponse {
++    pub journal: LedgerJournal,
++}
++
+ #[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Default, TS)]
+ #[serde(rename_all = "camelCase")]
+ pub struct NewConversationParams {
+diff --git a/codex-rs/app-server/Cargo.toml b/codex-rs/app-server/Cargo.toml
+index 545ef489..5ed0f98e 100644
+--- a/codex-rs/app-server/Cargo.toml
++++ b/codex-rs/app-server/Cargo.toml
+@@ -1,49 +1,54 @@
+-[package]
+-edition = "2024"
+-name = "codex-app-server"
+-version = { workspace = true }
+-
+-[[bin]]
+-name = "codex-app-server"
+-path = "src/main.rs"
+-
+-[lib]
+-name = "codex_app_server"
+-path = "src/lib.rs"
+-
+-[lints]
+-workspace = true
++[package]
++edition = "2024"
++name = "codex-app-server"
++version = { workspace = true }
++
++[[bin]]
++name = "codex-app-server"
++path = "src/main.rs"
++
++[lib]
++name = "codex_app_server"
++path = "src/lib.rs"
++
++[lints]
++workspace = true
++
++[features]
++default = []
++ledger = ["codex-ledger"]
+ 
+ [dependencies]
+-anyhow = { workspace = true }
+-codex-arg0 = { workspace = true }
+-codex-common = { workspace = true, features = ["cli"] }
+-codex-core = { workspace = true }
+-codex-file-search = { workspace = true }
+-codex-login = { workspace = true }
++anyhow = { workspace = true }
++codex-arg0 = { workspace = true }
++codex-common = { workspace = true, features = ["cli"] }
++codex-core = { workspace = true }
++codex-file-search = { workspace = true }
++codex-login = { workspace = true }
+ codex-protocol = { workspace = true }
+ codex-app-server-protocol = { workspace = true }
+ codex-utils-json-to-toml = { workspace = true }
+-serde = { workspace = true, features = ["derive"] }
+-serde_json = { workspace = true }
+-tokio = { workspace = true, features = [
+-    "io-std",
+-    "macros",
+-    "process",
+-    "rt-multi-thread",
+-    "signal",
+-] }
+-tracing = { workspace = true, features = ["log"] }
+-tracing-subscriber = { workspace = true, features = ["env-filter", "fmt"] }
+-uuid = { workspace = true, features = ["serde", "v7"] }
+-
+-[dev-dependencies]
+-app_test_support = { workspace = true }
+-assert_cmd = { workspace = true }
+-base64 = { workspace = true }
+-core_test_support = { workspace = true }
+-os_info = { workspace = true }
+-pretty_assertions = { workspace = true }
+-tempfile = { workspace = true }
+-toml = { workspace = true }
+-wiremock = { workspace = true }
++codex-ledger = { path = "../codex-ledger", optional = true }
++serde = { workspace = true, features = ["derive"] }
++serde_json = { workspace = true }
++tokio = { workspace = true, features = [
++    "io-std",
++    "macros",
++    "process",
++    "rt-multi-thread",
++    "signal",
++] }
++tracing = { workspace = true, features = ["log"] }
++tracing-subscriber = { workspace = true, features = ["env-filter", "fmt"] }
++uuid = { workspace = true, features = ["serde", "v7"] }
++
++[dev-dependencies]
++app_test_support = { workspace = true }
++assert_cmd = { workspace = true }
++base64 = { workspace = true }
++core_test_support = { workspace = true }
++os_info = { workspace = true }
++pretty_assertions = { workspace = true }
++tempfile = { workspace = true }
++toml = { workspace = true }
++wiremock = { workspace = true }
+diff --git a/codex-rs/app-server/README.md b/codex-rs/app-server/README.md
+index 2eb8a1ad..412305f5 100644
+--- a/codex-rs/app-server/README.md
++++ b/codex-rs/app-server/README.md
+@@ -1,15 +1,15 @@
+-# codex-app-server
+-
+-`codex app-server` is the harness Codex uses to power rich interfaces such as the [Codex VS Code extension](https://marketplace.visualstudio.com/items?itemName=openai.chatgpt). The message schema is currently unstable, but those who wish to build experimental UIs on top of Codex may find it valuable.
+-
+-## Protocol
+-
+-Similar to [MCP](https://modelcontextprotocol.io/), `codex app-server` supports bidirectional communication, streaming JSONL over stdio. The protocol is JSON-RPC 2.0, though the `"jsonrpc":"2.0"` header is omitted.
+-
+-## Message Schema
+-
+-Currently, you can dump a TypeScript version of the schema using `codex generate-ts`. It is specific to the version of Codex you used to run `generate-ts`, so the two are guaranteed to be compatible.
+-
+-```
+-codex generate-ts --out DIR
+-```
++# codex-app-server
++
++`codex app-server` is the harness Codex uses to power rich interfaces such as the [Codex VS Code extension](https://marketplace.visualstudio.com/items?itemName=openai.chatgpt). The message schema is currently unstable, but those who wish to build experimental UIs on top of Codex may find it valuable.
++
++## Protocol
++
++Similar to [MCP](https://modelcontextprotocol.io/), `codex app-server` supports bidirectional communication, streaming JSONL over stdio. The protocol is JSON-RPC 2.0, though the `"jsonrpc":"2.0"` header is omitted.
++
++## Message Schema
++
++Currently, you can dump a TypeScript version of the schema using `codex generate-ts`. It is specific to the version of Codex you used to run `generate-ts`, so the two are guaranteed to be compatible.
++
++```
++codex generate-ts --out DIR
++```
+diff --git a/codex-rs/app-server/src/codex_message_processor.rs b/codex-rs/app-server/src/codex_message_processor.rs
+index cb894a51..2848bf78 100644
+--- a/codex-rs/app-server/src/codex_message_processor.rs
++++ b/codex-rs/app-server/src/codex_message_processor.rs
+@@ -25,6 +25,64 @@ use codex_app_server_protocol::InputItem as WireInputItem;
+ use codex_app_server_protocol::InterruptConversationParams;
+ use codex_app_server_protocol::InterruptConversationResponse;
+ use codex_app_server_protocol::JSONRPCErrorError;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerAccount;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerAccountType;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCompany;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCreateCompanyParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCreateCompanyResponse;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCurrency;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCurrencyMode;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCurrencyRate;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerEntryOrigin;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerEntryStatus;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerFiscalCalendar;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerJournal;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerJournalEntry;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerJournalLine;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerJournalType;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerLockPeriodParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerLockPeriodResponse;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPeriodAction;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPeriodRef;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPeriodState;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPostEntryParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPostEntryResponse;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPostingMode;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPostingSide;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerReverseEntryParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerReverseEntryResponse;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerTaxCode;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerUpsertAccountParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerUpsertAccountResponse;
+ use codex_app_server_protocol::ListConversationsParams;
+ use codex_app_server_protocol::ListConversationsResponse;
+ use codex_app_server_protocol::LoginApiKeyParams;
+@@ -80,6 +138,60 @@ use codex_core::protocol::ExecApprovalRequestEvent;
+ use codex_core::protocol::InputItem as CoreInputItem;
+ use codex_core::protocol::Op;
+ use codex_core::protocol::ReviewDecision;
++#[cfg(feature = "ledger")]
++use codex_ledger::Account as LedgerAccountModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::AccountType as LedgerAccountTypeModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::CreateCompanyRequest as LedgerCreateCompanyRequest;
++#[cfg(feature = "ledger")]
++use codex_ledger::Currency as LedgerCurrencyModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::CurrencyMode as LedgerCurrencyModeModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::CurrencyRate as LedgerCurrencyRateModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::EntryOrigin as LedgerEntryOriginModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::EntryStatus as LedgerEntryStatusModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::FiscalCalendar as LedgerFiscalCalendarModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::InMemoryLedgerService;
++#[cfg(feature = "ledger")]
++use codex_ledger::Journal as LedgerJournalModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::JournalEntry as LedgerJournalEntryModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::JournalLine as LedgerJournalLineModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::LedgerError;
++#[cfg(feature = "ledger")]
++use codex_ledger::LedgerType as LedgerJournalTypeModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::LockPeriodRequest as LedgerLockPeriodRequest;
++#[cfg(feature = "ledger")]
++use codex_ledger::PeriodAction as LedgerPeriodActionModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::PeriodRef as LedgerPeriodRefModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::PeriodState as LedgerPeriodStateModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::PostEntryRequest as LedgerPostEntryRequest;
++#[cfg(feature = "ledger")]
++use codex_ledger::PostingMode as LedgerPostingModeModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::PostingSide as LedgerPostingSideModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::ReverseEntryRequest as LedgerReverseEntryRequest;
++#[cfg(feature = "ledger")]
++use codex_ledger::Role as LedgerRole;
++#[cfg(feature = "ledger")]
++use codex_ledger::TaxCode as LedgerTaxCodeModel;
++#[cfg(feature = "ledger")]
++use codex_ledger::TenantContext as LedgerTenantContext;
++#[cfg(feature = "ledger")]
++use codex_ledger::UpsertAccountRequest as LedgerUpsertAccountRequest;
+ use codex_login::ServerOptions as LoginServerOptions;
+ use codex_login::ShutdownHandle;
+ use codex_login::run_login_server;
+@@ -96,6 +208,8 @@ use std::sync::Arc;
+ use std::sync::atomic::AtomicBool;
+ use std::sync::atomic::Ordering;
+ use std::time::Duration;
++#[cfg(feature = "ledger")]
++use std::time::SystemTime;
+ use tokio::select;
+ use tokio::sync::Mutex;
+ use tokio::sync::oneshot;
+@@ -130,6 +244,8 @@ pub(crate) struct CodexMessageProcessor {
+     // Queue of pending interrupt requests per conversation. We reply when TurnAborted arrives.
+     pending_interrupts: Arc<Mutex<HashMap<ConversationId, Vec<RequestId>>>>,
+     pending_fuzzy_searches: Arc<Mutex<HashMap<String, Arc<AtomicBool>>>>,
++    #[cfg(feature = "ledger")]
++    ledger_service: Option<Arc<InMemoryLedgerService>>,
+ }
+ 
+ impl CodexMessageProcessor {
+@@ -139,6 +255,7 @@ impl CodexMessageProcessor {
+         outgoing: Arc<OutgoingMessageSender>,
+         codex_linux_sandbox_exe: Option<PathBuf>,
+         config: Arc<Config>,
++        #[cfg(feature = "ledger")] ledger_service: Option<Arc<InMemoryLedgerService>>,
+     ) -> Self {
+         Self {
+             auth_manager,
+@@ -150,6 +267,8 @@ impl CodexMessageProcessor {
+             active_login: Arc::new(Mutex::new(None)),
+             pending_interrupts: Arc::new(Mutex::new(HashMap::new())),
+             pending_fuzzy_searches: Arc::new(Mutex::new(HashMap::new())),
++            #[cfg(feature = "ledger")]
++            ledger_service,
+         }
+     }
+ 
+@@ -227,6 +346,86 @@ impl CodexMessageProcessor {
+             } => {
+                 self.get_user_agent(request_id).await;
+             }
++            ClientRequest::LedgerCreateCompany { request_id, params } => {
++                #[cfg(feature = "ledger")]
++                {
++                    self.handle_ledger_create_company(request_id, params).await;
++                }
++                #[cfg(not(feature = "ledger"))]
++                {
++                    let _ = params;
++                    let error = JSONRPCErrorError {
++                        code: INVALID_REQUEST_ERROR_CODE,
++                        message: "ledger feature not enabled".to_string(),
++                        data: None,
++                    };
++                    self.outgoing.send_error(request_id, error).await;
++                }
++            }
++            ClientRequest::LedgerUpsertAccount { request_id, params } => {
++                #[cfg(feature = "ledger")]
++                {
++                    self.handle_ledger_upsert_account(request_id, params).await;
++                }
++                #[cfg(not(feature = "ledger"))]
++                {
++                    let _ = params;
++                    let error = JSONRPCErrorError {
++                        code: INVALID_REQUEST_ERROR_CODE,
++                        message: "ledger feature not enabled".to_string(),
++                        data: None,
++                    };
++                    self.outgoing.send_error(request_id, error).await;
++                }
++            }
++            ClientRequest::LedgerPostEntry { request_id, params } => {
++                #[cfg(feature = "ledger")]
++                {
++                    self.handle_ledger_post_entry(request_id, params).await;
++                }
++                #[cfg(not(feature = "ledger"))]
++                {
++                    let _ = params;
++                    let error = JSONRPCErrorError {
++                        code: INVALID_REQUEST_ERROR_CODE,
++                        message: "ledger feature not enabled".to_string(),
++                        data: None,
++                    };
++                    self.outgoing.send_error(request_id, error).await;
++                }
++            }
++            ClientRequest::LedgerReverseEntry { request_id, params } => {
++                #[cfg(feature = "ledger")]
++                {
++                    self.handle_ledger_reverse_entry(request_id, params).await;
++                }
++                #[cfg(not(feature = "ledger"))]
++                {
++                    let _ = params;
++                    let error = JSONRPCErrorError {
++                        code: INVALID_REQUEST_ERROR_CODE,
++                        message: "ledger feature not enabled".to_string(),
++                        data: None,
++                    };
++                    self.outgoing.send_error(request_id, error).await;
++                }
++            }
++            ClientRequest::LedgerLockPeriod { request_id, params } => {
++                #[cfg(feature = "ledger")]
++                {
++                    self.handle_ledger_lock_period(request_id, params).await;
++                }
++                #[cfg(not(feature = "ledger"))]
++                {
++                    let _ = params;
++                    let error = JSONRPCErrorError {
++                        code: INVALID_REQUEST_ERROR_CODE,
++                        message: "ledger feature not enabled".to_string(),
++                        data: None,
++                    };
++                    self.outgoing.send_error(request_id, error).await;
++                }
++            }
+             ClientRequest::UserInfo {
+                 request_id,
+                 params: _,
+@@ -1486,6 +1685,548 @@ fn extract_conversation_summary(
+     })
+ }
+ 
++#[cfg(feature = "ledger")]
++impl CodexMessageProcessor {
++    async fn handle_ledger_create_company(
++        &self,
++        request_id: RequestId,
++        params: LedgerCreateCompanyParams,
++    ) {
++        let Some(service) = self.ledger_service.as_ref() else {
++            let error = JSONRPCErrorError {
++                code: INVALID_REQUEST_ERROR_CODE,
++                message: "ledger service not configured".to_string(),
++                data: None,
++            };
++            self.outgoing.send_error(request_id, error).await;
++            return;
++        };
++
++        let request = LedgerCreateCompanyRequest {
++            name: params.name,
++            base_currency: to_ledger_currency(params.base_currency),
++            fiscal_calendar: to_ledger_fiscal_calendar(params.fiscal_calendar),
++            tenant: default_ledger_tenant_context(),
++        };
++
++        match service.create_company(request).await {
++            Ok(company) => {
++                let response = LedgerCreateCompanyResponse {
++                    company: from_ledger_company(company),
++                };
++                self.outgoing.send_response(request_id, response).await;
++            }
++            Err(err) => {
++                let error = ledger_error_to_jsonrpc(err);
++                self.outgoing.send_error(request_id, error).await;
++            }
++        }
++    }
++
++    async fn handle_ledger_upsert_account(
++        &self,
++        request_id: RequestId,
++        params: LedgerUpsertAccountParams,
++    ) {
++        let Some(service) = self.ledger_service.as_ref() else {
++            let error = JSONRPCErrorError {
++                code: INVALID_REQUEST_ERROR_CODE,
++                message: "ledger service not configured".to_string(),
++                data: None,
++            };
++            self.outgoing.send_error(request_id, error).await;
++            return;
++        };
++
++        let request = LedgerUpsertAccountRequest {
++            account: to_ledger_account(params.account),
++            tenant: default_ledger_tenant_context(),
++        };
++
++        match service.upsert_account(request).await {
++            Ok(account) => {
++                let response = LedgerUpsertAccountResponse {
++                    account: from_ledger_account(account),
++                };
++                self.outgoing.send_response(request_id, response).await;
++            }
++            Err(err) => {
++                let error = ledger_error_to_jsonrpc(err);
++                self.outgoing.send_error(request_id, error).await;
++            }
++        }
++    }
++
++    async fn handle_ledger_post_entry(&self, request_id: RequestId, params: LedgerPostEntryParams) {
++        let Some(service) = self.ledger_service.as_ref() else {
++            let error = JSONRPCErrorError {
++                code: INVALID_REQUEST_ERROR_CODE,
++                message: "ledger service not configured".to_string(),
++                data: None,
++            };
++            self.outgoing.send_error(request_id, error).await;
++            return;
++        };
++
++        let LedgerPostEntryParams { entry, mode } = params;
++        let request = LedgerPostEntryRequest {
++            entry: to_ledger_journal_entry(entry),
++            tenant: default_ledger_tenant_context(),
++            mode: to_ledger_posting_mode(mode),
++        };
++
++        match service.post_entry(request).await {
++            Ok(entry) => {
++                let response = LedgerPostEntryResponse {
++                    entry: from_ledger_journal_entry(entry),
++                };
++                self.outgoing.send_response(request_id, response).await;
++            }
++            Err(err) => {
++                let error = ledger_error_to_jsonrpc(err);
++                self.outgoing.send_error(request_id, error).await;
++            }
++        }
++    }
++
++    async fn handle_ledger_reverse_entry(
++        &self,
++        request_id: RequestId,
++        params: LedgerReverseEntryParams,
++    ) {
++        let Some(service) = self.ledger_service.as_ref() else {
++            let error = JSONRPCErrorError {
++                code: INVALID_REQUEST_ERROR_CODE,
++                message: "ledger service not configured".to_string(),
++                data: None,
++            };
++            self.outgoing.send_error(request_id, error).await;
++            return;
++        };
++
++        let request = LedgerReverseEntryRequest {
++            entry_id: params.entry_id,
++            reason: params.reason,
++            tenant: default_ledger_tenant_context(),
++        };
++
++        match service.reverse_entry(request).await {
++            Ok(entry) => {
++                let response = LedgerReverseEntryResponse {
++                    entry: from_ledger_journal_entry(entry),
++                };
++                self.outgoing.send_response(request_id, response).await;
++            }
++            Err(err) => {
++                let error = ledger_error_to_jsonrpc(err);
++                self.outgoing.send_error(request_id, error).await;
++            }
++        }
++    }
++
++    async fn handle_ledger_lock_period(
++        &self,
++        request_id: RequestId,
++        params: LedgerLockPeriodParams,
++    ) {
++        let Some(service) = self.ledger_service.as_ref() else {
++            let error = JSONRPCErrorError {
++                code: INVALID_REQUEST_ERROR_CODE,
++                message: "ledger service not configured".to_string(),
++                data: None,
++            };
++            self.outgoing.send_error(request_id, error).await;
++            return;
++        };
++
++        let request = LedgerLockPeriodRequest {
++            journal_id: params.journal_id,
++            period: to_ledger_period_ref(params.period),
++            action: to_ledger_period_action(params.action),
++            tenant: default_ledger_tenant_context(),
++        };
++
++        match service.lock_period(request).await {
++            Ok(journal) => {
++                let response = LedgerLockPeriodResponse {
++                    journal: from_ledger_journal(journal),
++                };
++                self.outgoing.send_response(request_id, response).await;
++            }
++            Err(err) => {
++                let error = ledger_error_to_jsonrpc(err);
++                self.outgoing.send_error(request_id, error).await;
++            }
++        }
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn default_ledger_tenant_context() -> LedgerTenantContext {
++    LedgerTenantContext {
++        tenant_id: "ledger-admin".to_string(),
++        user_id: "codex-app-server".to_string(),
++        roles: vec![LedgerRole::ServiceAccount],
++        locale: Some("en-US".to_string()),
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_currency(currency: LedgerCurrency) -> LedgerCurrencyModel {
++    LedgerCurrencyModel {
++        code: currency.code,
++        precision: currency.precision,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_fiscal_calendar(calendar: LedgerFiscalCalendar) -> LedgerFiscalCalendarModel {
++    LedgerFiscalCalendarModel {
++        periods_per_year: calendar.periods_per_year,
++        opening_month: calendar.opening_month,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_company(company: codex_ledger::Company) -> LedgerCompany {
++    LedgerCompany {
++        id: company.id,
++        name: company.name,
++        base_currency: LedgerCurrency {
++            code: company.base_currency.code,
++            precision: company.base_currency.precision,
++        },
++        fiscal_calendar: LedgerFiscalCalendar {
++            periods_per_year: company.fiscal_calendar.periods_per_year,
++            opening_month: company.fiscal_calendar.opening_month,
++        },
++        metadata: company.metadata,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_account_type(account_type: LedgerAccountType) -> LedgerAccountTypeModel {
++    match account_type {
++        LedgerAccountType::Asset => LedgerAccountTypeModel::Asset,
++        LedgerAccountType::Liability => LedgerAccountTypeModel::Liability,
++        LedgerAccountType::Equity => LedgerAccountTypeModel::Equity,
++        LedgerAccountType::Revenue => LedgerAccountTypeModel::Revenue,
++        LedgerAccountType::Expense => LedgerAccountTypeModel::Expense,
++        LedgerAccountType::OffBalance => LedgerAccountTypeModel::OffBalance,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_account_type(account_type: LedgerAccountTypeModel) -> LedgerAccountType {
++    match account_type {
++        LedgerAccountTypeModel::Asset => LedgerAccountType::Asset,
++        LedgerAccountTypeModel::Liability => LedgerAccountType::Liability,
++        LedgerAccountTypeModel::Equity => LedgerAccountType::Equity,
++        LedgerAccountTypeModel::Revenue => LedgerAccountType::Revenue,
++        LedgerAccountTypeModel::Expense => LedgerAccountType::Expense,
++        LedgerAccountTypeModel::OffBalance => LedgerAccountType::OffBalance,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_currency_mode(mode: LedgerCurrencyMode) -> LedgerCurrencyModeModel {
++    match mode {
++        LedgerCurrencyMode::FunctionalOnly => LedgerCurrencyModeModel::FunctionalOnly,
++        LedgerCurrencyMode::Transactional => LedgerCurrencyModeModel::Transactional,
++        LedgerCurrencyMode::MultiCurrency => LedgerCurrencyModeModel::MultiCurrency,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_currency_mode(mode: LedgerCurrencyModeModel) -> LedgerCurrencyMode {
++    match mode {
++        LedgerCurrencyModeModel::FunctionalOnly => LedgerCurrencyMode::FunctionalOnly,
++        LedgerCurrencyModeModel::Transactional => LedgerCurrencyMode::Transactional,
++        LedgerCurrencyModeModel::MultiCurrency => LedgerCurrencyMode::MultiCurrency,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_tax_code(tax: LedgerTaxCode) -> LedgerTaxCodeModel {
++    LedgerTaxCodeModel {
++        code: tax.code,
++        description: tax.description,
++        rate_percent: tax.rate_percent,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_tax_code(tax: LedgerTaxCodeModel) -> LedgerTaxCode {
++    LedgerTaxCode {
++        code: tax.code,
++        description: tax.description,
++        rate_percent: tax.rate_percent,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_account(account: LedgerAccount) -> LedgerAccountModel {
++    LedgerAccountModel {
++        id: account.id,
++        company_id: account.company_id,
++        code: account.code,
++        name: account.name,
++        account_type: to_ledger_account_type(account.account_type),
++        parent_account_id: account.parent_account_id,
++        currency_mode: to_ledger_currency_mode(account.currency_mode),
++        tax_code: account.tax_code.map(to_ledger_tax_code),
++        is_summary: account.is_summary,
++        is_active: account.is_active,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_account(account: LedgerAccountModel) -> LedgerAccount {
++    LedgerAccount {
++        id: account.id,
++        company_id: account.company_id,
++        code: account.code,
++        name: account.name,
++        account_type: from_ledger_account_type(account.account_type),
++        parent_account_id: account.parent_account_id,
++        currency_mode: from_ledger_currency_mode(account.currency_mode),
++        tax_code: account.tax_code.map(from_ledger_tax_code),
++        is_summary: account.is_summary,
++        is_active: account.is_active,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_posting_side(side: LedgerPostingSide) -> LedgerPostingSideModel {
++    match side {
++        LedgerPostingSide::Debit => LedgerPostingSideModel::Debit,
++        LedgerPostingSide::Credit => LedgerPostingSideModel::Credit,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_posting_side(side: LedgerPostingSideModel) -> LedgerPostingSide {
++    match side {
++        LedgerPostingSideModel::Debit => LedgerPostingSide::Debit,
++        LedgerPostingSideModel::Credit => LedgerPostingSide::Credit,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_currency_rate(rate: LedgerCurrencyRate) -> LedgerCurrencyRateModel {
++    LedgerCurrencyRateModel {
++        base: to_ledger_currency(rate.base),
++        quote: to_ledger_currency(rate.quote),
++        rate: rate.rate,
++        source: rate.source,
++        observed_at: SystemTime::now(),
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_currency_rate(rate: LedgerCurrencyRateModel) -> LedgerCurrencyRate {
++    LedgerCurrencyRate {
++        base: LedgerCurrency {
++            code: rate.base.code,
++            precision: rate.base.precision,
++        },
++        quote: LedgerCurrency {
++            code: rate.quote.code,
++            precision: rate.quote.precision,
++        },
++        rate: rate.rate,
++        source: rate.source,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_journal_line(line: LedgerJournalLine) -> LedgerJournalLineModel {
++    LedgerJournalLineModel {
++        id: line.id,
++        account_id: line.account_id,
++        side: to_ledger_posting_side(line.side),
++        amount_minor: line.amount_minor,
++        currency: to_ledger_currency(line.currency),
++        functional_amount_minor: line.functional_amount_minor,
++        functional_currency: to_ledger_currency(line.functional_currency),
++        exchange_rate: line.exchange_rate.map(to_ledger_currency_rate),
++        tax_code: line.tax_code.map(to_ledger_tax_code),
++        memo: line.memo,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_journal_line(line: LedgerJournalLineModel) -> LedgerJournalLine {
++    LedgerJournalLine {
++        id: line.id,
++        account_id: line.account_id,
++        side: from_ledger_posting_side(line.side),
++        amount_minor: line.amount_minor,
++        currency: LedgerCurrency {
++            code: line.currency.code,
++            precision: line.currency.precision,
++        },
++        functional_amount_minor: line.functional_amount_minor,
++        functional_currency: LedgerCurrency {
++            code: line.functional_currency.code,
++            precision: line.functional_currency.precision,
++        },
++        exchange_rate: line.exchange_rate.map(from_ledger_currency_rate),
++        tax_code: line.tax_code.map(from_ledger_tax_code),
++        memo: line.memo,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_entry_status(status: LedgerEntryStatus) -> LedgerEntryStatusModel {
++    match status {
++        LedgerEntryStatus::Draft => LedgerEntryStatusModel::Draft,
++        LedgerEntryStatus::Proposed => LedgerEntryStatusModel::Proposed,
++        LedgerEntryStatus::Posted => LedgerEntryStatusModel::Posted,
++        LedgerEntryStatus::Reversed => LedgerEntryStatusModel::Reversed,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_entry_status(status: LedgerEntryStatusModel) -> LedgerEntryStatus {
++    match status {
++        LedgerEntryStatusModel::Draft => LedgerEntryStatus::Draft,
++        LedgerEntryStatusModel::Proposed => LedgerEntryStatus::Proposed,
++        LedgerEntryStatusModel::Posted => LedgerEntryStatus::Posted,
++        LedgerEntryStatusModel::Reversed => LedgerEntryStatus::Reversed,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_entry_origin(origin: LedgerEntryOrigin) -> LedgerEntryOriginModel {
++    match origin {
++        LedgerEntryOrigin::Manual => LedgerEntryOriginModel::Manual,
++        LedgerEntryOrigin::Ingestion => LedgerEntryOriginModel::Ingestion,
++        LedgerEntryOrigin::AiSuggested => LedgerEntryOriginModel::AiSuggested,
++        LedgerEntryOrigin::Adjustment => LedgerEntryOriginModel::Adjustment,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_entry_origin(origin: LedgerEntryOriginModel) -> LedgerEntryOrigin {
++    match origin {
++        LedgerEntryOriginModel::Manual => LedgerEntryOrigin::Manual,
++        LedgerEntryOriginModel::Ingestion => LedgerEntryOrigin::Ingestion,
++        LedgerEntryOriginModel::AiSuggested => LedgerEntryOrigin::AiSuggested,
++        LedgerEntryOriginModel::Adjustment => LedgerEntryOrigin::Adjustment,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_journal_entry(entry: LedgerJournalEntry) -> LedgerJournalEntryModel {
++    LedgerJournalEntryModel {
++        id: entry.id,
++        journal_id: entry.journal_id,
++        status: to_ledger_entry_status(entry.status),
++        lines: entry
++            .lines
++            .into_iter()
++            .map(to_ledger_journal_line)
++            .collect(),
++        origin: to_ledger_entry_origin(entry.origin),
++        memo: entry.memo,
++        reverses_entry_id: entry.reverses_entry_id,
++        reversed_by_entry_id: entry.reversed_by_entry_id,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_journal_entry(entry: LedgerJournalEntryModel) -> LedgerJournalEntry {
++    LedgerJournalEntry {
++        id: entry.id,
++        journal_id: entry.journal_id,
++        status: from_ledger_entry_status(entry.status),
++        lines: entry
++            .lines
++            .into_iter()
++            .map(from_ledger_journal_line)
++            .collect(),
++        origin: from_ledger_entry_origin(entry.origin),
++        memo: entry.memo,
++        reverses_entry_id: entry.reverses_entry_id,
++        reversed_by_entry_id: entry.reversed_by_entry_id,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_posting_mode(mode: LedgerPostingMode) -> LedgerPostingModeModel {
++    match mode {
++        LedgerPostingMode::DryRun => LedgerPostingModeModel::DryRun,
++        LedgerPostingMode::Commit => LedgerPostingModeModel::Commit,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_period_action(action: LedgerPeriodAction) -> LedgerPeriodActionModel {
++    match action {
++        LedgerPeriodAction::SoftClose => LedgerPeriodActionModel::SoftClose,
++        LedgerPeriodAction::Close => LedgerPeriodActionModel::Close,
++        LedgerPeriodAction::ReopenSoft => LedgerPeriodActionModel::ReopenSoft,
++        LedgerPeriodAction::ReopenFull => LedgerPeriodActionModel::ReopenFull,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn to_ledger_period_ref(period: LedgerPeriodRef) -> LedgerPeriodRefModel {
++    LedgerPeriodRefModel {
++        fiscal_year: period.fiscal_year,
++        period: period.period,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_journal_type(journal_type: LedgerJournalTypeModel) -> LedgerJournalType {
++    match journal_type {
++        LedgerJournalTypeModel::General => LedgerJournalType::General,
++        LedgerJournalTypeModel::AccountsPayable => LedgerJournalType::AccountsPayable,
++        LedgerJournalTypeModel::AccountsReceivable => LedgerJournalType::AccountsReceivable,
++        LedgerJournalTypeModel::Cash => LedgerJournalType::Cash,
++        LedgerJournalTypeModel::SubLedger => LedgerJournalType::SubLedger,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_period_state(state: LedgerPeriodStateModel) -> LedgerPeriodState {
++    match state {
++        LedgerPeriodStateModel::Open => LedgerPeriodState::Open,
++        LedgerPeriodStateModel::SoftClosed => LedgerPeriodState::SoftClosed,
++        LedgerPeriodStateModel::Closed => LedgerPeriodState::Closed,
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn from_ledger_journal(journal: LedgerJournalModel) -> LedgerJournal {
++    LedgerJournal {
++        id: journal.id,
++        company_id: journal.company_id,
++        ledger_type: from_ledger_journal_type(journal.ledger_type),
++        period_state: from_ledger_period_state(journal.period_state),
++    }
++}
++
++#[cfg(feature = "ledger")]
++fn ledger_error_to_jsonrpc(error: LedgerError) -> JSONRPCErrorError {
++    match error {
++        LedgerError::Internal(message) => JSONRPCErrorError {
++            code: INTERNAL_ERROR_CODE,
++            message,
++            data: None,
++        },
++        LedgerError::NotFound(message)
++        | LedgerError::Rejected(message)
++        | LedgerError::Validation(message) => JSONRPCErrorError {
++            code: INVALID_REQUEST_ERROR_CODE,
++            message,
++            data: None,
++        },
++    }
++}
++
+ #[cfg(test)]
+ mod tests {
+     use super::*;
+diff --git a/codex-rs/app-server/src/error_code.rs b/codex-rs/app-server/src/error_code.rs
+index 1ffd889d..68c1d73a 100644
+--- a/codex-rs/app-server/src/error_code.rs
++++ b/codex-rs/app-server/src/error_code.rs
+@@ -1,2 +1,2 @@
+-pub(crate) const INVALID_REQUEST_ERROR_CODE: i64 = -32600;
+-pub(crate) const INTERNAL_ERROR_CODE: i64 = -32603;
++pub(crate) const INVALID_REQUEST_ERROR_CODE: i64 = -32600;
++pub(crate) const INTERNAL_ERROR_CODE: i64 = -32603;
+diff --git a/codex-rs/app-server/src/fuzzy_file_search.rs b/codex-rs/app-server/src/fuzzy_file_search.rs
+index 6c83a0f4..dc7d9841 100644
+--- a/codex-rs/app-server/src/fuzzy_file_search.rs
++++ b/codex-rs/app-server/src/fuzzy_file_search.rs
+@@ -1,92 +1,92 @@
+-use std::num::NonZero;
+-use std::num::NonZeroUsize;
+-use std::path::Path;
+-use std::path::PathBuf;
+-use std::sync::Arc;
+-use std::sync::atomic::AtomicBool;
+-
+-use codex_app_server_protocol::FuzzyFileSearchResult;
+-use codex_file_search as file_search;
+-use tokio::task::JoinSet;
+-use tracing::warn;
+-
+-const LIMIT_PER_ROOT: usize = 50;
+-const MAX_THREADS: usize = 12;
+-const COMPUTE_INDICES: bool = true;
+-
+-pub(crate) async fn run_fuzzy_file_search(
+-    query: String,
+-    roots: Vec<String>,
+-    cancellation_flag: Arc<AtomicBool>,
+-) -> Vec<FuzzyFileSearchResult> {
+-    #[expect(clippy::expect_used)]
+-    let limit_per_root =
+-        NonZero::new(LIMIT_PER_ROOT).expect("LIMIT_PER_ROOT should be a valid non-zero usize");
+-
+-    let cores = std::thread::available_parallelism()
+-        .map(std::num::NonZero::get)
+-        .unwrap_or(1);
+-    let threads = cores.min(MAX_THREADS);
+-    let threads_per_root = (threads / roots.len()).max(1);
+-    let threads = NonZero::new(threads_per_root).unwrap_or(NonZeroUsize::MIN);
+-
+-    let mut files: Vec<FuzzyFileSearchResult> = Vec::new();
+-    let mut join_set = JoinSet::new();
+-
+-    for root in roots {
+-        let search_dir = PathBuf::from(&root);
+-        let query = query.clone();
+-        let cancel_flag = cancellation_flag.clone();
+-        join_set.spawn_blocking(move || {
+-            match file_search::run(
+-                query.as_str(),
+-                limit_per_root,
+-                &search_dir,
+-                Vec::new(),
+-                threads,
+-                cancel_flag,
+-                COMPUTE_INDICES,
+-            ) {
+-                Ok(res) => Ok((root, res)),
+-                Err(err) => Err((root, err)),
+-            }
+-        });
+-    }
+-
+-    while let Some(res) = join_set.join_next().await {
+-        match res {
+-            Ok(Ok((root, res))) => {
+-                for m in res.matches {
+-                    let path = m.path;
+-                    //TODO(shijie): Move file name generation to file_search lib.
+-                    let file_name = Path::new(&path)
+-                        .file_name()
+-                        .map(|name| name.to_string_lossy().into_owned())
+-                        .unwrap_or_else(|| path.clone());
+-                    let result = FuzzyFileSearchResult {
+-                        root: root.clone(),
+-                        path,
+-                        file_name,
+-                        score: m.score,
+-                        indices: m.indices,
+-                    };
+-                    files.push(result);
+-                }
+-            }
+-            Ok(Err((root, err))) => {
+-                warn!("fuzzy-file-search in dir '{root}' failed: {err}");
+-            }
+-            Err(err) => {
+-                warn!("fuzzy-file-search join_next failed: {err}");
+-            }
+-        }
+-    }
+-
+-    files.sort_by(file_search::cmp_by_score_desc_then_path_asc::<
+-        FuzzyFileSearchResult,
+-        _,
+-        _,
+-    >(|f| f.score, |f| f.path.as_str()));
+-
+-    files
+-}
++use std::num::NonZero;
++use std::num::NonZeroUsize;
++use std::path::Path;
++use std::path::PathBuf;
++use std::sync::Arc;
++use std::sync::atomic::AtomicBool;
++
++use codex_app_server_protocol::FuzzyFileSearchResult;
++use codex_file_search as file_search;
++use tokio::task::JoinSet;
++use tracing::warn;
++
++const LIMIT_PER_ROOT: usize = 50;
++const MAX_THREADS: usize = 12;
++const COMPUTE_INDICES: bool = true;
++
++pub(crate) async fn run_fuzzy_file_search(
++    query: String,
++    roots: Vec<String>,
++    cancellation_flag: Arc<AtomicBool>,
++) -> Vec<FuzzyFileSearchResult> {
++    #[expect(clippy::expect_used)]
++    let limit_per_root =
++        NonZero::new(LIMIT_PER_ROOT).expect("LIMIT_PER_ROOT should be a valid non-zero usize");
++
++    let cores = std::thread::available_parallelism()
++        .map(std::num::NonZero::get)
++        .unwrap_or(1);
++    let threads = cores.min(MAX_THREADS);
++    let threads_per_root = (threads / roots.len()).max(1);
++    let threads = NonZero::new(threads_per_root).unwrap_or(NonZeroUsize::MIN);
++
++    let mut files: Vec<FuzzyFileSearchResult> = Vec::new();
++    let mut join_set = JoinSet::new();
++
++    for root in roots {
++        let search_dir = PathBuf::from(&root);
++        let query = query.clone();
++        let cancel_flag = cancellation_flag.clone();
++        join_set.spawn_blocking(move || {
++            match file_search::run(
++                query.as_str(),
++                limit_per_root,
++                &search_dir,
++                Vec::new(),
++                threads,
++                cancel_flag,
++                COMPUTE_INDICES,
++            ) {
++                Ok(res) => Ok((root, res)),
++                Err(err) => Err((root, err)),
++            }
++        });
++    }
++
++    while let Some(res) = join_set.join_next().await {
++        match res {
++            Ok(Ok((root, res))) => {
++                for m in res.matches {
++                    let path = m.path;
++                    //TODO(shijie): Move file name generation to file_search lib.
++                    let file_name = Path::new(&path)
++                        .file_name()
++                        .map(|name| name.to_string_lossy().into_owned())
++                        .unwrap_or_else(|| path.clone());
++                    let result = FuzzyFileSearchResult {
++                        root: root.clone(),
++                        path,
++                        file_name,
++                        score: m.score,
++                        indices: m.indices,
++                    };
++                    files.push(result);
++                }
++            }
++            Ok(Err((root, err))) => {
++                warn!("fuzzy-file-search in dir '{root}' failed: {err}");
++            }
++            Err(err) => {
++                warn!("fuzzy-file-search join_next failed: {err}");
++            }
++        }
++    }
++
++    files.sort_by(file_search::cmp_by_score_desc_then_path_asc::<
++        FuzzyFileSearchResult,
++        _,
++        _,
++    >(|f| f.score, |f| f.path.as_str()));
++
++    files
++}
+diff --git a/codex-rs/app-server/src/lib.rs b/codex-rs/app-server/src/lib.rs
+index 75a8be01..9c5d3132 100644
+--- a/codex-rs/app-server/src/lib.rs
++++ b/codex-rs/app-server/src/lib.rs
+@@ -1,140 +1,140 @@
+-#![deny(clippy::print_stdout, clippy::print_stderr)]
+-
+-use std::io::ErrorKind;
+-use std::io::Result as IoResult;
+-use std::path::PathBuf;
+-
+-use codex_common::CliConfigOverrides;
+-use codex_core::config::Config;
+-use codex_core::config::ConfigOverrides;
+-
+-use codex_app_server_protocol::JSONRPCMessage;
+-use tokio::io::AsyncBufReadExt;
+-use tokio::io::AsyncWriteExt;
+-use tokio::io::BufReader;
+-use tokio::io::{self};
+-use tokio::sync::mpsc;
+-use tracing::debug;
+-use tracing::error;
+-use tracing::info;
+-use tracing_subscriber::EnvFilter;
+-
+-use crate::message_processor::MessageProcessor;
+-use crate::outgoing_message::OutgoingMessage;
+-use crate::outgoing_message::OutgoingMessageSender;
+-
+-mod codex_message_processor;
+-mod error_code;
+-mod fuzzy_file_search;
+-mod message_processor;
+-mod outgoing_message;
+-
+-/// Size of the bounded channels used to communicate between tasks. The value
+-/// is a balance between throughput and memory usage – 128 messages should be
+-/// plenty for an interactive CLI.
+-const CHANNEL_CAPACITY: usize = 128;
+-
+-pub async fn run_main(
+-    codex_linux_sandbox_exe: Option<PathBuf>,
+-    cli_config_overrides: CliConfigOverrides,
+-) -> IoResult<()> {
+-    // Install a simple subscriber so `tracing` output is visible.  Users can
+-    // control the log level with `RUST_LOG`.
+-    tracing_subscriber::fmt()
+-        .with_writer(std::io::stderr)
+-        .with_env_filter(EnvFilter::from_default_env())
+-        .init();
+-
+-    // Set up channels.
+-    let (incoming_tx, mut incoming_rx) = mpsc::channel::<JSONRPCMessage>(CHANNEL_CAPACITY);
+-    let (outgoing_tx, mut outgoing_rx) = mpsc::unbounded_channel::<OutgoingMessage>();
+-
+-    // Task: read from stdin, push to `incoming_tx`.
+-    let stdin_reader_handle = tokio::spawn({
+-        async move {
+-            let stdin = io::stdin();
+-            let reader = BufReader::new(stdin);
+-            let mut lines = reader.lines();
+-
+-            while let Some(line) = lines.next_line().await.unwrap_or_default() {
+-                match serde_json::from_str::<JSONRPCMessage>(&line) {
+-                    Ok(msg) => {
+-                        if incoming_tx.send(msg).await.is_err() {
+-                            // Receiver gone – nothing left to do.
+-                            break;
+-                        }
+-                    }
+-                    Err(e) => error!("Failed to deserialize JSONRPCMessage: {e}"),
+-                }
+-            }
+-
+-            debug!("stdin reader finished (EOF)");
+-        }
+-    });
+-
+-    // Parse CLI overrides once and derive the base Config eagerly so later
+-    // components do not need to work with raw TOML values.
+-    let cli_kv_overrides = cli_config_overrides.parse_overrides().map_err(|e| {
+-        std::io::Error::new(
+-            ErrorKind::InvalidInput,
+-            format!("error parsing -c overrides: {e}"),
+-        )
+-    })?;
+-    let config = Config::load_with_cli_overrides(cli_kv_overrides, ConfigOverrides::default())
+-        .await
+-        .map_err(|e| {
+-            std::io::Error::new(ErrorKind::InvalidData, format!("error loading config: {e}"))
+-        })?;
+-
+-    // Task: process incoming messages.
+-    let processor_handle = tokio::spawn({
+-        let outgoing_message_sender = OutgoingMessageSender::new(outgoing_tx);
+-        let mut processor = MessageProcessor::new(
+-            outgoing_message_sender,
+-            codex_linux_sandbox_exe,
+-            std::sync::Arc::new(config),
+-        );
+-        async move {
+-            while let Some(msg) = incoming_rx.recv().await {
+-                match msg {
+-                    JSONRPCMessage::Request(r) => processor.process_request(r).await,
+-                    JSONRPCMessage::Response(r) => processor.process_response(r).await,
+-                    JSONRPCMessage::Notification(n) => processor.process_notification(n).await,
+-                    JSONRPCMessage::Error(e) => processor.process_error(e),
+-                }
+-            }
+-
+-            info!("processor task exited (channel closed)");
+-        }
+-    });
+-
+-    // Task: write outgoing messages to stdout.
+-    let stdout_writer_handle = tokio::spawn(async move {
+-        let mut stdout = io::stdout();
+-        while let Some(outgoing_message) = outgoing_rx.recv().await {
+-            let Ok(value) = serde_json::to_value(outgoing_message) else {
+-                error!("Failed to convert OutgoingMessage to JSON value");
+-                continue;
+-            };
+-            match serde_json::to_string(&value) {
+-                Ok(mut json) => {
+-                    json.push('\n');
+-                    if let Err(e) = stdout.write_all(json.as_bytes()).await {
+-                        error!("Failed to write to stdout: {e}");
+-                        break;
+-                    }
+-                }
+-                Err(e) => error!("Failed to serialize JSONRPCMessage: {e}"),
+-            }
+-        }
+-
+-        info!("stdout writer exited (channel closed)");
+-    });
+-
+-    // Wait for all tasks to finish.  The typical exit path is the stdin reader
+-    // hitting EOF which, once it drops `incoming_tx`, propagates shutdown to
+-    // the processor and then to the stdout task.
+-    let _ = tokio::join!(stdin_reader_handle, processor_handle, stdout_writer_handle);
+-
+-    Ok(())
+-}
++#![deny(clippy::print_stdout, clippy::print_stderr)]
++
++use std::io::ErrorKind;
++use std::io::Result as IoResult;
++use std::path::PathBuf;
++
++use codex_common::CliConfigOverrides;
++use codex_core::config::Config;
++use codex_core::config::ConfigOverrides;
++
++use codex_app_server_protocol::JSONRPCMessage;
++use tokio::io::AsyncBufReadExt;
++use tokio::io::AsyncWriteExt;
++use tokio::io::BufReader;
++use tokio::io::{self};
++use tokio::sync::mpsc;
++use tracing::debug;
++use tracing::error;
++use tracing::info;
++use tracing_subscriber::EnvFilter;
++
++use crate::message_processor::MessageProcessor;
++use crate::outgoing_message::OutgoingMessage;
++use crate::outgoing_message::OutgoingMessageSender;
++
++mod codex_message_processor;
++mod error_code;
++mod fuzzy_file_search;
++mod message_processor;
++mod outgoing_message;
++
++/// Size of the bounded channels used to communicate between tasks. The value
++/// is a balance between throughput and memory usage – 128 messages should be
++/// plenty for an interactive CLI.
++const CHANNEL_CAPACITY: usize = 128;
++
++pub async fn run_main(
++    codex_linux_sandbox_exe: Option<PathBuf>,
++    cli_config_overrides: CliConfigOverrides,
++) -> IoResult<()> {
++    // Install a simple subscriber so `tracing` output is visible.  Users can
++    // control the log level with `RUST_LOG`.
++    tracing_subscriber::fmt()
++        .with_writer(std::io::stderr)
++        .with_env_filter(EnvFilter::from_default_env())
++        .init();
++
++    // Set up channels.
++    let (incoming_tx, mut incoming_rx) = mpsc::channel::<JSONRPCMessage>(CHANNEL_CAPACITY);
++    let (outgoing_tx, mut outgoing_rx) = mpsc::unbounded_channel::<OutgoingMessage>();
++
++    // Task: read from stdin, push to `incoming_tx`.
++    let stdin_reader_handle = tokio::spawn({
++        async move {
++            let stdin = io::stdin();
++            let reader = BufReader::new(stdin);
++            let mut lines = reader.lines();
++
++            while let Some(line) = lines.next_line().await.unwrap_or_default() {
++                match serde_json::from_str::<JSONRPCMessage>(&line) {
++                    Ok(msg) => {
++                        if incoming_tx.send(msg).await.is_err() {
++                            // Receiver gone – nothing left to do.
++                            break;
++                        }
++                    }
++                    Err(e) => error!("Failed to deserialize JSONRPCMessage: {e}"),
++                }
++            }
++
++            debug!("stdin reader finished (EOF)");
++        }
++    });
++
++    // Parse CLI overrides once and derive the base Config eagerly so later
++    // components do not need to work with raw TOML values.
++    let cli_kv_overrides = cli_config_overrides.parse_overrides().map_err(|e| {
++        std::io::Error::new(
++            ErrorKind::InvalidInput,
++            format!("error parsing -c overrides: {e}"),
++        )
++    })?;
++    let config = Config::load_with_cli_overrides(cli_kv_overrides, ConfigOverrides::default())
++        .await
++        .map_err(|e| {
++            std::io::Error::new(ErrorKind::InvalidData, format!("error loading config: {e}"))
++        })?;
++
++    // Task: process incoming messages.
++    let processor_handle = tokio::spawn({
++        let outgoing_message_sender = OutgoingMessageSender::new(outgoing_tx);
++        let mut processor = MessageProcessor::new(
++            outgoing_message_sender,
++            codex_linux_sandbox_exe,
++            std::sync::Arc::new(config),
++        );
++        async move {
++            while let Some(msg) = incoming_rx.recv().await {
++                match msg {
++                    JSONRPCMessage::Request(r) => processor.process_request(r).await,
++                    JSONRPCMessage::Response(r) => processor.process_response(r).await,
++                    JSONRPCMessage::Notification(n) => processor.process_notification(n).await,
++                    JSONRPCMessage::Error(e) => processor.process_error(e),
++                }
++            }
++
++            info!("processor task exited (channel closed)");
++        }
++    });
++
++    // Task: write outgoing messages to stdout.
++    let stdout_writer_handle = tokio::spawn(async move {
++        let mut stdout = io::stdout();
++        while let Some(outgoing_message) = outgoing_rx.recv().await {
++            let Ok(value) = serde_json::to_value(outgoing_message) else {
++                error!("Failed to convert OutgoingMessage to JSON value");
++                continue;
++            };
++            match serde_json::to_string(&value) {
++                Ok(mut json) => {
++                    json.push('\n');
++                    if let Err(e) = stdout.write_all(json.as_bytes()).await {
++                        error!("Failed to write to stdout: {e}");
++                        break;
++                    }
++                }
++                Err(e) => error!("Failed to serialize JSONRPCMessage: {e}"),
++            }
++        }
++
++        info!("stdout writer exited (channel closed)");
++    });
++
++    // Wait for all tasks to finish.  The typical exit path is the stdin reader
++    // hitting EOF which, once it drops `incoming_tx`, propagates shutdown to
++    // the processor and then to the stdout task.
++    let _ = tokio::join!(stdin_reader_handle, processor_handle, stdout_writer_handle);
++
++    Ok(())
++}
+diff --git a/codex-rs/app-server/src/main.rs b/codex-rs/app-server/src/main.rs
+index 689ec087..d85a18e4 100644
+--- a/codex-rs/app-server/src/main.rs
++++ b/codex-rs/app-server/src/main.rs
+@@ -1,10 +1,10 @@
+-use codex_app_server::run_main;
+-use codex_arg0::arg0_dispatch_or_else;
+-use codex_common::CliConfigOverrides;
+-
+-fn main() -> anyhow::Result<()> {
+-    arg0_dispatch_or_else(|codex_linux_sandbox_exe| async move {
+-        run_main(codex_linux_sandbox_exe, CliConfigOverrides::default()).await?;
+-        Ok(())
+-    })
+-}
++use codex_app_server::run_main;
++use codex_arg0::arg0_dispatch_or_else;
++use codex_common::CliConfigOverrides;
++
++fn main() -> anyhow::Result<()> {
++    arg0_dispatch_or_else(|codex_linux_sandbox_exe| async move {
++        run_main(codex_linux_sandbox_exe, CliConfigOverrides::default()).await?;
++        Ok(())
++    })
++}
+diff --git a/codex-rs/app-server/src/message_processor.rs b/codex-rs/app-server/src/message_processor.rs
+index 15086c19..abdfe695 100644
+--- a/codex-rs/app-server/src/message_processor.rs
++++ b/codex-rs/app-server/src/message_processor.rs
+@@ -17,6 +17,8 @@ use codex_core::ConversationManager;
+ use codex_core::config::Config;
+ use codex_core::default_client::USER_AGENT_SUFFIX;
+ use codex_core::default_client::get_codex_user_agent;
++#[cfg(feature = "ledger")]
++use codex_ledger::InMemoryLedgerService;
+ use codex_protocol::protocol::SessionSource;
+ use std::sync::Arc;
+ 
+@@ -40,12 +42,21 @@ impl MessageProcessor {
+             auth_manager.clone(),
+             SessionSource::VSCode,
+         ));
++        #[cfg(feature = "ledger")]
++        let ledger_service = match std::env::var("CODEX_LEDGER_IN_MEMORY") {
++            Ok(value) if matches!(value.as_str(), "1" | "true" | "TRUE" | "True") => {
++                Some(Arc::new(InMemoryLedgerService::new()))
++            }
++            _ => None,
++        };
+         let codex_message_processor = CodexMessageProcessor::new(
+             auth_manager,
+             conversation_manager,
+             outgoing.clone(),
+             codex_linux_sandbox_exe,
+             config,
++            #[cfg(feature = "ledger")]
++            ledger_service,
+         );
+ 
+         Self {
+diff --git a/codex-rs/app-server/src/outgoing_message.rs b/codex-rs/app-server/src/outgoing_message.rs
+index 96a2c5a9..69245208 100644
+--- a/codex-rs/app-server/src/outgoing_message.rs
++++ b/codex-rs/app-server/src/outgoing_message.rs
+@@ -1,174 +1,174 @@
+-use std::collections::HashMap;
+-use std::sync::atomic::AtomicI64;
+-use std::sync::atomic::Ordering;
+-
+-use codex_app_server_protocol::JSONRPCErrorError;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::Result;
+-use codex_app_server_protocol::ServerNotification;
+-use codex_app_server_protocol::ServerRequest;
+-use codex_app_server_protocol::ServerRequestPayload;
+-use serde::Serialize;
+-use tokio::sync::Mutex;
+-use tokio::sync::mpsc;
+-use tokio::sync::oneshot;
+-use tracing::warn;
+-
+-use crate::error_code::INTERNAL_ERROR_CODE;
+-
+-/// Sends messages to the client and manages request callbacks.
+-pub(crate) struct OutgoingMessageSender {
+-    next_request_id: AtomicI64,
+-    sender: mpsc::UnboundedSender<OutgoingMessage>,
+-    request_id_to_callback: Mutex<HashMap<RequestId, oneshot::Sender<Result>>>,
+-}
+-
+-impl OutgoingMessageSender {
+-    pub(crate) fn new(sender: mpsc::UnboundedSender<OutgoingMessage>) -> Self {
+-        Self {
+-            next_request_id: AtomicI64::new(0),
+-            sender,
+-            request_id_to_callback: Mutex::new(HashMap::new()),
+-        }
+-    }
+-
+-    pub(crate) async fn send_request(
+-        &self,
+-        request: ServerRequestPayload,
+-    ) -> oneshot::Receiver<Result> {
+-        let id = RequestId::Integer(self.next_request_id.fetch_add(1, Ordering::Relaxed));
+-        let outgoing_message_id = id.clone();
+-        let (tx_approve, rx_approve) = oneshot::channel();
+-        {
+-            let mut request_id_to_callback = self.request_id_to_callback.lock().await;
+-            request_id_to_callback.insert(id, tx_approve);
+-        }
+-
+-        let outgoing_message =
+-            OutgoingMessage::Request(request.request_with_id(outgoing_message_id));
+-        let _ = self.sender.send(outgoing_message);
+-        rx_approve
+-    }
+-
+-    pub(crate) async fn notify_client_response(&self, id: RequestId, result: Result) {
+-        let entry = {
+-            let mut request_id_to_callback = self.request_id_to_callback.lock().await;
+-            request_id_to_callback.remove_entry(&id)
+-        };
+-
+-        match entry {
+-            Some((id, sender)) => {
+-                if let Err(err) = sender.send(result) {
+-                    warn!("could not notify callback for {id:?} due to: {err:?}");
+-                }
+-            }
+-            None => {
+-                warn!("could not find callback for {id:?}");
+-            }
+-        }
+-    }
+-
+-    pub(crate) async fn send_response<T: Serialize>(&self, id: RequestId, response: T) {
+-        match serde_json::to_value(response) {
+-            Ok(result) => {
+-                let outgoing_message = OutgoingMessage::Response(OutgoingResponse { id, result });
+-                let _ = self.sender.send(outgoing_message);
+-            }
+-            Err(err) => {
+-                self.send_error(
+-                    id,
+-                    JSONRPCErrorError {
+-                        code: INTERNAL_ERROR_CODE,
+-                        message: format!("failed to serialize response: {err}"),
+-                        data: None,
+-                    },
+-                )
+-                .await;
+-            }
+-        }
+-    }
+-
+-    pub(crate) async fn send_server_notification(&self, notification: ServerNotification) {
+-        let _ = self
+-            .sender
+-            .send(OutgoingMessage::AppServerNotification(notification));
+-    }
+-
+-    /// All notifications should be migrated to [`ServerNotification`] and
+-    /// [`OutgoingMessage::Notification`] should be removed.
+-    pub(crate) async fn send_notification(&self, notification: OutgoingNotification) {
+-        let outgoing_message = OutgoingMessage::Notification(notification);
+-        let _ = self.sender.send(outgoing_message);
+-    }
+-
+-    pub(crate) async fn send_error(&self, id: RequestId, error: JSONRPCErrorError) {
+-        let outgoing_message = OutgoingMessage::Error(OutgoingError { id, error });
+-        let _ = self.sender.send(outgoing_message);
+-    }
+-}
+-
+-/// Outgoing message from the server to the client.
+-#[derive(Debug, Clone, Serialize)]
+-#[serde(untagged)]
+-pub(crate) enum OutgoingMessage {
+-    Request(ServerRequest),
+-    Notification(OutgoingNotification),
+-    /// AppServerNotification is specific to the case where this is run as an
+-    /// "app server" as opposed to an MCP server.
+-    AppServerNotification(ServerNotification),
+-    Response(OutgoingResponse),
+-    Error(OutgoingError),
+-}
+-
+-#[derive(Debug, Clone, PartialEq, Serialize)]
+-pub(crate) struct OutgoingNotification {
+-    pub method: String,
+-    #[serde(default, skip_serializing_if = "Option::is_none")]
+-    pub params: Option<serde_json::Value>,
+-}
+-
+-#[derive(Debug, Clone, PartialEq, Serialize)]
+-pub(crate) struct OutgoingResponse {
+-    pub id: RequestId,
+-    pub result: Result,
+-}
+-
+-#[derive(Debug, Clone, PartialEq, Serialize)]
+-pub(crate) struct OutgoingError {
+-    pub error: JSONRPCErrorError,
+-    pub id: RequestId,
+-}
+-
+-#[cfg(test)]
+-mod tests {
+-    use codex_app_server_protocol::LoginChatGptCompleteNotification;
+-    use pretty_assertions::assert_eq;
+-    use serde_json::json;
+-    use uuid::Uuid;
+-
+-    use super::*;
+-
+-    #[test]
+-    fn verify_server_notification_serialization() {
+-        let notification =
+-            ServerNotification::LoginChatGptComplete(LoginChatGptCompleteNotification {
+-                login_id: Uuid::nil(),
+-                success: true,
+-                error: None,
+-            });
+-
+-        let jsonrpc_notification = OutgoingMessage::AppServerNotification(notification);
+-        assert_eq!(
+-            json!({
+-                "method": "loginChatGptComplete",
+-                "params": {
+-                    "loginId": Uuid::nil(),
+-                    "success": true,
+-                },
+-            }),
+-            serde_json::to_value(jsonrpc_notification)
+-                .expect("ensure the strum macros serialize the method field correctly"),
+-            "ensure the strum macros serialize the method field correctly"
+-        );
+-    }
+-}
++use std::collections::HashMap;
++use std::sync::atomic::AtomicI64;
++use std::sync::atomic::Ordering;
++
++use codex_app_server_protocol::JSONRPCErrorError;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::Result;
++use codex_app_server_protocol::ServerNotification;
++use codex_app_server_protocol::ServerRequest;
++use codex_app_server_protocol::ServerRequestPayload;
++use serde::Serialize;
++use tokio::sync::Mutex;
++use tokio::sync::mpsc;
++use tokio::sync::oneshot;
++use tracing::warn;
++
++use crate::error_code::INTERNAL_ERROR_CODE;
++
++/// Sends messages to the client and manages request callbacks.
++pub(crate) struct OutgoingMessageSender {
++    next_request_id: AtomicI64,
++    sender: mpsc::UnboundedSender<OutgoingMessage>,
++    request_id_to_callback: Mutex<HashMap<RequestId, oneshot::Sender<Result>>>,
++}
++
++impl OutgoingMessageSender {
++    pub(crate) fn new(sender: mpsc::UnboundedSender<OutgoingMessage>) -> Self {
++        Self {
++            next_request_id: AtomicI64::new(0),
++            sender,
++            request_id_to_callback: Mutex::new(HashMap::new()),
++        }
++    }
++
++    pub(crate) async fn send_request(
++        &self,
++        request: ServerRequestPayload,
++    ) -> oneshot::Receiver<Result> {
++        let id = RequestId::Integer(self.next_request_id.fetch_add(1, Ordering::Relaxed));
++        let outgoing_message_id = id.clone();
++        let (tx_approve, rx_approve) = oneshot::channel();
++        {
++            let mut request_id_to_callback = self.request_id_to_callback.lock().await;
++            request_id_to_callback.insert(id, tx_approve);
++        }
++
++        let outgoing_message =
++            OutgoingMessage::Request(request.request_with_id(outgoing_message_id));
++        let _ = self.sender.send(outgoing_message);
++        rx_approve
++    }
++
++    pub(crate) async fn notify_client_response(&self, id: RequestId, result: Result) {
++        let entry = {
++            let mut request_id_to_callback = self.request_id_to_callback.lock().await;
++            request_id_to_callback.remove_entry(&id)
++        };
++
++        match entry {
++            Some((id, sender)) => {
++                if let Err(err) = sender.send(result) {
++                    warn!("could not notify callback for {id:?} due to: {err:?}");
++                }
++            }
++            None => {
++                warn!("could not find callback for {id:?}");
++            }
++        }
++    }
++
++    pub(crate) async fn send_response<T: Serialize>(&self, id: RequestId, response: T) {
++        match serde_json::to_value(response) {
++            Ok(result) => {
++                let outgoing_message = OutgoingMessage::Response(OutgoingResponse { id, result });
++                let _ = self.sender.send(outgoing_message);
++            }
++            Err(err) => {
++                self.send_error(
++                    id,
++                    JSONRPCErrorError {
++                        code: INTERNAL_ERROR_CODE,
++                        message: format!("failed to serialize response: {err}"),
++                        data: None,
++                    },
++                )
++                .await;
++            }
++        }
++    }
++
++    pub(crate) async fn send_server_notification(&self, notification: ServerNotification) {
++        let _ = self
++            .sender
++            .send(OutgoingMessage::AppServerNotification(notification));
++    }
++
++    /// All notifications should be migrated to [`ServerNotification`] and
++    /// [`OutgoingMessage::Notification`] should be removed.
++    pub(crate) async fn send_notification(&self, notification: OutgoingNotification) {
++        let outgoing_message = OutgoingMessage::Notification(notification);
++        let _ = self.sender.send(outgoing_message);
++    }
++
++    pub(crate) async fn send_error(&self, id: RequestId, error: JSONRPCErrorError) {
++        let outgoing_message = OutgoingMessage::Error(OutgoingError { id, error });
++        let _ = self.sender.send(outgoing_message);
++    }
++}
++
++/// Outgoing message from the server to the client.
++#[derive(Debug, Clone, Serialize)]
++#[serde(untagged)]
++pub(crate) enum OutgoingMessage {
++    Request(ServerRequest),
++    Notification(OutgoingNotification),
++    /// AppServerNotification is specific to the case where this is run as an
++    /// "app server" as opposed to an MCP server.
++    AppServerNotification(ServerNotification),
++    Response(OutgoingResponse),
++    Error(OutgoingError),
++}
++
++#[derive(Debug, Clone, PartialEq, Serialize)]
++pub(crate) struct OutgoingNotification {
++    pub method: String,
++    #[serde(default, skip_serializing_if = "Option::is_none")]
++    pub params: Option<serde_json::Value>,
++}
++
++#[derive(Debug, Clone, PartialEq, Serialize)]
++pub(crate) struct OutgoingResponse {
++    pub id: RequestId,
++    pub result: Result,
++}
++
++#[derive(Debug, Clone, PartialEq, Serialize)]
++pub(crate) struct OutgoingError {
++    pub error: JSONRPCErrorError,
++    pub id: RequestId,
++}
++
++#[cfg(test)]
++mod tests {
++    use codex_app_server_protocol::LoginChatGptCompleteNotification;
++    use pretty_assertions::assert_eq;
++    use serde_json::json;
++    use uuid::Uuid;
++
++    use super::*;
++
++    #[test]
++    fn verify_server_notification_serialization() {
++        let notification =
++            ServerNotification::LoginChatGptComplete(LoginChatGptCompleteNotification {
++                login_id: Uuid::nil(),
++                success: true,
++                error: None,
++            });
++
++        let jsonrpc_notification = OutgoingMessage::AppServerNotification(notification);
++        assert_eq!(
++            json!({
++                "method": "loginChatGptComplete",
++                "params": {
++                    "loginId": Uuid::nil(),
++                    "success": true,
++                },
++            }),
++            serde_json::to_value(jsonrpc_notification)
++                .expect("ensure the strum macros serialize the method field correctly"),
++            "ensure the strum macros serialize the method field correctly"
++        );
++    }
++}
+diff --git a/codex-rs/app-server/tests/all.rs b/codex-rs/app-server/tests/all.rs
+index 7e136e4c..515c318d 100644
+--- a/codex-rs/app-server/tests/all.rs
++++ b/codex-rs/app-server/tests/all.rs
+@@ -1,3 +1,3 @@
+-// Single integration test binary that aggregates all test modules.
+-// The submodules live in `tests/suite/`.
+-mod suite;
++// Single integration test binary that aggregates all test modules.
++// The submodules live in `tests/suite/`.
++mod suite;
+diff --git a/codex-rs/app-server/tests/common/Cargo.toml b/codex-rs/app-server/tests/common/Cargo.toml
+index 306b1e18..a8c7952e 100644
+--- a/codex-rs/app-server/tests/common/Cargo.toml
++++ b/codex-rs/app-server/tests/common/Cargo.toml
+@@ -1,21 +1,21 @@
+-[package]
+-edition = "2024"
+-name = "app_test_support"
+-version = { workspace = true }
+-
+-[lib]
+-path = "lib.rs"
+-
+-[dependencies]
+-anyhow = { workspace = true }
+-assert_cmd = { workspace = true }
+-codex-app-server-protocol = { workspace = true }
+-serde = { workspace = true }
+-serde_json = { workspace = true }
+-tokio = { workspace = true, features = [
+-    "io-std",
+-    "macros",
+-    "process",
+-    "rt-multi-thread",
+-] }
+-wiremock = { workspace = true }
++[package]
++edition = "2024"
++name = "app_test_support"
++version = { workspace = true }
++
++[lib]
++path = "lib.rs"
++
++[dependencies]
++anyhow = { workspace = true }
++assert_cmd = { workspace = true }
++codex-app-server-protocol = { workspace = true }
++serde = { workspace = true }
++serde_json = { workspace = true }
++tokio = { workspace = true, features = [
++    "io-std",
++    "macros",
++    "process",
++    "rt-multi-thread",
++] }
++wiremock = { workspace = true }
+diff --git a/codex-rs/app-server/tests/common/lib.rs b/codex-rs/app-server/tests/common/lib.rs
+index 2acb52de..c0cde925 100644
+--- a/codex-rs/app-server/tests/common/lib.rs
++++ b/codex-rs/app-server/tests/common/lib.rs
+@@ -1,17 +1,17 @@
+-mod mcp_process;
+-mod mock_model_server;
+-mod responses;
+-
+-use codex_app_server_protocol::JSONRPCResponse;
+-pub use mcp_process::McpProcess;
+-pub use mock_model_server::create_mock_chat_completions_server;
+-pub use responses::create_apply_patch_sse_response;
+-pub use responses::create_final_assistant_message_sse_response;
+-pub use responses::create_shell_sse_response;
+-use serde::de::DeserializeOwned;
+-
+-pub fn to_response<T: DeserializeOwned>(response: JSONRPCResponse) -> anyhow::Result<T> {
+-    let value = serde_json::to_value(response.result)?;
+-    let codex_response = serde_json::from_value(value)?;
+-    Ok(codex_response)
+-}
++mod mcp_process;
++mod mock_model_server;
++mod responses;
++
++use codex_app_server_protocol::JSONRPCResponse;
++pub use mcp_process::McpProcess;
++pub use mock_model_server::create_mock_chat_completions_server;
++pub use responses::create_apply_patch_sse_response;
++pub use responses::create_final_assistant_message_sse_response;
++pub use responses::create_shell_sse_response;
++use serde::de::DeserializeOwned;
++
++pub fn to_response<T: DeserializeOwned>(response: JSONRPCResponse) -> anyhow::Result<T> {
++    let value = serde_json::to_value(response.result)?;
++    let codex_response = serde_json::from_value(value)?;
++    Ok(codex_response)
++}
+diff --git a/codex-rs/app-server/tests/common/mcp_process.rs b/codex-rs/app-server/tests/common/mcp_process.rs
+index 29768df8..8eb99546 100644
+--- a/codex-rs/app-server/tests/common/mcp_process.rs
++++ b/codex-rs/app-server/tests/common/mcp_process.rs
+@@ -20,6 +20,16 @@ use codex_app_server_protocol::ClientNotification;
+ use codex_app_server_protocol::GetAuthStatusParams;
+ use codex_app_server_protocol::InitializeParams;
+ use codex_app_server_protocol::InterruptConversationParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerCreateCompanyParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerLockPeriodParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerPostEntryParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerReverseEntryParams;
++#[cfg(feature = "ledger")]
++use codex_app_server_protocol::LedgerUpsertAccountParams;
+ use codex_app_server_protocol::ListConversationsParams;
+ use codex_app_server_protocol::LoginApiKeyParams;
+ use codex_app_server_protocol::NewConversationParams;
+@@ -313,6 +323,51 @@ impl McpProcess {
+         self.send_request("fuzzyFileSearch", Some(params)).await
+     }
+ 
++    #[cfg(feature = "ledger")]
++    pub async fn send_ledger_create_company_request(
++        &mut self,
++        params: LedgerCreateCompanyParams,
++    ) -> anyhow::Result<i64> {
++        let params = Some(serde_json::to_value(params)?);
++        self.send_request("ledgerCreateCompany", params).await
++    }
++
++    #[cfg(feature = "ledger")]
++    pub async fn send_ledger_upsert_account_request(
++        &mut self,
++        params: LedgerUpsertAccountParams,
++    ) -> anyhow::Result<i64> {
++        let params = Some(serde_json::to_value(params)?);
++        self.send_request("ledgerUpsertAccount", params).await
++    }
++
++    #[cfg(feature = "ledger")]
++    pub async fn send_ledger_post_entry_request(
++        &mut self,
++        params: LedgerPostEntryParams,
++    ) -> anyhow::Result<i64> {
++        let params = Some(serde_json::to_value(params)?);
++        self.send_request("ledgerPostEntry", params).await
++    }
++
++    #[cfg(feature = "ledger")]
++    pub async fn send_ledger_reverse_entry_request(
++        &mut self,
++        params: LedgerReverseEntryParams,
++    ) -> anyhow::Result<i64> {
++        let params = Some(serde_json::to_value(params)?);
++        self.send_request("ledgerReverseEntry", params).await
++    }
++
++    #[cfg(feature = "ledger")]
++    pub async fn send_ledger_lock_period_request(
++        &mut self,
++        params: LedgerLockPeriodParams,
++    ) -> anyhow::Result<i64> {
++        let params = Some(serde_json::to_value(params)?);
++        self.send_request("ledgerLockPeriod", params).await
++    }
++
+     async fn send_request(
+         &mut self,
+         method: &str,
+diff --git a/codex-rs/app-server/tests/common/mock_model_server.rs b/codex-rs/app-server/tests/common/mock_model_server.rs
+index be7f3eb5..d73e8e51 100644
+--- a/codex-rs/app-server/tests/common/mock_model_server.rs
++++ b/codex-rs/app-server/tests/common/mock_model_server.rs
+@@ -1,47 +1,47 @@
+-use std::sync::atomic::AtomicUsize;
+-use std::sync::atomic::Ordering;
+-
+-use wiremock::Mock;
+-use wiremock::MockServer;
+-use wiremock::Respond;
+-use wiremock::ResponseTemplate;
+-use wiremock::matchers::method;
+-use wiremock::matchers::path;
+-
+-/// Create a mock server that will provide the responses, in order, for
+-/// requests to the `/v1/chat/completions` endpoint.
+-pub async fn create_mock_chat_completions_server(responses: Vec<String>) -> MockServer {
+-    let server = MockServer::start().await;
+-
+-    let num_calls = responses.len();
+-    let seq_responder = SeqResponder {
+-        num_calls: AtomicUsize::new(0),
+-        responses,
+-    };
+-
+-    Mock::given(method("POST"))
+-        .and(path("/v1/chat/completions"))
+-        .respond_with(seq_responder)
+-        .expect(num_calls as u64)
+-        .mount(&server)
+-        .await;
+-
+-    server
+-}
+-
+-struct SeqResponder {
+-    num_calls: AtomicUsize,
+-    responses: Vec<String>,
+-}
+-
+-impl Respond for SeqResponder {
+-    fn respond(&self, _: &wiremock::Request) -> ResponseTemplate {
+-        let call_num = self.num_calls.fetch_add(1, Ordering::SeqCst);
+-        match self.responses.get(call_num) {
+-            Some(response) => ResponseTemplate::new(200)
+-                .insert_header("content-type", "text/event-stream")
+-                .set_body_raw(response.clone(), "text/event-stream"),
+-            None => panic!("no response for {call_num}"),
+-        }
+-    }
+-}
++use std::sync::atomic::AtomicUsize;
++use std::sync::atomic::Ordering;
++
++use wiremock::Mock;
++use wiremock::MockServer;
++use wiremock::Respond;
++use wiremock::ResponseTemplate;
++use wiremock::matchers::method;
++use wiremock::matchers::path;
++
++/// Create a mock server that will provide the responses, in order, for
++/// requests to the `/v1/chat/completions` endpoint.
++pub async fn create_mock_chat_completions_server(responses: Vec<String>) -> MockServer {
++    let server = MockServer::start().await;
++
++    let num_calls = responses.len();
++    let seq_responder = SeqResponder {
++        num_calls: AtomicUsize::new(0),
++        responses,
++    };
++
++    Mock::given(method("POST"))
++        .and(path("/v1/chat/completions"))
++        .respond_with(seq_responder)
++        .expect(num_calls as u64)
++        .mount(&server)
++        .await;
++
++    server
++}
++
++struct SeqResponder {
++    num_calls: AtomicUsize,
++    responses: Vec<String>,
++}
++
++impl Respond for SeqResponder {
++    fn respond(&self, _: &wiremock::Request) -> ResponseTemplate {
++        let call_num = self.num_calls.fetch_add(1, Ordering::SeqCst);
++        match self.responses.get(call_num) {
++            Some(response) => ResponseTemplate::new(200)
++                .insert_header("content-type", "text/event-stream")
++                .set_body_raw(response.clone(), "text/event-stream"),
++            None => panic!("no response for {call_num}"),
++        }
++    }
++}
+diff --git a/codex-rs/app-server/tests/common/responses.rs b/codex-rs/app-server/tests/common/responses.rs
+index 9a827fb9..73ac2eb0 100644
+--- a/codex-rs/app-server/tests/common/responses.rs
++++ b/codex-rs/app-server/tests/common/responses.rs
+@@ -1,95 +1,95 @@
+-use serde_json::json;
+-use std::path::Path;
+-
+-pub fn create_shell_sse_response(
+-    command: Vec<String>,
+-    workdir: Option<&Path>,
+-    timeout_ms: Option<u64>,
+-    call_id: &str,
+-) -> anyhow::Result<String> {
+-    // The `arguments`` for the `shell` tool is a serialized JSON object.
+-    let tool_call_arguments = serde_json::to_string(&json!({
+-        "command": command,
+-        "workdir": workdir.map(|w| w.to_string_lossy()),
+-        "timeout": timeout_ms
+-    }))?;
+-    let tool_call = json!({
+-        "choices": [
+-            {
+-                "delta": {
+-                    "tool_calls": [
+-                        {
+-                            "id": call_id,
+-                            "function": {
+-                                "name": "shell",
+-                                "arguments": tool_call_arguments
+-                            }
+-                        }
+-                    ]
+-                },
+-                "finish_reason": "tool_calls"
+-            }
+-        ]
+-    });
+-
+-    let sse = format!(
+-        "data: {}\n\ndata: DONE\n\n",
+-        serde_json::to_string(&tool_call)?
+-    );
+-    Ok(sse)
+-}
+-
+-pub fn create_final_assistant_message_sse_response(message: &str) -> anyhow::Result<String> {
+-    let assistant_message = json!({
+-        "choices": [
+-            {
+-                "delta": {
+-                    "content": message
+-                },
+-                "finish_reason": "stop"
+-            }
+-        ]
+-    });
+-
+-    let sse = format!(
+-        "data: {}\n\ndata: DONE\n\n",
+-        serde_json::to_string(&assistant_message)?
+-    );
+-    Ok(sse)
+-}
+-
+-pub fn create_apply_patch_sse_response(
+-    patch_content: &str,
+-    call_id: &str,
+-) -> anyhow::Result<String> {
+-    // Use shell command to call apply_patch with heredoc format
+-    let shell_command = format!("apply_patch <<'EOF'\n{patch_content}\nEOF");
+-    let tool_call_arguments = serde_json::to_string(&json!({
+-        "command": ["bash", "-lc", shell_command]
+-    }))?;
+-
+-    let tool_call = json!({
+-        "choices": [
+-            {
+-                "delta": {
+-                    "tool_calls": [
+-                        {
+-                            "id": call_id,
+-                            "function": {
+-                                "name": "shell",
+-                                "arguments": tool_call_arguments
+-                            }
+-                        }
+-                    ]
+-                },
+-                "finish_reason": "tool_calls"
+-            }
+-        ]
+-    });
+-
+-    let sse = format!(
+-        "data: {}\n\ndata: DONE\n\n",
+-        serde_json::to_string(&tool_call)?
+-    );
+-    Ok(sse)
+-}
++use serde_json::json;
++use std::path::Path;
++
++pub fn create_shell_sse_response(
++    command: Vec<String>,
++    workdir: Option<&Path>,
++    timeout_ms: Option<u64>,
++    call_id: &str,
++) -> anyhow::Result<String> {
++    // The `arguments`` for the `shell` tool is a serialized JSON object.
++    let tool_call_arguments = serde_json::to_string(&json!({
++        "command": command,
++        "workdir": workdir.map(|w| w.to_string_lossy()),
++        "timeout": timeout_ms
++    }))?;
++    let tool_call = json!({
++        "choices": [
++            {
++                "delta": {
++                    "tool_calls": [
++                        {
++                            "id": call_id,
++                            "function": {
++                                "name": "shell",
++                                "arguments": tool_call_arguments
++                            }
++                        }
++                    ]
++                },
++                "finish_reason": "tool_calls"
++            }
++        ]
++    });
++
++    let sse = format!(
++        "data: {}\n\ndata: DONE\n\n",
++        serde_json::to_string(&tool_call)?
++    );
++    Ok(sse)
++}
++
++pub fn create_final_assistant_message_sse_response(message: &str) -> anyhow::Result<String> {
++    let assistant_message = json!({
++        "choices": [
++            {
++                "delta": {
++                    "content": message
++                },
++                "finish_reason": "stop"
++            }
++        ]
++    });
++
++    let sse = format!(
++        "data: {}\n\ndata: DONE\n\n",
++        serde_json::to_string(&assistant_message)?
++    );
++    Ok(sse)
++}
++
++pub fn create_apply_patch_sse_response(
++    patch_content: &str,
++    call_id: &str,
++) -> anyhow::Result<String> {
++    // Use shell command to call apply_patch with heredoc format
++    let shell_command = format!("apply_patch <<'EOF'\n{patch_content}\nEOF");
++    let tool_call_arguments = serde_json::to_string(&json!({
++        "command": ["bash", "-lc", shell_command]
++    }))?;
++
++    let tool_call = json!({
++        "choices": [
++            {
++                "delta": {
++                    "tool_calls": [
++                        {
++                            "id": call_id,
++                            "function": {
++                                "name": "shell",
++                                "arguments": tool_call_arguments
++                            }
++                        }
++                    ]
++                },
++                "finish_reason": "tool_calls"
++            }
++        ]
++    });
++
++    let sse = format!(
++        "data: {}\n\ndata: DONE\n\n",
++        serde_json::to_string(&tool_call)?
++    );
++    Ok(sse)
++}
+diff --git a/codex-rs/app-server/tests/suite/archive_conversation.rs b/codex-rs/app-server/tests/suite/archive_conversation.rs
+index 6dcfefdb..f5d2a58d 100644
+--- a/codex-rs/app-server/tests/suite/archive_conversation.rs
++++ b/codex-rs/app-server/tests/suite/archive_conversation.rs
+@@ -1,105 +1,105 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::ArchiveConversationParams;
+-use codex_app_server_protocol::ArchiveConversationResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::NewConversationParams;
+-use codex_app_server_protocol::NewConversationResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_core::ARCHIVED_SESSIONS_SUBDIR;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn archive_conversation_moves_rollout_into_archived_directory() {
+-    let codex_home = TempDir::new().expect("create temp dir");
+-    create_config_toml(codex_home.path()).expect("write config.toml");
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("initialize timeout")
+-        .expect("initialize request");
+-
+-    let new_request_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            model: Some("mock-model".to_string()),
+-            ..Default::default()
+-        })
+-        .await
+-        .expect("send newConversation");
+-    let new_response: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_request_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation response");
+-
+-    let NewConversationResponse {
+-        conversation_id,
+-        rollout_path,
+-        ..
+-    } = to_response::<NewConversationResponse>(new_response)
+-        .expect("deserialize newConversation response");
+-
+-    assert!(
+-        rollout_path.exists(),
+-        "expected rollout path {} to exist",
+-        rollout_path.display()
+-    );
+-
+-    let archive_request_id = mcp
+-        .send_archive_conversation_request(ArchiveConversationParams {
+-            conversation_id,
+-            rollout_path: rollout_path.clone(),
+-        })
+-        .await
+-        .expect("send archiveConversation");
+-    let archive_response: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(archive_request_id)),
+-    )
+-    .await
+-    .expect("archiveConversation timeout")
+-    .expect("archiveConversation response");
+-
+-    let _: ArchiveConversationResponse =
+-        to_response::<ArchiveConversationResponse>(archive_response)
+-            .expect("deserialize archiveConversation response");
+-
+-    let archived_directory = codex_home.path().join(ARCHIVED_SESSIONS_SUBDIR);
+-    let archived_rollout_path =
+-        archived_directory.join(rollout_path.file_name().unwrap_or_else(|| {
+-            panic!("rollout path {} missing file name", rollout_path.display())
+-        }));
+-
+-    assert!(
+-        !rollout_path.exists(),
+-        "expected rollout path {} to be moved",
+-        rollout_path.display()
+-    );
+-    assert!(
+-        archived_rollout_path.exists(),
+-        "expected archived rollout path {} to exist",
+-        archived_rollout_path.display()
+-    );
+-}
+-
+-fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(config_toml, config_contents())
+-}
+-
+-fn config_contents() -> &'static str {
+-    r#"model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "read-only"
+-"#
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::ArchiveConversationParams;
++use codex_app_server_protocol::ArchiveConversationResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::NewConversationParams;
++use codex_app_server_protocol::NewConversationResponse;
++use codex_app_server_protocol::RequestId;
++use codex_core::ARCHIVED_SESSIONS_SUBDIR;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn archive_conversation_moves_rollout_into_archived_directory() {
++    let codex_home = TempDir::new().expect("create temp dir");
++    create_config_toml(codex_home.path()).expect("write config.toml");
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("initialize timeout")
++        .expect("initialize request");
++
++    let new_request_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            model: Some("mock-model".to_string()),
++            ..Default::default()
++        })
++        .await
++        .expect("send newConversation");
++    let new_response: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_request_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation response");
++
++    let NewConversationResponse {
++        conversation_id,
++        rollout_path,
++        ..
++    } = to_response::<NewConversationResponse>(new_response)
++        .expect("deserialize newConversation response");
++
++    assert!(
++        rollout_path.exists(),
++        "expected rollout path {} to exist",
++        rollout_path.display()
++    );
++
++    let archive_request_id = mcp
++        .send_archive_conversation_request(ArchiveConversationParams {
++            conversation_id,
++            rollout_path: rollout_path.clone(),
++        })
++        .await
++        .expect("send archiveConversation");
++    let archive_response: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(archive_request_id)),
++    )
++    .await
++    .expect("archiveConversation timeout")
++    .expect("archiveConversation response");
++
++    let _: ArchiveConversationResponse =
++        to_response::<ArchiveConversationResponse>(archive_response)
++            .expect("deserialize archiveConversation response");
++
++    let archived_directory = codex_home.path().join(ARCHIVED_SESSIONS_SUBDIR);
++    let archived_rollout_path =
++        archived_directory.join(rollout_path.file_name().unwrap_or_else(|| {
++            panic!("rollout path {} missing file name", rollout_path.display())
++        }));
++
++    assert!(
++        !rollout_path.exists(),
++        "expected rollout path {} to be moved",
++        rollout_path.display()
++    );
++    assert!(
++        archived_rollout_path.exists(),
++        "expected archived rollout path {} to exist",
++        archived_rollout_path.display()
++    );
++}
++
++fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(config_toml, config_contents())
++}
++
++fn config_contents() -> &'static str {
++    r#"model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "read-only"
++"#
++}
+diff --git a/codex-rs/app-server/tests/suite/auth.rs b/codex-rs/app-server/tests/suite/auth.rs
+index f45a27fd..12de367e 100644
+--- a/codex-rs/app-server/tests/suite/auth.rs
++++ b/codex-rs/app-server/tests/suite/auth.rs
+@@ -1,223 +1,223 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::AuthMode;
+-use codex_app_server_protocol::GetAuthStatusParams;
+-use codex_app_server_protocol::GetAuthStatusResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::LoginApiKeyParams;
+-use codex_app_server_protocol::LoginApiKeyResponse;
+-use codex_app_server_protocol::RequestId;
+-use pretty_assertions::assert_eq;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-fn create_config_toml_custom_provider(
+-    codex_home: &Path,
+-    requires_openai_auth: bool,
+-) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    let requires_line = if requires_openai_auth {
+-        "requires_openai_auth = true\n"
+-    } else {
+-        ""
+-    };
+-    let contents = format!(
+-        r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "http://127.0.0.1:0/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-{requires_line}
+-"#
+-    );
+-    std::fs::write(config_toml, contents)
+-}
+-
+-fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-"#,
+-    )
+-}
+-
+-async fn login_with_api_key_via_request(mcp: &mut McpProcess, api_key: &str) {
+-    let request_id = mcp
+-        .send_login_api_key_request(LoginApiKeyParams {
+-            api_key: api_key.to_string(),
+-        })
+-        .await
+-        .unwrap_or_else(|e| panic!("send loginApiKey: {e}"));
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .unwrap_or_else(|e| panic!("loginApiKey timeout: {e}"))
+-    .unwrap_or_else(|e| panic!("loginApiKey response: {e}"));
+-    let _: LoginApiKeyResponse =
+-        to_response(resp).unwrap_or_else(|e| panic!("deserialize login response: {e}"));
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_auth_status_no_auth() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
+-
+-    let mut mcp = McpProcess::new_with_env(codex_home.path(), &[("OPENAI_API_KEY", None)])
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let request_id = mcp
+-        .send_get_auth_status_request(GetAuthStatusParams {
+-            include_token: Some(true),
+-            refresh_token: Some(false),
+-        })
+-        .await
+-        .expect("send getAuthStatus");
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getAuthStatus timeout")
+-    .expect("getAuthStatus response");
+-    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
+-    assert_eq!(status.auth_method, None, "expected no auth method");
+-    assert_eq!(status.auth_token, None, "expected no token");
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_auth_status_with_api_key() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
+-
+-    let request_id = mcp
+-        .send_get_auth_status_request(GetAuthStatusParams {
+-            include_token: Some(true),
+-            refresh_token: Some(false),
+-        })
+-        .await
+-        .expect("send getAuthStatus");
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getAuthStatus timeout")
+-    .expect("getAuthStatus response");
+-    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
+-    assert_eq!(status.auth_method, Some(AuthMode::ApiKey));
+-    assert_eq!(status.auth_token, Some("sk-test-key".to_string()));
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_auth_status_with_api_key_when_auth_not_required() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml_custom_provider(codex_home.path(), false)
+-        .unwrap_or_else(|err| panic!("write config.toml: {err}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
+-
+-    let request_id = mcp
+-        .send_get_auth_status_request(GetAuthStatusParams {
+-            include_token: Some(true),
+-            refresh_token: Some(false),
+-        })
+-        .await
+-        .expect("send getAuthStatus");
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getAuthStatus timeout")
+-    .expect("getAuthStatus response");
+-    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
+-    assert_eq!(status.auth_method, None, "expected no auth method");
+-    assert_eq!(status.auth_token, None, "expected no token");
+-    assert_eq!(
+-        status.requires_openai_auth,
+-        Some(false),
+-        "requires_openai_auth should be false",
+-    );
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_auth_status_with_api_key_no_include_token() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
+-
+-    // Build params via struct so None field is omitted in wire JSON.
+-    let params = GetAuthStatusParams {
+-        include_token: None,
+-        refresh_token: Some(false),
+-    };
+-    let request_id = mcp
+-        .send_get_auth_status_request(params)
+-        .await
+-        .expect("send getAuthStatus");
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getAuthStatus timeout")
+-    .expect("getAuthStatus response");
+-    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
+-    assert_eq!(status.auth_method, Some(AuthMode::ApiKey));
+-    assert!(status.auth_token.is_none(), "token must be omitted");
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::AuthMode;
++use codex_app_server_protocol::GetAuthStatusParams;
++use codex_app_server_protocol::GetAuthStatusResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::LoginApiKeyParams;
++use codex_app_server_protocol::LoginApiKeyResponse;
++use codex_app_server_protocol::RequestId;
++use pretty_assertions::assert_eq;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++fn create_config_toml_custom_provider(
++    codex_home: &Path,
++    requires_openai_auth: bool,
++) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    let requires_line = if requires_openai_auth {
++        "requires_openai_auth = true\n"
++    } else {
++        ""
++    };
++    let contents = format!(
++        r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "http://127.0.0.1:0/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++{requires_line}
++"#
++    );
++    std::fs::write(config_toml, contents)
++}
++
++fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++"#,
++    )
++}
++
++async fn login_with_api_key_via_request(mcp: &mut McpProcess, api_key: &str) {
++    let request_id = mcp
++        .send_login_api_key_request(LoginApiKeyParams {
++            api_key: api_key.to_string(),
++        })
++        .await
++        .unwrap_or_else(|e| panic!("send loginApiKey: {e}"));
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .unwrap_or_else(|e| panic!("loginApiKey timeout: {e}"))
++    .unwrap_or_else(|e| panic!("loginApiKey response: {e}"));
++    let _: LoginApiKeyResponse =
++        to_response(resp).unwrap_or_else(|e| panic!("deserialize login response: {e}"));
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_auth_status_no_auth() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
++
++    let mut mcp = McpProcess::new_with_env(codex_home.path(), &[("OPENAI_API_KEY", None)])
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let request_id = mcp
++        .send_get_auth_status_request(GetAuthStatusParams {
++            include_token: Some(true),
++            refresh_token: Some(false),
++        })
++        .await
++        .expect("send getAuthStatus");
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getAuthStatus timeout")
++    .expect("getAuthStatus response");
++    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
++    assert_eq!(status.auth_method, None, "expected no auth method");
++    assert_eq!(status.auth_token, None, "expected no token");
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_auth_status_with_api_key() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
++
++    let request_id = mcp
++        .send_get_auth_status_request(GetAuthStatusParams {
++            include_token: Some(true),
++            refresh_token: Some(false),
++        })
++        .await
++        .expect("send getAuthStatus");
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getAuthStatus timeout")
++    .expect("getAuthStatus response");
++    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
++    assert_eq!(status.auth_method, Some(AuthMode::ApiKey));
++    assert_eq!(status.auth_token, Some("sk-test-key".to_string()));
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_auth_status_with_api_key_when_auth_not_required() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml_custom_provider(codex_home.path(), false)
++        .unwrap_or_else(|err| panic!("write config.toml: {err}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
++
++    let request_id = mcp
++        .send_get_auth_status_request(GetAuthStatusParams {
++            include_token: Some(true),
++            refresh_token: Some(false),
++        })
++        .await
++        .expect("send getAuthStatus");
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getAuthStatus timeout")
++    .expect("getAuthStatus response");
++    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
++    assert_eq!(status.auth_method, None, "expected no auth method");
++    assert_eq!(status.auth_token, None, "expected no token");
++    assert_eq!(
++        status.requires_openai_auth,
++        Some(false),
++        "requires_openai_auth should be false",
++    );
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_auth_status_with_api_key_no_include_token() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    login_with_api_key_via_request(&mut mcp, "sk-test-key").await;
++
++    // Build params via struct so None field is omitted in wire JSON.
++    let params = GetAuthStatusParams {
++        include_token: None,
++        refresh_token: Some(false),
++    };
++    let request_id = mcp
++        .send_get_auth_status_request(params)
++        .await
++        .expect("send getAuthStatus");
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getAuthStatus timeout")
++    .expect("getAuthStatus response");
++    let status: GetAuthStatusResponse = to_response(resp).expect("deserialize status");
++    assert_eq!(status.auth_method, Some(AuthMode::ApiKey));
++    assert!(status.auth_token.is_none(), "token must be omitted");
++}
+diff --git a/codex-rs/app-server/tests/suite/codex_message_processor_flow.rs b/codex-rs/app-server/tests/suite/codex_message_processor_flow.rs
+index 4dff2a15..7cd40938 100644
+--- a/codex-rs/app-server/tests/suite/codex_message_processor_flow.rs
++++ b/codex-rs/app-server/tests/suite/codex_message_processor_flow.rs
+@@ -1,623 +1,623 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::create_final_assistant_message_sse_response;
+-use app_test_support::create_mock_chat_completions_server;
+-use app_test_support::create_shell_sse_response;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::AddConversationListenerParams;
+-use codex_app_server_protocol::AddConversationSubscriptionResponse;
+-use codex_app_server_protocol::ExecCommandApprovalParams;
+-use codex_app_server_protocol::InputItem;
+-use codex_app_server_protocol::JSONRPCNotification;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::NewConversationParams;
+-use codex_app_server_protocol::NewConversationResponse;
+-use codex_app_server_protocol::RemoveConversationListenerParams;
+-use codex_app_server_protocol::RemoveConversationSubscriptionResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SendUserMessageParams;
+-use codex_app_server_protocol::SendUserMessageResponse;
+-use codex_app_server_protocol::SendUserTurnParams;
+-use codex_app_server_protocol::SendUserTurnResponse;
+-use codex_app_server_protocol::ServerRequest;
+-use codex_core::protocol::AskForApproval;
+-use codex_core::protocol::SandboxPolicy;
+-use codex_core::protocol_config_types::ReasoningEffort;
+-use codex_core::protocol_config_types::ReasoningSummary;
+-use codex_core::spawn::CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR;
+-use codex_protocol::config_types::SandboxMode;
+-use codex_protocol::protocol::Event;
+-use codex_protocol::protocol::EventMsg;
+-use codex_protocol::protocol::InputMessageKind;
+-use pretty_assertions::assert_eq;
+-use std::env;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
+-async fn test_codex_jsonrpc_conversation_flow() {
+-    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
+-        println!(
+-            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
+-        );
+-        return;
+-    }
+-
+-    let tmp = TempDir::new().expect("tmp dir");
+-    // Temporary Codex home with config pointing at the mock server.
+-    let codex_home = tmp.path().join("codex_home");
+-    std::fs::create_dir(&codex_home).expect("create codex home dir");
+-    let working_directory = tmp.path().join("workdir");
+-    std::fs::create_dir(&working_directory).expect("create working directory");
+-
+-    // Create a mock model server that immediately ends each turn.
+-    // Two turns are expected: initial session configure + one user message.
+-    let responses = vec![
+-        create_shell_sse_response(
+-            vec!["ls".to_string()],
+-            Some(&working_directory),
+-            Some(5000),
+-            "call1234",
+-        )
+-        .expect("create shell sse response"),
+-        create_final_assistant_message_sse_response("Enjoy your new git repo!")
+-            .expect("create final assistant message"),
+-    ];
+-    let server = create_mock_chat_completions_server(responses).await;
+-    create_config_toml(&codex_home, &server.uri()).expect("write config");
+-
+-    // Start MCP server and initialize.
+-    let mut mcp = McpProcess::new(&codex_home).await.expect("spawn mcp");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init error");
+-
+-    // 1) newConversation
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            cwd: Some(working_directory.to_string_lossy().into_owned()),
+-            ..Default::default()
+-        })
+-        .await
+-        .expect("send newConversation");
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation resp");
+-    let new_conv_resp = to_response::<NewConversationResponse>(new_conv_resp)
+-        .expect("deserialize newConversation response");
+-    let NewConversationResponse {
+-        conversation_id,
+-        model,
+-        reasoning_effort: _,
+-        rollout_path: _,
+-    } = new_conv_resp;
+-    assert_eq!(model, "mock-model");
+-
+-    // 2) addConversationListener
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await
+-        .expect("send addConversationListener");
+-    let add_listener_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-    )
+-    .await
+-    .expect("addConversationListener timeout")
+-    .expect("addConversationListener resp");
+-    let AddConversationSubscriptionResponse { subscription_id } =
+-        to_response::<AddConversationSubscriptionResponse>(add_listener_resp)
+-            .expect("deserialize addConversationListener response");
+-
+-    // 3) sendUserMessage (should trigger notifications; we only validate an OK response)
+-    let send_user_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id,
+-            items: vec![codex_app_server_protocol::InputItem::Text {
+-                text: "text".to_string(),
+-            }],
+-        })
+-        .await
+-        .expect("send sendUserMessage");
+-    let send_user_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
+-    )
+-    .await
+-    .expect("sendUserMessage timeout")
+-    .expect("sendUserMessage resp");
+-    let SendUserMessageResponse {} = to_response::<SendUserMessageResponse>(send_user_resp)
+-        .expect("deserialize sendUserMessage response");
+-
+-    // Verify the task_finished notification is received.
+-    // Note this also ensures that the final request to the server was made.
+-    let task_finished_notification: JSONRPCNotification = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_finished_notification timeout")
+-    .expect("task_finished_notification resp");
+-    let serde_json::Value::Object(map) = task_finished_notification
+-        .params
+-        .expect("notification should have params")
+-    else {
+-        panic!("task_finished_notification should have params");
+-    };
+-    assert_eq!(
+-        map.get("conversationId")
+-            .expect("should have conversationId"),
+-        &serde_json::Value::String(conversation_id.to_string())
+-    );
+-
+-    // 4) removeConversationListener
+-    let remove_listener_id = mcp
+-        .send_remove_conversation_listener_request(RemoveConversationListenerParams {
+-            subscription_id,
+-        })
+-        .await
+-        .expect("send removeConversationListener");
+-    let remove_listener_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(remove_listener_id)),
+-    )
+-    .await
+-    .expect("removeConversationListener timeout")
+-    .expect("removeConversationListener resp");
+-    let RemoveConversationSubscriptionResponse {} =
+-        to_response(remove_listener_resp).expect("deserialize removeConversationListener response");
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
+-async fn test_send_user_turn_changes_approval_policy_behavior() {
+-    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
+-        println!(
+-            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
+-        );
+-        return;
+-    }
+-
+-    let tmp = TempDir::new().expect("tmp dir");
+-    let codex_home = tmp.path().join("codex_home");
+-    std::fs::create_dir(&codex_home).expect("create codex home dir");
+-    let working_directory = tmp.path().join("workdir");
+-    std::fs::create_dir(&working_directory).expect("create working directory");
+-
+-    // Mock server will request a python shell call for the first and second turn, then finish.
+-    let responses = vec![
+-        create_shell_sse_response(
+-            vec![
+-                "python3".to_string(),
+-                "-c".to_string(),
+-                "print(42)".to_string(),
+-            ],
+-            Some(&working_directory),
+-            Some(5000),
+-            "call1",
+-        )
+-        .expect("create first shell sse response"),
+-        create_final_assistant_message_sse_response("done 1")
+-            .expect("create final assistant message 1"),
+-        create_shell_sse_response(
+-            vec![
+-                "python3".to_string(),
+-                "-c".to_string(),
+-                "print(42)".to_string(),
+-            ],
+-            Some(&working_directory),
+-            Some(5000),
+-            "call2",
+-        )
+-        .expect("create second shell sse response"),
+-        create_final_assistant_message_sse_response("done 2")
+-            .expect("create final assistant message 2"),
+-    ];
+-    let server = create_mock_chat_completions_server(responses).await;
+-    create_config_toml(&codex_home, &server.uri()).expect("write config");
+-
+-    // Start MCP server and initialize.
+-    let mut mcp = McpProcess::new(&codex_home).await.expect("spawn mcp");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init error");
+-
+-    // 1) Start conversation with approval_policy=untrusted
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            cwd: Some(working_directory.to_string_lossy().into_owned()),
+-            ..Default::default()
+-        })
+-        .await
+-        .expect("send newConversation");
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation resp");
+-    let NewConversationResponse {
+-        conversation_id, ..
+-    } = to_response::<NewConversationResponse>(new_conv_resp)
+-        .expect("deserialize newConversation response");
+-
+-    // 2) addConversationListener
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await
+-        .expect("send addConversationListener");
+-    let _: AddConversationSubscriptionResponse =
+-        to_response::<AddConversationSubscriptionResponse>(
+-            timeout(
+-                DEFAULT_READ_TIMEOUT,
+-                mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-            )
+-            .await
+-            .expect("addConversationListener timeout")
+-            .expect("addConversationListener resp"),
+-        )
+-        .expect("deserialize addConversationListener response");
+-
+-    // 3) sendUserMessage triggers a shell call; approval policy is Untrusted so we should get an elicitation
+-    let send_user_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id,
+-            items: vec![codex_app_server_protocol::InputItem::Text {
+-                text: "run python".to_string(),
+-            }],
+-        })
+-        .await
+-        .expect("send sendUserMessage");
+-    let _send_user_resp: SendUserMessageResponse = to_response::<SendUserMessageResponse>(
+-        timeout(
+-            DEFAULT_READ_TIMEOUT,
+-            mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
+-        )
+-        .await
+-        .expect("sendUserMessage timeout")
+-        .expect("sendUserMessage resp"),
+-    )
+-    .expect("deserialize sendUserMessage response");
+-
+-    // Expect an ExecCommandApproval request (elicitation)
+-    let request = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_request_message(),
+-    )
+-    .await
+-    .expect("waiting for exec approval request timeout")
+-    .expect("exec approval request");
+-    let ServerRequest::ExecCommandApproval { request_id, params } = request else {
+-        panic!("expected ExecCommandApproval request, got: {request:?}");
+-    };
+-
+-    assert_eq!(
+-        ExecCommandApprovalParams {
+-            conversation_id,
+-            call_id: "call1".to_string(),
+-            command: vec![
+-                "python3".to_string(),
+-                "-c".to_string(),
+-                "print(42)".to_string(),
+-            ],
+-            cwd: working_directory.clone(),
+-            reason: None,
+-        },
+-        params
+-    );
+-
+-    // Approve so the first turn can complete
+-    mcp.send_response(
+-        request_id,
+-        serde_json::json!({ "decision": codex_core::protocol::ReviewDecision::Approved }),
+-    )
+-    .await
+-    .expect("send approval response");
+-
+-    // Wait for first TaskComplete
+-    let _ = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_complete 1 timeout")
+-    .expect("task_complete 1 notification");
+-
+-    // 4) sendUserTurn with approval_policy=never should run without elicitation
+-    let send_turn_id = mcp
+-        .send_send_user_turn_request(SendUserTurnParams {
+-            conversation_id,
+-            items: vec![codex_app_server_protocol::InputItem::Text {
+-                text: "run python again".to_string(),
+-            }],
+-            cwd: working_directory.clone(),
+-            approval_policy: AskForApproval::Never,
+-            sandbox_policy: SandboxPolicy::new_read_only_policy(),
+-            model: "mock-model".to_string(),
+-            effort: Some(ReasoningEffort::Medium),
+-            summary: ReasoningSummary::Auto,
+-        })
+-        .await
+-        .expect("send sendUserTurn");
+-    // Acknowledge sendUserTurn
+-    let _send_turn_resp: SendUserTurnResponse = to_response::<SendUserTurnResponse>(
+-        timeout(
+-            DEFAULT_READ_TIMEOUT,
+-            mcp.read_stream_until_response_message(RequestId::Integer(send_turn_id)),
+-        )
+-        .await
+-        .expect("sendUserTurn timeout")
+-        .expect("sendUserTurn resp"),
+-    )
+-    .expect("deserialize sendUserTurn response");
+-
+-    // Ensure we do NOT receive an ExecCommandApproval request before the task completes.
+-    // If any Request is seen while waiting for task_complete, the helper will error and the test fails.
+-    let _ = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_complete 2 timeout")
+-    .expect("task_complete 2 notification");
+-}
+-
+-// Helper: minimal config.toml pointing at mock provider.
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
+-async fn test_send_user_turn_updates_sandbox_and_cwd_between_turns() {
+-    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
+-        println!(
+-            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
+-        );
+-        return;
+-    }
+-
+-    let tmp = TempDir::new().expect("tmp dir");
+-    let codex_home = tmp.path().join("codex_home");
+-    std::fs::create_dir(&codex_home).expect("create codex home dir");
+-    let workspace_root = tmp.path().join("workspace");
+-    std::fs::create_dir(&workspace_root).expect("create workspace root");
+-    let first_cwd = workspace_root.join("turn1");
+-    let second_cwd = workspace_root.join("turn2");
+-    std::fs::create_dir(&first_cwd).expect("create first cwd");
+-    std::fs::create_dir(&second_cwd).expect("create second cwd");
+-
+-    let responses = vec![
+-        create_shell_sse_response(
+-            vec![
+-                "bash".to_string(),
+-                "-lc".to_string(),
+-                "echo first turn".to_string(),
+-            ],
+-            None,
+-            Some(5000),
+-            "call-first",
+-        )
+-        .expect("create first shell response"),
+-        create_final_assistant_message_sse_response("done first")
+-            .expect("create first final assistant message"),
+-        create_shell_sse_response(
+-            vec![
+-                "bash".to_string(),
+-                "-lc".to_string(),
+-                "echo second turn".to_string(),
+-            ],
+-            None,
+-            Some(5000),
+-            "call-second",
+-        )
+-        .expect("create second shell response"),
+-        create_final_assistant_message_sse_response("done second")
+-            .expect("create second final assistant message"),
+-    ];
+-    let server = create_mock_chat_completions_server(responses).await;
+-    create_config_toml(&codex_home, &server.uri()).expect("write config");
+-
+-    let mut mcp = McpProcess::new(&codex_home)
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            cwd: Some(first_cwd.to_string_lossy().into_owned()),
+-            approval_policy: Some(AskForApproval::Never),
+-            sandbox: Some(SandboxMode::WorkspaceWrite),
+-            ..Default::default()
+-        })
+-        .await
+-        .expect("send newConversation");
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation resp");
+-    let NewConversationResponse {
+-        conversation_id,
+-        model,
+-        ..
+-    } = to_response::<NewConversationResponse>(new_conv_resp)
+-        .expect("deserialize newConversation response");
+-
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await
+-        .expect("send addConversationListener");
+-    timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-    )
+-    .await
+-    .expect("addConversationListener timeout")
+-    .expect("addConversationListener resp");
+-
+-    let first_turn_id = mcp
+-        .send_send_user_turn_request(SendUserTurnParams {
+-            conversation_id,
+-            items: vec![InputItem::Text {
+-                text: "first turn".to_string(),
+-            }],
+-            cwd: first_cwd.clone(),
+-            approval_policy: AskForApproval::Never,
+-            sandbox_policy: SandboxPolicy::WorkspaceWrite {
+-                writable_roots: vec![first_cwd.clone()],
+-                network_access: false,
+-                exclude_tmpdir_env_var: false,
+-                exclude_slash_tmp: false,
+-            },
+-            model: model.clone(),
+-            effort: Some(ReasoningEffort::Medium),
+-            summary: ReasoningSummary::Auto,
+-        })
+-        .await
+-        .expect("send first sendUserTurn");
+-    timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(first_turn_id)),
+-    )
+-    .await
+-    .expect("sendUserTurn 1 timeout")
+-    .expect("sendUserTurn 1 resp");
+-    timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_complete 1 timeout")
+-    .expect("task_complete 1 notification");
+-
+-    let second_turn_id = mcp
+-        .send_send_user_turn_request(SendUserTurnParams {
+-            conversation_id,
+-            items: vec![InputItem::Text {
+-                text: "second turn".to_string(),
+-            }],
+-            cwd: second_cwd.clone(),
+-            approval_policy: AskForApproval::Never,
+-            sandbox_policy: SandboxPolicy::DangerFullAccess,
+-            model: model.clone(),
+-            effort: Some(ReasoningEffort::Medium),
+-            summary: ReasoningSummary::Auto,
+-        })
+-        .await
+-        .expect("send second sendUserTurn");
+-    timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(second_turn_id)),
+-    )
+-    .await
+-    .expect("sendUserTurn 2 timeout")
+-    .expect("sendUserTurn 2 resp");
+-
+-    let mut env_message: Option<String> = None;
+-    let second_cwd_str = second_cwd.to_string_lossy().into_owned();
+-    for _ in 0..10 {
+-        let notification = timeout(
+-            DEFAULT_READ_TIMEOUT,
+-            mcp.read_stream_until_notification_message("codex/event/user_message"),
+-        )
+-        .await
+-        .expect("user_message timeout")
+-        .expect("user_message notification");
+-        let params = notification
+-            .params
+-            .clone()
+-            .expect("user_message should include params");
+-        let event: Event = serde_json::from_value(params).expect("deserialize user_message event");
+-        if let EventMsg::UserMessage(user) = event.msg
+-            && matches!(user.kind, Some(InputMessageKind::EnvironmentContext))
+-            && user.message.contains(&second_cwd_str)
+-        {
+-            env_message = Some(user.message);
+-            break;
+-        }
+-    }
+-    let env_message = env_message.expect("expected environment context update");
+-    assert!(
+-        env_message.contains("<sandbox_mode>danger-full-access</sandbox_mode>"),
+-        "env context should reflect new sandbox mode: {env_message}"
+-    );
+-    assert!(
+-        env_message.contains("<network_access>enabled</network_access>"),
+-        "env context should enable network access for danger-full-access policy: {env_message}"
+-    );
+-    assert!(
+-        env_message.contains(&second_cwd_str),
+-        "env context should include updated cwd: {env_message}"
+-    );
+-
+-    let exec_begin_notification = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/exec_command_begin"),
+-    )
+-    .await
+-    .expect("exec_command_begin timeout")
+-    .expect("exec_command_begin notification");
+-    let params = exec_begin_notification
+-        .params
+-        .clone()
+-        .expect("exec_command_begin params");
+-    let event: Event = serde_json::from_value(params).expect("deserialize exec begin event");
+-    let exec_begin = match event.msg {
+-        EventMsg::ExecCommandBegin(exec_begin) => exec_begin,
+-        other => panic!("expected ExecCommandBegin event, got {other:?}"),
+-    };
+-    assert_eq!(
+-        exec_begin.cwd, second_cwd,
+-        "exec turn should run from updated cwd"
+-    );
+-    assert_eq!(
+-        exec_begin.command,
+-        vec![
+-            "bash".to_string(),
+-            "-lc".to_string(),
+-            "echo second turn".to_string()
+-        ],
+-        "exec turn should run expected command"
+-    );
+-
+-    timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_complete 2 timeout")
+-    .expect("task_complete 2 notification");
+-}
+-
+-fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        format!(
+-            r#"
+-model = "mock-model"
+-approval_policy = "untrusted"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "{server_uri}/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-"#
+-        ),
+-    )
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::create_final_assistant_message_sse_response;
++use app_test_support::create_mock_chat_completions_server;
++use app_test_support::create_shell_sse_response;
++use app_test_support::to_response;
++use codex_app_server_protocol::AddConversationListenerParams;
++use codex_app_server_protocol::AddConversationSubscriptionResponse;
++use codex_app_server_protocol::ExecCommandApprovalParams;
++use codex_app_server_protocol::InputItem;
++use codex_app_server_protocol::JSONRPCNotification;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::NewConversationParams;
++use codex_app_server_protocol::NewConversationResponse;
++use codex_app_server_protocol::RemoveConversationListenerParams;
++use codex_app_server_protocol::RemoveConversationSubscriptionResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SendUserMessageParams;
++use codex_app_server_protocol::SendUserMessageResponse;
++use codex_app_server_protocol::SendUserTurnParams;
++use codex_app_server_protocol::SendUserTurnResponse;
++use codex_app_server_protocol::ServerRequest;
++use codex_core::protocol::AskForApproval;
++use codex_core::protocol::SandboxPolicy;
++use codex_core::protocol_config_types::ReasoningEffort;
++use codex_core::protocol_config_types::ReasoningSummary;
++use codex_core::spawn::CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR;
++use codex_protocol::config_types::SandboxMode;
++use codex_protocol::protocol::Event;
++use codex_protocol::protocol::EventMsg;
++use codex_protocol::protocol::InputMessageKind;
++use pretty_assertions::assert_eq;
++use std::env;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
++async fn test_codex_jsonrpc_conversation_flow() {
++    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
++        println!(
++            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
++        );
++        return;
++    }
++
++    let tmp = TempDir::new().expect("tmp dir");
++    // Temporary Codex home with config pointing at the mock server.
++    let codex_home = tmp.path().join("codex_home");
++    std::fs::create_dir(&codex_home).expect("create codex home dir");
++    let working_directory = tmp.path().join("workdir");
++    std::fs::create_dir(&working_directory).expect("create working directory");
++
++    // Create a mock model server that immediately ends each turn.
++    // Two turns are expected: initial session configure + one user message.
++    let responses = vec![
++        create_shell_sse_response(
++            vec!["ls".to_string()],
++            Some(&working_directory),
++            Some(5000),
++            "call1234",
++        )
++        .expect("create shell sse response"),
++        create_final_assistant_message_sse_response("Enjoy your new git repo!")
++            .expect("create final assistant message"),
++    ];
++    let server = create_mock_chat_completions_server(responses).await;
++    create_config_toml(&codex_home, &server.uri()).expect("write config");
++
++    // Start MCP server and initialize.
++    let mut mcp = McpProcess::new(&codex_home).await.expect("spawn mcp");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init error");
++
++    // 1) newConversation
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            cwd: Some(working_directory.to_string_lossy().into_owned()),
++            ..Default::default()
++        })
++        .await
++        .expect("send newConversation");
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation resp");
++    let new_conv_resp = to_response::<NewConversationResponse>(new_conv_resp)
++        .expect("deserialize newConversation response");
++    let NewConversationResponse {
++        conversation_id,
++        model,
++        reasoning_effort: _,
++        rollout_path: _,
++    } = new_conv_resp;
++    assert_eq!(model, "mock-model");
++
++    // 2) addConversationListener
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await
++        .expect("send addConversationListener");
++    let add_listener_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++    )
++    .await
++    .expect("addConversationListener timeout")
++    .expect("addConversationListener resp");
++    let AddConversationSubscriptionResponse { subscription_id } =
++        to_response::<AddConversationSubscriptionResponse>(add_listener_resp)
++            .expect("deserialize addConversationListener response");
++
++    // 3) sendUserMessage (should trigger notifications; we only validate an OK response)
++    let send_user_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id,
++            items: vec![codex_app_server_protocol::InputItem::Text {
++                text: "text".to_string(),
++            }],
++        })
++        .await
++        .expect("send sendUserMessage");
++    let send_user_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
++    )
++    .await
++    .expect("sendUserMessage timeout")
++    .expect("sendUserMessage resp");
++    let SendUserMessageResponse {} = to_response::<SendUserMessageResponse>(send_user_resp)
++        .expect("deserialize sendUserMessage response");
++
++    // Verify the task_finished notification is received.
++    // Note this also ensures that the final request to the server was made.
++    let task_finished_notification: JSONRPCNotification = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_finished_notification timeout")
++    .expect("task_finished_notification resp");
++    let serde_json::Value::Object(map) = task_finished_notification
++        .params
++        .expect("notification should have params")
++    else {
++        panic!("task_finished_notification should have params");
++    };
++    assert_eq!(
++        map.get("conversationId")
++            .expect("should have conversationId"),
++        &serde_json::Value::String(conversation_id.to_string())
++    );
++
++    // 4) removeConversationListener
++    let remove_listener_id = mcp
++        .send_remove_conversation_listener_request(RemoveConversationListenerParams {
++            subscription_id,
++        })
++        .await
++        .expect("send removeConversationListener");
++    let remove_listener_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(remove_listener_id)),
++    )
++    .await
++    .expect("removeConversationListener timeout")
++    .expect("removeConversationListener resp");
++    let RemoveConversationSubscriptionResponse {} =
++        to_response(remove_listener_resp).expect("deserialize removeConversationListener response");
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
++async fn test_send_user_turn_changes_approval_policy_behavior() {
++    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
++        println!(
++            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
++        );
++        return;
++    }
++
++    let tmp = TempDir::new().expect("tmp dir");
++    let codex_home = tmp.path().join("codex_home");
++    std::fs::create_dir(&codex_home).expect("create codex home dir");
++    let working_directory = tmp.path().join("workdir");
++    std::fs::create_dir(&working_directory).expect("create working directory");
++
++    // Mock server will request a python shell call for the first and second turn, then finish.
++    let responses = vec![
++        create_shell_sse_response(
++            vec![
++                "python3".to_string(),
++                "-c".to_string(),
++                "print(42)".to_string(),
++            ],
++            Some(&working_directory),
++            Some(5000),
++            "call1",
++        )
++        .expect("create first shell sse response"),
++        create_final_assistant_message_sse_response("done 1")
++            .expect("create final assistant message 1"),
++        create_shell_sse_response(
++            vec![
++                "python3".to_string(),
++                "-c".to_string(),
++                "print(42)".to_string(),
++            ],
++            Some(&working_directory),
++            Some(5000),
++            "call2",
++        )
++        .expect("create second shell sse response"),
++        create_final_assistant_message_sse_response("done 2")
++            .expect("create final assistant message 2"),
++    ];
++    let server = create_mock_chat_completions_server(responses).await;
++    create_config_toml(&codex_home, &server.uri()).expect("write config");
++
++    // Start MCP server and initialize.
++    let mut mcp = McpProcess::new(&codex_home).await.expect("spawn mcp");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init error");
++
++    // 1) Start conversation with approval_policy=untrusted
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            cwd: Some(working_directory.to_string_lossy().into_owned()),
++            ..Default::default()
++        })
++        .await
++        .expect("send newConversation");
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation resp");
++    let NewConversationResponse {
++        conversation_id, ..
++    } = to_response::<NewConversationResponse>(new_conv_resp)
++        .expect("deserialize newConversation response");
++
++    // 2) addConversationListener
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await
++        .expect("send addConversationListener");
++    let _: AddConversationSubscriptionResponse =
++        to_response::<AddConversationSubscriptionResponse>(
++            timeout(
++                DEFAULT_READ_TIMEOUT,
++                mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++            )
++            .await
++            .expect("addConversationListener timeout")
++            .expect("addConversationListener resp"),
++        )
++        .expect("deserialize addConversationListener response");
++
++    // 3) sendUserMessage triggers a shell call; approval policy is Untrusted so we should get an elicitation
++    let send_user_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id,
++            items: vec![codex_app_server_protocol::InputItem::Text {
++                text: "run python".to_string(),
++            }],
++        })
++        .await
++        .expect("send sendUserMessage");
++    let _send_user_resp: SendUserMessageResponse = to_response::<SendUserMessageResponse>(
++        timeout(
++            DEFAULT_READ_TIMEOUT,
++            mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
++        )
++        .await
++        .expect("sendUserMessage timeout")
++        .expect("sendUserMessage resp"),
++    )
++    .expect("deserialize sendUserMessage response");
++
++    // Expect an ExecCommandApproval request (elicitation)
++    let request = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_request_message(),
++    )
++    .await
++    .expect("waiting for exec approval request timeout")
++    .expect("exec approval request");
++    let ServerRequest::ExecCommandApproval { request_id, params } = request else {
++        panic!("expected ExecCommandApproval request, got: {request:?}");
++    };
++
++    assert_eq!(
++        ExecCommandApprovalParams {
++            conversation_id,
++            call_id: "call1".to_string(),
++            command: vec![
++                "python3".to_string(),
++                "-c".to_string(),
++                "print(42)".to_string(),
++            ],
++            cwd: working_directory.clone(),
++            reason: None,
++        },
++        params
++    );
++
++    // Approve so the first turn can complete
++    mcp.send_response(
++        request_id,
++        serde_json::json!({ "decision": codex_core::protocol::ReviewDecision::Approved }),
++    )
++    .await
++    .expect("send approval response");
++
++    // Wait for first TaskComplete
++    let _ = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_complete 1 timeout")
++    .expect("task_complete 1 notification");
++
++    // 4) sendUserTurn with approval_policy=never should run without elicitation
++    let send_turn_id = mcp
++        .send_send_user_turn_request(SendUserTurnParams {
++            conversation_id,
++            items: vec![codex_app_server_protocol::InputItem::Text {
++                text: "run python again".to_string(),
++            }],
++            cwd: working_directory.clone(),
++            approval_policy: AskForApproval::Never,
++            sandbox_policy: SandboxPolicy::new_read_only_policy(),
++            model: "mock-model".to_string(),
++            effort: Some(ReasoningEffort::Medium),
++            summary: ReasoningSummary::Auto,
++        })
++        .await
++        .expect("send sendUserTurn");
++    // Acknowledge sendUserTurn
++    let _send_turn_resp: SendUserTurnResponse = to_response::<SendUserTurnResponse>(
++        timeout(
++            DEFAULT_READ_TIMEOUT,
++            mcp.read_stream_until_response_message(RequestId::Integer(send_turn_id)),
++        )
++        .await
++        .expect("sendUserTurn timeout")
++        .expect("sendUserTurn resp"),
++    )
++    .expect("deserialize sendUserTurn response");
++
++    // Ensure we do NOT receive an ExecCommandApproval request before the task completes.
++    // If any Request is seen while waiting for task_complete, the helper will error and the test fails.
++    let _ = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_complete 2 timeout")
++    .expect("task_complete 2 notification");
++}
++
++// Helper: minimal config.toml pointing at mock provider.
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
++async fn test_send_user_turn_updates_sandbox_and_cwd_between_turns() {
++    if env::var(CODEX_SANDBOX_NETWORK_DISABLED_ENV_VAR).is_ok() {
++        println!(
++            "Skipping test because it cannot execute when network is disabled in a Codex sandbox."
++        );
++        return;
++    }
++
++    let tmp = TempDir::new().expect("tmp dir");
++    let codex_home = tmp.path().join("codex_home");
++    std::fs::create_dir(&codex_home).expect("create codex home dir");
++    let workspace_root = tmp.path().join("workspace");
++    std::fs::create_dir(&workspace_root).expect("create workspace root");
++    let first_cwd = workspace_root.join("turn1");
++    let second_cwd = workspace_root.join("turn2");
++    std::fs::create_dir(&first_cwd).expect("create first cwd");
++    std::fs::create_dir(&second_cwd).expect("create second cwd");
++
++    let responses = vec![
++        create_shell_sse_response(
++            vec![
++                "bash".to_string(),
++                "-lc".to_string(),
++                "echo first turn".to_string(),
++            ],
++            None,
++            Some(5000),
++            "call-first",
++        )
++        .expect("create first shell response"),
++        create_final_assistant_message_sse_response("done first")
++            .expect("create first final assistant message"),
++        create_shell_sse_response(
++            vec![
++                "bash".to_string(),
++                "-lc".to_string(),
++                "echo second turn".to_string(),
++            ],
++            None,
++            Some(5000),
++            "call-second",
++        )
++        .expect("create second shell response"),
++        create_final_assistant_message_sse_response("done second")
++            .expect("create second final assistant message"),
++    ];
++    let server = create_mock_chat_completions_server(responses).await;
++    create_config_toml(&codex_home, &server.uri()).expect("write config");
++
++    let mut mcp = McpProcess::new(&codex_home)
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            cwd: Some(first_cwd.to_string_lossy().into_owned()),
++            approval_policy: Some(AskForApproval::Never),
++            sandbox: Some(SandboxMode::WorkspaceWrite),
++            ..Default::default()
++        })
++        .await
++        .expect("send newConversation");
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation resp");
++    let NewConversationResponse {
++        conversation_id,
++        model,
++        ..
++    } = to_response::<NewConversationResponse>(new_conv_resp)
++        .expect("deserialize newConversation response");
++
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await
++        .expect("send addConversationListener");
++    timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++    )
++    .await
++    .expect("addConversationListener timeout")
++    .expect("addConversationListener resp");
++
++    let first_turn_id = mcp
++        .send_send_user_turn_request(SendUserTurnParams {
++            conversation_id,
++            items: vec![InputItem::Text {
++                text: "first turn".to_string(),
++            }],
++            cwd: first_cwd.clone(),
++            approval_policy: AskForApproval::Never,
++            sandbox_policy: SandboxPolicy::WorkspaceWrite {
++                writable_roots: vec![first_cwd.clone()],
++                network_access: false,
++                exclude_tmpdir_env_var: false,
++                exclude_slash_tmp: false,
++            },
++            model: model.clone(),
++            effort: Some(ReasoningEffort::Medium),
++            summary: ReasoningSummary::Auto,
++        })
++        .await
++        .expect("send first sendUserTurn");
++    timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(first_turn_id)),
++    )
++    .await
++    .expect("sendUserTurn 1 timeout")
++    .expect("sendUserTurn 1 resp");
++    timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_complete 1 timeout")
++    .expect("task_complete 1 notification");
++
++    let second_turn_id = mcp
++        .send_send_user_turn_request(SendUserTurnParams {
++            conversation_id,
++            items: vec![InputItem::Text {
++                text: "second turn".to_string(),
++            }],
++            cwd: second_cwd.clone(),
++            approval_policy: AskForApproval::Never,
++            sandbox_policy: SandboxPolicy::DangerFullAccess,
++            model: model.clone(),
++            effort: Some(ReasoningEffort::Medium),
++            summary: ReasoningSummary::Auto,
++        })
++        .await
++        .expect("send second sendUserTurn");
++    timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(second_turn_id)),
++    )
++    .await
++    .expect("sendUserTurn 2 timeout")
++    .expect("sendUserTurn 2 resp");
++
++    let mut env_message: Option<String> = None;
++    let second_cwd_str = second_cwd.to_string_lossy().into_owned();
++    for _ in 0..10 {
++        let notification = timeout(
++            DEFAULT_READ_TIMEOUT,
++            mcp.read_stream_until_notification_message("codex/event/user_message"),
++        )
++        .await
++        .expect("user_message timeout")
++        .expect("user_message notification");
++        let params = notification
++            .params
++            .clone()
++            .expect("user_message should include params");
++        let event: Event = serde_json::from_value(params).expect("deserialize user_message event");
++        if let EventMsg::UserMessage(user) = event.msg
++            && matches!(user.kind, Some(InputMessageKind::EnvironmentContext))
++            && user.message.contains(&second_cwd_str)
++        {
++            env_message = Some(user.message);
++            break;
++        }
++    }
++    let env_message = env_message.expect("expected environment context update");
++    assert!(
++        env_message.contains("<sandbox_mode>danger-full-access</sandbox_mode>"),
++        "env context should reflect new sandbox mode: {env_message}"
++    );
++    assert!(
++        env_message.contains("<network_access>enabled</network_access>"),
++        "env context should enable network access for danger-full-access policy: {env_message}"
++    );
++    assert!(
++        env_message.contains(&second_cwd_str),
++        "env context should include updated cwd: {env_message}"
++    );
++
++    let exec_begin_notification = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/exec_command_begin"),
++    )
++    .await
++    .expect("exec_command_begin timeout")
++    .expect("exec_command_begin notification");
++    let params = exec_begin_notification
++        .params
++        .clone()
++        .expect("exec_command_begin params");
++    let event: Event = serde_json::from_value(params).expect("deserialize exec begin event");
++    let exec_begin = match event.msg {
++        EventMsg::ExecCommandBegin(exec_begin) => exec_begin,
++        other => panic!("expected ExecCommandBegin event, got {other:?}"),
++    };
++    assert_eq!(
++        exec_begin.cwd, second_cwd,
++        "exec turn should run from updated cwd"
++    );
++    assert_eq!(
++        exec_begin.command,
++        vec![
++            "bash".to_string(),
++            "-lc".to_string(),
++            "echo second turn".to_string()
++        ],
++        "exec turn should run expected command"
++    );
++
++    timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_complete 2 timeout")
++    .expect("task_complete 2 notification");
++}
++
++fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        format!(
++            r#"
++model = "mock-model"
++approval_policy = "untrusted"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "{server_uri}/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++"#
++        ),
++    )
++}
+diff --git a/codex-rs/app-server/tests/suite/config.rs b/codex-rs/app-server/tests/suite/config.rs
+index 577eeb38..460c1abe 100644
+--- a/codex-rs/app-server/tests/suite/config.rs
++++ b/codex-rs/app-server/tests/suite/config.rs
+@@ -1,163 +1,163 @@
+-use std::collections::HashMap;
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::GetUserSavedConfigResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::Profile;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SandboxSettings;
+-use codex_app_server_protocol::Tools;
+-use codex_app_server_protocol::UserSavedConfig;
+-use codex_core::protocol::AskForApproval;
+-use codex_protocol::config_types::ReasoningEffort;
+-use codex_protocol::config_types::ReasoningSummary;
+-use codex_protocol::config_types::SandboxMode;
+-use codex_protocol::config_types::Verbosity;
+-use pretty_assertions::assert_eq;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        r#"
+-model = "gpt-5-codex"
+-approval_policy = "on-request"
+-sandbox_mode = "workspace-write"
+-model_reasoning_summary = "detailed"
+-model_reasoning_effort = "high"
+-model_verbosity = "medium"
+-profile = "test"
+-
+-[sandbox_workspace_write]
+-writable_roots = ["/tmp"]
+-network_access = true
+-exclude_tmpdir_env_var = true
+-exclude_slash_tmp = true
+-
+-[tools]
+-web_search = false
+-view_image = true
+-
+-[profiles.test]
+-model = "gpt-4o"
+-approval_policy = "on-request"
+-model_reasoning_effort = "high"
+-model_reasoning_summary = "detailed"
+-model_verbosity = "medium"
+-model_provider = "openai"
+-chatgpt_base_url = "https://api.chatgpt.com"
+-"#,
+-    )
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
+-async fn get_config_toml_parses_all_fields() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).expect("write config.toml");
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let request_id = mcp
+-        .send_get_user_saved_config_request()
+-        .await
+-        .expect("send getUserSavedConfig");
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getUserSavedConfig timeout")
+-    .expect("getUserSavedConfig response");
+-
+-    let config: GetUserSavedConfigResponse = to_response(resp).expect("deserialize config");
+-    let expected = GetUserSavedConfigResponse {
+-        config: UserSavedConfig {
+-            approval_policy: Some(AskForApproval::OnRequest),
+-            sandbox_mode: Some(SandboxMode::WorkspaceWrite),
+-            sandbox_settings: Some(SandboxSettings {
+-                writable_roots: vec!["/tmp".into()],
+-                network_access: Some(true),
+-                exclude_tmpdir_env_var: Some(true),
+-                exclude_slash_tmp: Some(true),
+-            }),
+-            model: Some("gpt-5-codex".into()),
+-            model_reasoning_effort: Some(ReasoningEffort::High),
+-            model_reasoning_summary: Some(ReasoningSummary::Detailed),
+-            model_verbosity: Some(Verbosity::Medium),
+-            tools: Some(Tools {
+-                web_search: Some(false),
+-                view_image: Some(true),
+-            }),
+-            profile: Some("test".to_string()),
+-            profiles: HashMap::from([(
+-                "test".into(),
+-                Profile {
+-                    model: Some("gpt-4o".into()),
+-                    approval_policy: Some(AskForApproval::OnRequest),
+-                    model_reasoning_effort: Some(ReasoningEffort::High),
+-                    model_reasoning_summary: Some(ReasoningSummary::Detailed),
+-                    model_verbosity: Some(Verbosity::Medium),
+-                    model_provider: Some("openai".into()),
+-                    chatgpt_base_url: Some("https://api.chatgpt.com".into()),
+-                },
+-            )]),
+-        },
+-    };
+-
+-    assert_eq!(config, expected);
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_config_toml_empty() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let request_id = mcp
+-        .send_get_user_saved_config_request()
+-        .await
+-        .expect("send getUserSavedConfig");
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getUserSavedConfig timeout")
+-    .expect("getUserSavedConfig response");
+-
+-    let config: GetUserSavedConfigResponse = to_response(resp).expect("deserialize config");
+-    let expected = GetUserSavedConfigResponse {
+-        config: UserSavedConfig {
+-            approval_policy: None,
+-            sandbox_mode: None,
+-            sandbox_settings: None,
+-            model: None,
+-            model_reasoning_effort: None,
+-            model_reasoning_summary: None,
+-            model_verbosity: None,
+-            tools: None,
+-            profile: None,
+-            profiles: HashMap::new(),
+-        },
+-    };
+-
+-    assert_eq!(config, expected);
+-}
++use std::collections::HashMap;
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::GetUserSavedConfigResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::Profile;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SandboxSettings;
++use codex_app_server_protocol::Tools;
++use codex_app_server_protocol::UserSavedConfig;
++use codex_core::protocol::AskForApproval;
++use codex_protocol::config_types::ReasoningEffort;
++use codex_protocol::config_types::ReasoningSummary;
++use codex_protocol::config_types::SandboxMode;
++use codex_protocol::config_types::Verbosity;
++use pretty_assertions::assert_eq;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        r#"
++model = "gpt-5-codex"
++approval_policy = "on-request"
++sandbox_mode = "workspace-write"
++model_reasoning_summary = "detailed"
++model_reasoning_effort = "high"
++model_verbosity = "medium"
++profile = "test"
++
++[sandbox_workspace_write]
++writable_roots = ["/tmp"]
++network_access = true
++exclude_tmpdir_env_var = true
++exclude_slash_tmp = true
++
++[tools]
++web_search = false
++view_image = true
++
++[profiles.test]
++model = "gpt-4o"
++approval_policy = "on-request"
++model_reasoning_effort = "high"
++model_reasoning_summary = "detailed"
++model_verbosity = "medium"
++model_provider = "openai"
++chatgpt_base_url = "https://api.chatgpt.com"
++"#,
++    )
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
++async fn get_config_toml_parses_all_fields() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).expect("write config.toml");
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let request_id = mcp
++        .send_get_user_saved_config_request()
++        .await
++        .expect("send getUserSavedConfig");
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getUserSavedConfig timeout")
++    .expect("getUserSavedConfig response");
++
++    let config: GetUserSavedConfigResponse = to_response(resp).expect("deserialize config");
++    let expected = GetUserSavedConfigResponse {
++        config: UserSavedConfig {
++            approval_policy: Some(AskForApproval::OnRequest),
++            sandbox_mode: Some(SandboxMode::WorkspaceWrite),
++            sandbox_settings: Some(SandboxSettings {
++                writable_roots: vec!["/tmp".into()],
++                network_access: Some(true),
++                exclude_tmpdir_env_var: Some(true),
++                exclude_slash_tmp: Some(true),
++            }),
++            model: Some("gpt-5-codex".into()),
++            model_reasoning_effort: Some(ReasoningEffort::High),
++            model_reasoning_summary: Some(ReasoningSummary::Detailed),
++            model_verbosity: Some(Verbosity::Medium),
++            tools: Some(Tools {
++                web_search: Some(false),
++                view_image: Some(true),
++            }),
++            profile: Some("test".to_string()),
++            profiles: HashMap::from([(
++                "test".into(),
++                Profile {
++                    model: Some("gpt-4o".into()),
++                    approval_policy: Some(AskForApproval::OnRequest),
++                    model_reasoning_effort: Some(ReasoningEffort::High),
++                    model_reasoning_summary: Some(ReasoningSummary::Detailed),
++                    model_verbosity: Some(Verbosity::Medium),
++                    model_provider: Some("openai".into()),
++                    chatgpt_base_url: Some("https://api.chatgpt.com".into()),
++                },
++            )]),
++        },
++    };
++
++    assert_eq!(config, expected);
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_config_toml_empty() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let request_id = mcp
++        .send_get_user_saved_config_request()
++        .await
++        .expect("send getUserSavedConfig");
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getUserSavedConfig timeout")
++    .expect("getUserSavedConfig response");
++
++    let config: GetUserSavedConfigResponse = to_response(resp).expect("deserialize config");
++    let expected = GetUserSavedConfigResponse {
++        config: UserSavedConfig {
++            approval_policy: None,
++            sandbox_mode: None,
++            sandbox_settings: None,
++            model: None,
++            model_reasoning_effort: None,
++            model_reasoning_summary: None,
++            model_verbosity: None,
++            tools: None,
++            profile: None,
++            profiles: HashMap::new(),
++        },
++    };
++
++    assert_eq!(config, expected);
++}
+diff --git a/codex-rs/app-server/tests/suite/create_conversation.rs b/codex-rs/app-server/tests/suite/create_conversation.rs
+index 37a0db84..35a3c588 100644
+--- a/codex-rs/app-server/tests/suite/create_conversation.rs
++++ b/codex-rs/app-server/tests/suite/create_conversation.rs
+@@ -1,157 +1,157 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::create_final_assistant_message_sse_response;
+-use app_test_support::create_mock_chat_completions_server;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::AddConversationListenerParams;
+-use codex_app_server_protocol::AddConversationSubscriptionResponse;
+-use codex_app_server_protocol::InputItem;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::NewConversationParams;
+-use codex_app_server_protocol::NewConversationResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SendUserMessageParams;
+-use codex_app_server_protocol::SendUserMessageResponse;
+-use pretty_assertions::assert_eq;
+-use serde_json::json;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn test_conversation_create_and_send_message_ok() {
+-    // Mock server – we won't strictly rely on it, but provide one to satisfy any model wiring.
+-    let responses = vec![
+-        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
+-    ];
+-    let server = create_mock_chat_completions_server(responses).await;
+-
+-    // Temporary Codex home with config pointing at the mock server.
+-    let codex_home = TempDir::new().expect("create temp dir");
+-    create_config_toml(codex_home.path(), &server.uri()).expect("write config.toml");
+-
+-    // Start MCP server process and initialize.
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    // Create a conversation via the new JSON-RPC API.
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            model: Some("o3".to_string()),
+-            ..Default::default()
+-        })
+-        .await
+-        .expect("send newConversation");
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation resp");
+-    let NewConversationResponse {
+-        conversation_id,
+-        model,
+-        reasoning_effort: _,
+-        rollout_path: _,
+-    } = to_response::<NewConversationResponse>(new_conv_resp)
+-        .expect("deserialize newConversation response");
+-    assert_eq!(model, "o3");
+-
+-    // Add a listener so we receive notifications for this conversation (not strictly required for this test).
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await
+-        .expect("send addConversationListener");
+-    let _sub: AddConversationSubscriptionResponse =
+-        to_response::<AddConversationSubscriptionResponse>(
+-            timeout(
+-                DEFAULT_READ_TIMEOUT,
+-                mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-            )
+-            .await
+-            .expect("addConversationListener timeout")
+-            .expect("addConversationListener resp"),
+-        )
+-        .expect("deserialize addConversationListener response");
+-
+-    // Now send a user message via the wire API and expect an OK (empty object) result.
+-    let send_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id,
+-            items: vec![InputItem::Text {
+-                text: "Hello".to_string(),
+-            }],
+-        })
+-        .await
+-        .expect("send sendUserMessage");
+-    let send_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(send_id)),
+-    )
+-    .await
+-    .expect("sendUserMessage timeout")
+-    .expect("sendUserMessage resp");
+-    let _ok: SendUserMessageResponse = to_response::<SendUserMessageResponse>(send_resp)
+-        .expect("deserialize sendUserMessage response");
+-
+-    // avoid race condition by waiting for the mock server to receive the chat.completions request
+-    let deadline = std::time::Instant::now() + DEFAULT_READ_TIMEOUT;
+-    loop {
+-        let requests = server.received_requests().await.unwrap_or_default();
+-        if !requests.is_empty() {
+-            break;
+-        }
+-        if std::time::Instant::now() >= deadline {
+-            panic!("mock server did not receive the chat.completions request in time");
+-        }
+-        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
+-    }
+-
+-    // Verify the outbound request body matches expectations for Chat Completions.
+-    let request = &server.received_requests().await.unwrap()[0];
+-    let body = request
+-        .body_json::<serde_json::Value>()
+-        .expect("parse request body as JSON");
+-    assert_eq!(body["model"], json!("o3"));
+-    assert!(body["stream"].as_bool().unwrap_or(false));
+-    let messages = body["messages"]
+-        .as_array()
+-        .expect("messages should be array");
+-    let last = messages.last().expect("at least one message");
+-    assert_eq!(last["role"], json!("user"));
+-    assert_eq!(last["content"], json!("Hello"));
+-
+-    drop(server);
+-}
+-
+-// Helper to create a config.toml pointing at the mock model server.
+-fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        format!(
+-            r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "{server_uri}/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-"#
+-        ),
+-    )
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::create_final_assistant_message_sse_response;
++use app_test_support::create_mock_chat_completions_server;
++use app_test_support::to_response;
++use codex_app_server_protocol::AddConversationListenerParams;
++use codex_app_server_protocol::AddConversationSubscriptionResponse;
++use codex_app_server_protocol::InputItem;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::NewConversationParams;
++use codex_app_server_protocol::NewConversationResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SendUserMessageParams;
++use codex_app_server_protocol::SendUserMessageResponse;
++use pretty_assertions::assert_eq;
++use serde_json::json;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn test_conversation_create_and_send_message_ok() {
++    // Mock server – we won't strictly rely on it, but provide one to satisfy any model wiring.
++    let responses = vec![
++        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
++    ];
++    let server = create_mock_chat_completions_server(responses).await;
++
++    // Temporary Codex home with config pointing at the mock server.
++    let codex_home = TempDir::new().expect("create temp dir");
++    create_config_toml(codex_home.path(), &server.uri()).expect("write config.toml");
++
++    // Start MCP server process and initialize.
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    // Create a conversation via the new JSON-RPC API.
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            model: Some("o3".to_string()),
++            ..Default::default()
++        })
++        .await
++        .expect("send newConversation");
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation resp");
++    let NewConversationResponse {
++        conversation_id,
++        model,
++        reasoning_effort: _,
++        rollout_path: _,
++    } = to_response::<NewConversationResponse>(new_conv_resp)
++        .expect("deserialize newConversation response");
++    assert_eq!(model, "o3");
++
++    // Add a listener so we receive notifications for this conversation (not strictly required for this test).
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await
++        .expect("send addConversationListener");
++    let _sub: AddConversationSubscriptionResponse =
++        to_response::<AddConversationSubscriptionResponse>(
++            timeout(
++                DEFAULT_READ_TIMEOUT,
++                mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++            )
++            .await
++            .expect("addConversationListener timeout")
++            .expect("addConversationListener resp"),
++        )
++        .expect("deserialize addConversationListener response");
++
++    // Now send a user message via the wire API and expect an OK (empty object) result.
++    let send_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id,
++            items: vec![InputItem::Text {
++                text: "Hello".to_string(),
++            }],
++        })
++        .await
++        .expect("send sendUserMessage");
++    let send_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(send_id)),
++    )
++    .await
++    .expect("sendUserMessage timeout")
++    .expect("sendUserMessage resp");
++    let _ok: SendUserMessageResponse = to_response::<SendUserMessageResponse>(send_resp)
++        .expect("deserialize sendUserMessage response");
++
++    // avoid race condition by waiting for the mock server to receive the chat.completions request
++    let deadline = std::time::Instant::now() + DEFAULT_READ_TIMEOUT;
++    loop {
++        let requests = server.received_requests().await.unwrap_or_default();
++        if !requests.is_empty() {
++            break;
++        }
++        if std::time::Instant::now() >= deadline {
++            panic!("mock server did not receive the chat.completions request in time");
++        }
++        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
++    }
++
++    // Verify the outbound request body matches expectations for Chat Completions.
++    let request = &server.received_requests().await.unwrap()[0];
++    let body = request
++        .body_json::<serde_json::Value>()
++        .expect("parse request body as JSON");
++    assert_eq!(body["model"], json!("o3"));
++    assert!(body["stream"].as_bool().unwrap_or(false));
++    let messages = body["messages"]
++        .as_array()
++        .expect("messages should be array");
++    let last = messages.last().expect("at least one message");
++    assert_eq!(last["role"], json!("user"));
++    assert_eq!(last["content"], json!("Hello"));
++
++    drop(server);
++}
++
++// Helper to create a config.toml pointing at the mock model server.
++fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        format!(
++            r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "{server_uri}/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++"#
++        ),
++    )
++}
+diff --git a/codex-rs/app-server/tests/suite/fuzzy_file_search.rs b/codex-rs/app-server/tests/suite/fuzzy_file_search.rs
+index a2bc974a..c0b75ab5 100644
+--- a/codex-rs/app-server/tests/suite/fuzzy_file_search.rs
++++ b/codex-rs/app-server/tests/suite/fuzzy_file_search.rs
+@@ -1,146 +1,146 @@
+-use anyhow::Context;
+-use anyhow::Result;
+-use app_test_support::McpProcess;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::RequestId;
+-use pretty_assertions::assert_eq;
+-use serde_json::json;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn test_fuzzy_file_search_sorts_and_includes_indices() -> Result<()> {
+-    // Prepare a temporary Codex home and a separate root with test files.
+-    let codex_home = TempDir::new().context("create temp codex home")?;
+-    let root = TempDir::new().context("create temp search root")?;
+-
+-    // Create files designed to have deterministic ordering for query "abe".
+-    std::fs::write(root.path().join("abc"), "x").context("write file abc")?;
+-    std::fs::write(root.path().join("abcde"), "x").context("write file abcde")?;
+-    std::fs::write(root.path().join("abexy"), "x").context("write file abexy")?;
+-    std::fs::write(root.path().join("zzz.txt"), "x").context("write file zzz")?;
+-    let sub_dir = root.path().join("sub");
+-    std::fs::create_dir_all(&sub_dir).context("create sub dir")?;
+-    let sub_abce_path = sub_dir.join("abce");
+-    std::fs::write(&sub_abce_path, "x").context("write file sub/abce")?;
+-    let sub_abce_rel = sub_abce_path
+-        .strip_prefix(root.path())
+-        .context("strip root prefix from sub/abce")?
+-        .to_string_lossy()
+-        .to_string();
+-
+-    // Start MCP server and initialize.
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .context("spawn mcp")?;
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .context("init timeout")?
+-        .context("init failed")?;
+-
+-    let root_path = root.path().to_string_lossy().to_string();
+-    // Send fuzzyFileSearch request.
+-    let request_id = mcp
+-        .send_fuzzy_file_search_request("abe", vec![root_path.clone()], None)
+-        .await
+-        .context("send fuzzyFileSearch")?;
+-
+-    // Read response and verify shape and ordering.
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .context("fuzzyFileSearch timeout")?
+-    .context("fuzzyFileSearch resp")?;
+-
+-    let value = resp.result;
+-    // The path separator on Windows affects the score.
+-    let expected_score = if cfg!(windows) { 69 } else { 72 };
+-
+-    assert_eq!(
+-        value,
+-        json!({
+-            "files": [
+-                {
+-                    "root": root_path.clone(),
+-                    "path": "abexy",
+-                    "file_name": "abexy",
+-                    "score": 88,
+-                    "indices": [0, 1, 2],
+-                },
+-                {
+-                    "root": root_path.clone(),
+-                    "path": "abcde",
+-                    "file_name": "abcde",
+-                    "score": 74,
+-                    "indices": [0, 1, 4],
+-                },
+-                {
+-                    "root": root_path.clone(),
+-                    "path": sub_abce_rel,
+-                    "file_name": "abce",
+-                    "score": expected_score,
+-                    "indices": [4, 5, 7],
+-                },
+-            ]
+-        })
+-    );
+-
+-    Ok(())
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn test_fuzzy_file_search_accepts_cancellation_token() -> Result<()> {
+-    let codex_home = TempDir::new().context("create temp codex home")?;
+-    let root = TempDir::new().context("create temp search root")?;
+-
+-    std::fs::write(root.path().join("alpha.txt"), "contents").context("write alpha")?;
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .context("spawn mcp")?;
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .context("init timeout")?
+-        .context("init failed")?;
+-
+-    let root_path = root.path().to_string_lossy().to_string();
+-    let request_id = mcp
+-        .send_fuzzy_file_search_request("alp", vec![root_path.clone()], None)
+-        .await
+-        .context("send fuzzyFileSearch")?;
+-
+-    let request_id_2 = mcp
+-        .send_fuzzy_file_search_request(
+-            "alp",
+-            vec![root_path.clone()],
+-            Some(request_id.to_string()),
+-        )
+-        .await
+-        .context("send fuzzyFileSearch")?;
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id_2)),
+-    )
+-    .await
+-    .context("fuzzyFileSearch timeout")?
+-    .context("fuzzyFileSearch resp")?;
+-
+-    let files = resp
+-        .result
+-        .get("files")
+-        .context("files key missing")?
+-        .as_array()
+-        .context("files not array")?
+-        .clone();
+-
+-    assert_eq!(files.len(), 1);
+-    assert_eq!(files[0]["root"], root_path);
+-    assert_eq!(files[0]["path"], "alpha.txt");
+-
+-    Ok(())
+-}
++use anyhow::Context;
++use anyhow::Result;
++use app_test_support::McpProcess;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::RequestId;
++use pretty_assertions::assert_eq;
++use serde_json::json;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn test_fuzzy_file_search_sorts_and_includes_indices() -> Result<()> {
++    // Prepare a temporary Codex home and a separate root with test files.
++    let codex_home = TempDir::new().context("create temp codex home")?;
++    let root = TempDir::new().context("create temp search root")?;
++
++    // Create files designed to have deterministic ordering for query "abe".
++    std::fs::write(root.path().join("abc"), "x").context("write file abc")?;
++    std::fs::write(root.path().join("abcde"), "x").context("write file abcde")?;
++    std::fs::write(root.path().join("abexy"), "x").context("write file abexy")?;
++    std::fs::write(root.path().join("zzz.txt"), "x").context("write file zzz")?;
++    let sub_dir = root.path().join("sub");
++    std::fs::create_dir_all(&sub_dir).context("create sub dir")?;
++    let sub_abce_path = sub_dir.join("abce");
++    std::fs::write(&sub_abce_path, "x").context("write file sub/abce")?;
++    let sub_abce_rel = sub_abce_path
++        .strip_prefix(root.path())
++        .context("strip root prefix from sub/abce")?
++        .to_string_lossy()
++        .to_string();
++
++    // Start MCP server and initialize.
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .context("spawn mcp")?;
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .context("init timeout")?
++        .context("init failed")?;
++
++    let root_path = root.path().to_string_lossy().to_string();
++    // Send fuzzyFileSearch request.
++    let request_id = mcp
++        .send_fuzzy_file_search_request("abe", vec![root_path.clone()], None)
++        .await
++        .context("send fuzzyFileSearch")?;
++
++    // Read response and verify shape and ordering.
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .context("fuzzyFileSearch timeout")?
++    .context("fuzzyFileSearch resp")?;
++
++    let value = resp.result;
++    // The path separator on Windows affects the score.
++    let expected_score = if cfg!(windows) { 69 } else { 72 };
++
++    assert_eq!(
++        value,
++        json!({
++            "files": [
++                {
++                    "root": root_path.clone(),
++                    "path": "abexy",
++                    "file_name": "abexy",
++                    "score": 88,
++                    "indices": [0, 1, 2],
++                },
++                {
++                    "root": root_path.clone(),
++                    "path": "abcde",
++                    "file_name": "abcde",
++                    "score": 74,
++                    "indices": [0, 1, 4],
++                },
++                {
++                    "root": root_path.clone(),
++                    "path": sub_abce_rel,
++                    "file_name": "abce",
++                    "score": expected_score,
++                    "indices": [4, 5, 7],
++                },
++            ]
++        })
++    );
++
++    Ok(())
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn test_fuzzy_file_search_accepts_cancellation_token() -> Result<()> {
++    let codex_home = TempDir::new().context("create temp codex home")?;
++    let root = TempDir::new().context("create temp search root")?;
++
++    std::fs::write(root.path().join("alpha.txt"), "contents").context("write alpha")?;
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .context("spawn mcp")?;
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .context("init timeout")?
++        .context("init failed")?;
++
++    let root_path = root.path().to_string_lossy().to_string();
++    let request_id = mcp
++        .send_fuzzy_file_search_request("alp", vec![root_path.clone()], None)
++        .await
++        .context("send fuzzyFileSearch")?;
++
++    let request_id_2 = mcp
++        .send_fuzzy_file_search_request(
++            "alp",
++            vec![root_path.clone()],
++            Some(request_id.to_string()),
++        )
++        .await
++        .context("send fuzzyFileSearch")?;
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id_2)),
++    )
++    .await
++    .context("fuzzyFileSearch timeout")?
++    .context("fuzzyFileSearch resp")?;
++
++    let files = resp
++        .result
++        .get("files")
++        .context("files key missing")?
++        .as_array()
++        .context("files not array")?
++        .clone();
++
++    assert_eq!(files.len(), 1);
++    assert_eq!(files[0]["root"], root_path);
++    assert_eq!(files[0]["path"], "alpha.txt");
++
++    Ok(())
++}
+diff --git a/codex-rs/app-server/tests/suite/interrupt.rs b/codex-rs/app-server/tests/suite/interrupt.rs
+index 2500d20f..b68875fe 100644
+--- a/codex-rs/app-server/tests/suite/interrupt.rs
++++ b/codex-rs/app-server/tests/suite/interrupt.rs
+@@ -1,159 +1,159 @@
+-#![cfg(unix)]
+-// Support code lives in the `app_test_support` crate under tests/common.
+-
+-use std::path::Path;
+-
+-use codex_app_server_protocol::AddConversationListenerParams;
+-use codex_app_server_protocol::InterruptConversationParams;
+-use codex_app_server_protocol::InterruptConversationResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::NewConversationParams;
+-use codex_app_server_protocol::NewConversationResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SendUserMessageParams;
+-use codex_app_server_protocol::SendUserMessageResponse;
+-use codex_core::protocol::TurnAbortReason;
+-use core_test_support::skip_if_no_network;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::create_mock_chat_completions_server;
+-use app_test_support::create_shell_sse_response;
+-use app_test_support::to_response;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn test_shell_command_interruption() {
+-    skip_if_no_network!();
+-
+-    if let Err(err) = shell_command_interruption().await {
+-        panic!("failure: {err}");
+-    }
+-}
+-
+-async fn shell_command_interruption() -> anyhow::Result<()> {
+-    // Use a cross-platform blocking command. On Windows plain `sleep` is not guaranteed to exist
+-    // (MSYS/GNU coreutils may be absent) and the failure causes the tool call to finish immediately,
+-    // which triggers a second model request before the test sends the explicit follow-up. That
+-    // prematurely consumes the second mocked SSE response and leads to a third POST (panic: no response for 2).
+-    // Powershell Start-Sleep is always available on Windows runners. On Unix we keep using `sleep`.
+-    #[cfg(target_os = "windows")]
+-    let shell_command = vec![
+-        "powershell".to_string(),
+-        "-Command".to_string(),
+-        "Start-Sleep -Seconds 10".to_string(),
+-    ];
+-    #[cfg(not(target_os = "windows"))]
+-    let shell_command = vec!["sleep".to_string(), "10".to_string()];
+-
+-    let tmp = TempDir::new()?;
+-    // Temporary Codex home with config pointing at the mock server.
+-    let codex_home = tmp.path().join("codex_home");
+-    std::fs::create_dir(&codex_home)?;
+-    let working_directory = tmp.path().join("workdir");
+-    std::fs::create_dir(&working_directory)?;
+-
+-    // Create mock server with a single SSE response: the long sleep command
+-    let server = create_mock_chat_completions_server(vec![create_shell_sse_response(
+-        shell_command.clone(),
+-        Some(&working_directory),
+-        Some(10_000), // 10 seconds timeout in ms
+-        "call_sleep",
+-    )?])
+-    .await;
+-    create_config_toml(&codex_home, server.uri())?;
+-
+-    // Start MCP server and initialize.
+-    let mut mcp = McpProcess::new(&codex_home).await?;
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize()).await??;
+-
+-    // 1) newConversation
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams {
+-            cwd: Some(working_directory.to_string_lossy().into_owned()),
+-            ..Default::default()
+-        })
+-        .await?;
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await??;
+-    let new_conv_resp = to_response::<NewConversationResponse>(new_conv_resp)?;
+-    let NewConversationResponse {
+-        conversation_id, ..
+-    } = new_conv_resp;
+-
+-    // 2) addConversationListener
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await?;
+-    let _add_listener_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-    )
+-    .await??;
+-
+-    // 3) sendUserMessage (should trigger notifications; we only validate an OK response)
+-    let send_user_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id,
+-            items: vec![codex_app_server_protocol::InputItem::Text {
+-                text: "run first sleep command".to_string(),
+-            }],
+-        })
+-        .await?;
+-    let send_user_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
+-    )
+-    .await??;
+-    let SendUserMessageResponse {} = to_response::<SendUserMessageResponse>(send_user_resp)?;
+-
+-    // Give the command a moment to start
+-    tokio::time::sleep(std::time::Duration::from_secs(1)).await;
+-
+-    // 4) send interrupt request
+-    let interrupt_id = mcp
+-        .send_interrupt_conversation_request(InterruptConversationParams { conversation_id })
+-        .await?;
+-    let interrupt_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(interrupt_id)),
+-    )
+-    .await??;
+-    let InterruptConversationResponse { abort_reason } =
+-        to_response::<InterruptConversationResponse>(interrupt_resp)?;
+-    assert_eq!(TurnAbortReason::Interrupted, abort_reason);
+-
+-    Ok(())
+-}
+-
+-// ---------------------------------------------------------------------------
+-// Helpers
+-// ---------------------------------------------------------------------------
+-
+-fn create_config_toml(codex_home: &Path, server_uri: String) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        format!(
+-            r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "{server_uri}/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-"#
+-        ),
+-    )
+-}
++#![cfg(unix)]
++// Support code lives in the `app_test_support` crate under tests/common.
++
++use std::path::Path;
++
++use codex_app_server_protocol::AddConversationListenerParams;
++use codex_app_server_protocol::InterruptConversationParams;
++use codex_app_server_protocol::InterruptConversationResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::NewConversationParams;
++use codex_app_server_protocol::NewConversationResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SendUserMessageParams;
++use codex_app_server_protocol::SendUserMessageResponse;
++use codex_core::protocol::TurnAbortReason;
++use core_test_support::skip_if_no_network;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++use app_test_support::McpProcess;
++use app_test_support::create_mock_chat_completions_server;
++use app_test_support::create_shell_sse_response;
++use app_test_support::to_response;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn test_shell_command_interruption() {
++    skip_if_no_network!();
++
++    if let Err(err) = shell_command_interruption().await {
++        panic!("failure: {err}");
++    }
++}
++
++async fn shell_command_interruption() -> anyhow::Result<()> {
++    // Use a cross-platform blocking command. On Windows plain `sleep` is not guaranteed to exist
++    // (MSYS/GNU coreutils may be absent) and the failure causes the tool call to finish immediately,
++    // which triggers a second model request before the test sends the explicit follow-up. That
++    // prematurely consumes the second mocked SSE response and leads to a third POST (panic: no response for 2).
++    // Powershell Start-Sleep is always available on Windows runners. On Unix we keep using `sleep`.
++    #[cfg(target_os = "windows")]
++    let shell_command = vec![
++        "powershell".to_string(),
++        "-Command".to_string(),
++        "Start-Sleep -Seconds 10".to_string(),
++    ];
++    #[cfg(not(target_os = "windows"))]
++    let shell_command = vec!["sleep".to_string(), "10".to_string()];
++
++    let tmp = TempDir::new()?;
++    // Temporary Codex home with config pointing at the mock server.
++    let codex_home = tmp.path().join("codex_home");
++    std::fs::create_dir(&codex_home)?;
++    let working_directory = tmp.path().join("workdir");
++    std::fs::create_dir(&working_directory)?;
++
++    // Create mock server with a single SSE response: the long sleep command
++    let server = create_mock_chat_completions_server(vec![create_shell_sse_response(
++        shell_command.clone(),
++        Some(&working_directory),
++        Some(10_000), // 10 seconds timeout in ms
++        "call_sleep",
++    )?])
++    .await;
++    create_config_toml(&codex_home, server.uri())?;
++
++    // Start MCP server and initialize.
++    let mut mcp = McpProcess::new(&codex_home).await?;
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize()).await??;
++
++    // 1) newConversation
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams {
++            cwd: Some(working_directory.to_string_lossy().into_owned()),
++            ..Default::default()
++        })
++        .await?;
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await??;
++    let new_conv_resp = to_response::<NewConversationResponse>(new_conv_resp)?;
++    let NewConversationResponse {
++        conversation_id, ..
++    } = new_conv_resp;
++
++    // 2) addConversationListener
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await?;
++    let _add_listener_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++    )
++    .await??;
++
++    // 3) sendUserMessage (should trigger notifications; we only validate an OK response)
++    let send_user_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id,
++            items: vec![codex_app_server_protocol::InputItem::Text {
++                text: "run first sleep command".to_string(),
++            }],
++        })
++        .await?;
++    let send_user_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(send_user_id)),
++    )
++    .await??;
++    let SendUserMessageResponse {} = to_response::<SendUserMessageResponse>(send_user_resp)?;
++
++    // Give the command a moment to start
++    tokio::time::sleep(std::time::Duration::from_secs(1)).await;
++
++    // 4) send interrupt request
++    let interrupt_id = mcp
++        .send_interrupt_conversation_request(InterruptConversationParams { conversation_id })
++        .await?;
++    let interrupt_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(interrupt_id)),
++    )
++    .await??;
++    let InterruptConversationResponse { abort_reason } =
++        to_response::<InterruptConversationResponse>(interrupt_resp)?;
++    assert_eq!(TurnAbortReason::Interrupted, abort_reason);
++
++    Ok(())
++}
++
++// ---------------------------------------------------------------------------
++// Helpers
++// ---------------------------------------------------------------------------
++
++fn create_config_toml(codex_home: &Path, server_uri: String) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        format!(
++            r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "{server_uri}/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++"#
++        ),
++    )
++}
+diff --git a/codex-rs/app-server/tests/suite/list_resume.rs b/codex-rs/app-server/tests/suite/list_resume.rs
+index a4178b08..ef451949 100644
+--- a/codex-rs/app-server/tests/suite/list_resume.rs
++++ b/codex-rs/app-server/tests/suite/list_resume.rs
+@@ -1,210 +1,210 @@
+-use std::fs;
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::JSONRPCNotification;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::ListConversationsParams;
+-use codex_app_server_protocol::ListConversationsResponse;
+-use codex_app_server_protocol::NewConversationParams; // reused for overrides shape
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::ResumeConversationParams;
+-use codex_app_server_protocol::ResumeConversationResponse;
+-use codex_app_server_protocol::ServerNotification;
+-use codex_app_server_protocol::SessionConfiguredNotification;
+-use pretty_assertions::assert_eq;
+-use serde_json::json;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-use uuid::Uuid;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn test_list_and_resume_conversations() {
+-    // Prepare a temporary CODEX_HOME with a few fake rollout files.
+-    let codex_home = TempDir::new().expect("create temp dir");
+-    create_fake_rollout(
+-        codex_home.path(),
+-        "2025-01-02T12-00-00",
+-        "2025-01-02T12:00:00Z",
+-        "Hello A",
+-    );
+-    create_fake_rollout(
+-        codex_home.path(),
+-        "2025-01-01T13-00-00",
+-        "2025-01-01T13:00:00Z",
+-        "Hello B",
+-    );
+-    create_fake_rollout(
+-        codex_home.path(),
+-        "2025-01-01T12-00-00",
+-        "2025-01-01T12:00:00Z",
+-        "Hello C",
+-    );
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    // Request first page with size 2
+-    let req_id = mcp
+-        .send_list_conversations_request(ListConversationsParams {
+-            page_size: Some(2),
+-            cursor: None,
+-        })
+-        .await
+-        .expect("send listConversations");
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(req_id)),
+-    )
+-    .await
+-    .expect("listConversations timeout")
+-    .expect("listConversations resp");
+-    let ListConversationsResponse { items, next_cursor } =
+-        to_response::<ListConversationsResponse>(resp).expect("deserialize response");
+-
+-    assert_eq!(items.len(), 2);
+-    // Newest first; preview text should match
+-    assert_eq!(items[0].preview, "Hello A");
+-    assert_eq!(items[1].preview, "Hello B");
+-    assert!(items[0].path.is_absolute());
+-    assert!(next_cursor.is_some());
+-
+-    // Request the next page using the cursor
+-    let req_id2 = mcp
+-        .send_list_conversations_request(ListConversationsParams {
+-            page_size: Some(2),
+-            cursor: next_cursor,
+-        })
+-        .await
+-        .expect("send listConversations page 2");
+-    let resp2: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(req_id2)),
+-    )
+-    .await
+-    .expect("listConversations page 2 timeout")
+-    .expect("listConversations page 2 resp");
+-    let ListConversationsResponse {
+-        items: items2,
+-        next_cursor: next2,
+-        ..
+-    } = to_response::<ListConversationsResponse>(resp2).expect("deserialize response");
+-    assert_eq!(items2.len(), 1);
+-    assert_eq!(items2[0].preview, "Hello C");
+-    assert!(next2.is_some());
+-
+-    // Now resume one of the sessions and expect a SessionConfigured notification and response.
+-    let resume_req_id = mcp
+-        .send_resume_conversation_request(ResumeConversationParams {
+-            path: items[0].path.clone(),
+-            overrides: Some(NewConversationParams {
+-                model: Some("o3".to_string()),
+-                ..Default::default()
+-            }),
+-        })
+-        .await
+-        .expect("send resumeConversation");
+-
+-    // Expect a codex/event notification with msg.type == sessionConfigured
+-    let notification: JSONRPCNotification = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("sessionConfigured"),
+-    )
+-    .await
+-    .expect("sessionConfigured notification timeout")
+-    .expect("sessionConfigured notification");
+-    let session_configured: ServerNotification = notification
+-        .try_into()
+-        .expect("deserialize sessionConfigured notification");
+-    // Basic shape assertion: ensure event type is sessionConfigured
+-    let ServerNotification::SessionConfigured(SessionConfiguredNotification {
+-        model,
+-        rollout_path,
+-        ..
+-    }) = session_configured
+-    else {
+-        unreachable!("expected sessionConfigured notification");
+-    };
+-    assert_eq!(model, "o3");
+-    assert_eq!(items[0].path.clone(), rollout_path);
+-
+-    // Then the response for resumeConversation
+-    let resume_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(resume_req_id)),
+-    )
+-    .await
+-    .expect("resumeConversation timeout")
+-    .expect("resumeConversation resp");
+-    let ResumeConversationResponse {
+-        conversation_id, ..
+-    } = to_response::<ResumeConversationResponse>(resume_resp)
+-        .expect("deserialize resumeConversation response");
+-    // conversation id should be a valid UUID
+-    assert!(!conversation_id.to_string().is_empty());
+-}
+-
+-fn create_fake_rollout(codex_home: &Path, filename_ts: &str, meta_rfc3339: &str, preview: &str) {
+-    let uuid = Uuid::new_v4();
+-    // sessions/YYYY/MM/DD/ derived from filename_ts (YYYY-MM-DDThh-mm-ss)
+-    let year = &filename_ts[0..4];
+-    let month = &filename_ts[5..7];
+-    let day = &filename_ts[8..10];
+-    let dir = codex_home.join("sessions").join(year).join(month).join(day);
+-    fs::create_dir_all(&dir).unwrap_or_else(|e| panic!("create sessions dir: {e}"));
+-
+-    let file_path = dir.join(format!("rollout-{filename_ts}-{uuid}.jsonl"));
+-    let mut lines = Vec::new();
+-    // Meta line with timestamp (flattened meta in payload for new schema)
+-    lines.push(
+-        json!({
+-            "timestamp": meta_rfc3339,
+-            "type": "session_meta",
+-            "payload": {
+-                "id": uuid,
+-                "timestamp": meta_rfc3339,
+-                "cwd": "/",
+-                "originator": "codex",
+-                "cli_version": "0.0.0",
+-                "instructions": null
+-            }
+-        })
+-        .to_string(),
+-    );
+-    // Minimal user message entry as a persisted response item (with envelope timestamp)
+-    lines.push(
+-        json!({
+-            "timestamp": meta_rfc3339,
+-            "type":"response_item",
+-            "payload": {
+-                "type":"message",
+-                "role":"user",
+-                "content":[{"type":"input_text","text": preview}]
+-            }
+-        })
+-        .to_string(),
+-    );
+-    // Add a matching user message event line to satisfy filters
+-    lines.push(
+-        json!({
+-            "timestamp": meta_rfc3339,
+-            "type":"event_msg",
+-            "payload": {
+-                "type":"user_message",
+-                "message": preview,
+-                "kind": "plain"
+-            }
+-        })
+-        .to_string(),
+-    );
+-    fs::write(file_path, lines.join("\n") + "\n")
+-        .unwrap_or_else(|e| panic!("write rollout file: {e}"));
+-}
++use std::fs;
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::JSONRPCNotification;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::ListConversationsParams;
++use codex_app_server_protocol::ListConversationsResponse;
++use codex_app_server_protocol::NewConversationParams; // reused for overrides shape
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::ResumeConversationParams;
++use codex_app_server_protocol::ResumeConversationResponse;
++use codex_app_server_protocol::ServerNotification;
++use codex_app_server_protocol::SessionConfiguredNotification;
++use pretty_assertions::assert_eq;
++use serde_json::json;
++use tempfile::TempDir;
++use tokio::time::timeout;
++use uuid::Uuid;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn test_list_and_resume_conversations() {
++    // Prepare a temporary CODEX_HOME with a few fake rollout files.
++    let codex_home = TempDir::new().expect("create temp dir");
++    create_fake_rollout(
++        codex_home.path(),
++        "2025-01-02T12-00-00",
++        "2025-01-02T12:00:00Z",
++        "Hello A",
++    );
++    create_fake_rollout(
++        codex_home.path(),
++        "2025-01-01T13-00-00",
++        "2025-01-01T13:00:00Z",
++        "Hello B",
++    );
++    create_fake_rollout(
++        codex_home.path(),
++        "2025-01-01T12-00-00",
++        "2025-01-01T12:00:00Z",
++        "Hello C",
++    );
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    // Request first page with size 2
++    let req_id = mcp
++        .send_list_conversations_request(ListConversationsParams {
++            page_size: Some(2),
++            cursor: None,
++        })
++        .await
++        .expect("send listConversations");
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(req_id)),
++    )
++    .await
++    .expect("listConversations timeout")
++    .expect("listConversations resp");
++    let ListConversationsResponse { items, next_cursor } =
++        to_response::<ListConversationsResponse>(resp).expect("deserialize response");
++
++    assert_eq!(items.len(), 2);
++    // Newest first; preview text should match
++    assert_eq!(items[0].preview, "Hello A");
++    assert_eq!(items[1].preview, "Hello B");
++    assert!(items[0].path.is_absolute());
++    assert!(next_cursor.is_some());
++
++    // Request the next page using the cursor
++    let req_id2 = mcp
++        .send_list_conversations_request(ListConversationsParams {
++            page_size: Some(2),
++            cursor: next_cursor,
++        })
++        .await
++        .expect("send listConversations page 2");
++    let resp2: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(req_id2)),
++    )
++    .await
++    .expect("listConversations page 2 timeout")
++    .expect("listConversations page 2 resp");
++    let ListConversationsResponse {
++        items: items2,
++        next_cursor: next2,
++        ..
++    } = to_response::<ListConversationsResponse>(resp2).expect("deserialize response");
++    assert_eq!(items2.len(), 1);
++    assert_eq!(items2[0].preview, "Hello C");
++    assert!(next2.is_some());
++
++    // Now resume one of the sessions and expect a SessionConfigured notification and response.
++    let resume_req_id = mcp
++        .send_resume_conversation_request(ResumeConversationParams {
++            path: items[0].path.clone(),
++            overrides: Some(NewConversationParams {
++                model: Some("o3".to_string()),
++                ..Default::default()
++            }),
++        })
++        .await
++        .expect("send resumeConversation");
++
++    // Expect a codex/event notification with msg.type == sessionConfigured
++    let notification: JSONRPCNotification = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("sessionConfigured"),
++    )
++    .await
++    .expect("sessionConfigured notification timeout")
++    .expect("sessionConfigured notification");
++    let session_configured: ServerNotification = notification
++        .try_into()
++        .expect("deserialize sessionConfigured notification");
++    // Basic shape assertion: ensure event type is sessionConfigured
++    let ServerNotification::SessionConfigured(SessionConfiguredNotification {
++        model,
++        rollout_path,
++        ..
++    }) = session_configured
++    else {
++        unreachable!("expected sessionConfigured notification");
++    };
++    assert_eq!(model, "o3");
++    assert_eq!(items[0].path.clone(), rollout_path);
++
++    // Then the response for resumeConversation
++    let resume_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(resume_req_id)),
++    )
++    .await
++    .expect("resumeConversation timeout")
++    .expect("resumeConversation resp");
++    let ResumeConversationResponse {
++        conversation_id, ..
++    } = to_response::<ResumeConversationResponse>(resume_resp)
++        .expect("deserialize resumeConversation response");
++    // conversation id should be a valid UUID
++    assert!(!conversation_id.to_string().is_empty());
++}
++
++fn create_fake_rollout(codex_home: &Path, filename_ts: &str, meta_rfc3339: &str, preview: &str) {
++    let uuid = Uuid::new_v4();
++    // sessions/YYYY/MM/DD/ derived from filename_ts (YYYY-MM-DDThh-mm-ss)
++    let year = &filename_ts[0..4];
++    let month = &filename_ts[5..7];
++    let day = &filename_ts[8..10];
++    let dir = codex_home.join("sessions").join(year).join(month).join(day);
++    fs::create_dir_all(&dir).unwrap_or_else(|e| panic!("create sessions dir: {e}"));
++
++    let file_path = dir.join(format!("rollout-{filename_ts}-{uuid}.jsonl"));
++    let mut lines = Vec::new();
++    // Meta line with timestamp (flattened meta in payload for new schema)
++    lines.push(
++        json!({
++            "timestamp": meta_rfc3339,
++            "type": "session_meta",
++            "payload": {
++                "id": uuid,
++                "timestamp": meta_rfc3339,
++                "cwd": "/",
++                "originator": "codex",
++                "cli_version": "0.0.0",
++                "instructions": null
++            }
++        })
++        .to_string(),
++    );
++    // Minimal user message entry as a persisted response item (with envelope timestamp)
++    lines.push(
++        json!({
++            "timestamp": meta_rfc3339,
++            "type":"response_item",
++            "payload": {
++                "type":"message",
++                "role":"user",
++                "content":[{"type":"input_text","text": preview}]
++            }
++        })
++        .to_string(),
++    );
++    // Add a matching user message event line to satisfy filters
++    lines.push(
++        json!({
++            "timestamp": meta_rfc3339,
++            "type":"event_msg",
++            "payload": {
++                "type":"user_message",
++                "message": preview,
++                "kind": "plain"
++            }
++        })
++        .to_string(),
++    );
++    fs::write(file_path, lines.join("\n") + "\n")
++        .unwrap_or_else(|e| panic!("write rollout file: {e}"));
++}
+diff --git a/codex-rs/app-server/tests/suite/login.rs b/codex-rs/app-server/tests/suite/login.rs
+index 6dcbde11..0eaa4ecb 100644
+--- a/codex-rs/app-server/tests/suite/login.rs
++++ b/codex-rs/app-server/tests/suite/login.rs
+@@ -1,146 +1,146 @@
+-use std::path::Path;
+-use std::time::Duration;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::CancelLoginChatGptParams;
+-use codex_app_server_protocol::CancelLoginChatGptResponse;
+-use codex_app_server_protocol::GetAuthStatusParams;
+-use codex_app_server_protocol::GetAuthStatusResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::LoginChatGptResponse;
+-use codex_app_server_protocol::LogoutChatGptResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_login::login_with_api_key;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-// Helper to create a config.toml; mirrors create_conversation.rs
+-fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "http://127.0.0.1:0/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-"#,
+-    )
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn logout_chatgpt_removes_auth() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).expect("write config.toml");
+-    login_with_api_key(codex_home.path(), "sk-test-key").expect("seed api key");
+-    assert!(codex_home.path().join("auth.json").exists());
+-
+-    let mut mcp = McpProcess::new_with_env(codex_home.path(), &[("OPENAI_API_KEY", None)])
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let id = mcp
+-        .send_logout_chat_gpt_request()
+-        .await
+-        .expect("send logoutChatGpt");
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(id)),
+-    )
+-    .await
+-    .expect("logoutChatGpt timeout")
+-    .expect("logoutChatGpt response");
+-    let _ok: LogoutChatGptResponse = to_response(resp).expect("deserialize logout response");
+-
+-    assert!(
+-        !codex_home.path().join("auth.json").exists(),
+-        "auth.json should be deleted"
+-    );
+-
+-    // Verify status reflects signed-out state.
+-    let status_id = mcp
+-        .send_get_auth_status_request(GetAuthStatusParams {
+-            include_token: Some(true),
+-            refresh_token: Some(false),
+-        })
+-        .await
+-        .expect("send getAuthStatus");
+-    let status_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(status_id)),
+-    )
+-    .await
+-    .expect("getAuthStatus timeout")
+-    .expect("getAuthStatus response");
+-    let status: GetAuthStatusResponse = to_response(status_resp).expect("deserialize status");
+-    assert_eq!(status.auth_method, None);
+-    assert_eq!(status.auth_token, None);
+-}
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn login_and_cancel_chatgpt() {
+-    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
+-    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let login_id = mcp
+-        .send_login_chat_gpt_request()
+-        .await
+-        .expect("send loginChatGpt");
+-    let login_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(login_id)),
+-    )
+-    .await
+-    .expect("loginChatGpt timeout")
+-    .expect("loginChatGpt response");
+-    let login: LoginChatGptResponse = to_response(login_resp).expect("deserialize login resp");
+-
+-    let cancel_id = mcp
+-        .send_cancel_login_chat_gpt_request(CancelLoginChatGptParams {
+-            login_id: login.login_id,
+-        })
+-        .await
+-        .expect("send cancelLoginChatGpt");
+-    let cancel_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(cancel_id)),
+-    )
+-    .await
+-    .expect("cancelLoginChatGpt timeout")
+-    .expect("cancelLoginChatGpt response");
+-    let _ok: CancelLoginChatGptResponse =
+-        to_response(cancel_resp).expect("deserialize cancel response");
+-
+-    // Optionally observe the completion notification; do not fail if it races.
+-    let maybe_note = timeout(
+-        Duration::from_secs(2),
+-        mcp.read_stream_until_notification_message("codex/event/login_chat_gpt_complete"),
+-    )
+-    .await;
+-    if maybe_note.is_err() {
+-        eprintln!("warning: did not observe login_chat_gpt_complete notification after cancel");
+-    }
+-}
++use std::path::Path;
++use std::time::Duration;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::CancelLoginChatGptParams;
++use codex_app_server_protocol::CancelLoginChatGptResponse;
++use codex_app_server_protocol::GetAuthStatusParams;
++use codex_app_server_protocol::GetAuthStatusResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::LoginChatGptResponse;
++use codex_app_server_protocol::LogoutChatGptResponse;
++use codex_app_server_protocol::RequestId;
++use codex_login::login_with_api_key;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++// Helper to create a config.toml; mirrors create_conversation.rs
++fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "http://127.0.0.1:0/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++"#,
++    )
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn logout_chatgpt_removes_auth() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).expect("write config.toml");
++    login_with_api_key(codex_home.path(), "sk-test-key").expect("seed api key");
++    assert!(codex_home.path().join("auth.json").exists());
++
++    let mut mcp = McpProcess::new_with_env(codex_home.path(), &[("OPENAI_API_KEY", None)])
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let id = mcp
++        .send_logout_chat_gpt_request()
++        .await
++        .expect("send logoutChatGpt");
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(id)),
++    )
++    .await
++    .expect("logoutChatGpt timeout")
++    .expect("logoutChatGpt response");
++    let _ok: LogoutChatGptResponse = to_response(resp).expect("deserialize logout response");
++
++    assert!(
++        !codex_home.path().join("auth.json").exists(),
++        "auth.json should be deleted"
++    );
++
++    // Verify status reflects signed-out state.
++    let status_id = mcp
++        .send_get_auth_status_request(GetAuthStatusParams {
++            include_token: Some(true),
++            refresh_token: Some(false),
++        })
++        .await
++        .expect("send getAuthStatus");
++    let status_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(status_id)),
++    )
++    .await
++    .expect("getAuthStatus timeout")
++    .expect("getAuthStatus response");
++    let status: GetAuthStatusResponse = to_response(status_resp).expect("deserialize status");
++    assert_eq!(status.auth_method, None);
++    assert_eq!(status.auth_token, None);
++}
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn login_and_cancel_chatgpt() {
++    let codex_home = TempDir::new().unwrap_or_else(|e| panic!("create tempdir: {e}"));
++    create_config_toml(codex_home.path()).unwrap_or_else(|err| panic!("write config.toml: {err}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let login_id = mcp
++        .send_login_chat_gpt_request()
++        .await
++        .expect("send loginChatGpt");
++    let login_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(login_id)),
++    )
++    .await
++    .expect("loginChatGpt timeout")
++    .expect("loginChatGpt response");
++    let login: LoginChatGptResponse = to_response(login_resp).expect("deserialize login resp");
++
++    let cancel_id = mcp
++        .send_cancel_login_chat_gpt_request(CancelLoginChatGptParams {
++            login_id: login.login_id,
++        })
++        .await
++        .expect("send cancelLoginChatGpt");
++    let cancel_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(cancel_id)),
++    )
++    .await
++    .expect("cancelLoginChatGpt timeout")
++    .expect("cancelLoginChatGpt response");
++    let _ok: CancelLoginChatGptResponse =
++        to_response(cancel_resp).expect("deserialize cancel response");
++
++    // Optionally observe the completion notification; do not fail if it races.
++    let maybe_note = timeout(
++        Duration::from_secs(2),
++        mcp.read_stream_until_notification_message("codex/event/login_chat_gpt_complete"),
++    )
++    .await;
++    if maybe_note.is_err() {
++        eprintln!("warning: did not observe login_chat_gpt_complete notification after cancel");
++    }
++}
+diff --git a/codex-rs/app-server/tests/suite/mod.rs b/codex-rs/app-server/tests/suite/mod.rs
+index 78ce310e..17706ef4 100644
+--- a/codex-rs/app-server/tests/suite/mod.rs
++++ b/codex-rs/app-server/tests/suite/mod.rs
+@@ -5,6 +5,8 @@ mod config;
+ mod create_conversation;
+ mod fuzzy_file_search;
+ mod interrupt;
++#[cfg(feature = "ledger")]
++mod ledger_create_company;
+ mod list_resume;
+ mod login;
+ mod send_message;
+diff --git a/codex-rs/app-server/tests/suite/send_message.rs b/codex-rs/app-server/tests/suite/send_message.rs
+index 22fb02dc..252a0430 100644
+--- a/codex-rs/app-server/tests/suite/send_message.rs
++++ b/codex-rs/app-server/tests/suite/send_message.rs
+@@ -1,186 +1,186 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::create_final_assistant_message_sse_response;
+-use app_test_support::create_mock_chat_completions_server;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::AddConversationListenerParams;
+-use codex_app_server_protocol::AddConversationSubscriptionResponse;
+-use codex_app_server_protocol::InputItem;
+-use codex_app_server_protocol::JSONRPCNotification;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::NewConversationParams;
+-use codex_app_server_protocol::NewConversationResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SendUserMessageParams;
+-use codex_app_server_protocol::SendUserMessageResponse;
+-use codex_protocol::ConversationId;
+-use pretty_assertions::assert_eq;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test]
+-async fn test_send_message_success() {
+-    // Spin up a mock completions server that immediately ends the Codex turn.
+-    // Two Codex turns hit the mock model (session start + send-user-message). Provide two SSE responses.
+-    let responses = vec![
+-        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
+-        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
+-    ];
+-    let server = create_mock_chat_completions_server(responses).await;
+-
+-    // Create a temporary Codex home with config pointing at the mock server.
+-    let codex_home = TempDir::new().expect("create temp dir");
+-    create_config_toml(codex_home.path(), &server.uri()).expect("write config.toml");
+-
+-    // Start MCP server process and initialize.
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timed out")
+-        .expect("init failed");
+-
+-    // Start a conversation using the new wire API.
+-    let new_conv_id = mcp
+-        .send_new_conversation_request(NewConversationParams::default())
+-        .await
+-        .expect("send newConversation");
+-    let new_conv_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
+-    )
+-    .await
+-    .expect("newConversation timeout")
+-    .expect("newConversation resp");
+-    let NewConversationResponse {
+-        conversation_id, ..
+-    } = to_response::<_>(new_conv_resp).expect("deserialize newConversation response");
+-
+-    // 2) addConversationListener
+-    let add_listener_id = mcp
+-        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
+-        .await
+-        .expect("send addConversationListener");
+-    let add_listener_resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
+-    )
+-    .await
+-    .expect("addConversationListener timeout")
+-    .expect("addConversationListener resp");
+-    let AddConversationSubscriptionResponse { subscription_id: _ } =
+-        to_response::<_>(add_listener_resp).expect("deserialize addConversationListener response");
+-
+-    // Now exercise sendUserMessage twice.
+-    send_message("Hello", conversation_id, &mut mcp).await;
+-    send_message("Hello again", conversation_id, &mut mcp).await;
+-}
+-
+-#[expect(clippy::expect_used)]
+-async fn send_message(message: &str, conversation_id: ConversationId, mcp: &mut McpProcess) {
+-    // Now exercise sendUserMessage.
+-    let send_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id,
+-            items: vec![InputItem::Text {
+-                text: message.to_string(),
+-            }],
+-        })
+-        .await
+-        .expect("send sendUserMessage");
+-
+-    let response: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(send_id)),
+-    )
+-    .await
+-    .expect("sendUserMessage response timeout")
+-    .expect("sendUserMessage response error");
+-
+-    let _ok: SendUserMessageResponse = to_response::<SendUserMessageResponse>(response)
+-        .expect("deserialize sendUserMessage response");
+-
+-    // Verify the task_finished notification is received.
+-    // Note this also ensures that the final request to the server was made.
+-    let task_finished_notification: JSONRPCNotification = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_notification_message("codex/event/task_complete"),
+-    )
+-    .await
+-    .expect("task_finished_notification timeout")
+-    .expect("task_finished_notification resp");
+-    let serde_json::Value::Object(map) = task_finished_notification
+-        .params
+-        .expect("notification should have params")
+-    else {
+-        panic!("task_finished_notification should have params");
+-    };
+-    assert_eq!(
+-        map.get("conversationId")
+-            .expect("should have conversationId"),
+-        &serde_json::Value::String(conversation_id.to_string())
+-    );
+-}
+-
+-#[tokio::test]
+-async fn test_send_message_session_not_found() {
+-    // Start MCP without creating a Codex session
+-    let codex_home = TempDir::new().expect("tempdir");
+-    let mut mcp = McpProcess::new(codex_home.path()).await.expect("spawn");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("timeout")
+-        .expect("init");
+-
+-    let unknown = ConversationId::new();
+-    let req_id = mcp
+-        .send_send_user_message_request(SendUserMessageParams {
+-            conversation_id: unknown,
+-            items: vec![InputItem::Text {
+-                text: "ping".to_string(),
+-            }],
+-        })
+-        .await
+-        .expect("send sendUserMessage");
+-
+-    // Expect an error response for unknown conversation.
+-    let err = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_error_message(RequestId::Integer(req_id)),
+-    )
+-    .await
+-    .expect("timeout")
+-    .expect("error");
+-    assert_eq!(err.id, RequestId::Integer(req_id));
+-}
+-
+-// ---------------------------------------------------------------------------
+-// Helpers
+-// ---------------------------------------------------------------------------
+-
+-fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        format!(
+-            r#"
+-model = "mock-model"
+-approval_policy = "never"
+-sandbox_mode = "danger-full-access"
+-
+-model_provider = "mock_provider"
+-
+-[model_providers.mock_provider]
+-name = "Mock provider for test"
+-base_url = "{server_uri}/v1"
+-wire_api = "chat"
+-request_max_retries = 0
+-stream_max_retries = 0
+-"#
+-        ),
+-    )
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::create_final_assistant_message_sse_response;
++use app_test_support::create_mock_chat_completions_server;
++use app_test_support::to_response;
++use codex_app_server_protocol::AddConversationListenerParams;
++use codex_app_server_protocol::AddConversationSubscriptionResponse;
++use codex_app_server_protocol::InputItem;
++use codex_app_server_protocol::JSONRPCNotification;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::NewConversationParams;
++use codex_app_server_protocol::NewConversationResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SendUserMessageParams;
++use codex_app_server_protocol::SendUserMessageResponse;
++use codex_protocol::ConversationId;
++use pretty_assertions::assert_eq;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test]
++async fn test_send_message_success() {
++    // Spin up a mock completions server that immediately ends the Codex turn.
++    // Two Codex turns hit the mock model (session start + send-user-message). Provide two SSE responses.
++    let responses = vec![
++        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
++        create_final_assistant_message_sse_response("Done").expect("build mock assistant message"),
++    ];
++    let server = create_mock_chat_completions_server(responses).await;
++
++    // Create a temporary Codex home with config pointing at the mock server.
++    let codex_home = TempDir::new().expect("create temp dir");
++    create_config_toml(codex_home.path(), &server.uri()).expect("write config.toml");
++
++    // Start MCP server process and initialize.
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timed out")
++        .expect("init failed");
++
++    // Start a conversation using the new wire API.
++    let new_conv_id = mcp
++        .send_new_conversation_request(NewConversationParams::default())
++        .await
++        .expect("send newConversation");
++    let new_conv_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(new_conv_id)),
++    )
++    .await
++    .expect("newConversation timeout")
++    .expect("newConversation resp");
++    let NewConversationResponse {
++        conversation_id, ..
++    } = to_response::<_>(new_conv_resp).expect("deserialize newConversation response");
++
++    // 2) addConversationListener
++    let add_listener_id = mcp
++        .send_add_conversation_listener_request(AddConversationListenerParams { conversation_id })
++        .await
++        .expect("send addConversationListener");
++    let add_listener_resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(add_listener_id)),
++    )
++    .await
++    .expect("addConversationListener timeout")
++    .expect("addConversationListener resp");
++    let AddConversationSubscriptionResponse { subscription_id: _ } =
++        to_response::<_>(add_listener_resp).expect("deserialize addConversationListener response");
++
++    // Now exercise sendUserMessage twice.
++    send_message("Hello", conversation_id, &mut mcp).await;
++    send_message("Hello again", conversation_id, &mut mcp).await;
++}
++
++#[expect(clippy::expect_used)]
++async fn send_message(message: &str, conversation_id: ConversationId, mcp: &mut McpProcess) {
++    // Now exercise sendUserMessage.
++    let send_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id,
++            items: vec![InputItem::Text {
++                text: message.to_string(),
++            }],
++        })
++        .await
++        .expect("send sendUserMessage");
++
++    let response: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(send_id)),
++    )
++    .await
++    .expect("sendUserMessage response timeout")
++    .expect("sendUserMessage response error");
++
++    let _ok: SendUserMessageResponse = to_response::<SendUserMessageResponse>(response)
++        .expect("deserialize sendUserMessage response");
++
++    // Verify the task_finished notification is received.
++    // Note this also ensures that the final request to the server was made.
++    let task_finished_notification: JSONRPCNotification = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_notification_message("codex/event/task_complete"),
++    )
++    .await
++    .expect("task_finished_notification timeout")
++    .expect("task_finished_notification resp");
++    let serde_json::Value::Object(map) = task_finished_notification
++        .params
++        .expect("notification should have params")
++    else {
++        panic!("task_finished_notification should have params");
++    };
++    assert_eq!(
++        map.get("conversationId")
++            .expect("should have conversationId"),
++        &serde_json::Value::String(conversation_id.to_string())
++    );
++}
++
++#[tokio::test]
++async fn test_send_message_session_not_found() {
++    // Start MCP without creating a Codex session
++    let codex_home = TempDir::new().expect("tempdir");
++    let mut mcp = McpProcess::new(codex_home.path()).await.expect("spawn");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("timeout")
++        .expect("init");
++
++    let unknown = ConversationId::new();
++    let req_id = mcp
++        .send_send_user_message_request(SendUserMessageParams {
++            conversation_id: unknown,
++            items: vec![InputItem::Text {
++                text: "ping".to_string(),
++            }],
++        })
++        .await
++        .expect("send sendUserMessage");
++
++    // Expect an error response for unknown conversation.
++    let err = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_error_message(RequestId::Integer(req_id)),
++    )
++    .await
++    .expect("timeout")
++    .expect("error");
++    assert_eq!(err.id, RequestId::Integer(req_id));
++}
++
++// ---------------------------------------------------------------------------
++// Helpers
++// ---------------------------------------------------------------------------
++
++fn create_config_toml(codex_home: &Path, server_uri: &str) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        format!(
++            r#"
++model = "mock-model"
++approval_policy = "never"
++sandbox_mode = "danger-full-access"
++
++model_provider = "mock_provider"
++
++[model_providers.mock_provider]
++name = "Mock provider for test"
++base_url = "{server_uri}/v1"
++wire_api = "chat"
++request_max_retries = 0
++stream_max_retries = 0
++"#
++        ),
++    )
++}
+diff --git a/codex-rs/app-server/tests/suite/set_default_model.rs b/codex-rs/app-server/tests/suite/set_default_model.rs
+index 6769faa9..c84e051a 100644
+--- a/codex-rs/app-server/tests/suite/set_default_model.rs
++++ b/codex-rs/app-server/tests/suite/set_default_model.rs
+@@ -1,76 +1,76 @@
+-use std::path::Path;
+-
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::SetDefaultModelParams;
+-use codex_app_server_protocol::SetDefaultModelResponse;
+-use codex_core::config::ConfigToml;
+-use pretty_assertions::assert_eq;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn set_default_model_persists_overrides() {
+-    let codex_home = TempDir::new().expect("create tempdir");
+-    create_config_toml(codex_home.path()).expect("write config.toml");
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("init timeout")
+-        .expect("init failed");
+-
+-    let params = SetDefaultModelParams {
+-        model: Some("gpt-4.1".to_string()),
+-        reasoning_effort: None,
+-    };
+-
+-    let request_id = mcp
+-        .send_set_default_model_request(params)
+-        .await
+-        .expect("send setDefaultModel");
+-
+-    let resp: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("setDefaultModel timeout")
+-    .expect("setDefaultModel response");
+-
+-    let _: SetDefaultModelResponse =
+-        to_response(resp).expect("deserialize setDefaultModel response");
+-
+-    let config_path = codex_home.path().join("config.toml");
+-    let config_contents = tokio::fs::read_to_string(&config_path)
+-        .await
+-        .expect("read config.toml");
+-    let config_toml: ConfigToml = toml::from_str(&config_contents).expect("parse config.toml");
+-
+-    assert_eq!(
+-        ConfigToml {
+-            model: Some("gpt-4.1".to_string()),
+-            model_reasoning_effort: None,
+-            ..Default::default()
+-        },
+-        config_toml,
+-    );
+-}
+-
+-// Helper to create a config.toml; mirrors create_conversation.rs
+-fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
+-    let config_toml = codex_home.join("config.toml");
+-    std::fs::write(
+-        config_toml,
+-        r#"
+-model = "gpt-5-codex"
+-model_reasoning_effort = "medium"
+-"#,
+-    )
+-}
++use std::path::Path;
++
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::SetDefaultModelParams;
++use codex_app_server_protocol::SetDefaultModelResponse;
++use codex_core::config::ConfigToml;
++use pretty_assertions::assert_eq;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn set_default_model_persists_overrides() {
++    let codex_home = TempDir::new().expect("create tempdir");
++    create_config_toml(codex_home.path()).expect("write config.toml");
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("init timeout")
++        .expect("init failed");
++
++    let params = SetDefaultModelParams {
++        model: Some("gpt-4.1".to_string()),
++        reasoning_effort: None,
++    };
++
++    let request_id = mcp
++        .send_set_default_model_request(params)
++        .await
++        .expect("send setDefaultModel");
++
++    let resp: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("setDefaultModel timeout")
++    .expect("setDefaultModel response");
++
++    let _: SetDefaultModelResponse =
++        to_response(resp).expect("deserialize setDefaultModel response");
++
++    let config_path = codex_home.path().join("config.toml");
++    let config_contents = tokio::fs::read_to_string(&config_path)
++        .await
++        .expect("read config.toml");
++    let config_toml: ConfigToml = toml::from_str(&config_contents).expect("parse config.toml");
++
++    assert_eq!(
++        ConfigToml {
++            model: Some("gpt-4.1".to_string()),
++            model_reasoning_effort: None,
++            ..Default::default()
++        },
++        config_toml,
++    );
++}
++
++// Helper to create a config.toml; mirrors create_conversation.rs
++fn create_config_toml(codex_home: &Path) -> std::io::Result<()> {
++    let config_toml = codex_home.join("config.toml");
++    std::fs::write(
++        config_toml,
++        r#"
++model = "gpt-5-codex"
++model_reasoning_effort = "medium"
++"#,
++    )
++}
+diff --git a/codex-rs/app-server/tests/suite/user_agent.rs b/codex-rs/app-server/tests/suite/user_agent.rs
+index 95a0b1a3..3f7b06ec 100644
+--- a/codex-rs/app-server/tests/suite/user_agent.rs
++++ b/codex-rs/app-server/tests/suite/user_agent.rs
+@@ -1,50 +1,50 @@
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use codex_app_server_protocol::GetUserAgentResponse;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::RequestId;
+-use pretty_assertions::assert_eq;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn get_user_agent_returns_current_codex_user_agent() {
+-    let codex_home = TempDir::new().unwrap_or_else(|err| panic!("create tempdir: {err}"));
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("initialize timeout")
+-        .expect("initialize request");
+-
+-    let request_id = mcp
+-        .send_get_user_agent_request()
+-        .await
+-        .expect("send getUserAgent");
+-    let response: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("getUserAgent timeout")
+-    .expect("getUserAgent response");
+-
+-    let os_info = os_info::get();
+-    let user_agent = format!(
+-        "codex_cli_rs/0.0.0 ({} {}; {}) {} (codex-app-server-tests; 0.1.0)",
+-        os_info.os_type(),
+-        os_info.version(),
+-        os_info.architecture().unwrap_or("unknown"),
+-        codex_core::terminal::user_agent()
+-    );
+-
+-    let received: GetUserAgentResponse =
+-        to_response(response).expect("deserialize getUserAgent response");
+-    let expected = GetUserAgentResponse { user_agent };
+-
+-    assert_eq!(received, expected);
+-}
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use codex_app_server_protocol::GetUserAgentResponse;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::RequestId;
++use pretty_assertions::assert_eq;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: std::time::Duration = std::time::Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn get_user_agent_returns_current_codex_user_agent() {
++    let codex_home = TempDir::new().unwrap_or_else(|err| panic!("create tempdir: {err}"));
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("initialize timeout")
++        .expect("initialize request");
++
++    let request_id = mcp
++        .send_get_user_agent_request()
++        .await
++        .expect("send getUserAgent");
++    let response: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("getUserAgent timeout")
++    .expect("getUserAgent response");
++
++    let os_info = os_info::get();
++    let user_agent = format!(
++        "codex_cli_rs/0.0.0 ({} {}; {}) {} (codex-app-server-tests; 0.1.0)",
++        os_info.os_type(),
++        os_info.version(),
++        os_info.architecture().unwrap_or("unknown"),
++        codex_core::terminal::user_agent()
++    );
++
++    let received: GetUserAgentResponse =
++        to_response(response).expect("deserialize getUserAgent response");
++    let expected = GetUserAgentResponse { user_agent };
++
++    assert_eq!(received, expected);
++}
+diff --git a/codex-rs/app-server/tests/suite/user_info.rs b/codex-rs/app-server/tests/suite/user_info.rs
+index edd041e5..2f412c02 100644
+--- a/codex-rs/app-server/tests/suite/user_info.rs
++++ b/codex-rs/app-server/tests/suite/user_info.rs
+@@ -1,78 +1,78 @@
+-use std::time::Duration;
+-
+-use anyhow::Context;
+-use app_test_support::McpProcess;
+-use app_test_support::to_response;
+-use base64::Engine;
+-use base64::engine::general_purpose::URL_SAFE_NO_PAD;
+-use codex_app_server_protocol::JSONRPCResponse;
+-use codex_app_server_protocol::RequestId;
+-use codex_app_server_protocol::UserInfoResponse;
+-use codex_core::auth::AuthDotJson;
+-use codex_core::auth::get_auth_file;
+-use codex_core::auth::write_auth_json;
+-use codex_core::token_data::IdTokenInfo;
+-use codex_core::token_data::TokenData;
+-use pretty_assertions::assert_eq;
+-use serde_json::json;
+-use tempfile::TempDir;
+-use tokio::time::timeout;
+-
+-const DEFAULT_READ_TIMEOUT: Duration = Duration::from_secs(10);
+-
+-#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+-async fn user_info_returns_email_from_auth_json() {
+-    let codex_home = TempDir::new().expect("create tempdir");
+-
+-    let auth_path = get_auth_file(codex_home.path());
+-    let mut id_token = IdTokenInfo::default();
+-    id_token.email = Some("user@example.com".to_string());
+-    id_token.raw_jwt = encode_id_token_with_email("user@example.com").expect("encode id token");
+-
+-    let auth = AuthDotJson {
+-        openai_api_key: None,
+-        tokens: Some(TokenData {
+-            id_token,
+-            access_token: "access".to_string(),
+-            refresh_token: "refresh".to_string(),
+-            account_id: None,
+-        }),
+-        last_refresh: None,
+-    };
+-    write_auth_json(&auth_path, &auth).expect("write auth.json");
+-
+-    let mut mcp = McpProcess::new(codex_home.path())
+-        .await
+-        .expect("spawn mcp process");
+-    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
+-        .await
+-        .expect("initialize timeout")
+-        .expect("initialize request");
+-
+-    let request_id = mcp.send_user_info_request().await.expect("send userInfo");
+-    let response: JSONRPCResponse = timeout(
+-        DEFAULT_READ_TIMEOUT,
+-        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
+-    )
+-    .await
+-    .expect("userInfo timeout")
+-    .expect("userInfo response");
+-
+-    let received: UserInfoResponse = to_response(response).expect("deserialize userInfo response");
+-    let expected = UserInfoResponse {
+-        alleged_user_email: Some("user@example.com".to_string()),
+-    };
+-
+-    assert_eq!(received, expected);
+-}
+-
+-fn encode_id_token_with_email(email: &str) -> anyhow::Result<String> {
+-    let header_b64 = URL_SAFE_NO_PAD.encode(
+-        serde_json::to_vec(&json!({ "alg": "none", "typ": "JWT" }))
+-            .context("serialize jwt header")?,
+-    );
+-    let payload =
+-        serde_json::to_vec(&json!({ "email": email })).context("serialize jwt payload")?;
+-    let payload_b64 = URL_SAFE_NO_PAD.encode(payload);
+-    Ok(format!("{header_b64}.{payload_b64}.signature"))
+-}
++use std::time::Duration;
++
++use anyhow::Context;
++use app_test_support::McpProcess;
++use app_test_support::to_response;
++use base64::Engine;
++use base64::engine::general_purpose::URL_SAFE_NO_PAD;
++use codex_app_server_protocol::JSONRPCResponse;
++use codex_app_server_protocol::RequestId;
++use codex_app_server_protocol::UserInfoResponse;
++use codex_core::auth::AuthDotJson;
++use codex_core::auth::get_auth_file;
++use codex_core::auth::write_auth_json;
++use codex_core::token_data::IdTokenInfo;
++use codex_core::token_data::TokenData;
++use pretty_assertions::assert_eq;
++use serde_json::json;
++use tempfile::TempDir;
++use tokio::time::timeout;
++
++const DEFAULT_READ_TIMEOUT: Duration = Duration::from_secs(10);
++
++#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
++async fn user_info_returns_email_from_auth_json() {
++    let codex_home = TempDir::new().expect("create tempdir");
++
++    let auth_path = get_auth_file(codex_home.path());
++    let mut id_token = IdTokenInfo::default();
++    id_token.email = Some("user@example.com".to_string());
++    id_token.raw_jwt = encode_id_token_with_email("user@example.com").expect("encode id token");
++
++    let auth = AuthDotJson {
++        openai_api_key: None,
++        tokens: Some(TokenData {
++            id_token,
++            access_token: "access".to_string(),
++            refresh_token: "refresh".to_string(),
++            account_id: None,
++        }),
++        last_refresh: None,
++    };
++    write_auth_json(&auth_path, &auth).expect("write auth.json");
++
++    let mut mcp = McpProcess::new(codex_home.path())
++        .await
++        .expect("spawn mcp process");
++    timeout(DEFAULT_READ_TIMEOUT, mcp.initialize())
++        .await
++        .expect("initialize timeout")
++        .expect("initialize request");
++
++    let request_id = mcp.send_user_info_request().await.expect("send userInfo");
++    let response: JSONRPCResponse = timeout(
++        DEFAULT_READ_TIMEOUT,
++        mcp.read_stream_until_response_message(RequestId::Integer(request_id)),
++    )
++    .await
++    .expect("userInfo timeout")
++    .expect("userInfo response");
++
++    let received: UserInfoResponse = to_response(response).expect("deserialize userInfo response");
++    let expected = UserInfoResponse {
++        alleged_user_email: Some("user@example.com".to_string()),
++    };
++
++    assert_eq!(received, expected);
++}
++
++fn encode_id_token_with_email(email: &str) -> anyhow::Result<String> {
++    let header_b64 = URL_SAFE_NO_PAD.encode(
++        serde_json::to_vec(&json!({ "alg": "none", "typ": "JWT" }))
++            .context("serialize jwt header")?,
++    );
++    let payload =
++        serde_json::to_vec(&json!({ "email": email })).context("serialize jwt payload")?;
++    let payload_b64 = URL_SAFE_NO_PAD.encode(payload);
++    Ok(format!("{header_b64}.{payload_b64}.signature"))
++}
+diff --git a/codex-rs/apply-patch/Cargo.toml b/codex-rs/apply-patch/Cargo.toml
+index a239cd63..8dbc0ea2 100644
+--- a/codex-rs/apply-patch/Cargo.toml
++++ b/codex-rs/apply-patch/Cargo.toml
+@@ -1,28 +1,28 @@
+-[package]
+-edition = "2024"
+-name = "codex-apply-patch"
+-version = { workspace = true }
+-
+-[lib]
+-name = "codex_apply_patch"
+-path = "src/lib.rs"
+-
+-[[bin]]
+-name = "apply_patch"
+-path = "src/main.rs"
+-
+-[lints]
+-workspace = true
+-
+-[dependencies]
+-anyhow = { workspace = true }
+-similar = { workspace = true }
+-thiserror = { workspace = true }
+-tree-sitter = { workspace = true }
+-tree-sitter-bash = { workspace = true }
+-
+-[dev-dependencies]
+-assert_cmd = { workspace = true }
+-assert_matches = { workspace = true }
+-pretty_assertions = { workspace = true }
+-tempfile = { workspace = true }
++[package]
++edition = "2024"
++name = "codex-apply-patch"
++version = { workspace = true }
++
++[lib]
++name = "codex_apply_patch"
++path = "src/lib.rs"
++
++[[bin]]
++name = "apply_patch"
++path = "src/main.rs"
++
++[lints]
++workspace = true
++
++[dependencies]
++anyhow = { workspace = true }
++similar = { workspace = true }
++thiserror = { workspace = true }
++tree-sitter = { workspace = true }
++tree-sitter-bash = { workspace = true }
++
++[dev-dependencies]
++assert_cmd = { workspace = true }
++assert_matches = { workspace = true }
++pretty_assertions = { workspace = true }
++tempfile = { workspace = true }
+diff --git a/codex-rs/apply-patch/apply_patch_tool_instructions.md b/codex-rs/apply-patch/apply_patch_tool_instructions.md
+index 64114daa..d786f471 100644
+--- a/codex-rs/apply-patch/apply_patch_tool_instructions.md
++++ b/codex-rs/apply-patch/apply_patch_tool_instructions.md
+@@ -1,75 +1,75 @@
+-## `apply_patch`
+-
+-Use the `apply_patch` shell command to edit files.
+-Your patch language is a stripped‑down, file‑oriented diff format designed to be easy to parse and safe to apply. You can think of it as a high‑level envelope:
+-
+-*** Begin Patch
+-[ one or more file sections ]
+-*** End Patch
+-
+-Within that envelope, you get a sequence of file operations.
+-You MUST include a header to specify the action you are taking.
+-Each operation starts with one of three headers:
+-
+-*** Add File: <path> - create a new file. Every following line is a + line (the initial contents).
+-*** Delete File: <path> - remove an existing file. Nothing follows.
+-*** Update File: <path> - patch an existing file in place (optionally with a rename).
+-
+-May be immediately followed by *** Move to: <new path> if you want to rename the file.
+-Then one or more “hunks”, each introduced by @@ (optionally followed by a hunk header).
+-Within a hunk each line starts with:
+-
+-For instructions on [context_before] and [context_after]:
+-- By default, show 3 lines of code immediately above and 3 lines immediately below each change. If a change is within 3 lines of a previous change, do NOT duplicate the first change’s [context_after] lines in the second change’s [context_before] lines.
+-- If 3 lines of context is insufficient to uniquely identify the snippet of code within the file, use the @@ operator to indicate the class or function to which the snippet belongs. For instance, we might have:
+-@@ class BaseClass
+-[3 lines of pre-context]
+-- [old_code]
+-+ [new_code]
+-[3 lines of post-context]
+-
+-- If a code block is repeated so many times in a class or function such that even a single `@@` statement and 3 lines of context cannot uniquely identify the snippet of code, you can use multiple `@@` statements to jump to the right context. For instance:
+-
+-@@ class BaseClass
+-@@ 	 def method():
+-[3 lines of pre-context]
+-- [old_code]
+-+ [new_code]
+-[3 lines of post-context]
+-
+-The full grammar definition is below:
+-Patch := Begin { FileOp } End
+-Begin := "*** Begin Patch" NEWLINE
+-End := "*** End Patch" NEWLINE
+-FileOp := AddFile | DeleteFile | UpdateFile
+-AddFile := "*** Add File: " path NEWLINE { "+" line NEWLINE }
+-DeleteFile := "*** Delete File: " path NEWLINE
+-UpdateFile := "*** Update File: " path NEWLINE [ MoveTo ] { Hunk }
+-MoveTo := "*** Move to: " newPath NEWLINE
+-Hunk := "@@" [ header ] NEWLINE { HunkLine } [ "*** End of File" NEWLINE ]
+-HunkLine := (" " | "-" | "+") text NEWLINE
+-
+-A full patch can combine several operations:
+-
+-*** Begin Patch
+-*** Add File: hello.txt
+-+Hello world
+-*** Update File: src/app.py
+-*** Move to: src/main.py
+-@@ def greet():
+--print("Hi")
+-+print("Hello, world!")
+-*** Delete File: obsolete.txt
+-*** End Patch
+-
+-It is important to remember:
+-
+-- You must include a header with your intended action (Add/Delete/Update)
+-- You must prefix new lines with `+` even when creating a new file
+-- File references can only be relative, NEVER ABSOLUTE.
+-
+-You can invoke apply_patch like:
+-
+-```
+-shell {"command":["apply_patch","*** Begin Patch\n*** Add File: hello.txt\n+Hello, world!\n*** End Patch\n"]}
+-```
++## `apply_patch`
++
++Use the `apply_patch` shell command to edit files.
++Your patch language is a stripped‑down, file‑oriented diff format designed to be easy to parse and safe to apply. You can think of it as a high‑level envelope:
++
++*** Begin Patch
++[ one or more file sections ]
++*** End Patch
++
++Within that envelope, you get a sequence of file operations.
++You MUST include a header to specify the action you are taking.
++Each operation starts with one of three headers:
++
++*** Add File: <path> - create a new file. Every following line is a + line (the initial contents).
++*** Delete File: <path> - remove an existing file. Nothing follows.
++*** Update File: <path> - patch an existing file in place (optionally with a rename).
++
++May be immediately followed by *** Move to: <new path> if you want to rename the file.
++Then one or more “hunks”, each introduced by @@ (optionally followed by a hunk header).
++Within a hunk each line starts with
\ No newline at end of file
diff --git a/.code/agents/18051/exec-call_Sx6wSTUpNVdl4uJnwsUfX887.txt b/.code/agents/18051/exec-call_Sx6wSTUpNVdl4uJnwsUfX887.txt
new file mode 100644
index 00000000..90705e47
--- /dev/null
+++ b/.code/agents/18051/exec-call_Sx6wSTUpNVdl4uJnwsUfX887.txt
@@ -0,0 +1,1125 @@
+## main...origin/main
+ M .codespellignore
+ M .codespellrc
+ M .devcontainer/Dockerfile
+ M .devcontainer/README.md
+ M .devcontainer/devcontainer.json
+ M .github/ISSUE_TEMPLATE/2-bug-report.yml
+ M .github/ISSUE_TEMPLATE/3-docs-issue.yml
+ M .github/ISSUE_TEMPLATE/4-feature-request.yml
+ M .github/ISSUE_TEMPLATE/5-vs-code-extension.yml
+ M .github/codex/home/config.toml
+ M .github/codex/labels/codex-attempt.md
+ M .github/codex/labels/codex-review.md
+ M .github/codex/labels/codex-rust-review.md
+ M .github/codex/labels/codex-triage.md
+ M .github/dependabot.yaml
+ M .github/dotslash-config.json
+ M .github/prompts/issue-deduplicator.txt
+ M .github/prompts/issue-labeler.txt
+ M .github/pull_request_template.md
+ M .github/workflows/ci.yml
+ M .github/workflows/cla.yml
+ M .github/workflows/codespell.yml
+ M .github/workflows/issue-deduplicator.yml
+ M .github/workflows/issue-labeler.yml
+ M .github/workflows/rust-ci.yml
+ M .github/workflows/rust-release.yml
+ M .github/workflows/sdk.yml
+ M .gitignore
+ M .npmrc
+ M .prettierignore
+ M .prettierrc.toml
+ M .vscode/extensions.json
+ M .vscode/launch.json
+ M .vscode/settings.json
+ M AGENTS.md
+ M CHANGELOG.md
+ M LICENSE
+ M NOTICE
+ M PNPM.md
+ M README.md
+ M cliff.toml
+ M codex-cli/.dockerignore
+ M codex-cli/.gitignore
+ M codex-cli/Dockerfile
+ M codex-cli/README.md
+ M codex-cli/bin/codex.js
+ M codex-cli/bin/rg
+ M codex-cli/package-lock.json
+ M codex-cli/package.json
+ M codex-cli/scripts/README.md
+ M codex-cli/scripts/build_container.sh
+ M codex-cli/scripts/build_npm_package.py
+ M codex-cli/scripts/init_firewall.sh
+ M codex-cli/scripts/install_native_deps.py
+ M codex-cli/scripts/run_in_container.sh
+ M codex-rs/.gitignore
+ M codex-rs/Cargo.lock
+ M codex-rs/Cargo.toml
+ M codex-rs/README.md
+ M codex-rs/ansi-escape/Cargo.toml
+ M codex-rs/ansi-escape/README.md
+ M codex-rs/ansi-escape/src/lib.rs
+ M codex-rs/app-server-protocol/Cargo.toml
+ M codex-rs/app-server-protocol/src/jsonrpc_lite.rs
+ M codex-rs/app-server-protocol/src/lib.rs
+ M codex-rs/app-server-protocol/src/protocol.rs
+ M codex-rs/app-server/Cargo.toml
+ M codex-rs/app-server/README.md
+ M codex-rs/app-server/src/codex_message_processor.rs
+ M codex-rs/app-server/src/error_code.rs
+ M codex-rs/app-server/src/fuzzy_file_search.rs
+ M codex-rs/app-server/src/lib.rs
+ M codex-rs/app-server/src/main.rs
+ M codex-rs/app-server/src/message_processor.rs
+ M codex-rs/app-server/src/outgoing_message.rs
+ M codex-rs/app-server/tests/all.rs
+ M codex-rs/app-server/tests/common/Cargo.toml
+ M codex-rs/app-server/tests/common/lib.rs
+ M codex-rs/app-server/tests/common/mcp_process.rs
+ M codex-rs/app-server/tests/common/mock_model_server.rs
+ M codex-rs/app-server/tests/common/responses.rs
+ M codex-rs/app-server/tests/suite/archive_conversation.rs
+ M codex-rs/app-server/tests/suite/auth.rs
+ M codex-rs/app-server/tests/suite/codex_message_processor_flow.rs
+ M codex-rs/app-server/tests/suite/config.rs
+ M codex-rs/app-server/tests/suite/create_conversation.rs
+ M codex-rs/app-server/tests/suite/fuzzy_file_search.rs
+ M codex-rs/app-server/tests/suite/interrupt.rs
+ M codex-rs/app-server/tests/suite/list_resume.rs
+ M codex-rs/app-server/tests/suite/login.rs
+ M codex-rs/app-server/tests/suite/mod.rs
+ M codex-rs/app-server/tests/suite/send_message.rs
+ M codex-rs/app-server/tests/suite/set_default_model.rs
+ M codex-rs/app-server/tests/suite/user_agent.rs
+ M codex-rs/app-server/tests/suite/user_info.rs
+ M codex-rs/apply-patch/Cargo.toml
+ M codex-rs/apply-patch/apply_patch_tool_instructions.md
+ M codex-rs/apply-patch/src/lib.rs
+ M codex-rs/apply-patch/src/main.rs
+ M codex-rs/apply-patch/src/parser.rs
+ M codex-rs/apply-patch/src/seek_sequence.rs
+ M codex-rs/apply-patch/src/standalone_executable.rs
+ M codex-rs/apply-patch/tests/all.rs
+ M codex-rs/apply-patch/tests/suite/cli.rs
+ M codex-rs/apply-patch/tests/suite/mod.rs
+ M codex-rs/arg0/Cargo.toml
+ M codex-rs/arg0/src/lib.rs
+ M codex-rs/backend-client/Cargo.toml
+ M codex-rs/backend-client/src/client.rs
+ M codex-rs/backend-client/src/lib.rs
+ M codex-rs/backend-client/src/types.rs
+ M codex-rs/backend-client/tests/fixtures/task_details_with_diff.json
+ M codex-rs/backend-client/tests/fixtures/task_details_with_error.json
+ M codex-rs/chatgpt/Cargo.toml
+ M codex-rs/chatgpt/README.md
+ M codex-rs/chatgpt/src/apply_command.rs
+ M codex-rs/chatgpt/src/chatgpt_client.rs
+ M codex-rs/chatgpt/src/chatgpt_token.rs
+ M codex-rs/chatgpt/src/get_task.rs
+ M codex-rs/chatgpt/src/lib.rs
+ M codex-rs/chatgpt/tests/all.rs
+ M codex-rs/chatgpt/tests/suite/apply_command_e2e.rs
+ M codex-rs/chatgpt/tests/suite/mod.rs
+ M codex-rs/chatgpt/tests/task_turn_fixture.json
+ M codex-rs/cli/Cargo.toml
+ M codex-rs/cli/src/debug_sandbox.rs
+ M codex-rs/cli/src/exit_status.rs
+ M codex-rs/cli/src/lib.rs
+ M codex-rs/cli/src/login.rs
+ M codex-rs/cli/src/main.rs
+ M codex-rs/cli/src/mcp_cmd.rs
+ M codex-rs/cli/tests/mcp_add_remove.rs
+ M codex-rs/cli/tests/mcp_list.rs
+ M codex-rs/clippy.toml
+ M codex-rs/cloud-tasks-client/Cargo.toml
+ M codex-rs/cloud-tasks-client/src/api.rs
+ M codex-rs/cloud-tasks-client/src/http.rs
+ M codex-rs/cloud-tasks-client/src/lib.rs
+ M codex-rs/cloud-tasks-client/src/mock.rs
+ M codex-rs/cloud-tasks/Cargo.toml
+ M codex-rs/cloud-tasks/src/app.rs
+ M codex-rs/cloud-tasks/src/cli.rs
+ M codex-rs/cloud-tasks/src/env_detect.rs
+ M codex-rs/cloud-tasks/src/lib.rs
+ M codex-rs/cloud-tasks/src/new_task.rs
+ M codex-rs/cloud-tasks/src/scrollable_diff.rs
+ M codex-rs/cloud-tasks/src/ui.rs
+ M codex-rs/cloud-tasks/src/util.rs
+ M codex-rs/cloud-tasks/tests/env_filter.rs
+ M codex-rs/codex-backend-openapi-models/Cargo.toml
+ M codex-rs/codex-backend-openapi-models/src/lib.rs
+ M codex-rs/codex-backend-openapi-models/src/models/code_task_details_response.rs
+ M codex-rs/codex-backend-openapi-models/src/models/external_pull_request_response.rs
+ M codex-rs/codex-backend-openapi-models/src/models/git_pull_request.rs
+ M codex-rs/codex-backend-openapi-models/src/models/mod.rs
+ M codex-rs/codex-backend-openapi-models/src/models/paginated_list_task_list_item_.rs
+ M codex-rs/codex-backend-openapi-models/src/models/task_list_item.rs
+ M codex-rs/codex-backend-openapi-models/src/models/task_response.rs
+ M codex-rs/common/Cargo.toml
+ M codex-rs/common/README.md
+ M codex-rs/common/src/approval_mode_cli_arg.rs
+ M codex-rs/common/src/approval_presets.rs
+ M codex-rs/common/src/config_override.rs
+ M codex-rs/common/src/config_summary.rs
+ M codex-rs/common/src/elapsed.rs
+ M codex-rs/common/src/fuzzy_match.rs
+ M codex-rs/common/src/lib.rs
+ M codex-rs/common/src/model_presets.rs
+ M codex-rs/common/src/sandbox_mode_cli_arg.rs
+ M codex-rs/common/src/sandbox_summary.rs
+ M codex-rs/config.md
+ M codex-rs/core/Cargo.toml
+ M codex-rs/core/README.md
+ M codex-rs/core/gpt_5_codex_prompt.md
+ M codex-rs/core/prompt.md
+ M codex-rs/core/review_prompt.md
+ M codex-rs/core/src/apply_patch.rs
+ M codex-rs/core/src/auth.rs
+ M codex-rs/core/src/bash.rs
+ M codex-rs/core/src/chat_completions.rs
+ M codex-rs/core/src/client.rs
+ M codex-rs/core/src/client_common.rs
+ M codex-rs/core/src/codex.rs
+ M codex-rs/core/src/codex/compact.rs
+ M codex-rs/core/src/codex_conversation.rs
+ M codex-rs/core/src/command_safety/is_dangerous_command.rs
+ M codex-rs/core/src/command_safety/is_safe_command.rs
+ M codex-rs/core/src/command_safety/mod.rs
+ M codex-rs/core/src/command_safety/windows_safe_commands.rs
+ M codex-rs/core/src/config.rs
+ M codex-rs/core/src/config_edit.rs
+ M codex-rs/core/src/config_loader/macos.rs
+ M codex-rs/core/src/config_loader/mod.rs
+ M codex-rs/core/src/config_profile.rs
+ M codex-rs/core/src/config_types.rs
+ M codex-rs/core/src/conversation_history.rs
+ M codex-rs/core/src/conversation_manager.rs
+ M codex-rs/core/src/custom_prompts.rs
+ M codex-rs/core/src/default_client.rs
+ M codex-rs/core/src/environment_context.rs
+ M codex-rs/core/src/error.rs
+ M codex-rs/core/src/event_mapping.rs
+ M codex-rs/core/src/exec.rs
+ M codex-rs/core/src/exec_command/exec_command_params.rs
+ M codex-rs/core/src/exec_command/exec_command_session.rs
+ M codex-rs/core/src/exec_command/mod.rs
+ M codex-rs/core/src/exec_command/responses_api.rs
+ M codex-rs/core/src/exec_command/session_id.rs
+ M codex-rs/core/src/exec_command/session_manager.rs
+ M codex-rs/core/src/exec_env.rs
+ M codex-rs/core/src/executor/backends.rs
+ M codex-rs/core/src/executor/cache.rs
+ M codex-rs/core/src/executor/mod.rs
+ M codex-rs/core/src/executor/runner.rs
+ M codex-rs/core/src/executor/sandbox.rs
+ M codex-rs/core/src/features.rs
+ M codex-rs/core/src/features/legacy.rs
+ M codex-rs/core/src/flags.rs
+ M codex-rs/core/src/function_tool.rs
+ M codex-rs/core/src/git_info.rs
+ M codex-rs/core/src/landlock.rs
+ M codex-rs/core/src/lib.rs
+ M codex-rs/core/src/mcp/auth.rs
+ M codex-rs/core/src/mcp/mod.rs
+ M codex-rs/core/src/mcp_connection_manager.rs
+ M codex-rs/core/src/mcp_tool_call.rs
+ M codex-rs/core/src/message_history.rs
+ M codex-rs/core/src/model_family.rs
+ M codex-rs/core/src/model_provider_info.rs
+ M codex-rs/core/src/openai_model_info.rs
+ M codex-rs/core/src/openai_tools.rs
+ M codex-rs/core/src/otel_init.rs
+ M codex-rs/core/src/parse_command.rs
+ M codex-rs/core/src/project_doc.rs
+ M codex-rs/core/src/review_format.rs
+ M codex-rs/core/src/rollout/list.rs
+ M codex-rs/core/src/rollout/mod.rs
+ M codex-rs/core/src/rollout/policy.rs
+ M codex-rs/core/src/rollout/recorder.rs
+ M codex-rs/core/src/rollout/tests.rs
+ M codex-rs/core/src/safety.rs
+ M codex-rs/core/src/seatbelt.rs
+ M codex-rs/core/src/seatbelt_base_policy.sbpl
+ M codex-rs/core/src/shell.rs
+ M codex-rs/core/src/spawn.rs
+ M codex-rs/core/src/state/mod.rs
+ M codex-rs/core/src/state/service.rs
+ M codex-rs/core/src/state/session.rs
+ M codex-rs/core/src/state/turn.rs
+ M codex-rs/core/src/tasks/compact.rs
+ M codex-rs/core/src/tasks/mod.rs
+ M codex-rs/core/src/tasks/regular.rs
+ M codex-rs/core/src/tasks/review.rs
+ M codex-rs/core/src/terminal.rs
+ M codex-rs/core/src/token_data.rs
+ M codex-rs/core/src/tools/context.rs
+ M codex-rs/core/src/tools/handlers/apply_patch.rs
+ M codex-rs/core/src/tools/handlers/exec_stream.rs
+ M codex-rs/core/src/tools/handlers/grep_files.rs
+ M codex-rs/core/src/tools/handlers/list_dir.rs
+ M codex-rs/core/src/tools/handlers/mcp.rs
+ M codex-rs/core/src/tools/handlers/mod.rs
+ M codex-rs/core/src/tools/handlers/plan.rs
+ M codex-rs/core/src/tools/handlers/read_file.rs
+ M codex-rs/core/src/tools/handlers/shell.rs
+ M codex-rs/core/src/tools/handlers/test_sync.rs
+ M codex-rs/core/src/tools/handlers/tool_apply_patch.lark
+ M codex-rs/core/src/tools/handlers/unified_exec.rs
+ M codex-rs/core/src/tools/handlers/view_image.rs
+ M codex-rs/core/src/tools/mod.rs
+ M codex-rs/core/src/tools/parallel.rs
+ M codex-rs/core/src/tools/registry.rs
+ M codex-rs/core/src/tools/router.rs
+ M codex-rs/core/src/tools/spec.rs
+ M codex-rs/core/src/truncate.rs
+ M codex-rs/core/src/turn_diff_tracker.rs
+ M codex-rs/core/src/unified_exec/errors.rs
+ M codex-rs/core/src/unified_exec/mod.rs
+ M codex-rs/core/src/user_instructions.rs
+ M codex-rs/core/src/user_notification.rs
+ M codex-rs/core/src/util.rs
+ M codex-rs/core/templates/compact/history_bridge.md
+ M codex-rs/core/templates/compact/prompt.md
+ M codex-rs/core/tests/all.rs
+ M codex-rs/core/tests/chat_completions_payload.rs
+ M codex-rs/core/tests/chat_completions_sse.rs
+ M codex-rs/core/tests/cli_responses_fixture.sse
+ M codex-rs/core/tests/common/Cargo.toml
+ M codex-rs/core/tests/common/lib.rs
+ M codex-rs/core/tests/common/responses.rs
+ M codex-rs/core/tests/common/test_codex.rs
+ M codex-rs/core/tests/common/test_codex_exec.rs
+ M codex-rs/core/tests/fixtures/completed_template.json
+ M codex-rs/core/tests/fixtures/incomplete_sse.json
+ M codex-rs/core/tests/responses_headers.rs
+ M codex-rs/core/tests/suite/abort_tasks.rs
+ M codex-rs/core/tests/suite/cli_stream.rs
+ M codex-rs/core/tests/suite/client.rs
+ M codex-rs/core/tests/suite/compact.rs
+ M codex-rs/core/tests/suite/compact_resume_fork.rs
+ M codex-rs/core/tests/suite/exec.rs
+ M codex-rs/core/tests/suite/exec_stream_events.rs
+ M codex-rs/core/tests/suite/fork_conversation.rs
+ M codex-rs/core/tests/suite/grep_files.rs
+ M codex-rs/core/tests/suite/json_result.rs
+ M codex-rs/core/tests/suite/list_dir.rs
+ M codex-rs/core/tests/suite/live_cli.rs
+ M codex-rs/core/tests/suite/mod.rs
+ M codex-rs/core/tests/suite/model_overrides.rs
+ M codex-rs/core/tests/suite/model_tools.rs
+ M codex-rs/core/tests/suite/otel.rs
+ M codex-rs/core/tests/suite/prompt_caching.rs
+ M codex-rs/core/tests/suite/read_file.rs
+ M codex-rs/core/tests/suite/review.rs
+ M codex-rs/core/tests/suite/rmcp_client.rs
+ M codex-rs/core/tests/suite/rollout_list_find.rs
+ M codex-rs/core/tests/suite/seatbelt.rs
+ M codex-rs/core/tests/suite/shell_serialization.rs
+ M codex-rs/core/tests/suite/stream_error_allows_next_turn.rs
+ M codex-rs/core/tests/suite/stream_no_completed.rs
+ M codex-rs/core/tests/suite/tool_harness.rs
+ M codex-rs/core/tests/suite/tool_parallelism.rs
+ M codex-rs/core/tests/suite/tools.rs
+ M codex-rs/core/tests/suite/unified_exec.rs
+ M codex-rs/core/tests/suite/user_notification.rs
+ M codex-rs/core/tests/suite/view_image.rs
+ M codex-rs/default.nix
+ M codex-rs/docs/codex_mcp_interface.md
+ M codex-rs/docs/protocol_v1.md
+ M codex-rs/exec/Cargo.toml
+ M codex-rs/exec/src/cli.rs
+ M codex-rs/exec/src/event_processor.rs
+ M codex-rs/exec/src/event_processor_with_human_output.rs
+ M codex-rs/exec/src/event_processor_with_jsonl_output.rs
+ M codex-rs/exec/src/exec_events.rs
+ M codex-rs/exec/src/lib.rs
+ M codex-rs/exec/src/main.rs
+ M codex-rs/exec/tests/all.rs
+ M codex-rs/exec/tests/event_processor_with_json_output.rs
+ M codex-rs/exec/tests/fixtures/apply_patch_freeform_final.txt
+ M codex-rs/exec/tests/fixtures/cli_responses_fixture.sse
+ M codex-rs/exec/tests/suite/apply_patch.rs
+ M codex-rs/exec/tests/suite/auth_env.rs
+ M codex-rs/exec/tests/suite/mod.rs
+ M codex-rs/exec/tests/suite/originator.rs
+ M codex-rs/exec/tests/suite/output_schema.rs
+ M codex-rs/exec/tests/suite/resume.rs
+ M codex-rs/exec/tests/suite/sandbox.rs
+ M codex-rs/exec/tests/suite/server_error_exit.rs
+ M codex-rs/execpolicy/Cargo.toml
+ M codex-rs/execpolicy/README.md
+ M codex-rs/execpolicy/build.rs
+ M codex-rs/execpolicy/src/arg_matcher.rs
+ M codex-rs/execpolicy/src/arg_resolver.rs
+ M codex-rs/execpolicy/src/arg_type.rs
+ M codex-rs/execpolicy/src/default.policy
+ M codex-rs/execpolicy/src/error.rs
+ M codex-rs/execpolicy/src/exec_call.rs
+ M codex-rs/execpolicy/src/execv_checker.rs
+ M codex-rs/execpolicy/src/lib.rs
+ M codex-rs/execpolicy/src/main.rs
+ M codex-rs/execpolicy/src/opt.rs
+ M codex-rs/execpolicy/src/policy.rs
+ M codex-rs/execpolicy/src/policy_parser.rs
+ M codex-rs/execpolicy/src/program.rs
+ M codex-rs/execpolicy/src/sed_command.rs
+ M codex-rs/execpolicy/src/valid_exec.rs
+ M codex-rs/execpolicy/tests/all.rs
+ M codex-rs/execpolicy/tests/suite/bad.rs
+ M codex-rs/execpolicy/tests/suite/cp.rs
+ M codex-rs/execpolicy/tests/suite/good.rs
+ M codex-rs/execpolicy/tests/suite/head.rs
+ M codex-rs/execpolicy/tests/suite/literal.rs
+ M codex-rs/execpolicy/tests/suite/ls.rs
+ M codex-rs/execpolicy/tests/suite/mod.rs
+ M codex-rs/execpolicy/tests/suite/parse_sed_command.rs
+ M codex-rs/execpolicy/tests/suite/pwd.rs
+ M codex-rs/execpolicy/tests/suite/sed.rs
+ M codex-rs/file-search/Cargo.toml
+ M codex-rs/file-search/README.md
+ M codex-rs/file-search/src/cli.rs
+ M codex-rs/file-search/src/lib.rs
+ M codex-rs/file-search/src/main.rs
+ M codex-rs/git-apply/Cargo.toml
+ M codex-rs/git-apply/src/lib.rs
+ M codex-rs/git-tooling/Cargo.toml
+ M codex-rs/git-tooling/README.md
+ M codex-rs/git-tooling/src/errors.rs
+ M codex-rs/git-tooling/src/ghost_commits.rs
+ M codex-rs/git-tooling/src/lib.rs
+ M codex-rs/git-tooling/src/operations.rs
+ M codex-rs/git-tooling/src/platform.rs
+ M codex-rs/justfile
+ M codex-rs/linux-sandbox/Cargo.toml
+ M codex-rs/linux-sandbox/README.md
+ M codex-rs/linux-sandbox/src/landlock.rs
+ M codex-rs/linux-sandbox/src/lib.rs
+ M codex-rs/linux-sandbox/src/linux_run_main.rs
+ M codex-rs/linux-sandbox/src/main.rs
+ M codex-rs/linux-sandbox/tests/all.rs
+ M codex-rs/linux-sandbox/tests/suite/landlock.rs
+ M codex-rs/linux-sandbox/tests/suite/mod.rs
+ M codex-rs/login/Cargo.toml
+ M codex-rs/login/src/assets/success.html
+ M codex-rs/login/src/device_code_auth.rs
+ M codex-rs/login/src/lib.rs
+ M codex-rs/login/src/pkce.rs
+ M codex-rs/login/src/server.rs
+ M codex-rs/login/tests/all.rs
+ M codex-rs/login/tests/suite/device_code_login.rs
+ M codex-rs/login/tests/suite/login_server_e2e.rs
+ M codex-rs/login/tests/suite/mod.rs
+ M codex-rs/mcp-client/Cargo.toml
+ M codex-rs/mcp-client/src/lib.rs
+ M codex-rs/mcp-client/src/main.rs
+ M codex-rs/mcp-client/src/mcp_client.rs
+ M codex-rs/mcp-server/Cargo.toml
+ M codex-rs/mcp-server/src/codex_tool_config.rs
+ M codex-rs/mcp-server/src/codex_tool_runner.rs
+ M codex-rs/mcp-server/src/error_code.rs
+ M codex-rs/mcp-server/src/exec_approval.rs
+ M codex-rs/mcp-server/src/lib.rs
+ M codex-rs/mcp-server/src/main.rs
+ M codex-rs/mcp-server/src/message_processor.rs
+ M codex-rs/mcp-server/src/outgoing_message.rs
+ M codex-rs/mcp-server/src/patch_approval.rs
+ M codex-rs/mcp-server/src/tool_handlers/mod.rs
+ M codex-rs/mcp-server/tests/all.rs
+ M codex-rs/mcp-server/tests/common/Cargo.toml
+ M codex-rs/mcp-server/tests/common/lib.rs
+ M codex-rs/mcp-server/tests/common/mcp_process.rs
+ M codex-rs/mcp-server/tests/common/mock_model_server.rs
+ M codex-rs/mcp-server/tests/common/responses.rs
+ M codex-rs/mcp-server/tests/suite/codex_tool.rs
+ M codex-rs/mcp-server/tests/suite/mod.rs
+ M codex-rs/mcp-types/Cargo.toml
+ M codex-rs/mcp-types/README.md
+ M codex-rs/mcp-types/check_lib_rs.py
+ M codex-rs/mcp-types/generate_mcp_types.py
+ M codex-rs/mcp-types/schema/2025-03-26/schema.json
+ M codex-rs/mcp-types/schema/2025-06-18/schema.json
+ M codex-rs/mcp-types/src/lib.rs
+ M codex-rs/mcp-types/tests/all.rs
+ M codex-rs/mcp-types/tests/suite/initialize.rs
+ M codex-rs/mcp-types/tests/suite/mod.rs
+ M codex-rs/mcp-types/tests/suite/progress_notification.rs
+ M codex-rs/ollama/Cargo.toml
+ M codex-rs/ollama/src/client.rs
+ M codex-rs/ollama/src/lib.rs
+ M codex-rs/ollama/src/parser.rs
+ M codex-rs/ollama/src/pull.rs
+ M codex-rs/ollama/src/url.rs
+ M codex-rs/otel/Cargo.toml
+ M codex-rs/otel/src/config.rs
+ M codex-rs/otel/src/lib.rs
+ M codex-rs/otel/src/otel_event_manager.rs
+ M codex-rs/otel/src/otel_provider.rs
+ M codex-rs/process-hardening/Cargo.toml
+ M codex-rs/process-hardening/README.md
+ M codex-rs/process-hardening/src/lib.rs
+ M codex-rs/protocol-ts/Cargo.toml
+ M codex-rs/protocol-ts/generate-ts
+ M codex-rs/protocol-ts/src/lib.rs
+ M codex-rs/protocol-ts/src/main.rs
+ M codex-rs/protocol/Cargo.toml
+ M codex-rs/protocol/README.md
+ M codex-rs/protocol/src/config_types.rs
+ M codex-rs/protocol/src/conversation_id.rs
+ M codex-rs/protocol/src/custom_prompts.rs
+ M codex-rs/protocol/src/lib.rs
+ M codex-rs/protocol/src/message_history.rs
+ M codex-rs/protocol/src/models.rs
+ M codex-rs/protocol/src/num_format.rs
+ M codex-rs/protocol/src/parse_command.rs
+ M codex-rs/protocol/src/plan_tool.rs
+ M codex-rs/protocol/src/protocol.rs
+ M codex-rs/responses-api-proxy/Cargo.toml
+ M codex-rs/responses-api-proxy/README.md
+ M codex-rs/responses-api-proxy/npm/README.md
+ M codex-rs/responses-api-proxy/npm/bin/codex-responses-api-proxy.js
+ M codex-rs/responses-api-proxy/npm/package.json
+ M codex-rs/responses-api-proxy/src/lib.rs
+ M codex-rs/responses-api-proxy/src/main.rs
+ M codex-rs/responses-api-proxy/src/read_api_key.rs
+ M codex-rs/rmcp-client/Cargo.toml
+ M codex-rs/rmcp-client/src/auth_status.rs
+ M codex-rs/rmcp-client/src/bin/rmcp_test_server.rs
+ M codex-rs/rmcp-client/src/bin/test_stdio_server.rs
+ M codex-rs/rmcp-client/src/bin/test_streamable_http_server.rs
+ M codex-rs/rmcp-client/src/find_codex_home.rs
+ M codex-rs/rmcp-client/src/lib.rs
+ M codex-rs/rmcp-client/src/logging_client_handler.rs
+ M codex-rs/rmcp-client/src/oauth.rs
+ M codex-rs/rmcp-client/src/perform_oauth_login.rs
+ M codex-rs/rmcp-client/src/rmcp_client.rs
+ M codex-rs/rmcp-client/src/utils.rs
+ M codex-rs/rust-toolchain.toml
+ M codex-rs/rustfmt.toml
+ M codex-rs/scripts/create_github_release
+ M codex-rs/tui/Cargo.toml
+ M codex-rs/tui/frames/blocks/frame_1.txt
+ M codex-rs/tui/frames/blocks/frame_10.txt
+ M codex-rs/tui/frames/blocks/frame_11.txt
+ M codex-rs/tui/frames/blocks/frame_12.txt
+ M codex-rs/tui/frames/blocks/frame_13.txt
+ M codex-rs/tui/frames/blocks/frame_14.txt
+ M codex-rs/tui/frames/blocks/frame_15.txt
+ M codex-rs/tui/frames/blocks/frame_16.txt
+ M codex-rs/tui/frames/blocks/frame_17.txt
+ M codex-rs/tui/frames/blocks/frame_18.txt
+ M codex-rs/tui/frames/blocks/frame_19.txt
+ M codex-rs/tui/frames/blocks/frame_2.txt
+ M codex-rs/tui/frames/blocks/frame_20.txt
+ M codex-rs/tui/frames/blocks/frame_21.txt
+ M codex-rs/tui/frames/blocks/frame_22.txt
+ M codex-rs/tui/frames/blocks/frame_23.txt
+ M codex-rs/tui/frames/blocks/frame_24.txt
+ M codex-rs/tui/frames/blocks/frame_25.txt
+ M codex-rs/tui/frames/blocks/frame_26.txt
+ M codex-rs/tui/frames/blocks/frame_27.txt
+ M codex-rs/tui/frames/blocks/frame_28.txt
+ M codex-rs/tui/frames/blocks/frame_29.txt
+ M codex-rs/tui/frames/blocks/frame_3.txt
+ M codex-rs/tui/frames/blocks/frame_30.txt
+ M codex-rs/tui/frames/blocks/frame_31.txt
+ M codex-rs/tui/frames/blocks/frame_32.txt
+ M codex-rs/tui/frames/blocks/frame_33.txt
+ M codex-rs/tui/frames/blocks/frame_34.txt
+ M codex-rs/tui/frames/blocks/frame_35.txt
+ M codex-rs/tui/frames/blocks/frame_36.txt
+ M codex-rs/tui/frames/blocks/frame_4.txt
+ M codex-rs/tui/frames/blocks/frame_5.txt
+ M codex-rs/tui/frames/blocks/frame_6.txt
+ M codex-rs/tui/frames/blocks/frame_7.txt
+ M codex-rs/tui/frames/blocks/frame_8.txt
+ M codex-rs/tui/frames/blocks/frame_9.txt
+ M codex-rs/tui/frames/codex/frame_1.txt
+ M codex-rs/tui/frames/codex/frame_10.txt
+ M codex-rs/tui/frames/codex/frame_11.txt
+ M codex-rs/tui/frames/codex/frame_12.txt
+ M codex-rs/tui/frames/codex/frame_13.txt
+ M codex-rs/tui/frames/codex/frame_14.txt
+ M codex-rs/tui/frames/codex/frame_15.txt
+ M codex-rs/tui/frames/codex/frame_16.txt
+ M codex-rs/tui/frames/codex/frame_17.txt
+ M codex-rs/tui/frames/codex/frame_18.txt
+ M codex-rs/tui/frames/codex/frame_19.txt
+ M codex-rs/tui/frames/codex/frame_2.txt
+ M codex-rs/tui/frames/codex/frame_20.txt
+ M codex-rs/tui/frames/codex/frame_21.txt
+ M codex-rs/tui/frames/codex/frame_22.txt
+ M codex-rs/tui/frames/codex/frame_23.txt
+ M codex-rs/tui/frames/codex/frame_24.txt
+ M codex-rs/tui/frames/codex/frame_25.txt
+ M codex-rs/tui/frames/codex/frame_26.txt
+ M codex-rs/tui/frames/codex/frame_27.txt
+ M codex-rs/tui/frames/codex/frame_28.txt
+ M codex-rs/tui/frames/codex/frame_29.txt
+ M codex-rs/tui/frames/codex/frame_3.txt
+ M codex-rs/tui/frames/codex/frame_30.txt
+ M codex-rs/tui/frames/codex/frame_31.txt
+ M codex-rs/tui/frames/codex/frame_32.txt
+ M codex-rs/tui/frames/codex/frame_33.txt
+ M codex-rs/tui/frames/codex/frame_34.txt
+ M codex-rs/tui/frames/codex/frame_35.txt
+ M codex-rs/tui/frames/codex/frame_36.txt
+ M codex-rs/tui/frames/codex/frame_4.txt
+ M codex-rs/tui/frames/codex/frame_5.txt
+ M codex-rs/tui/frames/codex/frame_6.txt
+ M codex-rs/tui/frames/codex/frame_7.txt
+ M codex-rs/tui/frames/codex/frame_8.txt
+ M codex-rs/tui/frames/codex/frame_9.txt
+ M codex-rs/tui/frames/default/frame_1.txt
+ M codex-rs/tui/frames/default/frame_10.txt
+ M codex-rs/tui/frames/default/frame_11.txt
+ M codex-rs/tui/frames/default/frame_12.txt
+ M codex-rs/tui/frames/default/frame_13.txt
+ M codex-rs/tui/frames/default/frame_14.txt
+ M codex-rs/tui/frames/default/frame_15.txt
+ M codex-rs/tui/frames/default/frame_16.txt
+ M codex-rs/tui/frames/default/frame_17.txt
+ M codex-rs/tui/frames/default/frame_18.txt
+ M codex-rs/tui/frames/default/frame_19.txt
+ M codex-rs/tui/frames/default/frame_2.txt
+ M codex-rs/tui/frames/default/frame_20.txt
+ M codex-rs/tui/frames/default/frame_21.txt
+ M codex-rs/tui/frames/default/frame_22.txt
+ M codex-rs/tui/frames/default/frame_23.txt
+ M codex-rs/tui/frames/default/frame_24.txt
+ M codex-rs/tui/frames/default/frame_25.txt
+ M codex-rs/tui/frames/default/frame_26.txt
+ M codex-rs/tui/frames/default/frame_27.txt
+ M codex-rs/tui/frames/default/frame_28.txt
+ M codex-rs/tui/frames/default/frame_29.txt
+ M codex-rs/tui/frames/default/frame_3.txt
+ M codex-rs/tui/frames/default/frame_30.txt
+ M codex-rs/tui/frames/default/frame_31.txt
+ M codex-rs/tui/frames/default/frame_32.txt
+ M codex-rs/tui/frames/default/frame_33.txt
+ M codex-rs/tui/frames/default/frame_34.txt
+ M codex-rs/tui/frames/default/frame_35.txt
+ M codex-rs/tui/frames/default/frame_36.txt
+ M codex-rs/tui/frames/default/frame_4.txt
+ M codex-rs/tui/frames/default/frame_5.txt
+ M codex-rs/tui/frames/default/frame_6.txt
+ M codex-rs/tui/frames/default/frame_7.txt
+ M codex-rs/tui/frames/default/frame_8.txt
+ M codex-rs/tui/frames/default/frame_9.txt
+ M codex-rs/tui/frames/dots/frame_1.txt
+ M codex-rs/tui/frames/dots/frame_10.txt
+ M codex-rs/tui/frames/dots/frame_11.txt
+ M codex-rs/tui/frames/dots/frame_12.txt
+ M codex-rs/tui/frames/dots/frame_13.txt
+ M codex-rs/tui/frames/dots/frame_14.txt
+ M codex-rs/tui/frames/dots/frame_15.txt
+ M codex-rs/tui/frames/dots/frame_16.txt
+ M codex-rs/tui/frames/dots/frame_17.txt
+ M codex-rs/tui/frames/dots/frame_18.txt
+ M codex-rs/tui/frames/dots/frame_19.txt
+ M codex-rs/tui/frames/dots/frame_2.txt
+ M codex-rs/tui/frames/dots/frame_20.txt
+ M codex-rs/tui/frames/dots/frame_21.txt
+ M codex-rs/tui/frames/dots/frame_22.txt
+ M codex-rs/tui/frames/dots/frame_23.txt
+ M codex-rs/tui/frames/dots/frame_24.txt
+ M codex-rs/tui/frames/dots/frame_25.txt
+ M codex-rs/tui/frames/dots/frame_26.txt
+ M codex-rs/tui/frames/dots/frame_27.txt
+ M codex-rs/tui/frames/dots/frame_28.txt
+ M codex-rs/tui/frames/dots/frame_29.txt
+ M codex-rs/tui/frames/dots/frame_3.txt
+ M codex-rs/tui/frames/dots/frame_30.txt
+ M codex-rs/tui/frames/dots/frame_31.txt
+ M codex-rs/tui/frames/dots/frame_32.txt
+ M codex-rs/tui/frames/dots/frame_33.txt
+ M codex-rs/tui/frames/dots/frame_34.txt
+ M codex-rs/tui/frames/dots/frame_35.txt
+ M codex-rs/tui/frames/dots/frame_36.txt
+ M codex-rs/tui/frames/dots/frame_4.txt
+ M codex-rs/tui/frames/dots/frame_5.txt
+ M codex-rs/tui/frames/dots/frame_6.txt
+ M codex-rs/tui/frames/dots/frame_7.txt
+ M codex-rs/tui/frames/dots/frame_8.txt
+ M codex-rs/tui/frames/dots/frame_9.txt
+ M codex-rs/tui/frames/hash/frame_1.txt
+ M codex-rs/tui/frames/hash/frame_10.txt
+ M codex-rs/tui/frames/hash/frame_11.txt
+ M codex-rs/tui/frames/hash/frame_12.txt
+ M codex-rs/tui/frames/hash/frame_13.txt
+ M codex-rs/tui/frames/hash/frame_14.txt
+ M codex-rs/tui/frames/hash/frame_15.txt
+ M codex-rs/tui/frames/hash/frame_16.txt
+ M codex-rs/tui/frames/hash/frame_17.txt
+ M codex-rs/tui/frames/hash/frame_18.txt
+ M codex-rs/tui/frames/hash/frame_19.txt
+ M codex-rs/tui/frames/hash/frame_2.txt
+ M codex-rs/tui/frames/hash/frame_20.txt
+ M codex-rs/tui/frames/hash/frame_21.txt
+ M codex-rs/tui/frames/hash/frame_22.txt
+ M codex-rs/tui/frames/hash/frame_23.txt
+ M codex-rs/tui/frames/hash/frame_24.txt
+ M codex-rs/tui/frames/hash/frame_25.txt
+ M codex-rs/tui/frames/hash/frame_26.txt
+ M codex-rs/tui/frames/hash/frame_27.txt
+ M codex-rs/tui/frames/hash/frame_28.txt
+ M codex-rs/tui/frames/hash/frame_29.txt
+ M codex-rs/tui/frames/hash/frame_3.txt
+ M codex-rs/tui/frames/hash/frame_30.txt
+ M codex-rs/tui/frames/hash/frame_31.txt
+ M codex-rs/tui/frames/hash/frame_32.txt
+ M codex-rs/tui/frames/hash/frame_33.txt
+ M codex-rs/tui/frames/hash/frame_34.txt
+ M codex-rs/tui/frames/hash/frame_35.txt
+ M codex-rs/tui/frames/hash/frame_36.txt
+ M codex-rs/tui/frames/hash/frame_4.txt
+ M codex-rs/tui/frames/hash/frame_5.txt
+ M codex-rs/tui/frames/hash/frame_6.txt
+ M codex-rs/tui/frames/hash/frame_7.txt
+ M codex-rs/tui/frames/hash/frame_8.txt
+ M codex-rs/tui/frames/hash/frame_9.txt
+ M codex-rs/tui/frames/hbars/frame_1.txt
+ M codex-rs/tui/frames/hbars/frame_10.txt
+ M codex-rs/tui/frames/hbars/frame_11.txt
+ M codex-rs/tui/frames/hbars/frame_12.txt
+ M codex-rs/tui/frames/hbars/frame_13.txt
+ M codex-rs/tui/frames/hbars/frame_14.txt
+ M codex-rs/tui/frames/hbars/frame_15.txt
+ M codex-rs/tui/frames/hbars/frame_16.txt
+ M codex-rs/tui/frames/hbars/frame_17.txt
+ M codex-rs/tui/frames/hbars/frame_18.txt
+ M codex-rs/tui/frames/hbars/frame_19.txt
+ M codex-rs/tui/frames/hbars/frame_2.txt
+ M codex-rs/tui/frames/hbars/frame_20.txt
+ M codex-rs/tui/frames/hbars/frame_21.txt
+ M codex-rs/tui/frames/hbars/frame_22.txt
+ M codex-rs/tui/frames/hbars/frame_23.txt
+ M codex-rs/tui/frames/hbars/frame_24.txt
+ M codex-rs/tui/frames/hbars/frame_25.txt
+ M codex-rs/tui/frames/hbars/frame_26.txt
+ M codex-rs/tui/frames/hbars/frame_27.txt
+ M codex-rs/tui/frames/hbars/frame_28.txt
+ M codex-rs/tui/frames/hbars/frame_29.txt
+ M codex-rs/tui/frames/hbars/frame_3.txt
+ M codex-rs/tui/frames/hbars/frame_30.txt
+ M codex-rs/tui/frames/hbars/frame_31.txt
+ M codex-rs/tui/frames/hbars/frame_32.txt
+ M codex-rs/tui/frames/hbars/frame_33.txt
+ M codex-rs/tui/frames/hbars/frame_34.txt
+ M codex-rs/tui/frames/hbars/frame_35.txt
+ M codex-rs/tui/frames/hbars/frame_36.txt
+ M codex-rs/tui/frames/hbars/frame_4.txt
+ M codex-rs/tui/frames/hbars/frame_5.txt
+ M codex-rs/tui/frames/hbars/frame_6.txt
+ M codex-rs/tui/frames/hbars/frame_7.txt
+ M codex-rs/tui/frames/hbars/frame_8.txt
+ M codex-rs/tui/frames/hbars/frame_9.txt
+ M codex-rs/tui/frames/openai/frame_1.txt
+ M codex-rs/tui/frames/openai/frame_10.txt
+ M codex-rs/tui/frames/openai/frame_11.txt
+ M codex-rs/tui/frames/openai/frame_12.txt
+ M codex-rs/tui/frames/openai/frame_13.txt
+ M codex-rs/tui/frames/openai/frame_14.txt
+ M codex-rs/tui/frames/openai/frame_15.txt
+ M codex-rs/tui/frames/openai/frame_16.txt
+ M codex-rs/tui/frames/openai/frame_17.txt
+ M codex-rs/tui/frames/openai/frame_18.txt
+ M codex-rs/tui/frames/openai/frame_19.txt
+ M codex-rs/tui/frames/openai/frame_2.txt
+ M codex-rs/tui/frames/openai/frame_20.txt
+ M codex-rs/tui/frames/openai/frame_21.txt
+ M codex-rs/tui/frames/openai/frame_22.txt
+ M codex-rs/tui/frames/openai/frame_23.txt
+ M codex-rs/tui/frames/openai/frame_24.txt
+ M codex-rs/tui/frames/openai/frame_25.txt
+ M codex-rs/tui/frames/openai/frame_26.txt
+ M codex-rs/tui/frames/openai/frame_27.txt
+ M codex-rs/tui/frames/openai/frame_28.txt
+ M codex-rs/tui/frames/openai/frame_29.txt
+ M codex-rs/tui/frames/openai/frame_3.txt
+ M codex-rs/tui/frames/openai/frame_30.txt
+ M codex-rs/tui/frames/openai/frame_31.txt
+ M codex-rs/tui/frames/openai/frame_32.txt
+ M codex-rs/tui/frames/openai/frame_33.txt
+ M codex-rs/tui/frames/openai/frame_34.txt
+ M codex-rs/tui/frames/openai/frame_35.txt
+ M codex-rs/tui/frames/openai/frame_36.txt
+ M codex-rs/tui/frames/openai/frame_4.txt
+ M codex-rs/tui/frames/openai/frame_5.txt
+ M codex-rs/tui/frames/openai/frame_6.txt
+ M codex-rs/tui/frames/openai/frame_7.txt
+ M codex-rs/tui/frames/openai/frame_8.txt
+ M codex-rs/tui/frames/openai/frame_9.txt
+ M codex-rs/tui/frames/shapes/frame_1.txt
+ M codex-rs/tui/frames/shapes/frame_10.txt
+ M codex-rs/tui/frames/shapes/frame_11.txt
+ M codex-rs/tui/frames/shapes/frame_12.txt
+ M codex-rs/tui/frames/shapes/frame_13.txt
+ M codex-rs/tui/frames/shapes/frame_14.txt
+ M codex-rs/tui/frames/shapes/frame_15.txt
+ M codex-rs/tui/frames/shapes/frame_16.txt
+ M codex-rs/tui/frames/shapes/frame_17.txt
+ M codex-rs/tui/frames/shapes/frame_18.txt
+ M codex-rs/tui/frames/shapes/frame_19.txt
+ M codex-rs/tui/frames/shapes/frame_2.txt
+ M codex-rs/tui/frames/shapes/frame_20.txt
+ M codex-rs/tui/frames/shapes/frame_21.txt
+ M codex-rs/tui/frames/shapes/frame_22.txt
+ M codex-rs/tui/frames/shapes/frame_23.txt
+ M codex-rs/tui/frames/shapes/frame_24.txt
+ M codex-rs/tui/frames/shapes/frame_25.txt
+ M codex-rs/tui/frames/shapes/frame_26.txt
+ M codex-rs/tui/frames/shapes/frame_27.txt
+ M codex-rs/tui/frames/shapes/frame_28.txt
+ M codex-rs/tui/frames/shapes/frame_29.txt
+ M codex-rs/tui/frames/shapes/frame_3.txt
+ M codex-rs/tui/frames/shapes/frame_30.txt
+ M codex-rs/tui/frames/shapes/frame_31.txt
+ M codex-rs/tui/frames/shapes/frame_32.txt
+ M codex-rs/tui/frames/shapes/frame_33.txt
+ M codex-rs/tui/frames/shapes/frame_34.txt
+ M codex-rs/tui/frames/shapes/frame_35.txt
+ M codex-rs/tui/frames/shapes/frame_36.txt
+ M codex-rs/tui/frames/shapes/frame_4.txt
+ M codex-rs/tui/frames/shapes/frame_5.txt
+ M codex-rs/tui/frames/shapes/frame_6.txt
+ M codex-rs/tui/frames/shapes/frame_7.txt
+ M codex-rs/tui/frames/shapes/frame_8.txt
+ M codex-rs/tui/frames/shapes/frame_9.txt
+ M codex-rs/tui/frames/slug/frame_1.txt
+ M codex-rs/tui/frames/slug/frame_10.txt
+ M codex-rs/tui/frames/slug/frame_11.txt
+ M codex-rs/tui/frames/slug/frame_12.txt
+ M codex-rs/tui/frames/slug/frame_13.txt
+ M codex-rs/tui/frames/slug/frame_14.txt
+ M codex-rs/tui/frames/slug/frame_15.txt
+ M codex-rs/tui/frames/slug/frame_16.txt
+ M codex-rs/tui/frames/slug/frame_17.txt
+ M codex-rs/tui/frames/slug/frame_18.txt
+ M codex-rs/tui/frames/slug/frame_19.txt
+ M codex-rs/tui/frames/slug/frame_2.txt
+ M codex-rs/tui/frames/slug/frame_20.txt
+ M codex-rs/tui/frames/slug/frame_21.txt
+ M codex-rs/tui/frames/slug/frame_22.txt
+ M codex-rs/tui/frames/slug/frame_23.txt
+ M codex-rs/tui/frames/slug/frame_24.txt
+ M codex-rs/tui/frames/slug/frame_25.txt
+ M codex-rs/tui/frames/slug/frame_26.txt
+ M codex-rs/tui/frames/slug/frame_27.txt
+ M codex-rs/tui/frames/slug/frame_28.txt
+ M codex-rs/tui/frames/slug/frame_29.txt
+ M codex-rs/tui/frames/slug/frame_3.txt
+ M codex-rs/tui/frames/slug/frame_30.txt
+ M codex-rs/tui/frames/slug/frame_31.txt
+ M codex-rs/tui/frames/slug/frame_32.txt
+ M codex-rs/tui/frames/slug/frame_33.txt
+ M codex-rs/tui/frames/slug/frame_34.txt
+ M codex-rs/tui/frames/slug/frame_35.txt
+ M codex-rs/tui/frames/slug/frame_36.txt
+ M codex-rs/tui/frames/slug/frame_4.txt
+ M codex-rs/tui/frames/slug/frame_5.txt
+ M codex-rs/tui/frames/slug/frame_6.txt
+ M codex-rs/tui/frames/slug/frame_7.txt
+ M codex-rs/tui/frames/slug/frame_8.txt
+ M codex-rs/tui/frames/slug/frame_9.txt
+ M codex-rs/tui/frames/vbars/frame_1.txt
+ M codex-rs/tui/frames/vbars/frame_10.txt
+ M codex-rs/tui/frames/vbars/frame_11.txt
+ M codex-rs/tui/frames/vbars/frame_12.txt
+ M codex-rs/tui/frames/vbars/frame_13.txt
+ M codex-rs/tui/frames/vbars/frame_14.txt
+ M codex-rs/tui/frames/vbars/frame_15.txt
+ M codex-rs/tui/frames/vbars/frame_16.txt
+ M codex-rs/tui/frames/vbars/frame_17.txt
+ M codex-rs/tui/frames/vbars/frame_18.txt
+ M codex-rs/tui/frames/vbars/frame_19.txt
+ M codex-rs/tui/frames/vbars/frame_2.txt
+ M codex-rs/tui/frames/vbars/frame_20.txt
+ M codex-rs/tui/frames/vbars/frame_21.txt
+ M codex-rs/tui/frames/vbars/frame_22.txt
+ M codex-rs/tui/frames/vbars/frame_23.txt
+ M codex-rs/tui/frames/vbars/frame_24.txt
+ M codex-rs/tui/frames/vbars/frame_25.txt
+ M codex-rs/tui/frames/vbars/frame_26.txt
+ M codex-rs/tui/frames/vbars/frame_27.txt
+ M codex-rs/tui/frames/vbars/frame_28.txt
+ M codex-rs/tui/frames/vbars/frame_29.txt
+ M codex-rs/tui/frames/vbars/frame_3.txt
+ M codex-rs/tui/frames/vbars/frame_30.txt
+ M codex-rs/tui/frames/vbars/frame_31.txt
+ M codex-rs/tui/frames/vbars/frame_32.txt
+ M codex-rs/tui/frames/vbars/frame_33.txt
+ M codex-rs/tui/frames/vbars/frame_34.txt
+ M codex-rs/tui/frames/vbars/frame_35.txt
+ M codex-rs/tui/frames/vbars/frame_36.txt
+ M codex-rs/tui/frames/vbars/frame_4.txt
+ M codex-rs/tui/frames/vbars/frame_5.txt
+ M codex-rs/tui/frames/vbars/frame_6.txt
+ M codex-rs/tui/frames/vbars/frame_7.txt
+ M codex-rs/tui/frames/vbars/frame_8.txt
+ M codex-rs/tui/frames/vbars/frame_9.txt
+ M codex-rs/tui/prompt_for_init_command.md
+ M codex-rs/tui/src/app.rs
+ M codex-rs/tui/src/app_backtrack.rs
+ M codex-rs/tui/src/app_event.rs
+ M codex-rs/tui/src/app_event_sender.rs
+ M codex-rs/tui/src/ascii_animation.rs
+ M codex-rs/tui/src/bin/md-events.rs
+ M codex-rs/tui/src/bottom_pane/approval_overlay.rs
+ M codex-rs/tui/src/bottom_pane/bottom_pane_view.rs
+ M codex-rs/tui/src/bottom_pane/chat_composer.rs
+ M codex-rs/tui/src/bottom_pane/chat_composer_history.rs
+ M codex-rs/tui/src/bottom_pane/command_popup.rs
+ M codex-rs/tui/src/bottom_pane/custom_prompt_view.rs
+ M codex-rs/tui/src/bottom_pane/file_search_popup.rs
+ M codex-rs/tui/src/bottom_pane/footer.rs
+ M codex-rs/tui/src/bottom_pane/list_selection_view.rs
+ M codex-rs/tui/src/bottom_pane/mod.rs
+ M codex-rs/tui/src/bottom_pane/paste_burst.rs
+ M codex-rs/tui/src/bottom_pane/popup_consts.rs
+ M codex-rs/tui/src/bottom_pane/prompt_args.rs
+ M codex-rs/tui/src/bottom_pane/scroll_state.rs
+ M codex-rs/tui/src/bottom_pane/selection_popup_common.rs
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__backspace_after_pastes.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__empty.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_ctrl_c_interrupt.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_ctrl_c_quit.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_ctrl_c_then_esc_hint.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_esc_hint_backtrack.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_esc_hint_from_overlay.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_hidden_while_typing.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_overlay_then_external_esc_hint.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__footer_mode_shortcut_overlay.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__large.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__multiple_pastes.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__slash_popup_mo.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__chat_composer__tests__small.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_ctrl_c_quit_idle.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_ctrl_c_quit_running.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_esc_hint_idle.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_esc_hint_primed.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_shortcuts_context_running.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_shortcuts_default.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__footer__tests__footer_shortcuts_shift_and_esc.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__list_selection_view__tests__list_selection_spacing_with_subtitle.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__list_selection_view__tests__list_selection_spacing_without_subtitle.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__tests__status_and_composer_fill_height_without_bottom_padding.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__tests__status_hidden_when_height_too_small_height_1.snap
+ M codex-rs/tui/src/bottom_pane/snapshots/codex_tui__bottom_pane__tests__status_hidden_when_height_too_small_height_2.snap
+ M codex-rs/tui/src/bottom_pane/textarea.rs
+ M codex-rs/tui/src/chatwidget.rs
+ M codex-rs/tui/src/chatwidget/agent.rs
+ M codex-rs/tui/src/chatwidget/interrupts.rs
+ M codex-rs/tui/src/chatwidget/session_header.rs
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__apply_patch_manual_flow_history_approved.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__approval_modal_exec.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__approval_modal_exec_no_reason.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__approval_modal_patch.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__binary_size_ideal_response.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_idle_h1.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_idle_h2.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_idle_h3.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_running_h1.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_running_h2.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chat_small_running_h3.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chatwidget_exec_and_status_layout_vt100_snapshot.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__chatwidget_markdown_code_blocks_vt100_snapshot.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__deltas_then_same_final_message_are_rendered_snapshot.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__disabled_slash_command_while_task_running_snapshot.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exec_approval_history_decision_aborted_long.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exec_approval_history_decision_aborted_multiline.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exec_approval_history_decision_approved_short.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exec_approval_modal_exec.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step1_start_ls.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step2_finish_ls.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step3_start_cat_foo.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step4_finish_cat_foo.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step5_finish_sed_range.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__exploring_step6_finish_cat_bar.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__final_reasoning_then_message_without_deltas_are_rendered.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__interrupt_exec_marks_failed.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__local_image_attachment_history_snapshot.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__model_reasoning_selection_popup.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__model_selection_popup.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__status_widget_active.snap
+ M codex-rs/tui/src/chatwidget/snapshots/codex_tui__chatwidget__tests__status_widget_and_approval_modal.snap
+ M codex-rs/tui/src/chatwidget/tests.rs
+ M codex-rs/tui/src/citation_regex.rs
+ M codex-rs/tui/src/cli.rs
+ M codex-rs/tui/src/clipboard_paste.rs
+ M codex-rs/tui/src/color.rs
+ M codex-rs/tui/src/custom_terminal.rs
+ M codex-rs/tui/src/diff_render.rs
+ M codex-rs/tui/src/exec_cell/mod.rs
+ M codex-rs/tui/src/exec_cell/model.rs
+ M codex-rs/tui/src/exec_cell/render.rs
+ M codex-rs/tui/src/exec_command.rs
+ M codex-rs/tui/src/file_search.rs
+ M codex-rs/tui/src/frames.rs
+ M codex-rs/tui/src/get_git_diff.rs
+ M codex-rs/tui/src/history_cell.rs
+ M codex-rs/tui/src/insert_history.rs
+ M codex-rs/tui/src/key_hint.rs
+ M codex-rs/tui/src/lib.rs
+ M codex-rs/tui/src/live_wrap.rs
+ M codex-rs/tui/src/main.rs
+ M codex-rs/tui/src/markdown.rs
+ M codex-rs/tui/src/markdown_render.rs
+ M codex-rs/tui/src/markdown_render_tests.rs
+ M codex-rs/tui/src/markdown_stream.rs
+ M codex-rs/tui/src/onboarding/auth.rs
+ M codex-rs/tui/src/onboarding/mod.rs
+ M codex-rs/tui/src/onboarding/onboarding_screen.rs
+ M codex-rs/tui/src/onboarding/snapshots/codex_tui__onboarding__trust_directory__tests__renders_snapshot_for_git_repo.snap
+ M codex-rs/tui/src/onboarding/trust_directory.rs
+ M codex-rs/tui/src/onboarding/welcome.rs
+ M codex-rs/tui/src/onboarding/windows.rs
+ M codex-rs/tui/src/pager_overlay.rs
+ M codex-rs/tui/src/public_widgets/composer_input.rs
+ M codex-rs/tui/src/public_widgets/mod.rs
+ M codex-rs/tui/src/render/highlight.rs
+ M codex-rs/tui/src/render/line_utils.rs
+ M codex-rs/tui/src/render/mod.rs
+ M codex-rs/tui/src/render/renderable.rs
+ M codex-rs/tui/src/resume_picker.rs
+ M codex-rs/tui/src/session_log.rs
+ M codex-rs/tui/src/shimmer.rs
+ M codex-rs/tui/src/slash_command.rs
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__add_details.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_add_block.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_delete_block.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_multiple_files_block.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_block.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_block_line_numbers_three_digits_text.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_block_relativizes_path.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_block_wraps_long_lines.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_block_wraps_long_lines_text.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__apply_update_with_rename_block.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__blank_context_line.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__single_line_replacement_counts.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__update_details_with_rename.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__vertical_ellipsis_between_hunks.snap
+ M codex-rs/tui/src/snapshots/codex_tui__diff_render__tests__wrap_behavior_insert.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__active_mcp_tool_call_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__coalesced_reads_dedupe_names.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__coalesces_reads_across_multiple_calls.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__coalesces_sequential_reads_within_one_call.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__completed_mcp_tool_call_error_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__completed_mcp_tool_call_multiple_outputs_inline_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__completed_mcp_tool_call_multiple_outputs_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__completed_mcp_tool_call_success_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__completed_mcp_tool_call_wrapped_outputs_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__multiline_command_both_lines_wrap_with_correct_prefixes.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__multiline_command_without_wrap_uses_branch_then_eight_spaces.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__multiline_command_wraps_with_extra_indent_on_subsequent_lines.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__plan_update_with_note_and_wrapping_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__plan_update_without_note_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__ran_cell_multiline_with_stderr_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__single_line_command_compact_when_fits.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__single_line_command_wraps_with_four_space_continuation.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__stderr_tail_more_than_five_lines_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__history_cell__tests__user_history_cell_wraps_and_prefixes_each_line_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__markdown_render__markdown_render_tests__markdown_render_complex_snapshot.snap
+ M codex-rs/tui/src/snapshots/codex_tui__pager_overlay__tests__static_overlay_snapshot_basic.snap
+ M codex-rs/tui/src/snapshots/codex_tui__pager_overlay__tests__static_overlay_wraps_long_lines.snap
+ M codex-rs/tui/src/snapshots/codex_tui__pager_overlay__tests__transcript_overlay_apply_patch_scroll_vt100.snap
+ M codex-rs/tui/src/snapshots/codex_tui__pager_overlay__tests__transcript_overlay_snapshot_basic.snap
+ M codex-rs/tui/src/snapshots/codex_tui__resume_picker__tests__resume_picker_table.snap
+ M codex-rs/tui/src/snapshots/codex_tui__status_indicator_widget__tests__renders_truncated.snap
+ M codex-rs/tui/src/snapshots/codex_tui__status_indicator_widget__tests__renders_with_queued_messages.snap
+ M codex-rs/tui/src/snapshots/codex_tui__status_indicator_widget__tests__renders_with_working_header.snap
+ M codex-rs/tui/src/status/account.rs
+ M codex-rs/tui/src/status/card.rs
+ M codex-rs/tui/src/status/format.rs
+ M codex-rs/tui/src/status/helpers.rs
+ M codex-rs/tui/src/status/mod.rs
+ M codex-rs/tui/src/status/rate_limits.rs
+ M codex-rs/tui/src/status/snapshots/codex_tui__status__tests__status_snapshot_includes_monthly_limit.snap
+ M codex-rs/tui/src/status/snapshots/codex_tui__status__tests__status_snapshot_includes_reasoning_details.snap
+ M codex-rs/tui/src/status/snapshots/codex_tui__status__tests__status_snapshot_shows_empty_limits_message.snap
+ M codex-rs/tui/src/status/snapshots/codex_tui__status__tests__status_snapshot_shows_missing_limits_message.snap
+ M codex-rs/tui/src/status/snapshots/codex_tui__status__tests__status_snapshot_truncates_in_narrow_terminal.snap
+ M codex-rs/tui/src/status/tests.rs
+ M codex-rs/tui/src/status_indicator_widget.rs
+ M codex-rs/tui/src/streaming/controller.rs
+ M codex-rs/tui/src/streaming/mod.rs
+ M codex-rs/tui/src/style.rs
+ M codex-rs/tui/src/terminal_palette.rs
+ M codex-rs/tui/src/test_backend.rs
+ M codex-rs/tui/src/text_formatting.rs
+ M codex-rs/tui/src/tui.rs
+ M codex-rs/tui/src/ui_consts.rs
+ M codex-rs/tui/src/updates.rs
+ M codex-rs/tui/src/version.rs
+ M codex-rs/tui/src/wrapping.rs
+ M codex-rs/tui/styles.md
+ M codex-rs/tui/tests/all.rs
+ M codex-rs/tui/tests/fixtures/binary-size-log.jsonl
+ M codex-rs/tui/tests/fixtures/oss-story.jsonl
+ M codex-rs/tui/tests/suite/mod.rs
+ M codex-rs/tui/tests/suite/status_indicator.rs
+ M codex-rs/tui/tests/suite/vt100_history.rs
+ M codex-rs/tui/tests/suite/vt100_live_commit.rs
+ M codex-rs/tui/tests/test_backend.rs
+ M codex-rs/utils/json-to-toml/Cargo.toml
+ M codex-rs/utils/json-to-toml/src/lib.rs
+ M codex-rs/utils/readiness/Cargo.toml
+ M codex-rs/utils/readiness/src/lib.rs
+ M codex-rs/utils/string/Cargo.toml
+ M codex-rs/utils/string/src/lib.rs
+ M docs/CLA.md
+ M docs/advanced.md
+ M docs/authentication.md
+ M docs/config.md
+ M docs/contributing.md
+ M docs/exec.md
+ M docs/experimental.md
+ M docs/faq.md
+ M docs/getting-started.md
+ M docs/install.md
+ M docs/license.md
+ M docs/open-source-fund.md
+ M docs/platform-sandboxing.md
+ M docs/prompts.md
+ M docs/release_management.md
+ M docs/sandbox.md
+ M docs/zdr.md
+ M flake.lock
+ M flake.nix
+ M package.json
+ M pnpm-lock.yaml
+ M pnpm-workspace.yaml
+ M scripts/asciicheck.py
+ M scripts/readme_toc.py
+ M scripts/stage_npm_packages.py
+ M sdk/typescript/.prettierignore
+ M sdk/typescript/.prettierrc
+ M sdk/typescript/README.md
+ M sdk/typescript/eslint.config.js
+ M sdk/typescript/jest.config.cjs
+ M sdk/typescript/package.json
+ M sdk/typescript/samples/basic_streaming.ts
+ M sdk/typescript/samples/helpers.ts
+ M sdk/typescript/samples/structured_output.ts
+ M sdk/typescript/samples/structured_output_zod.ts
+ M sdk/typescript/src/codex.ts
+ M sdk/typescript/src/codexOptions.ts
+ M sdk/typescript/src/events.ts
+ M sdk/typescript/src/exec.ts
+ M sdk/typescript/src/index.ts
+ M sdk/typescript/src/items.ts
+ M sdk/typescript/src/outputSchemaFile.ts
+ M sdk/typescript/src/thread.ts
+ M sdk/typescript/src/threadOptions.ts
+ M sdk/typescript/src/turnOptions.ts
+ M sdk/typescript/tests/codexExecSpy.ts
+ M sdk/typescript/tests/responsesProxy.ts
+ M sdk/typescript/tests/run.test.ts
+ M sdk/typescript/tests/runStreamed.test.ts
+ M sdk/typescript/tsconfig.json
+ M sdk/typescript/tsup.config.ts
+?? .code/
+?? codex-rs/app-server/tests/suite/ledger_create_company.rs
+?? codex-rs/codex-ledger/
+?? docs/accounting/
diff --git a/.code/agents/4896925f-bc61-4131-8007-c744395a234b/result.txt b/.code/agents/4896925f-bc61-4131-8007-c744395a234b/result.txt
new file mode 100644
index 00000000..4001c72e
--- /dev/null
+++ b/.code/agents/4896925f-bc61-4131-8007-c744395a234b/result.txt
@@ -0,0 +1,363 @@
+[2025-10-15T12:54:30] OpenAI Codex v0.0.0 (research preview)
+--------
+workdir: /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+model: gpt-5-codex
+provider: openai
+approval: never
+sandbox: read-only
+reasoning effort: high
+reasoning summaries: auto
+--------
+[2025-10-15T12:54:30] User instructions:
+Context: Check codex-rs/app-server/src/codex_message_processor.rs ledger helper functions and ensure we need symmetrical to/from conversions for ledger structs. Note missing conversions for posting side, entry status, origin, currency modes, etc.
+
+Agent: Validate ledger JSON-RPC handler design for app-server, ensuring conversions align with codex-ledger. Identify tricky enum mappings and potential error cases when bridging ledger service to JSON-RPC.
+[2025-10-15T12:54:32] OpenAI Codex v0.0.0 (research preview)
+--------
+workdir: /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+model: gpt-5-codex
+provider: openai
+approval: never
+sandbox: read-only
+reasoning effort: high
+reasoning summaries: auto
+--------
+[2025-10-15T12:54:32] User instructions:
+Context: Check codex-rs/app-server/src/codex_message_processor.rs ledger helper functions and ensure we need symmetrical to/from conversions for ledger structs. Note missing conversions for posting side, entry status, origin, currency modes, etc.
+
+Agent: Validate ledger JSON-RPC handler design for app-server, ensuring conversions align with codex-ledger. Identify tricky enum mappings and potential error cases when bridging ledger service to JSON-RPC.
+
+[2025-10-15T12:54:40] thinking
+
+**Planning symmetric conversion analysis**
+
+I'll analyze code to ensure JSON and internal conversions in codex_message_processor.rs are symmetrical and document any gaps, focusing on key types like posting side and currency modes, all within a read-only environment that prevents running tests or file modifications.
+[2025-10-15T12:54:56] exec bash -lc ls in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+[2025-10-15T12:54:56] bash -lc ls succeeded in 5ms:
+AGENTS.md
+CHANGELOG.md
+LICENSE
+NOTICE
+PNPM.md
+README.md
+cliff.toml
+codex-cli
+codex-rs
+docs
+flake.lock
+flake.nix
+package.json
+pnpm-lock.yaml
+pnpm-workspace.yaml
+scripts
+sdk
+[2025-10-15T12:54:56] tokens used: 9,684
+
+[2025-10-15T12:55:02] thinking
+
+**Checking app-server contents**
+[2025-10-15T12:55:16] exec bash -lc ls in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:55:16] bash -lc ls succeeded in 5ms:
+Cargo.lock
+Cargo.toml
+README.md
+ansi-escape
+app-server
+app-server-protocol
+apply-patch
+arg0
+backend-client
+chatgpt
+cli
+clippy.toml
+cloud-tasks
+cloud-tasks-client
+code
+codex-backend-openapi-models
+common
+config.md
+core
+default.nix
+[2025-10-15T12:55:20] tokens used: 10,572
+
+[2025-10-15T12:55:23] thinking
+
+**Planning to locate and open file**
+[2025-10-15T12:55:28] exec bash -lc "sed -n '1,200p' app-server/src/codex_message_processor.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:55:28] bash -lc "sed -n '1,200p' app-server/src/codex_message_processor.rs" succeeded in 4ms:
+use crate::error_code::INTERNAL_ERROR_CODE;
+use crate::error_code::INVALID_REQUEST_ERROR_CODE;
+use crate::fuzzy_file_search::run_fuzzy_file_search;
+use crate::outgoing_message::OutgoingMessageSender;
+use crate::outgoing_message::OutgoingNotification;
+use codex_app_server_protocol::AddConversationListenerParams;
+use codex_app_server_protocol::AddConversationSubscriptionResponse;
+use codex_app_server_protocol::ApplyPatchApprovalParams;
+use codex_app_server_protocol::ApplyPatchApprovalResponse;
+use codex_app_server_protocol::ArchiveConversationParams;
+use codex_app_server_protocol::ArchiveConversationResponse;
+use codex_app_server_protocol::AuthStatusChangeNotification;
+use codex_app_server_protocol::ClientRequest;
+use codex_app_server_protocol::ConversationSummary;
+use codex_app_server_protocol::ExecCommandApprovalParams;
+use codex_app_server_protocol::ExecCommandApprovalResponse;
+use codex_app_server_protocol::ExecOneOffCommandParams;
+use codex_app_server_protocol::ExecOneOffCommandResponse;
+use codex_app_server_protocol::FuzzyFileSearchParams;
+use codex_app_server_protocol::FuzzyFileSearchResponse;
+[2025-10-15T12:55:32] tokens used: 10,975
+
+[2025-10-15T12:55:34] thinking
+
+**Searching for ledger functions**
+[2025-10-15T12:55:39] exec bash -lc 'rg "ledger" -n app-server/src/codex_message_processor.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:55:39] bash -lc 'rg "ledger" -n app-server/src/codex_message_processor.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:55:41] tokens used: 13,408
+
+[2025-10-15T12:55:44] thinking
+
+**Searching for ledger support**
+[2025-10-15T12:55:59] exec bash -lc 'rg "Ledger" -n app-server/src/codex_message_processor.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:55:59] bash -lc 'rg "Ledger" -n app-server/src/codex_message_processor.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:56:03] tokens used: 13,652
+
+[2025-10-15T12:56:05] thinking
+
+**Searching for ledger functions in app-server**
+[2025-10-15T12:56:08] exec bash -lc 'rg "ledger" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs/app-server
+[2025-10-15T12:56:08] bash -lc 'rg "ledger" -n' exited 1 in 16ms:
+ERROR
+[2025-10-15T12:56:10] tokens used: 13,890
+
+[2025-10-15T12:56:13] thinking
+
+**Searching for ledger references**
+[2025-10-15T12:56:20] exec bash -lc 'rg "ledger" -n ..' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:56:20] bash -lc 'rg "ledger" -n ..' exited 1 in 19ms:
+ERROR
+[2025-10-15T12:56:24] tokens used: 14,112
+
+[2025-10-15T12:56:27] thinking
+
+**Searching for ledger mentions case-insensitively**
+[2025-10-15T12:56:34] exec bash -lc 'rg -i "ledger" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:56:34] bash -lc 'rg -i "ledger" -n' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:56:37] tokens used: 14,420
+
+[2025-10-15T12:56:40] thinking
+
+**Investigating ledger references**
+[2025-10-15T12:56:41] exec bash -lc 'rg "EntryStatus" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:56:41] bash -lc 'rg "EntryStatus" -n' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:56:45] tokens used: 14,693
+
+[2025-10-15T12:56:48] thinking
+
+**Checking git branch and status**
+[2025-10-15T12:56:55] exec bash -lc 'git status --short' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+[2025-10-15T12:56:55] bash -lc 'git status --short' succeeded in 173ms:
+[2025-10-15T12:56:55] tokens used: 14,844
+
+[2025-10-15T12:57:02] thinking
+
+**Checking for ledger implementation files**
+[2025-10-15T12:57:16] exec bash -lc 'ls app-server/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:57:16] bash -lc 'ls app-server/src' succeeded in 5ms:
+codex_message_processor.rs
+error_code.rs
+fuzzy_file_search.rs
+lib.rs
+main.rs
+message_processor.rs
+outgoing_message.rs
+[2025-10-15T12:57:20] tokens used: 15,169
+
+[2025-10-15T12:57:24] thinking
+
+**Reviewing ledger-related TODOs**
+[2025-10-15T12:57:41] exec bash -lc 'rg "ledger" -n ..' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+[2025-10-15T12:57:41] bash -lc 'rg "ledger" -n ..' exited 1 in 699ms:
+ERROR
+[2025-10-15T12:57:41] tokens used: 15,757
+
+[2025-10-15T12:57:50] thinking
+
+**Checking for ledger functionality absence**
+[2025-10-15T12:58:09] exec bash -lc "sed -n '400,800p' app-server/src/codex_message_processor.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:58:09] bash -lc "sed -n '400,800p' app-server/src/codex_message_processor.rs" succeeded in 4ms:
+            self.outgoing.send_error(request_id, error).await;
+        }
+    }
+
+    async fn logout_chatgpt(&mut self, request_id: RequestId) {
+        {
+            // Cancel any active login attempt.
+            let mut guard = self.active_login.lock().await;
+            if let Some(active) = guard.take() {
+                active.drop();
+            }
+        }
+
+        if let Err(err) = self.auth_manager.logout() {
+            let error = JSONRPCErrorError {
+                code: INTERNAL_ERROR_CODE,
+                message: format!("logout failed: {err}"),
+                data: None,
+            };
+            self.outgoing.send_error(request_id, error).await;
+[2025-10-15T12:58:11] tokens used: 16,730
+
+[2025-10-15T12:58:17] thinking
+
+**Searching for ledger-related code**
+[2025-10-15T12:58:34] exec bash -lc "sed -n '1,160p' app-server/src/lib.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:58:34] bash -lc "sed -n '1,160p' app-server/src/lib.rs" succeeded in 4ms:
+#![deny(clippy::print_stdout, clippy::print_stderr)]
+
+use std::io::ErrorKind;
+use std::io::Result as IoResult;
+use std::path::PathBuf;
+
+use codex_common::CliConfigOverrides;
+use codex_core::config::Config;
+use codex_core::config::ConfigOverrides;
+
+use codex_app_server_protocol::JSONRPCMessage;
+use tokio::io::AsyncBufReadExt;
+use tokio::io::AsyncWriteExt;
+use tokio::io::BufReader;
+use tokio::io::{self};
+use tokio::sync::mpsc;
+use tracing::debug;
+use tracing::error;
+use tracing::info;
+use tracing_subscriber::EnvFilter;
+[2025-10-15T12:58:34] tokens used: 21,369
+
+[2025-10-15T12:58:42] thinking
+
+**Searching for ledger crate**
+[2025-10-15T12:58:45] exec bash -lc 'rg "codex-ledger" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:58:45] bash -lc 'rg "codex-ledger" -n' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:58:45] tokens used: 23,013
+
+[2025-10-15T12:58:53] thinking
+
+**Considering ledger functionality location**
+[2025-10-15T12:58:59] exec bash -lc 'rg -i "ledger" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+[2025-10-15T12:58:59] bash -lc 'rg -i "ledger" -n' exited 1 in 20ms:
+ERROR
+[2025-10-15T12:58:59] tokens used: 23,384
+
+[2025-10-15T12:59:10] thinking
+
+**Investigating missing ledger code references**
+[2025-10-15T12:59:13] exec bash -lc 'ls app-server-protocol/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:59:13] bash -lc 'ls app-server-protocol/src' succeeded in 4ms:
+jsonrpc_lite.rs
+lib.rs
+protocol.rs
+[2025-10-15T12:59:16] tokens used: 23,843
+
+[2025-10-15T12:59:19] thinking
+
+**Checking protocol.rs file**
+[2025-10-15T12:59:24] exec bash -lc "sed -n '1,200p' app-server-protocol/src/protocol.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:59:24] bash -lc "sed -n '1,200p' app-server-protocol/src/protocol.rs" succeeded in 5ms:
+use std::collections::HashMap;
+use std::path::PathBuf;
+
+use crate::JSONRPCNotification;
+use crate::JSONRPCRequest;
+use crate::RequestId;
+use codex_protocol::ConversationId;
+use codex_protocol::config_types::ReasoningEffort;
+use codex_protocol::config_types::ReasoningSummary;
+use codex_protocol::config_types::SandboxMode;
+use codex_protocol::config_types::Verbosity;
+use codex_protocol::protocol::AskForApproval;
+use codex_protocol::protocol::EventMsg;
+use codex_protocol::protocol::FileChange;
+use codex_protocol::protocol::ReviewDecision;
+use codex_protocol::protocol::SandboxPolicy;
+use codex_protocol::protocol::TurnAbortReason;
+use paste::paste;
+use serde::Deserialize;
+use serde::Serialize;
+[2025-10-15T12:59:28] tokens used: 24,077
+
+[2025-10-15T12:59:37] thinking
+
+**Investigating missing ledger code**
+[2025-10-15T12:59:52] exec bash -lc 'rg "EntryStatus" -n ..' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T12:59:52] bash -lc 'rg "EntryStatus" -n ..' exited 1 in 19ms:
+ERROR
+[2025-10-15T12:59:55] tokens used: 27,066
+
+[2025-10-15T13:00:00] thinking
+
+**Assessing codebase state and updating strategy**
+[2025-10-15T13:00:15] exec bash -lc 'ls ../..' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs/app-server/src
+[2025-10-15T13:00:15] bash -lc 'ls ../..' succeeded in 4ms:
+Cargo.lock
+Cargo.toml
+README.md
+ansi-escape
+app-server
+app-server-protocol
+apply-patch
+arg0
+backend-client
+chatgpt
+cli
+clippy.toml
+cloud-tasks
+cloud-tasks-client
+code
+codex-backend-openapi-models
+common
+config.md
+core
+default.nix
+[2025-10-15T13:00:18] tokens used: 28,280
+
+[2025-10-15T13:00:30] thinking
+
+**Assessing missing ledger code and conversions**
+
+I see no ledger helper functions in the specified app-server path and can’t find associated code elsewhere, so the user might want me to highlight the absence of symmetrical to/from conversions for ledger structs like PostingSide, EntryStatus, and others. Since I can’t access remote repos or network, I’m relying on general ledger domain knowledge to note likely enum mappings and potential error points, and I plan to inform the user about these gaps and the missing code references with appropriate caveats.
+[2025-10-15T13:00:34] exec bash -lc 'rg "Currency" -n' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc
+[2025-10-15T13:00:34] bash -lc 'rg "Currency" -n' exited 1 in 18ms:
+ERROR
+[2025-10-15T13:00:34] tokens used: 29,120
+
+[2025-10-15T13:00:42] thinking
+
+**Checking for missing ledger crate**
+[2025-10-15T13:00:43] exec bash -lc 'grep -n "ledger" Cargo.toml' in /home/sammu/.code/working/CodexAccountant/branches/code-code-validate-ledger-json-rpc/codex-rs
+[2025-10-15T13:00:43] bash -lc 'grep -n "ledger" Cargo.toml' exited 1 in 4ms:
+ERROR
+[2025-10-15T13:00:43] tokens used: 30,142
+
+[2025-10-15T13:01:07] thinking
+
+**Analyzing missing ledger JSON-RPC conversions**
+
+There’s no ledger helper code in `codex-rs/app-server/src/codex_message_processor.rs`; I confirmed this by searching for ledger references. Since symmetrical conversions for types like PostingSide, EntryStatus, EntryOrigin, and CurrencyMode are absent, I’ll highlight missing mappings, potential tricky enums, and error handling cases. I plan to suggest implementing bi-directional From/TryFrom conversions, considering variants carefully, and handling invalid values with JSON-RPC errors, all framed as design recommendations without code changes.
+[2025-10-15T13:01:09] codex
+
+**Ledger Mapping Gaps**
+- `codex-rs/app-server/src/codex_message_processor.rs` currently has no ledger-specific request handlers or helpers, so there is no symmetry between wire types and the `codex-ledger` domain. All conversions (posting side, entry status, entry origin, currency mode, etc.) still need to be implemented.
+- When adding those helpers, mirror every enum/struct in both directions. Provide `From`/`TryFrom` impls (or dedicated helpers) for JSON → ledger and ledger → JSON so values such as `PostingSide::{Debit,Credit}`, the full `EntryStatus` set (e.g. draft/pending/posted/voided), `EntryOrigin` flavors (manual/imported/system), and currency-mode flags stay round‑trip safe.
+- Treat unknown strings or missing variants as hard errors and surface a JSON-RPC failure (e.g. via `JSONRPCErrorError`) instead of silently defaulting—this avoids producing invalid ledger commands.
+- Watch for optional fields like effective dates, exchange rates, or multi-currency payloads; ensure optional `None`/`Some` state is preserved when mapping back to the ledger service.
+- Centralize mapping tables so UI additions stay in sync with the ledger crate. A small `into_wire_*` / `try_from_wire_*` module keeps enum drift visible in reviews.
+
+**Next step**
+1. Introduce the ledger request handlers plus the full set of `TryFrom`/`From` conversions for every ledger type that crosses the JSON-RPC boundary, then add targeted tests to confirm round-tripping.
+[2025-10-15T13:01:22] tokens used: 31,788
diff --git a/.code/agents/5dfdefcb-9e4e-4b8c-a887-aaccd3619c5d/result.txt b/.code/agents/5dfdefcb-9e4e-4b8c-a887-aaccd3619c5d/result.txt
new file mode 100644
index 00000000..42e1a599
--- /dev/null
+++ b/.code/agents/5dfdefcb-9e4e-4b8c-a887-aaccd3619c5d/result.txt
@@ -0,0 +1,519 @@
+[2025-10-15T12:54:10] OpenAI Codex v0.0.0 (research preview)
+--------
+workdir: /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc
+model: gpt-5-codex
+provider: openai
+approval: never
+sandbox: read-only
+reasoning effort: high
+reasoning summaries: auto
+--------
+[2025-10-15T12:54:10] User instructions:
+Context: Focus on codex-rs/app-server-protocol/src/protocol.rs and codex-rs/app-server/src/codex_message_processor.rs. Ledger enums exist in codex-ledger crate; ensure conversion helpers cover account types, posting modes, period actions, etc. Provide notes on error mapping using ledger_error_to_jsonrpc.
+
+Agent: Cross-check ledger JSON-RPC protocol structs and conversions for the app-server ledger feature. Propose code edits ensuring ledgerUpsertAccount/postEntry/reverseEntry/lockPeriod requests/responses map to codex-ledger models correctly, and highlight any missing enum conversions or serde attributes.
+[2025-10-15T12:54:12] OpenAI Codex v0.0.0 (research preview)
+--------
+workdir: /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc
+model: gpt-5-codex
+provider: openai
+approval: never
+sandbox: read-only
+reasoning effort: high
+reasoning summaries: auto
+--------
+[2025-10-15T12:54:12] User instructions:
+Context: Focus on codex-rs/app-server-protocol/src/protocol.rs and codex-rs/app-server/src/codex_message_processor.rs. Ledger enums exist in codex-ledger crate; ensure conversion helpers cover account types, posting modes, period actions, etc. Provide notes on error mapping using ledger_error_to_jsonrpc.
+
+Agent: Cross-check ledger JSON-RPC protocol structs and conversions for the app-server ledger feature. Propose code edits ensuring ledgerUpsertAccount/postEntry/reverseEntry/lockPeriod requests/responses map to codex-ledger models correctly, and highlight any missing enum conversions or serde attributes.
+
+[2025-10-15T12:54:20] thinking
+
+**Preparing a multi-step read-only plan**
+[2025-10-15T12:54:38] exec bash -lc ls in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:54:38] bash -lc ls succeeded in 5ms:
+AGENTS.md
+CHANGELOG.md
+LICENSE
+NOTICE
+PNPM.md
+README.md
+cliff.toml
+codex-cli
+codex-rs
+docs
+flake.lock
+flake.nix
+package.json
+pnpm-lock.yaml
+pnpm-workspace.yaml
+scripts
+sdk
+[2025-10-15T12:54:38] tokens used: 9,593
+
+[2025-10-15T12:54:43] thinking
+
+**Preparing to create a plan**
+[2025-10-15T12:54:48] exec bash -lc pwd in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:54:48] bash -lc pwd succeeded in 4ms:
+/home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc
+[2025-10-15T12:54:52] tokens used: 9,854
+
+[2025-10-15T12:54:54] thinking
+
+**Preparing to create plan**
+[2025-10-15T12:55:10] tool agent
+{
+  "task": "Plan for reviewing codex-rs ledger JSON-RPC conversions",
+  "models": [
+    "code"
+  ],
+  "context": "Need to inspect codex-rs/app-server-protocol/src/protocol.rs and codex-rs/app-server/src/codex_message_processor.rs to ensure ledger enums conversions align with codex-ledger types. In read-only mode, so will analyze and propose edits.",
+  "output": "concise plan",
+  "files": null,
+  "read_only": true
+}
+[2025-10-15T12:55:10] 🤖 Agent 8b8bba9f [code] started. Use `agent {"action":"wait","agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559","return_all":true}` to follow progress, or `agent {"action":"result","agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559"}` when it finishes.
+[2025-10-15T12:55:10] tool agent success
+{"agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559","status":"started","message":"Agent started successfully","next_steps":"🤖 Agent 8b8bba9f [code] started. Use `agent {\"action\":\"wait\",\"agent_id\":\"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559\",\"return_all\":true}` to follow progress, or `agent {\"action\":\"result\",\"agent_id\":\"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559\"}` when it finishes.","skipped":null}
+[2025-10-15T12:55:13] tokens used: 10,150
+
+[2025-10-15T12:55:15] thinking
+
+**Waiting for plan**
+[2025-10-15T12:55:32] tool agent
+{
+  "agent_id": "8b8bba9f-0c98-4e5f-9f65-fc9c2f561559",
+  "batch_id": null,
+  "timeout_seconds": 120,
+  "return_all": true
+}
+[2025-10-15T12:55:32] tool agent success
+{"agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559","status":"completed","wait_time_seconds":0,"total_lines":54,"agent_result_hint":"agent {\"action\":\"result\",\"agent_id\":\"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559\"}","agent_result_params":{"action":"result","agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559"},"output_preview":"\nVersion:          Code 1.105.0 (03c265b1adee71ac88f833e065f7bb956b60550a, 2025-10-08T14:09:35.891Z)\nOS Version:       Windows_NT x64 10.0.26100\nCPUs:             AMD Ryzen 7 9800X3D 8-Core Processor            (16 x 4700)\nMemory (System):  31.16GB (13.01GB free)\nVM:               33%\nScreen Reader:    no\nProcess Argv:     --new-window --crash-reporter-id fcce57d1-422a-4fd6-a752-e27888210d7c\nGPU Status:       2d_canvas:                              enabled\n                  direct_rendering_display_compositor:    disabled_off_ok\n                  gpu_compositing:                        enabled\n                  multiple_raster_threads:                enabled_on\n                  opengl:                                 enabled_on\n                  rasterization:                          enabled\n                  raw_draw:                               disabled_off_ok\n                  skia_graphite:                          disabled_off\n                  trees_in_viz:                           disabled_off\n                  video_decode:                           enabled\n                  video_encode:                           enabled\n                  vulkan:                                 disabled_off\n                  webgl:                                  enabled\n                  webgl2:                                 enabled\n                  webgpu:                                 enabled\n                  webnn:                                  disabled_off\n\nCPU %\tMem MB\t   PID\tProcess\n    0\t   146\t  4128\tcode\n    0\t    29\t   276\t   crashpad-handler\n    0\t   191\t 14164\twindow [1] (Welcome - CodexAccountant - Visual Studio Code)\n    0\t    94\t 14512\tpty-host\n    0\t   136\t 15300\tshared-process\n    0\t    48\t 21688\t   utility-network-service\n    0\t   103\t 32400\tfile-watcher [1]\n    0\t    85\t 32660\t   gpu-process\n    0\t   579\t 33164\textension-host [1]\n    0\t    10\t  2856\t     c:\\Users\\sammu\\.vscode\\extensions\\openai.chatgpt-0.5.19-win32-x64\\bin\\windows-x86_64\\codex.exe app-server\n    0\t     6\t  7652\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    79\t  6832\t     C:\\Users\\sammu\\AppData\\Local\\cloud-code\\cloudcode_cli\\cloudcode_cli\\62c1f047\\cloudcode_cli.exe duet -trace -logtostderr\n    0\t     6\t 30472\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    88\t 14540\t     electron-nodejs (eslintServer.js )\n    0\t    27\t 19252\t     c:\\Users\\sammu\\.vscode\\extensions\\rust-lang.rust-analyzer-0.3.2593-win32-x64\\server\\rust-analyzer.exe\n    0\t     6\t 11676\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    90\t 31392\t     \"C:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe\" \"c:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\json-language-features\\server\\dist\\node\\jsonServerMain\" --node-ipc --clientProcessId=33164\n    0\t    89\t 32536\t     \"C:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe\" c:\\Users\\sammu\\.vscode\\extensions\\google.geminicodeassist-2.53.0\\agent\\agent.mjs\n\nWorkspace Stats: \n|  Window (Welcome - CodexAccountant - Visual Studio Code)\n|    Folder (CodexAccountant): 3544 files\n|      File types: rs(462) txt(431) o(311) json(181) timestamp(163) d(142)\n|                  snap(107) rmeta(106) rlib(104) md(58)\n|      Conf files: github-actions(8) package.json(4) dockerfile(2)\n|                  devcontainer.json(1) launch.json(1) settings.json(1)\n|                  agents.md(1) tsconfig.json(1)\n|      Launch Configs: lldb(2)","output_file":"/home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.code/agents/8b8bba9f-0c98-4e5f-9f65-fc9c2f561559/result.txt"}
+[2025-10-15T12:55:35] tokens used: 10,557
+
+[2025-10-15T12:55:37] thinking
+
+**Fetching plan from agent result**
+[2025-10-15T12:55:40] tool agent
+{
+  "agent_id": "8b8bba9f-0c98-4e5f-9f65-fc9c2f561559"
+}
+[2025-10-15T12:55:40] tool agent success
+{"agent_id":"8b8bba9f-0c98-4e5f-9f65-fc9c2f561559","status":"completed","output_preview":"\nVersion:          Code 1.105.0 (03c265b1adee71ac88f833e065f7bb956b60550a, 2025-10-08T14:09:35.891Z)\nOS Version:       Windows_NT x64 10.0.26100\nCPUs:             AMD Ryzen 7 9800X3D 8-Core Processor            (16 x 4700)\nMemory (System):  31.16GB (13.01GB free)\nVM:               33%\nScreen Reader:    no\nProcess Argv:     --new-window --crash-reporter-id fcce57d1-422a-4fd6-a752-e27888210d7c\nGPU Status:       2d_canvas:                              enabled\n                  direct_rendering_display_compositor:    disabled_off_ok\n                  gpu_compositing:                        enabled\n                  multiple_raster_threads:                enabled_on\n                  opengl:                                 enabled_on\n                  rasterization:                          enabled\n                  raw_draw:                               disabled_off_ok\n                  skia_graphite:                          disabled_off\n                  trees_in_viz:                           disabled_off\n                  video_decode:                           enabled\n                  video_encode:                           enabled\n                  vulkan:                                 disabled_off\n                  webgl:                                  enabled\n                  webgl2:                                 enabled\n                  webgpu:                                 enabled\n                  webnn:                                  disabled_off\n\nCPU %\tMem MB\t   PID\tProcess\n    0\t   146\t  4128\tcode\n    0\t    29\t   276\t   crashpad-handler\n    0\t   191\t 14164\twindow [1] (Welcome - CodexAccountant - Visual Studio Code)\n    0\t    94\t 14512\tpty-host\n    0\t   136\t 15300\tshared-process\n    0\t    48\t 21688\t   utility-network-service\n    0\t   103\t 32400\tfile-watcher [1]\n    0\t    85\t 32660\t   gpu-process\n    0\t   579\t 33164\textension-host [1]\n    0\t    10\t  2856\t     c:\\Users\\sammu\\.vscode\\extensions\\openai.chatgpt-0.5.19-win32-x64\\bin\\windows-x86_64\\codex.exe app-server\n    0\t     6\t  7652\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    79\t  6832\t     C:\\Users\\sammu\\AppData\\Local\\cloud-code\\cloudcode_cli\\cloudcode_cli\\62c1f047\\cloudcode_cli.exe duet -trace -logtostderr\n    0\t     6\t 30472\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    88\t 14540\t     electron-nodejs (eslintServer.js )\n    0\t    27\t 19252\t     c:\\Users\\sammu\\.vscode\\extensions\\rust-lang.rust-analyzer-0.3.2593-win32-x64\\server\\rust-analyzer.exe\n    0\t     6\t 11676\t       C:\\windows\\system32\\conhost.exe 0x4\n    0\t    90\t 31392\t     \"C:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe\" \"c:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\json-language-features\\server\\dist\\node\\jsonServerMain\" --node-ipc --clientProcessId=33164\n    0\t    89\t 32536\t     \"C:\\Users\\sammu\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe\" c:\\Users\\sammu\\.vscode\\extensions\\google.geminicodeassist-2.53.0\\agent\\agent.mjs\n\nWorkspace Stats: \n|  Window (Welcome - CodexAccountant - Visual Studio Code)\n|    Folder (CodexAccountant): 3544 files\n|      File types: rs(462) txt(431) o(311) json(181) timestamp(163) d(142)\n|                  snap(107) rmeta(106) rlib(104) md(58)\n|      Conf files: github-actions(8) package.json(4) dockerfile(2)\n|                  devcontainer.json(1) launch.json(1) settings.json(1)\n|                  agents.md(1) tsconfig.json(1)\n|      Launch Configs: lldb(2)","output_total_lines":54,"output_file":"/home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.code/agents/8b8bba9f-0c98-4e5f-9f65-fc9c2f561559/result.txt"}
+[2025-10-15T12:55:44] tokens used: 12,031
+
+[2025-10-15T12:55:51] thinking
+
+**Devising a manual plan for inspection**
+[2025-10-15T12:56:04] exec bash -lc "sed -n '1,200p' codex-rs/app-server-protocol/src/protocol.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:56:04] bash -lc "sed -n '1,200p' codex-rs/app-server-protocol/src/protocol.rs" succeeded in 4ms:
+use std::collections::HashMap;
+use std::path::PathBuf;
+
+use crate::JSONRPCNotification;
+use crate::JSONRPCRequest;
+use crate::RequestId;
+use codex_protocol::ConversationId;
+use codex_protocol::config_types::ReasoningEffort;
+use codex_protocol::config_types::ReasoningSummary;
+use codex_protocol::config_types::SandboxMode;
+use codex_protocol::config_types::Verbosity;
+use codex_protocol::protocol::AskForApproval;
+use codex_protocol::protocol::EventMsg;
+use codex_protocol::protocol::FileChange;
+use codex_protocol::protocol::ReviewDecision;
+use codex_protocol::protocol::SandboxPolicy;
+use codex_protocol::protocol::TurnAbortReason;
+use paste::paste;
+use serde::Deserialize;
+use serde::Serialize;
+[2025-10-15T12:56:07] tokens used: 14,039
+
+[2025-10-15T12:56:11] thinking
+
+**Searching ledger sections**
+[2025-10-15T12:56:13] exec bash -lc 'rg -n "ledger" codex-rs/app-server-protocol/src/protocol.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:56:13] bash -lc 'rg -n "ledger" codex-rs/app-server-protocol/src/protocol.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:56:17] tokens used: 16,800
+
+[2025-10-15T12:56:20] thinking
+
+**Searching for ledger definitions**
+[2025-10-15T12:56:25] exec bash -lc 'rg -n "Ledger" codex-rs/app-server-protocol/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:56:25] bash -lc 'rg -n "Ledger" codex-rs/app-server-protocol/src' exited 1 in 17ms:
+ERROR
+[2025-10-15T12:56:29] tokens used: 17,670
+
+[2025-10-15T12:56:31] thinking
+
+**Searching for ledgerUpsertAccount function**
+[2025-10-15T12:56:37] exec bash -lc 'rg -n "ledgerUpsertAccount" -n codex-rs/app-server-protocol/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:56:37] bash -lc 'rg -n "ledgerUpsertAccount" -n codex-rs/app-server-protocol/src' exited 1 in 17ms:
+ERROR
+[2025-10-15T12:56:37] tokens used: 17,859
+
+[2025-10-15T12:56:43] thinking
+
+**Searching for ledger references in protocol.rs**
+[2025-10-15T12:56:48] exec bash -lc 'rg -ni "ledger" codex-rs/app-server-protocol/src/protocol.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:56:48] bash -lc 'rg -ni "ledger" codex-rs/app-server-protocol/src/protocol.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:56:52] tokens used: 19,057
+
+[2025-10-15T12:56:55] thinking
+
+**Checking for ledger code**
+[2025-10-15T12:57:00] exec bash -lc "sed -n '1,200p' codex-rs/app-server/src/codex_message_processor.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:57:00] bash -lc "sed -n '1,200p' codex-rs/app-server/src/codex_message_processor.rs" succeeded in 4ms:
+use crate::error_code::INTERNAL_ERROR_CODE;
+use crate::error_code::INVALID_REQUEST_ERROR_CODE;
+use crate::fuzzy_file_search::run_fuzzy_file_search;
+use crate::outgoing_message::OutgoingMessageSender;
+use crate::outgoing_message::OutgoingNotification;
+use codex_app_server_protocol::AddConversationListenerParams;
+use codex_app_server_protocol::AddConversationSubscriptionResponse;
+use codex_app_server_protocol::ApplyPatchApprovalParams;
+use codex_app_server_protocol::ApplyPatchApprovalResponse;
+use codex_app_server_protocol::ArchiveConversationParams;
+use codex_app_server_protocol::ArchiveConversationResponse;
+use codex_app_server_protocol::AuthStatusChangeNotification;
+use codex_app_server_protocol::ClientRequest;
+use codex_app_server_protocol::ConversationSummary;
+use codex_app_server_protocol::ExecCommandApprovalParams;
+use codex_app_server_protocol::ExecCommandApprovalResponse;
+use codex_app_server_protocol::ExecOneOffCommandParams;
+use codex_app_server_protocol::ExecOneOffCommandResponse;
+use codex_app_server_protocol::FuzzyFileSearchParams;
+use codex_app_server_protocol::FuzzyFileSearchResponse;
+[2025-10-15T12:57:04] tokens used: 19,210
+
+[2025-10-15T12:57:06] thinking
+
+**Searching for ledger handling**
+[2025-10-15T12:57:12] exec bash -lc 'rg -ni "ledger" codex-rs/app-server/src/codex_message_processor.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:57:12] bash -lc 'rg -ni "ledger" codex-rs/app-server/src/codex_message_processor.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:57:13] tokens used: 21,527
+
+[2025-10-15T12:57:19] thinking
+
+**Verifying ledger integration and searching for error mapping**
+[2025-10-15T12:57:40] exec bash -lc 'rg -n "ledger_error_to_jsonrpc" -n codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:57:40] bash -lc 'rg -n "ledger_error_to_jsonrpc" -n codex-rs' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:57:41] tokens used: 21,828
+
+[2025-10-15T12:57:50] thinking
+
+**Searching for LedgerRequest references**
+[2025-10-15T12:57:55] exec bash -lc 'rg -n "ledger" codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:57:55] bash -lc 'rg -n "ledger" codex-rs' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:57:58] tokens used: 22,077
+
+[2025-10-15T12:58:01] thinking
+
+**Searching for ledger references**
+[2025-10-15T12:58:06] exec bash -lc 'rg -ni "ledger"' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:58:06] bash -lc 'rg -ni "ledger"' exited 1 in 20ms:
+ERROR
+[2025-10-15T12:58:06] tokens used: 22,293
+
+[2025-10-15T12:58:11] thinking
+
+**Checking for ledger presence**
+[2025-10-15T12:58:28] exec bash -lc 'ls codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:58:28] bash -lc 'ls codex-rs' succeeded in 4ms:
+Cargo.lock
+Cargo.toml
+README.md
+ansi-escape
+app-server
+app-server-protocol
+apply-patch
+arg0
+backend-client
+chatgpt
+cli
+clippy.toml
+cloud-tasks
+cloud-tasks-client
+code
+codex-backend-openapi-models
+common
+config.md
+core
+default.nix
+[2025-10-15T12:58:31] tokens used: 22,477
+
+[2025-10-15T12:58:33] thinking
+
+**Searching for ledger directories**
+[2025-10-15T12:58:39] exec bash -lc "find codex-rs -maxdepth 2 -type d -name '*ledger*'" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:58:39] bash -lc "find codex-rs -maxdepth 2 -type d -name '*ledger*'" succeeded in 5ms:
+[2025-10-15T12:58:43] tokens used: 22,832
+
+[2025-10-15T12:58:44] thinking
+
+**Searching for ledger references**
+[2025-10-15T12:58:49] exec bash -lc 'rg -n "Posting" codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:58:49] bash -lc 'rg -n "Posting" codex-rs' exited 1 in 18ms:
+ERROR
+[2025-10-15T12:58:49] tokens used: 23,091
+
+[2025-10-15T12:58:57] thinking
+
+**Searching for ledger-related code**
+[2025-10-15T12:59:02] exec bash -lc "find . -maxdepth 3 -type d -name '*ledger*'" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:59:02] bash -lc "find . -maxdepth 3 -type d -name '*ledger*'" succeeded in 5ms:
+[2025-10-15T12:59:02] tokens used: 23,363
+
+[2025-10-15T12:59:10] thinking
+
+**Checking for ledger crate presence**
+[2025-10-15T12:59:13] exec bash -lc 'rg -ni "account_type"' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:59:13] bash -lc 'rg -ni "account_type"' exited 1 in 19ms:
+ERROR
+[2025-10-15T12:59:13] tokens used: 23,734
+
+[2025-10-15T12:59:22] thinking
+
+**Verifying branch and repository state**
+[2025-10-15T12:59:27] exec bash -lc 'git status -sb' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:59:27] bash -lc 'git status -sb' succeeded in 174ms:
+## code-code-cross-check-ledger-json-rpc
+?? .code/
+[2025-10-15T12:59:27] tokens used: 23,981
+
+[2025-10-15T12:59:35] thinking
+
+**Searching for ledger-related terms**
+[2025-10-15T12:59:41] exec bash -lc 'rg -n "period" codex-rs/app-server-protocol/src/protocol.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:59:41] bash -lc 'rg -n "period" codex-rs/app-server-protocol/src/protocol.rs' exited 1 in 5ms:
+ERROR
+[2025-10-15T12:59:43] tokens used: 43,132
+
+[2025-10-15T12:59:47] thinking
+
+**Investigating feature implementation locations**
+[2025-10-15T12:59:52] exec bash -lc 'rg -n "UpsertAccount" codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T12:59:52] bash -lc 'rg -n "UpsertAccount" codex-rs' exited 1 in 17ms:
+ERROR
+[2025-10-15T12:59:52] tokens used: 43,375
+
+[2025-10-15T12:59:59] thinking
+
+**Verifying ledger module presence**
+[2025-10-15T13:00:06] exec bash -lc 'rg -n "ledger" codex-rs/Cargo.toml' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:00:06] bash -lc 'rg -n "ledger" codex-rs/Cargo.toml' exited 1 in 5ms:
+ERROR
+[2025-10-15T13:00:09] tokens used: 43,907
+
+[2025-10-15T13:00:16] thinking
+
+**Checking for codex-ledger crate**
+[2025-10-15T13:00:17] exec bash -lc 'rg -ni "ledger" ..' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:00:17] bash -lc 'rg -ni "ledger" ..' exited 1 in 65ms:
+ERROR
+[2025-10-15T13:00:17] tokens used: 44,321
+
+[2025-10-15T13:00:26] thinking
+
+**Investigating missing ledger code**
+[2025-10-15T13:00:32] exec bash -lc 'rg -ni "upsert" codex-rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:00:32] bash -lc 'rg -ni "upsert" codex-rs' exited 1 in 19ms:
+ERROR
+[2025-10-15T13:00:32] tokens used: 44,813
+
+[2025-10-15T13:00:41] thinking
+
+**Searching for account_type references**
+[2025-10-15T13:00:45] exec bash -lc 'rg -n "PostingMode" -g"*.rs"' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:00:45] bash -lc 'rg -n "PostingMode" -g"*.rs"' exited 1 in 22ms:
+ERROR
+[2025-10-15T13:00:45] tokens used: 45,119
+
+[2025-10-15T13:00:58] thinking
+
+**Assessing missing ledger definitions and planning next steps**
+
+I found no ledger-related code after inspecting key files, so I’m considering how to update the plan to reflect this. Since I can’t locate the `codex-ledger` crate enums, I’m thinking about proposing general placeholder enums and documenting missing conversions, possibly noting plan progress in the final message to keep things clear. I’ll also check for any relevant design docs by searching for terms like `accounting` to gather more context before moving forward.
+[2025-10-15T13:01:04] exec bash -lc 'rg -ni "account" codex-rs/app-server-protocol/src/protocol.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:01:04] bash -lc 'rg -ni "account" codex-rs/app-server-protocol/src/protocol.rs' exited 1 in 6ms:
+ERROR
+[2025-10-15T13:01:04] tokens used: 45,764
+
+[2025-10-15T13:01:12] thinking
+
+**Checking for missing dependency**
+[2025-10-15T13:01:31] exec bash -lc 'rg -n "codex-ledger" codex-rs/Cargo.lock' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:01:31] bash -lc 'rg -n "codex-ledger" codex-rs/Cargo.lock' exited 1 in 5ms:
+ERROR
+[2025-10-15T13:01:35] tokens used: 46,037
+
+[2025-10-15T13:01:38] thinking
+
+**Searching for ledger crate**
+[2025-10-15T13:01:41] exec bash -lc 'rg -ni "codex-ledger"' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:01:41] bash -lc 'rg -ni "codex-ledger"' exited 1 in 19ms:
+ERROR
+[2025-10-15T13:01:41] tokens used: 46,273
+
+[2025-10-15T13:01:50] thinking
+
+**Identifying missing ledger components and dependencies**
+[2025-10-15T13:01:56] exec bash -lc 'rg -n "ledger" codex-rs/**/Cargo.toml' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:01:56] bash -lc 'rg -n "ledger" codex-rs/**/Cargo.toml' exited 1 in 8ms:
+ERROR
+[2025-10-15T13:01:56] tokens used: 46,799
+
+[2025-10-15T13:02:07] thinking
+
+**Preparing ledger integration proposals**
+[2025-10-15T13:02:14] exec bash -lc 'wc -l codex-rs/app-server-protocol/src/protocol.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:02:14] bash -lc 'wc -l codex-rs/app-server-protocol/src/protocol.rs' succeeded in 5ms:
+932 codex-rs/app-server-protocol/src/protocol.rs
+[2025-10-15T13:02:14] tokens used: 47,428
+
+[2025-10-15T13:02:20] thinking
+
+**Inspecting ledger sections near file end**
+[2025-10-15T13:02:25] exec bash -lc "sed -n '700,932p' codex-rs/app-server-protocol/src/protocol.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:02:25] bash -lc "sed -n '700,932p' codex-rs/app-server-protocol/src/protocol.rs" succeeded in 4ms:
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+pub struct ExecCommandApprovalResponse {
+    pub decision: ReviewDecision,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+pub struct ApplyPatchApprovalResponse {
+    pub decision: ReviewDecision,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+#[ts(rename_all = "camelCase")]
+pub struct FuzzyFileSearchParams {
+    pub query: String,
+    pub roots: Vec<String>,
+    // if provided, will cancel any previous request that used the same value
+    #[serde(skip_serializing_if = "Option::is_none")]
+[2025-10-15T13:02:29] tokens used: 47,672
+
+[2025-10-15T13:02:46] thinking
+
+**Outlining ledger feature integration**
+
+I'm mapping out what new ledger-related request and response types need adding, focusing on consistent serialization and conversions with ledger domain enums. Since the ledger crate isn't accessible, I'll suggest placeholders and note the unknowns. I also plan to update client and server request enums and adapt message processor handlers to incorporate ledger operations, aiming to align with existing coding patterns and propose clear next steps despite missing crate details.
+[2025-10-15T13:02:59] exec bash -lc 'rg -ni "ledger" codex-rs/core' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:02:59] bash -lc 'rg -ni "ledger" codex-rs/core' exited 1 in 16ms:
+ERROR
+[2025-10-15T13:03:02] tokens used: 50,618
+
+[2025-10-15T13:03:05] thinking
+
+**Searching repository for UpsertAccount**
+[2025-10-15T13:03:18] exec bash -lc 'rg -ni "account" codex-rs/app-server/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:03:18] bash -lc 'rg -ni "account" codex-rs/app-server/src' exited 1 in 16ms:
+ERROR
+[2025-10-15T13:03:18] tokens used: 50,929
+
+[2025-10-15T13:03:25] thinking
+
+**Analyzing missing ledger implementation components**
+[2025-10-15T13:03:42] exec bash -lc 'rg -n "to_jsonrpc" codex-rs/app-server/src' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:03:42] bash -lc 'rg -n "to_jsonrpc" codex-rs/app-server/src' exited 1 in 16ms:
+ERROR
+[2025-10-15T13:03:42] tokens used: 51,188
+
+[2025-10-15T13:03:48] thinking
+
+**Searching for error mapping functions**
+[2025-10-15T13:04:03] exec bash -lc 'rg -n "JSONRPCError" codex-rs/app-server/src/codex_message_processor.rs' in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:04:03] bash -lc 'rg -n "JSONRPCError" codex-rs/app-server/src/codex_message_processor.rs' succeeded in 5ms:
+27:use codex_app_server_protocol::JSONRPCErrorError;
+268:                let error = JSONRPCErrorError {
+288:            Error(JSONRPCErrorError),
+365:            Err(err) => LoginChatGptReply::Error(JSONRPCErrorError {
+395:            let error = JSONRPCErrorError {
+414:            let error = JSONRPCErrorError {
+506:                let error = JSONRPCErrorError {
+519:                let error = JSONRPCErrorError {
+573:                let error = JSONRPCErrorError {
+587:            let error = JSONRPCErrorError {
+644:                    let error = JSONRPCErrorError {
+660:                    let error = JSONRPCErrorError {
+686:                let error = JSONRPCErrorError {
+719:                let error = JSONRPCErrorError {
+763:                let error = JSONRPCErrorError {
+822:                let error = JSONRPCErrorError {
+847:            let error = JSONRPCErrorError {
+861:            let error = JSONRPCErrorError {
+877:            let error = JSONRPCErrorError {
+957:                let error = JSONRPCErrorError {
+[2025-10-15T13:04:03] tokens used: 51,416
+
+[2025-10-15T13:04:10] thinking
+
+**Inspecting JSONRPCErrorError usage**
+[2025-10-15T13:04:15] exec bash -lc "sed -n '240,320p' codex-rs/app-server/src/codex_message_processor.rs" in /home/sammu/.code/working/CodexAccountant/branches/code-code-cross-check-ledger-json-rpc/.
+[2025-10-15T13:04:15] bash -lc "sed -n '240,320p' codex-rs/app-server/src/codex_message_processor.rs" succeeded in 4ms:
+                self.exec_one_off_command(request_id, params).await;
+            }
+        }
+    }
+
+    async fn login_api_key(&mut self, request_id: RequestId, params: LoginApiKeyParams) {
+        {
+            let mut guard = self.active_login.lock().await;
+            if let Some(active) = guard.take() {
+                active.drop();
+            }
+        }
+
+        match login_with_api_key(&self.config.codex_home, &params.api_key) {
+            Ok(()) => {
+                self.auth_manager.reload();
+                self.outgoing
+                    .send_response(request_id, LoginApiKeyResponse {})
+                    .await;
+
+[2025-10-15T13:04:15] tokens used: 51,950
+
+[2025-10-15T13:04:53] thinking
+
+**Reviewing ledger integration gaps**
+
+I’m mapping out how ledger errors should convert to JSON-RPC errors via a helper like `ledger_error_to_jsonrpc`. I notice `protocol.rs` lacks ledger request/response types with proper serde and TypeScript annotations, so I’ll propose adding enums and conversion traits reflecting ledger domain concepts. I’ll also suggest wiring these new client requests into the message processor with proper error handling. Since the actual ledger crate isn’t available, I’ll outline general mappings and emphasize the need to confirm specifics once it’s accessible. Finally, I'll summarize file locations for the additions and propose practical next steps like implementing and testing these changes.
+[2025-10-15T13:04:56] codex
+
+**Ledger Review**
+- Verified `codex-rs/app-server-protocol/src/protocol.rs` and `codex-rs/app-server/src/codex_message_processor.rs`; neither currently exposes the ledger JSON-RPC routes (`ledgerUpsertAccount`, `ledgerPostEntry`, `ledgerReverseEntry`, `ledgerLockPeriod`), so no wire structs or handlers exist yet.
+- Workspace lacks any `codex-ledger` dependency; make sure that crate is added to the app-server workspace (and `Cargo.lock`) before wiring these requests.
+
+**Protocol.rs Updates**
+- Extend `client_request_definitions!` with the four ledger methods so the client can invoke them; add `LedgerUpsertAccountParams/Response`, `LedgerPostEntryParams/Response`, `LedgerReverseEntryParams/Response`, and `LedgerLockPeriodParams/Response` near `codex-rs/app-server-protocol/src/protocol.rs:78`.
+- Import ledger model types (`codex_ledger::accounts::{AccountId, AccountType, PostingMode, …}` etc.) and introduce matching wire enums (`WireAccountType`, `WirePostingMode`, `WirePeriodAction`, …). Derive `Serialize`, `Deserialize`, `TS`, and use `#[serde(rename_all = "camelCase")]` so JSON matches the front-end naming convention.
+- Provide `impl From<WireAccountType> for AccountType` / `TryFrom<AccountType> for WireAccountType` pairs (same for posting modes, period actions, any balance-side or entry-status enums) so conversion logic stays centralized and exhaustive; validate every ledger enum has a wire twin to avoid `unreachable!()` fall-throughs.
+- For request/response payloads, flatten nested structs where possible and use `#[serde(skip_serializing_if = "Option::is_none")]` on optional fields (e.g., memo, description, reference numbers) to keep JSON lean. Ensure IDs that map to UUIDs or ledger numeric IDs use the project’s standard serialization (`uuid::serde` or plain strings, whichever ledger expects).
+
+**Codex Message Processor**
+- Add match arms in `process_request` around `codex-rs/app-server/src/codex_message_processor.rs:154` for each new `ClientRequest::Ledger*` variant. Each arm should: parse params into ledger domain structs via the conversion helpers, invoke the relevant ledger service method (e.g., `ledger.upsert_account`, `ledger.post_entry`), await the result, and send either a success response or mapped error.
+- Introduce helper methods like `async fn ledger_upsert_account(&self, request_id, params)` mirroring existing patterns (see `login_api_key`) so logic stays compartmentalized.
+- Import the ledger service/manager at the top of the file and store it on `CodexMessageProcessor` (add a field, constructor parameter, and initialization). Ensure the new field is thread-safe (likely `Arc<LedgerService>`).
+- When sending responses, convert ledger models back to wire structs using the reverse `From` implementations to keep serde and TypeScript definitions in sync.
+
+**Error Mapping**
+- Implement `fn ledger_error_to_jsonrpc(err: LedgerError) -> JSONRPCErrorError` (place near other helpers in `codex_message_processor.rs`). Suggested mapping:
+  - Validation-style errors (`LedgerError::InvalidAccount`, `LedgerError::BalanceMismatch`, `LedgerError::PeriodLocked`, etc.) → `INVALID_REQUEST_ERROR_CODE`.
+  - Missing resources (`LedgerError::AccountNotFound`, `LedgerError::EntryNotFound`) → `INVALID_REQUEST_ERROR_CODE` with a clear message so the client can surface it.
+  - Internal/IO/database issues → `INTERNAL_ERROR_CODE` and include `Some(serde_json::json!({ "kind": ..., "details": ... }))` when safe, otherwise leave `data: None`.
+- Ensure every ledger error variant is covered; add `match` arms rather than `match _` fallbacks to avoid silently swallowing new variants.
+
+**Next Steps**
+1. Add the `codex-ledger` dependency and implement the protocol/handler scaffolding above, then run `just fmt`, `just fix -p codex-app-server`, and targeted ledger tests once available.
+[2025-10-15T13:05:13] tokens used: 55,145
diff --git a/.code/agents/9cc0a0fd-a9fe-4852-b57a-06b48eb8117e/result.txt b/.code/agents/9cc0a0fd-a9fe-4852-b57a-06b48eb8117e/result.txt
new file mode 100644
index 00000000..e73388d7
--- /dev/null
+++ b/.code/agents/9cc0a0fd-a9fe-4852-b57a-06b48eb8117e/result.txt
@@ -0,0 +1,54 @@
+
+Version:          Code 1.105.0 (03c265b1adee71ac88f833e065f7bb956b60550a, 2025-10-08T14:09:35.891Z)
+OS Version:       Windows_NT x64 10.0.26100
+CPUs:             AMD Ryzen 7 9800X3D 8-Core Processor            (16 x 4700)
+Memory (System):  31.16GB (13.29GB free)
+VM:               33%
+Screen Reader:    no
+Process Argv:     --new-window --crash-reporter-id fcce57d1-422a-4fd6-a752-e27888210d7c
+GPU Status:       2d_canvas:                              enabled
+                  direct_rendering_display_compositor:    disabled_off_ok
+                  gpu_compositing:                        enabled
+                  multiple_raster_threads:                enabled_on
+                  opengl:                                 enabled_on
+                  rasterization:                          enabled
+                  raw_draw:                               disabled_off_ok
+                  skia_graphite:                          disabled_off
+                  trees_in_viz:                           disabled_off
+                  video_decode:                           enabled
+                  video_encode:                           enabled
+                  vulkan:                                 disabled_off
+                  webgl:                                  enabled
+                  webgl2:                                 enabled
+                  webgpu:                                 enabled
+                  webnn:                                  disabled_off
+
+CPU %	Mem MB	   PID	Process
+    0	   140	  4128	code
+    0	    29	   276	   crashpad-handler
+    0	   191	 14164	window [1] (Welcome - CodexAccountant - Visual Studio Code)
+    0	    95	 14512	pty-host
+    0	   146	 15300	shared-process
+    0	    48	 21688	   utility-network-service
+    0	   103	 32400	file-watcher [1]
+    0	    85	 32660	   gpu-process
+    0	   579	 33164	extension-host [1]
+    0	    10	  2856	     c:\Users\sammu\.vscode\extensions\openai.chatgpt-0.5.19-win32-x64\bin\windows-x86_64\codex.exe app-server
+    0	     6	  7652	       C:\windows\system32\conhost.exe 0x4
+    0	    79	  6832	     C:\Users\sammu\AppData\Local\cloud-code\cloudcode_cli\cloudcode_cli\62c1f047\cloudcode_cli.exe duet -trace -logtostderr
+    0	     6	 30472	       C:\windows\system32\conhost.exe 0x4
+    0	    90	 14540	     electron-nodejs (eslintServer.js )
+    0	    27	 19252	     c:\Users\sammu\.vscode\extensions\rust-lang.rust-analyzer-0.3.2593-win32-x64\server\rust-analyzer.exe
+    0	     6	 11676	       C:\windows\system32\conhost.exe 0x4
+    0	    90	 31392	     "C:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\Code.exe" "c:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\json-language-features\server\dist\node\jsonServerMain" --node-ipc --clientProcessId=33164
+    0	    90	 32536	     "C:\Users\sammu\AppData\Local\Programs\Microsoft VS Code\Code.exe" c:\Users\sammu\.vscode\extensions\google.geminicodeassist-2.53.0\agent\agent.mjs
+
+Workspace Stats: 
+|  Window (Welcome - CodexAccountant - Visual Studio Code)
+|    Folder (CodexAccountant): 3540 files
+|      File types: rs(462) txt(429) o(311) json(181) timestamp(163) d(142)
+|                  snap(107) rmeta(106) rlib(104) md(58)
+|      Conf files: github-actions(8) package.json(4) dockerfile(2)
+|                  devcontainer.json(1) launch.json(1) settings.json(1)
+|                  agents.md(1) tsconfig.json(1)
+|      Launch Configs: lldb(2)
diff --git a/.code/agents/bdd72b6a-fae6-4b2b-8718-2059344a10b2/error.txt b/.code/agents/bdd72b6a-fae6-4b2b-8718-2059344a10b2/error.txt
new file mode 100644
index 00000000..352ba763
--- /dev/null
+++ b/.code/agents/bdd72b6a-fae6-4b2b-8718-2059344a10b2/error.txt
@@ -0,0 +1 @@
+git apply exited with status exit status: 128 while applying cloud diff
\ No newline at end of file
diff --git a/.code/agents/ca6d5fdd-f5a6-48c4-a272-a7ce8376b2e4/error.txt b/.code/agents/ca6d5fdd-f5a6-48c4-a272-a7ce8376b2e4/error.txt
new file mode 100644
index 00000000..352ba763
--- /dev/null
+++ b/.code/agents/ca6d5fdd-f5a6-48c4-a272-a7ce8376b2e4/error.txt
@@ -0,0 +1 @@
+git apply exited with status exit status: 128 while applying cloud diff
\ No newline at end of file
diff --git a/codex-rs/app-server-protocol/src/protocol.rs b/codex-rs/app-server-protocol/src/protocol.rs
index a80c75c4..9befe971 100644
--- a/codex-rs/app-server-protocol/src/protocol.rs
+++ b/codex-rs/app-server-protocol/src/protocol.rs
@@ -175,6 +175,22 @@ client_request_definitions! {
         params: LedgerCreateCompanyParams,
         response: LedgerCreateCompanyResponse,
     },
+    LedgerUpsertAccount {
+        params: LedgerUpsertAccountParams,
+        response: LedgerUpsertAccountResponse,
+    },
+    LedgerPostEntry {
+        params: LedgerPostEntryParams,
+        response: LedgerPostEntryResponse,
+    },
+    LedgerReverseEntry {
+        params: LedgerReverseEntryParams,
+        response: LedgerReverseEntryResponse,
+    },
+    LedgerLockPeriod {
+        params: LedgerLockPeriodParams,
+        response: LedgerLockPeriodResponse,
+    },
 }
 
 #[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Default, TS)]
@@ -229,8 +245,6 @@ pub struct LedgerCreateCompanyParams {
     pub name: String,
     pub base_currency: LedgerCurrency,
     pub fiscal_calendar: LedgerFiscalCalendar,
-    #[serde(skip_serializing_if = "Option::is_none")]
-    pub metadata: Option<String>,
 }
 
 #[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
@@ -239,6 +253,221 @@ pub struct LedgerCreateCompanyResponse {
     pub company: LedgerCompany,
 }
 
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerAccountType {
+    Asset,
+    Liability,
+    Equity,
+    Revenue,
+    Expense,
+    OffBalance,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerCurrencyMode {
+    FunctionalOnly,
+    Transactional,
+    MultiCurrency,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerTaxCode {
+    pub code: String,
+    pub description: String,
+    pub rate_percent: f32,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerAccount {
+    pub id: String,
+    pub company_id: String,
+    pub code: String,
+    pub name: String,
+    pub account_type: LedgerAccountType,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub parent_account_id: Option<String>,
+    pub currency_mode: LedgerCurrencyMode,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub tax_code: Option<LedgerTaxCode>,
+    pub is_summary: bool,
+    pub is_active: bool,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerUpsertAccountParams {
+    pub account: LedgerAccount,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerUpsertAccountResponse {
+    pub account: LedgerAccount,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerCurrencyRate {
+    pub base: LedgerCurrency,
+    pub quote: LedgerCurrency,
+    pub rate: f64,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub source: Option<String>,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerPostingSide {
+    Debit,
+    Credit,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerJournalLine {
+    pub id: String,
+    pub account_id: String,
+    pub side: LedgerPostingSide,
+    pub amount_minor: i64,
+    pub currency: LedgerCurrency,
+    pub functional_amount_minor: i64,
+    pub functional_currency: LedgerCurrency,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub exchange_rate: Option<LedgerCurrencyRate>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub tax_code: Option<LedgerTaxCode>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub memo: Option<String>,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerEntryStatus {
+    Draft,
+    Proposed,
+    Posted,
+    Reversed,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerEntryOrigin {
+    Manual,
+    Ingestion,
+    AiSuggested,
+    Adjustment,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerJournalEntry {
+    pub id: String,
+    pub journal_id: String,
+    pub status: LedgerEntryStatus,
+    pub lines: Vec<LedgerJournalLine>,
+    pub origin: LedgerEntryOrigin,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub memo: Option<String>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub reverses_entry_id: Option<String>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub reversed_by_entry_id: Option<String>,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerPostingMode {
+    DryRun,
+    Commit,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerPostEntryParams {
+    pub entry: LedgerJournalEntry,
+    pub mode: LedgerPostingMode,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerPostEntryResponse {
+    pub entry: LedgerJournalEntry,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerReverseEntryParams {
+    pub entry_id: String,
+    pub reason: String,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerReverseEntryResponse {
+    pub entry: LedgerJournalEntry,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerPeriodRef {
+    pub fiscal_year: i32,
+    pub period: u8,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerPeriodAction {
+    SoftClose,
+    Close,
+    ReopenSoft,
+    ReopenFull,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerJournalType {
+    General,
+    AccountsPayable,
+    AccountsReceivable,
+    Cash,
+    SubLedger,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq, TS)]
+#[serde(rename_all = "camelCase")]
+pub enum LedgerPeriodState {
+    Open,
+    SoftClosed,
+    Closed,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerJournal {
+    pub id: String,
+    pub company_id: String,
+    pub ledger_type: LedgerJournalType,
+    pub period_state: LedgerPeriodState,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerLockPeriodParams {
+    pub journal_id: String,
+    pub period: LedgerPeriodRef,
+    pub action: LedgerPeriodAction,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, TS)]
+#[serde(rename_all = "camelCase")]
+pub struct LedgerLockPeriodResponse {
+    pub journal: LedgerJournal,
+}
+
 #[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Default, TS)]
 #[serde(rename_all = "camelCase")]
 pub struct NewConversationParams {
diff --git a/codex-rs/app-server/src/codex_message_processor.rs b/codex-rs/app-server/src/codex_message_processor.rs
index 04c307cd..2848bf78 100644
--- a/codex-rs/app-server/src/codex_message_processor.rs
+++ b/codex-rs/app-server/src/codex_message_processor.rs
@@ -26,6 +26,10 @@ use codex_app_server_protocol::InterruptConversationParams;
 use codex_app_server_protocol::InterruptConversationResponse;
 use codex_app_server_protocol::JSONRPCErrorError;
 #[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerAccount;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerAccountType;
+#[cfg(feature = "ledger")]
 use codex_app_server_protocol::LedgerCompany;
 #[cfg(feature = "ledger")]
 use codex_app_server_protocol::LedgerCreateCompanyParams;
@@ -34,7 +38,51 @@ use codex_app_server_protocol::LedgerCreateCompanyResponse;
 #[cfg(feature = "ledger")]
 use codex_app_server_protocol::LedgerCurrency;
 #[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerCurrencyMode;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerCurrencyRate;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerEntryOrigin;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerEntryStatus;
+#[cfg(feature = "ledger")]
 use codex_app_server_protocol::LedgerFiscalCalendar;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerJournal;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerJournalEntry;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerJournalLine;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerJournalType;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerLockPeriodParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerLockPeriodResponse;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPeriodAction;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPeriodRef;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPeriodState;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPostEntryParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPostEntryResponse;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPostingMode;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPostingSide;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerReverseEntryParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerReverseEntryResponse;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerTaxCode;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerUpsertAccountParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerUpsertAccountResponse;
 use codex_app_server_protocol::ListConversationsParams;
 use codex_app_server_protocol::ListConversationsResponse;
 use codex_app_server_protocol::LoginApiKeyParams;
@@ -91,19 +139,59 @@ use codex_core::protocol::InputItem as CoreInputItem;
 use codex_core::protocol::Op;
 use codex_core::protocol::ReviewDecision;
 #[cfg(feature = "ledger")]
+use codex_ledger::Account as LedgerAccountModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::AccountType as LedgerAccountTypeModel;
+#[cfg(feature = "ledger")]
 use codex_ledger::CreateCompanyRequest as LedgerCreateCompanyRequest;
 #[cfg(feature = "ledger")]
 use codex_ledger::Currency as LedgerCurrencyModel;
 #[cfg(feature = "ledger")]
+use codex_ledger::CurrencyMode as LedgerCurrencyModeModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::CurrencyRate as LedgerCurrencyRateModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::EntryOrigin as LedgerEntryOriginModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::EntryStatus as LedgerEntryStatusModel;
+#[cfg(feature = "ledger")]
 use codex_ledger::FiscalCalendar as LedgerFiscalCalendarModel;
 #[cfg(feature = "ledger")]
 use codex_ledger::InMemoryLedgerService;
 #[cfg(feature = "ledger")]
+use codex_ledger::Journal as LedgerJournalModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::JournalEntry as LedgerJournalEntryModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::JournalLine as LedgerJournalLineModel;
+#[cfg(feature = "ledger")]
 use codex_ledger::LedgerError;
 #[cfg(feature = "ledger")]
+use codex_ledger::LedgerType as LedgerJournalTypeModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::LockPeriodRequest as LedgerLockPeriodRequest;
+#[cfg(feature = "ledger")]
+use codex_ledger::PeriodAction as LedgerPeriodActionModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::PeriodRef as LedgerPeriodRefModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::PeriodState as LedgerPeriodStateModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::PostEntryRequest as LedgerPostEntryRequest;
+#[cfg(feature = "ledger")]
+use codex_ledger::PostingMode as LedgerPostingModeModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::PostingSide as LedgerPostingSideModel;
+#[cfg(feature = "ledger")]
+use codex_ledger::ReverseEntryRequest as LedgerReverseEntryRequest;
+#[cfg(feature = "ledger")]
 use codex_ledger::Role as LedgerRole;
 #[cfg(feature = "ledger")]
+use codex_ledger::TaxCode as LedgerTaxCodeModel;
+#[cfg(feature = "ledger")]
 use codex_ledger::TenantContext as LedgerTenantContext;
+#[cfg(feature = "ledger")]
+use codex_ledger::UpsertAccountRequest as LedgerUpsertAccountRequest;
 use codex_login::ServerOptions as LoginServerOptions;
 use codex_login::ShutdownHandle;
 use codex_login::run_login_server;
@@ -120,6 +208,8 @@ use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering;
 use std::time::Duration;
+#[cfg(feature = "ledger")]
+use std::time::SystemTime;
 use tokio::select;
 use tokio::sync::Mutex;
 use tokio::sync::oneshot;
@@ -272,6 +362,70 @@ impl CodexMessageProcessor {
                     self.outgoing.send_error(request_id, error).await;
                 }
             }
+            ClientRequest::LedgerUpsertAccount { request_id, params } => {
+                #[cfg(feature = "ledger")]
+                {
+                    self.handle_ledger_upsert_account(request_id, params).await;
+                }
+                #[cfg(not(feature = "ledger"))]
+                {
+                    let _ = params;
+                    let error = JSONRPCErrorError {
+                        code: INVALID_REQUEST_ERROR_CODE,
+                        message: "ledger feature not enabled".to_string(),
+                        data: None,
+                    };
+                    self.outgoing.send_error(request_id, error).await;
+                }
+            }
+            ClientRequest::LedgerPostEntry { request_id, params } => {
+                #[cfg(feature = "ledger")]
+                {
+                    self.handle_ledger_post_entry(request_id, params).await;
+                }
+                #[cfg(not(feature = "ledger"))]
+                {
+                    let _ = params;
+                    let error = JSONRPCErrorError {
+                        code: INVALID_REQUEST_ERROR_CODE,
+                        message: "ledger feature not enabled".to_string(),
+                        data: None,
+                    };
+                    self.outgoing.send_error(request_id, error).await;
+                }
+            }
+            ClientRequest::LedgerReverseEntry { request_id, params } => {
+                #[cfg(feature = "ledger")]
+                {
+                    self.handle_ledger_reverse_entry(request_id, params).await;
+                }
+                #[cfg(not(feature = "ledger"))]
+                {
+                    let _ = params;
+                    let error = JSONRPCErrorError {
+                        code: INVALID_REQUEST_ERROR_CODE,
+                        message: "ledger feature not enabled".to_string(),
+                        data: None,
+                    };
+                    self.outgoing.send_error(request_id, error).await;
+                }
+            }
+            ClientRequest::LedgerLockPeriod { request_id, params } => {
+                #[cfg(feature = "ledger")]
+                {
+                    self.handle_ledger_lock_period(request_id, params).await;
+                }
+                #[cfg(not(feature = "ledger"))]
+                {
+                    let _ = params;
+                    let error = JSONRPCErrorError {
+                        code: INVALID_REQUEST_ERROR_CODE,
+                        message: "ledger feature not enabled".to_string(),
+                        data: None,
+                    };
+                    self.outgoing.send_error(request_id, error).await;
+                }
+            }
             ClientRequest::UserInfo {
                 request_id,
                 params: _,
@@ -1552,7 +1706,6 @@ impl CodexMessageProcessor {
             name: params.name,
             base_currency: to_ledger_currency(params.base_currency),
             fiscal_calendar: to_ledger_fiscal_calendar(params.fiscal_calendar),
-            metadata: params.metadata,
             tenant: default_ledger_tenant_context(),
         };
 
@@ -1569,6 +1722,143 @@ impl CodexMessageProcessor {
             }
         }
     }
+
+    async fn handle_ledger_upsert_account(
+        &self,
+        request_id: RequestId,
+        params: LedgerUpsertAccountParams,
+    ) {
+        let Some(service) = self.ledger_service.as_ref() else {
+            let error = JSONRPCErrorError {
+                code: INVALID_REQUEST_ERROR_CODE,
+                message: "ledger service not configured".to_string(),
+                data: None,
+            };
+            self.outgoing.send_error(request_id, error).await;
+            return;
+        };
+
+        let request = LedgerUpsertAccountRequest {
+            account: to_ledger_account(params.account),
+            tenant: default_ledger_tenant_context(),
+        };
+
+        match service.upsert_account(request).await {
+            Ok(account) => {
+                let response = LedgerUpsertAccountResponse {
+                    account: from_ledger_account(account),
+                };
+                self.outgoing.send_response(request_id, response).await;
+            }
+            Err(err) => {
+                let error = ledger_error_to_jsonrpc(err);
+                self.outgoing.send_error(request_id, error).await;
+            }
+        }
+    }
+
+    async fn handle_ledger_post_entry(&self, request_id: RequestId, params: LedgerPostEntryParams) {
+        let Some(service) = self.ledger_service.as_ref() else {
+            let error = JSONRPCErrorError {
+                code: INVALID_REQUEST_ERROR_CODE,
+                message: "ledger service not configured".to_string(),
+                data: None,
+            };
+            self.outgoing.send_error(request_id, error).await;
+            return;
+        };
+
+        let LedgerPostEntryParams { entry, mode } = params;
+        let request = LedgerPostEntryRequest {
+            entry: to_ledger_journal_entry(entry),
+            tenant: default_ledger_tenant_context(),
+            mode: to_ledger_posting_mode(mode),
+        };
+
+        match service.post_entry(request).await {
+            Ok(entry) => {
+                let response = LedgerPostEntryResponse {
+                    entry: from_ledger_journal_entry(entry),
+                };
+                self.outgoing.send_response(request_id, response).await;
+            }
+            Err(err) => {
+                let error = ledger_error_to_jsonrpc(err);
+                self.outgoing.send_error(request_id, error).await;
+            }
+        }
+    }
+
+    async fn handle_ledger_reverse_entry(
+        &self,
+        request_id: RequestId,
+        params: LedgerReverseEntryParams,
+    ) {
+        let Some(service) = self.ledger_service.as_ref() else {
+            let error = JSONRPCErrorError {
+                code: INVALID_REQUEST_ERROR_CODE,
+                message: "ledger service not configured".to_string(),
+                data: None,
+            };
+            self.outgoing.send_error(request_id, error).await;
+            return;
+        };
+
+        let request = LedgerReverseEntryRequest {
+            entry_id: params.entry_id,
+            reason: params.reason,
+            tenant: default_ledger_tenant_context(),
+        };
+
+        match service.reverse_entry(request).await {
+            Ok(entry) => {
+                let response = LedgerReverseEntryResponse {
+                    entry: from_ledger_journal_entry(entry),
+                };
+                self.outgoing.send_response(request_id, response).await;
+            }
+            Err(err) => {
+                let error = ledger_error_to_jsonrpc(err);
+                self.outgoing.send_error(request_id, error).await;
+            }
+        }
+    }
+
+    async fn handle_ledger_lock_period(
+        &self,
+        request_id: RequestId,
+        params: LedgerLockPeriodParams,
+    ) {
+        let Some(service) = self.ledger_service.as_ref() else {
+            let error = JSONRPCErrorError {
+                code: INVALID_REQUEST_ERROR_CODE,
+                message: "ledger service not configured".to_string(),
+                data: None,
+            };
+            self.outgoing.send_error(request_id, error).await;
+            return;
+        };
+
+        let request = LedgerLockPeriodRequest {
+            journal_id: params.journal_id,
+            period: to_ledger_period_ref(params.period),
+            action: to_ledger_period_action(params.action),
+            tenant: default_ledger_tenant_context(),
+        };
+
+        match service.lock_period(request).await {
+            Ok(journal) => {
+                let response = LedgerLockPeriodResponse {
+                    journal: from_ledger_journal(journal),
+                };
+                self.outgoing.send_response(request_id, response).await;
+            }
+            Err(err) => {
+                let error = ledger_error_to_jsonrpc(err);
+                self.outgoing.send_error(request_id, error).await;
+            }
+        }
+    }
 }
 
 #[cfg(feature = "ledger")]
@@ -1614,6 +1904,311 @@ fn from_ledger_company(company: codex_ledger::Company) -> LedgerCompany {
     }
 }
 
+#[cfg(feature = "ledger")]
+fn to_ledger_account_type(account_type: LedgerAccountType) -> LedgerAccountTypeModel {
+    match account_type {
+        LedgerAccountType::Asset => LedgerAccountTypeModel::Asset,
+        LedgerAccountType::Liability => LedgerAccountTypeModel::Liability,
+        LedgerAccountType::Equity => LedgerAccountTypeModel::Equity,
+        LedgerAccountType::Revenue => LedgerAccountTypeModel::Revenue,
+        LedgerAccountType::Expense => LedgerAccountTypeModel::Expense,
+        LedgerAccountType::OffBalance => LedgerAccountTypeModel::OffBalance,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_account_type(account_type: LedgerAccountTypeModel) -> LedgerAccountType {
+    match account_type {
+        LedgerAccountTypeModel::Asset => LedgerAccountType::Asset,
+        LedgerAccountTypeModel::Liability => LedgerAccountType::Liability,
+        LedgerAccountTypeModel::Equity => LedgerAccountType::Equity,
+        LedgerAccountTypeModel::Revenue => LedgerAccountType::Revenue,
+        LedgerAccountTypeModel::Expense => LedgerAccountType::Expense,
+        LedgerAccountTypeModel::OffBalance => LedgerAccountType::OffBalance,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_currency_mode(mode: LedgerCurrencyMode) -> LedgerCurrencyModeModel {
+    match mode {
+        LedgerCurrencyMode::FunctionalOnly => LedgerCurrencyModeModel::FunctionalOnly,
+        LedgerCurrencyMode::Transactional => LedgerCurrencyModeModel::Transactional,
+        LedgerCurrencyMode::MultiCurrency => LedgerCurrencyModeModel::MultiCurrency,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_currency_mode(mode: LedgerCurrencyModeModel) -> LedgerCurrencyMode {
+    match mode {
+        LedgerCurrencyModeModel::FunctionalOnly => LedgerCurrencyMode::FunctionalOnly,
+        LedgerCurrencyModeModel::Transactional => LedgerCurrencyMode::Transactional,
+        LedgerCurrencyModeModel::MultiCurrency => LedgerCurrencyMode::MultiCurrency,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_tax_code(tax: LedgerTaxCode) -> LedgerTaxCodeModel {
+    LedgerTaxCodeModel {
+        code: tax.code,
+        description: tax.description,
+        rate_percent: tax.rate_percent,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_tax_code(tax: LedgerTaxCodeModel) -> LedgerTaxCode {
+    LedgerTaxCode {
+        code: tax.code,
+        description: tax.description,
+        rate_percent: tax.rate_percent,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_account(account: LedgerAccount) -> LedgerAccountModel {
+    LedgerAccountModel {
+        id: account.id,
+        company_id: account.company_id,
+        code: account.code,
+        name: account.name,
+        account_type: to_ledger_account_type(account.account_type),
+        parent_account_id: account.parent_account_id,
+        currency_mode: to_ledger_currency_mode(account.currency_mode),
+        tax_code: account.tax_code.map(to_ledger_tax_code),
+        is_summary: account.is_summary,
+        is_active: account.is_active,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_account(account: LedgerAccountModel) -> LedgerAccount {
+    LedgerAccount {
+        id: account.id,
+        company_id: account.company_id,
+        code: account.code,
+        name: account.name,
+        account_type: from_ledger_account_type(account.account_type),
+        parent_account_id: account.parent_account_id,
+        currency_mode: from_ledger_currency_mode(account.currency_mode),
+        tax_code: account.tax_code.map(from_ledger_tax_code),
+        is_summary: account.is_summary,
+        is_active: account.is_active,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_posting_side(side: LedgerPostingSide) -> LedgerPostingSideModel {
+    match side {
+        LedgerPostingSide::Debit => LedgerPostingSideModel::Debit,
+        LedgerPostingSide::Credit => LedgerPostingSideModel::Credit,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_posting_side(side: LedgerPostingSideModel) -> LedgerPostingSide {
+    match side {
+        LedgerPostingSideModel::Debit => LedgerPostingSide::Debit,
+        LedgerPostingSideModel::Credit => LedgerPostingSide::Credit,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_currency_rate(rate: LedgerCurrencyRate) -> LedgerCurrencyRateModel {
+    LedgerCurrencyRateModel {
+        base: to_ledger_currency(rate.base),
+        quote: to_ledger_currency(rate.quote),
+        rate: rate.rate,
+        source: rate.source,
+        observed_at: SystemTime::now(),
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_currency_rate(rate: LedgerCurrencyRateModel) -> LedgerCurrencyRate {
+    LedgerCurrencyRate {
+        base: LedgerCurrency {
+            code: rate.base.code,
+            precision: rate.base.precision,
+        },
+        quote: LedgerCurrency {
+            code: rate.quote.code,
+            precision: rate.quote.precision,
+        },
+        rate: rate.rate,
+        source: rate.source,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_journal_line(line: LedgerJournalLine) -> LedgerJournalLineModel {
+    LedgerJournalLineModel {
+        id: line.id,
+        account_id: line.account_id,
+        side: to_ledger_posting_side(line.side),
+        amount_minor: line.amount_minor,
+        currency: to_ledger_currency(line.currency),
+        functional_amount_minor: line.functional_amount_minor,
+        functional_currency: to_ledger_currency(line.functional_currency),
+        exchange_rate: line.exchange_rate.map(to_ledger_currency_rate),
+        tax_code: line.tax_code.map(to_ledger_tax_code),
+        memo: line.memo,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_journal_line(line: LedgerJournalLineModel) -> LedgerJournalLine {
+    LedgerJournalLine {
+        id: line.id,
+        account_id: line.account_id,
+        side: from_ledger_posting_side(line.side),
+        amount_minor: line.amount_minor,
+        currency: LedgerCurrency {
+            code: line.currency.code,
+            precision: line.currency.precision,
+        },
+        functional_amount_minor: line.functional_amount_minor,
+        functional_currency: LedgerCurrency {
+            code: line.functional_currency.code,
+            precision: line.functional_currency.precision,
+        },
+        exchange_rate: line.exchange_rate.map(from_ledger_currency_rate),
+        tax_code: line.tax_code.map(from_ledger_tax_code),
+        memo: line.memo,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_entry_status(status: LedgerEntryStatus) -> LedgerEntryStatusModel {
+    match status {
+        LedgerEntryStatus::Draft => LedgerEntryStatusModel::Draft,
+        LedgerEntryStatus::Proposed => LedgerEntryStatusModel::Proposed,
+        LedgerEntryStatus::Posted => LedgerEntryStatusModel::Posted,
+        LedgerEntryStatus::Reversed => LedgerEntryStatusModel::Reversed,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_entry_status(status: LedgerEntryStatusModel) -> LedgerEntryStatus {
+    match status {
+        LedgerEntryStatusModel::Draft => LedgerEntryStatus::Draft,
+        LedgerEntryStatusModel::Proposed => LedgerEntryStatus::Proposed,
+        LedgerEntryStatusModel::Posted => LedgerEntryStatus::Posted,
+        LedgerEntryStatusModel::Reversed => LedgerEntryStatus::Reversed,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_entry_origin(origin: LedgerEntryOrigin) -> LedgerEntryOriginModel {
+    match origin {
+        LedgerEntryOrigin::Manual => LedgerEntryOriginModel::Manual,
+        LedgerEntryOrigin::Ingestion => LedgerEntryOriginModel::Ingestion,
+        LedgerEntryOrigin::AiSuggested => LedgerEntryOriginModel::AiSuggested,
+        LedgerEntryOrigin::Adjustment => LedgerEntryOriginModel::Adjustment,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_entry_origin(origin: LedgerEntryOriginModel) -> LedgerEntryOrigin {
+    match origin {
+        LedgerEntryOriginModel::Manual => LedgerEntryOrigin::Manual,
+        LedgerEntryOriginModel::Ingestion => LedgerEntryOrigin::Ingestion,
+        LedgerEntryOriginModel::AiSuggested => LedgerEntryOrigin::AiSuggested,
+        LedgerEntryOriginModel::Adjustment => LedgerEntryOrigin::Adjustment,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_journal_entry(entry: LedgerJournalEntry) -> LedgerJournalEntryModel {
+    LedgerJournalEntryModel {
+        id: entry.id,
+        journal_id: entry.journal_id,
+        status: to_ledger_entry_status(entry.status),
+        lines: entry
+            .lines
+            .into_iter()
+            .map(to_ledger_journal_line)
+            .collect(),
+        origin: to_ledger_entry_origin(entry.origin),
+        memo: entry.memo,
+        reverses_entry_id: entry.reverses_entry_id,
+        reversed_by_entry_id: entry.reversed_by_entry_id,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_journal_entry(entry: LedgerJournalEntryModel) -> LedgerJournalEntry {
+    LedgerJournalEntry {
+        id: entry.id,
+        journal_id: entry.journal_id,
+        status: from_ledger_entry_status(entry.status),
+        lines: entry
+            .lines
+            .into_iter()
+            .map(from_ledger_journal_line)
+            .collect(),
+        origin: from_ledger_entry_origin(entry.origin),
+        memo: entry.memo,
+        reverses_entry_id: entry.reverses_entry_id,
+        reversed_by_entry_id: entry.reversed_by_entry_id,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_posting_mode(mode: LedgerPostingMode) -> LedgerPostingModeModel {
+    match mode {
+        LedgerPostingMode::DryRun => LedgerPostingModeModel::DryRun,
+        LedgerPostingMode::Commit => LedgerPostingModeModel::Commit,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_period_action(action: LedgerPeriodAction) -> LedgerPeriodActionModel {
+    match action {
+        LedgerPeriodAction::SoftClose => LedgerPeriodActionModel::SoftClose,
+        LedgerPeriodAction::Close => LedgerPeriodActionModel::Close,
+        LedgerPeriodAction::ReopenSoft => LedgerPeriodActionModel::ReopenSoft,
+        LedgerPeriodAction::ReopenFull => LedgerPeriodActionModel::ReopenFull,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn to_ledger_period_ref(period: LedgerPeriodRef) -> LedgerPeriodRefModel {
+    LedgerPeriodRefModel {
+        fiscal_year: period.fiscal_year,
+        period: period.period,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_journal_type(journal_type: LedgerJournalTypeModel) -> LedgerJournalType {
+    match journal_type {
+        LedgerJournalTypeModel::General => LedgerJournalType::General,
+        LedgerJournalTypeModel::AccountsPayable => LedgerJournalType::AccountsPayable,
+        LedgerJournalTypeModel::AccountsReceivable => LedgerJournalType::AccountsReceivable,
+        LedgerJournalTypeModel::Cash => LedgerJournalType::Cash,
+        LedgerJournalTypeModel::SubLedger => LedgerJournalType::SubLedger,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_period_state(state: LedgerPeriodStateModel) -> LedgerPeriodState {
+    match state {
+        LedgerPeriodStateModel::Open => LedgerPeriodState::Open,
+        LedgerPeriodStateModel::SoftClosed => LedgerPeriodState::SoftClosed,
+        LedgerPeriodStateModel::Closed => LedgerPeriodState::Closed,
+    }
+}
+
+#[cfg(feature = "ledger")]
+fn from_ledger_journal(journal: LedgerJournalModel) -> LedgerJournal {
+    LedgerJournal {
+        id: journal.id,
+        company_id: journal.company_id,
+        ledger_type: from_ledger_journal_type(journal.ledger_type),
+        period_state: from_ledger_period_state(journal.period_state),
+    }
+}
+
 #[cfg(feature = "ledger")]
 fn ledger_error_to_jsonrpc(error: LedgerError) -> JSONRPCErrorError {
     match error {
diff --git a/codex-rs/app-server/tests/common/mcp_process.rs b/codex-rs/app-server/tests/common/mcp_process.rs
index db1c016a..8eb99546 100644
--- a/codex-rs/app-server/tests/common/mcp_process.rs
+++ b/codex-rs/app-server/tests/common/mcp_process.rs
@@ -22,6 +22,14 @@ use codex_app_server_protocol::InitializeParams;
 use codex_app_server_protocol::InterruptConversationParams;
 #[cfg(feature = "ledger")]
 use codex_app_server_protocol::LedgerCreateCompanyParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerLockPeriodParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerPostEntryParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerReverseEntryParams;
+#[cfg(feature = "ledger")]
+use codex_app_server_protocol::LedgerUpsertAccountParams;
 use codex_app_server_protocol::ListConversationsParams;
 use codex_app_server_protocol::LoginApiKeyParams;
 use codex_app_server_protocol::NewConversationParams;
@@ -324,6 +332,42 @@ impl McpProcess {
         self.send_request("ledgerCreateCompany", params).await
     }
 
+    #[cfg(feature = "ledger")]
+    pub async fn send_ledger_upsert_account_request(
+        &mut self,
+        params: LedgerUpsertAccountParams,
+    ) -> anyhow::Result<i64> {
+        let params = Some(serde_json::to_value(params)?);
+        self.send_request("ledgerUpsertAccount", params).await
+    }
+
+    #[cfg(feature = "ledger")]
+    pub async fn send_ledger_post_entry_request(
+        &mut self,
+        params: LedgerPostEntryParams,
+    ) -> anyhow::Result<i64> {
+        let params = Some(serde_json::to_value(params)?);
+        self.send_request("ledgerPostEntry", params).await
+    }
+
+    #[cfg(feature = "ledger")]
+    pub async fn send_ledger_reverse_entry_request(
+        &mut self,
+        params: LedgerReverseEntryParams,
+    ) -> anyhow::Result<i64> {
+        let params = Some(serde_json::to_value(params)?);
+        self.send_request("ledgerReverseEntry", params).await
+    }
+
+    #[cfg(feature = "ledger")]
+    pub async fn send_ledger_lock_period_request(
+        &mut self,
+        params: LedgerLockPeriodParams,
+    ) -> anyhow::Result<i64> {
+        let params = Some(serde_json::to_value(params)?);
+        self.send_request("ledgerLockPeriod", params).await
+    }
+
     async fn send_request(
         &mut self,
         method: &str,
